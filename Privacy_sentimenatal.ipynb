{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9a77a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upgrading pip...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install --upgrade pip --quiet --no-cache-dir\n",
      "Installing core packages...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install numpy pandas scikit-learn matplotlib seaborn tqdm --quiet --no-cache-dir\n",
      "Installing PyTorch with CUDA...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio --quiet --no-cache-dir\n",
      "Installing HuggingFace...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install transformers datasets accelerate --quiet --no-cache-dir\n",
      "Installing privacy & text...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install opacus nltk --quiet --no-cache-dir\n",
      "Installing XAI...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install captum lime shap --quiet --no-cache-dir\n",
      "Installing encryption & PDF...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install pycryptodome reportlab --quiet --no-cache-dir\n",
      "\n",
      "ALL DONE! NOW:\n",
      "1. RESTART KERNEL\n",
      "2. Run Cell 2+\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 1 – Install ALL dependencies (SPACE-SAFE + RESTART)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import shlex\n",
    "\n",
    "def pip_install(package_cmd):\n",
    "    full_cmd = f'\"{sys.executable}\" -m pip install {package_cmd} --quiet --no-cache-dir'\n",
    "    print(f\"> {full_cmd}\")\n",
    "    get_ipython().system(full_cmd)\n",
    "\n",
    "print(\"Upgrading pip...\")\n",
    "pip_install(\"--upgrade pip\")\n",
    "\n",
    "print(\"Installing core packages...\")\n",
    "pip_install(\"numpy pandas scikit-learn matplotlib seaborn tqdm\")\n",
    "\n",
    "print(\"Installing PyTorch with CUDA...\")\n",
    "pip_install(\"--index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio\")\n",
    "\n",
    "print(\"Installing HuggingFace...\")\n",
    "pip_install(\"transformers datasets accelerate\")\n",
    "\n",
    "print(\"Installing privacy & text...\")\n",
    "pip_install(\"opacus nltk\")\n",
    "\n",
    "print(\"Installing XAI...\")\n",
    "pip_install(\"captum lime shap\")\n",
    "\n",
    "print(\"Installing encryption & PDF...\")\n",
    "pip_install(\"pycryptodome reportlab\")\n",
    "\n",
    "print(\"\\nALL DONE! NOW:\")\n",
    "print(\"1. RESTART KERNEL\")\n",
    "print(\"2. Run Cell 2+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f8acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: tqdm in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pycryptodome in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (3.23.0)\n",
      "Requirement already satisfied: matplotlib in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: filelock in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: colorama in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from requests->transformers) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "# CELL 1 – INSTALL (run & restart kernel)\n",
    "!pip install torch transformers tqdm scikit-learn pycryptodome matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba62a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Bubt task\\Ml-Project(new)\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f677cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "GPU name: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 1 – Imports & GPU check\n",
    "# --------------------------------------------------------------\n",
    "import os, json, random, time, warnings, string, re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, f1_score,\n",
    "                             confusion_matrix, classification_report,\n",
    "                             roc_auc_score, roc_curve, auc,\n",
    "                             precision_recall_curve)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import (BertTokenizer, BertForSequenceClassification,\n",
    "                          get_linear_schedule_with_warmup)\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# XAI\n",
    "from captum.attr import IntegratedGradients\n",
    "import lime.lime_text\n",
    "import shap\n",
    "\n",
    "# Encryption\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def seed_all(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "seed_all()\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {DEVICE}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d144d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# Cell 2.0 – Imports & GPU Check\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e57aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 2 – Text cleaning\n",
    "# --------------------------------------------------------------\n",
    "def clean_text(t):\n",
    "    if pd.isna(t): return \"\"\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r'http\\S+|www\\S+|https\\S+', '', t, flags=re.MULTILINE)\n",
    "    t = re.sub(r'<.*?>', '', t)\n",
    "    t = re.sub(r'[^a-zA-Z\\s]', '', t)\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e9682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder: data\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell: Create 'data' folder\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "print(\"Created folder: data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1c0a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data/my_reviews.csv with 500 rows\n",
      "First 5 rows:\n",
      "              review  sentiment\n",
      "0    Waste of money!          0\n",
      "1  Highly recommend!          1\n",
      "2       Never again!          0\n",
      "3         Excellent!          1\n",
      "4           Perfect!          1\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell: Create my_reviews.csv with 500 rows\n",
    "# --------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 250 positive + 250 negative = 500 rows\n",
    "pos_phrases = [\n",
    "    \"I love this!\", \"Amazing!\", \"Best ever!\", \"Highly recommend!\", \"Perfect!\",\n",
    "    \"Excellent!\", \"So happy!\", \"Great!\", \"Fantastic!\", \"Worth it!\"\n",
    "]\n",
    "neg_phrases = [\n",
    "    \"Terrible!\", \"Waste of money!\", \"Disappointing!\", \"Poor quality!\", \"Never again!\",\n",
    "    \"Bad service!\", \"Hated it!\", \"Not worth it!\", \"Broken!\", \"Misleading!\"\n",
    "]\n",
    "\n",
    "# Repeat to reach 250 each\n",
    "texts = (pos_phrases * 25) + (neg_phrases * 25)\n",
    "labels = [1] * 250 + [0] * 250\n",
    "\n",
    "# Shuffle\n",
    "combined = list(zip(texts, labels))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(combined)\n",
    "texts, labels = zip(*combined)\n",
    "\n",
    "# Save\n",
    "df = pd.DataFrame({'review': texts, 'sentiment': labels})\n",
    "df.to_csv('data/my_reviews.csv', index=False)\n",
    "print(f\"Created data/my_reviews.csv with {len(df)} rows\")\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb8b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading IMDB...\n",
      "Downloading Yelp...\n",
      "Downloading Twitter...\n",
      "Twitter: 7093 Neg, 17849 Pos available\n",
      "Added 500 custom rows (250+250)\n",
      "Raw merged: 55593 rows\n",
      "After cleaning: 55593 rows\n",
      "Before final: Neg=27343, Pos=28250\n",
      "\n",
      "BALANCED DATASET SAVED: data/merged_dataset_balanced.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL: 50000 rows → 25,000 Negative + 25,000 Positive\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user oh let me know if you hear about whats on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after receiving a ridiculously rude private me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>getting lost in space frozen for years thats u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this was shown as part of the th edinburgh int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one of my collegue have been raving about oreg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>theo robertson has commented that waw didnt ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i saw this in a sneak two days before the offi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this is a place for really good middle eastern...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>birkenstocks with socks straw hats cargo short...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>just realized i hadnt written a review about t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  user oh let me know if you hear about whats on...          1\n",
       "1  after receiving a ridiculously rude private me...          0\n",
       "2  getting lost in space frozen for years thats u...          0\n",
       "3  this was shown as part of the th edinburgh int...          0\n",
       "4  one of my collegue have been raving about oreg...          1\n",
       "5  theo robertson has commented that waw didnt ad...          1\n",
       "6  i saw this in a sneak two days before the offi...          0\n",
       "7  this is a place for really good middle eastern...          1\n",
       "8  birkenstocks with socks straw hats cargo short...          0\n",
       "9  just realized i hadnt written a review about t...          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 3 – ROBUST 50/50 BALANCED DATASET (25k + 25k = 50k)\n",
    "# --------------------------------------------------------------\n",
    "def load_and_merge_datasets(my_csv_path='data/my_reviews.csv',\n",
    "                            target_total=50_000,\n",
    "                            custom_ratio=0.01):  # 500 rows\n",
    "    dfs = []\n",
    "\n",
    "    # ---- 1. Load public datasets ----\n",
    "    print(\"Downloading IMDB...\")\n",
    "    imdb = load_dataset('imdb', split='train')\n",
    "\n",
    "    print(\"Downloading Yelp...\")\n",
    "    yelp = load_dataset('yelp_review_full', split='train')\n",
    "\n",
    "    print(\"Downloading Twitter...\")\n",
    "    twitter_raw = load_dataset(\"cardiffnlp/tweet_eval\", name=\"sentiment\", split=\"train\")\n",
    "    twitter = twitter_raw.filter(lambda x: x['label'] != 1)\n",
    "    twitter = twitter.map(lambda x: {'text': x['text'], 'label': 0 if x['label'] == 0 else 1})\n",
    "\n",
    "    # ---- 2. Final target per class ----\n",
    "    final_per_class = target_total // 2  # 25,000\n",
    "    custom_per_class = 250  # 250 neg + 250 pos = 500\n",
    "\n",
    "    # ---- 3. IMDB: 50/50 (large enough) ----\n",
    "    df_imdb = pd.DataFrame({'review': imdb['text'], 'sentiment': imdb['label']})\n",
    "    imdb_neg = df_imdb[df_imdb['sentiment'] == 0].sample(min(10000, len(df_imdb[df_imdb['sentiment'] == 0])), random_state=42)\n",
    "    imdb_pos = df_imdb[df_imdb['sentiment'] == 1].sample(min(10000, len(df_imdb[df_imdb['sentiment'] == 1])), random_state=42)\n",
    "    dfs.append(pd.concat([imdb_neg, imdb_pos]))\n",
    "\n",
    "    # ---- 4. Yelp: 50/50 (map 0,1→0; 2,3,4→1) ----\n",
    "    df_yelp = pd.DataFrame({'review': yelp['text'], 'sentiment': yelp['label']})\n",
    "    df_yelp['sentiment'] = df_yelp['sentiment'].map(lambda x: 0 if x in [0,1] else 1)\n",
    "    yelp_neg = df_yelp[df_yelp['sentiment'] == 0].sample(min(10000, len(df_yelp[df_yelp['sentiment'] == 0])), random_state=42)\n",
    "    yelp_pos = df_yelp[df_yelp['sentiment'] == 1].sample(min(10000, len(df_yelp[df_yelp['sentiment'] == 1])), random_state=42)\n",
    "    dfs.append(pd.concat([yelp_neg, yelp_pos]))\n",
    "\n",
    "    # ---- 5. Twitter: Take ALL available (safe) ----\n",
    "    df_tw = pd.DataFrame({'review': twitter['text'], 'sentiment': twitter['label']})\n",
    "    tw_neg_count = len(df_tw[df_tw['sentiment'] == 0])\n",
    "    tw_pos_count = len(df_tw[df_tw['sentiment'] == 1])\n",
    "    print(f\"Twitter: {tw_neg_count} Neg, {tw_pos_count} Pos available\")\n",
    "    tw_neg = df_tw[df_tw['sentiment'] == 0].sample(min(tw_neg_count, 8000), random_state=42)\n",
    "    tw_pos = df_tw[df_tw['sentiment'] == 1].sample(min(tw_pos_count, 8000), random_state=42)\n",
    "    dfs.append(pd.concat([tw_neg, tw_pos]))\n",
    "\n",
    "    # ---- 6. Custom: 250 + 250 ----\n",
    "    if not os.path.exists(my_csv_path):\n",
    "        raise FileNotFoundError(f\"{my_csv_path} not found!\")\n",
    "    my = pd.read_csv(my_csv_path, usecols=['review','sentiment'])\n",
    "    my_neg = my[my['sentiment'] == 0].sample(250, random_state=42)\n",
    "    my_pos = my[my['sentiment'] == 1].sample(250, random_state=42)\n",
    "    dfs.append(pd.concat([my_neg, my_pos]))\n",
    "    print(f\"Added 500 custom rows (250+250)\")\n",
    "\n",
    "    # ---- 7. Merge & clean ----\n",
    "    full = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Raw merged: {len(full)} rows\")\n",
    "\n",
    "    full['review'] = full['review'].apply(clean_text)\n",
    "    full = full[full['review'].str.len() > 0].reset_index(drop=True)\n",
    "    print(f\"After cleaning: {len(full)} rows\")\n",
    "\n",
    "    # ---- 8. FINAL 50/50: 25k + 25k ----\n",
    "    neg = full[full['sentiment'] == 0]\n",
    "    pos = full[full['sentiment'] == 1]\n",
    "\n",
    "    print(f\"Before final: Neg={len(neg)}, Pos={len(pos)}\")\n",
    "\n",
    "    final_neg = neg.sample(final_per_class, replace=True, random_state=42) if len(neg) < final_per_class else neg.sample(final_per_class, random_state=42)\n",
    "    final_pos = pos.sample(final_per_class, replace=True, random_state=42) if len(pos) < final_per_class else pos.sample(final_per_class, random_state=42)\n",
    "\n",
    "    df_final = pd.concat([final_neg, final_pos]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# RUN + SAVE + PLOT\n",
    "# ----------------------------------------------------------------\n",
    "df_all = load_and_merge_datasets()\n",
    "\n",
    "# ---- SAVE ----\n",
    "save_path = 'data/merged_dataset_balanced.csv'\n",
    "df_all[['review', 'sentiment']].to_csv(save_path, index=False)\n",
    "print(f\"\\nBALANCED DATASET SAVED: {save_path}\")\n",
    "\n",
    "# ---- PLOT ----\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "counts = df_all['sentiment'].value_counts().sort_index()\n",
    "labels = ['Negative', 'Positive']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=labels, y=counts.values, palette='coolwarm')\n",
    "plt.title('PERFECT 50/50 BALANCE')\n",
    "plt.ylabel('Count')\n",
    "for i, v in enumerate(counts.values):\n",
    "    plt.text(i, v + 200, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(counts.values, labels=labels, autopct='%1.1f%%', colors=['#ff6666', '#66b3ff'], startangle=90)\n",
    "plt.title('50.0% | 50.0%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFINAL: {len(df_all)} rows → 25,000 Negative + 25,000 Positive\")\n",
    "print(\"First 10 rows:\")\n",
    "display(df_all[['review', 'sentiment']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995cc602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 35000 | Val: 7500 | Test: 7500\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – Train / Val / Test split\n",
    "y = df_all['sentiment'].values\n",
    "X_idx = np.arange(len(df_all))\n",
    "\n",
    "train_idx, temp_idx = train_test_split(X_idx, test_size=0.30, stratify=y, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.50, stratify=y[temp_idx], random_state=42)\n",
    "\n",
    "train_df = df_all.iloc[train_idx].reset_index(drop=True)\n",
    "val_df   = df_all.iloc[val_idx].reset_index(drop=True)\n",
    "test_df  = df_all.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38183e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    17500\n",
       "1    17500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.value_counts('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5008f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Ready → Train:35000 Val:7500 Test:7500\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 5 – Tokenization + Safe Dataset\n",
    "# --------------------------------------------------------------\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "print(\"Tokenizing...\")\n",
    "tokenized_train = tokenize_batch(train_df['review'].tolist())\n",
    "tokenized_val   = tokenize_batch(val_df['review'].tolist())\n",
    "tokenized_test  = tokenize_batch(test_df['review'].tolist())\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = list(labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx].clone().detach() for k,v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "    def __len__(self): return len(self.labels)\n",
    "\n",
    "train_ds = ReviewDataset(tokenized_train, train_df['sentiment'].values)\n",
    "val_ds   = ReviewDataset(tokenized_val,   val_df['sentiment'].values)\n",
    "test_ds  = ReviewDataset(tokenized_test,  test_df['sentiment'].values)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "print(f\"Ready → Train:{len(train_ds)} Val:{len(val_ds)} Test:{len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132277af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 6 – Model Definition (with Warning Suppression)\n",
    "# --------------------------------------------------------------\n",
    "import logging\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "def get_model():\n",
    "    return BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=2,\n",
    "        problem_type=\"single_label_classification\",\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d49883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 7 – Encryption / Decryption (Weight Delta Only)\n",
    "# --------------------------------------------------------------\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "import io\n",
    "import torch\n",
    "\n",
    "def encrypt_state(delta_dict, key):\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(delta_dict, buffer)\n",
    "    data = buffer.getvalue()\n",
    "    buffer.close()\n",
    "\n",
    "    cipher = AES.new(key, AES.MODE_GCM)\n",
    "    ciphertext, tag = cipher.encrypt_and_digest(pad(data, AES.block_size))\n",
    "    \n",
    "    return {\n",
    "        'ciphertext': ciphertext,\n",
    "        'nonce': cipher.nonce,\n",
    "        'tag': tag\n",
    "    }\n",
    "\n",
    "def decrypt_state(enc, key):\n",
    "    cipher = AES.new(key, AES.MODE_GCM, nonce=enc['nonce'])\n",
    "    plaintext = cipher.decrypt(enc['ciphertext'])\n",
    "    cipher.verify(enc['tag'])\n",
    "    plaintext = unpad(plaintext, AES.block_size)\n",
    "    \n",
    "    buffer = io.BytesIO(plaintext)\n",
    "    delta_dict = torch.load(buffer, map_location='cpu')\n",
    "    buffer.close()\n",
    "    return delta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1632b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting functorch\n",
      "  Using cached functorch-2.0.0-py2.py3-none-any.whl.metadata (346 bytes)\n",
      "INFO: pip is looking at multiple versions of functorch to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached functorch-1.13.1-py2.py3-none-any.whl.metadata (353 bytes)\n",
      "  Using cached functorch-1.13.0-py2.py3-none-any.whl.metadata (353 bytes)\n",
      "\n",
      "The conflict is caused by:\n",
      "    functorch 2.0.0 depends on torch<2.1 and >=2.0\n",
      "    functorch 1.13.1 depends on torch<1.13.2 and >=1.13.1\n",
      "    functorch 1.13.0 depends on torch<1.13.1 and >=1.13.0\n",
      "\n",
      "Additionally, some packages in these conflicts have no matching distributions available for your environment:\n",
      "    torch\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install functorch==1.13.0, functorch==1.13.1 and functorch==2.0.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install functorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987e2623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opacus==1.0.2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.8 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (2.5.1+cu121)\n",
      "Requirement already satisfied: scipy>=1.2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (1.16.2)\n",
      "Requirement already satisfied: filelock in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (4.15.0)\n",
      "Requirement already satisfied: networkx in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8->opacus==1.0.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from jinja2->torch>=1.8->opacus==1.0.2) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opacus==1.0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43523c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 8 – ClientSimulator + LocalTrainer (PATE: Teachers = No DP)\n",
    "# --------------------------------------------------------------\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "# ==============================================================\n",
    "# 1. CLIENT SIMULATOR (unchanged)\n",
    "# ==============================================================\n",
    "class ClientSimulator:\n",
    "    def __init__(self, n_clients, seed=42):\n",
    "        self.n_clients = n_clients\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    def split(self, dataset):\n",
    "        n = len(dataset)\n",
    "        indices = torch.randperm(n).tolist()\n",
    "        base = n // self.n_clients\n",
    "        rem = n % self.n_clients\n",
    "        clients = []\n",
    "        start = 0\n",
    "        for i in range(self.n_clients):\n",
    "            extra = 1 if i < rem else 0\n",
    "            size = base + extra\n",
    "            end = start + size\n",
    "            clients.append({\n",
    "                'id': i,\n",
    "                'dataset': Subset(dataset, indices[start:end]),\n",
    "                'size': size\n",
    "            })\n",
    "            start = end\n",
    "        print(f\"  [Split] {n} samples → {self.n_clients} clients\")\n",
    "        for c in clients:\n",
    "            print(f\"    Client {c['id']}: {c['size']} samples\")\n",
    "        return clients\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 2. LOCAL TRAINER (TEACHERS: NO DP-SGD → High Accuracy)\n",
    "# ==============================================================\n",
    "class LocalTrainer:\n",
    "    def __init__(self, lr, epochs, batch):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "\n",
    "    def train(self, client_id, client_ds, global_state, round_key):\n",
    "        model = get_model()\n",
    "        model.load_state_dict(global_state)\n",
    "        model.train()\n",
    "        model.to(DEVICE)\n",
    "\n",
    "        loader = DataLoader(client_ds, batch_size=self.batch, shuffle=True)\n",
    "        opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "\n",
    "        total_steps = len(loader) * self.epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            opt,\n",
    "            num_warmup_steps=int(0.1 * total_steps),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        print(f\"  [Teacher {client_id}] Training {len(client_ds)} samples → {self.epochs} epochs\")\n",
    "        pbar = tqdm(total=total_steps, desc=f\"  T{client_id}\", leave=False)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in loader:\n",
    "                opt.zero_grad()\n",
    "\n",
    "                out = model(\n",
    "                    input_ids=batch['input_ids'].to(DEVICE),\n",
    "                    attention_mask=batch['attention_mask'].to(DEVICE),\n",
    "                    labels=batch['labels'].to(DEVICE)\n",
    "                )\n",
    "\n",
    "                loss = out.loss\n",
    "                loss.backward()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                opt.step()\n",
    "                scheduler.step()\n",
    "                pbar.update(1)\n",
    "\n",
    "            avg_loss = epoch_loss / len(loader)\n",
    "            print(f\"    → Teacher {client_id} Epoch {epoch+1}/{self.epochs} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        # Return encrypted model delta\n",
    "        delta = {k: model.state_dict()[k] - global_state[k] for k in global_state}\n",
    "        return encrypt_state(delta, round_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21686485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 9 – Helper Functions (FIXED federated_average)\n",
    "# --------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_model():\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\", num_labels=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# FIXED: Works with your AES-GCM dict\n",
    "def federated_average(cipher_updates, round_key, client_sizes, global_state):\n",
    "    total_size = sum(client_sizes)\n",
    "    decrypted_deltas = []\n",
    "\n",
    "    for enc in cipher_updates:\n",
    "        delta = decrypt_state(enc, round_key)\n",
    "        # Ensure all keys exist and match shape\n",
    "        full_delta = {}\n",
    "        for k in global_state.keys():\n",
    "            if k in delta:\n",
    "                expected = global_state[k].shape\n",
    "                full_delta[k] = delta[k].reshape(expected).to(DEVICE)\n",
    "            else:\n",
    "                full_delta[k] = torch.zeros_like(global_state[k])\n",
    "        decrypted_deltas.append(full_delta)\n",
    "\n",
    "    # Weighted average\n",
    "    avg_delta = {}\n",
    "    for k in global_state.keys():\n",
    "        weighted = sum(\n",
    "            decrypted_deltas[i][k] * client_sizes[i] for i in range(len(decrypted_deltas))\n",
    "        )\n",
    "        avg_delta[k] = weighted / total_size\n",
    "\n",
    "    # Update global model\n",
    "    new_global = {k: global_state[k] + avg_delta[k] for k in global_state}\n",
    "    return new_global\n",
    "\n",
    "def evaluate(state_dict, loader):\n",
    "    model = get_model()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    all_preds = all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            out = model(\n",
    "                input_ids=batch['input_ids'].to(DEVICE),\n",
    "                attention_mask=batch['attention_mask'].to(DEVICE)\n",
    "            )\n",
    "            preds = out.logits.argmax(dim=-1)\n",
    "            correct += (preds == batch['labels'].to(DEVICE)).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].numpy())\n",
    "    return {\n",
    "        'acc': correct / total,\n",
    "        'f1': f1_score(all_labels, all_preds, average='macro')\n",
    "    }\n",
    "\n",
    "def get_random_bytes(n):\n",
    "    import os\n",
    "    return os.urandom(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d34bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST HYPERPARAMETERS LOADED:\n",
      "  lr: 1e-05\n",
      "  batch: 8\n",
      "  rounds: 8\n",
      "  clients: 3\n",
      "  local_epochs: 8\n"
     ]
    }
   ],
   "source": [
    "# === LOAD BEST HYPERPARAMETERS (NO TUNING) ===\n",
    "import json\n",
    "import os\n",
    "\n",
    "HP_FILE = \"best_hp.json\"\n",
    "if not os.path.exists(HP_FILE):\n",
    "    raise FileNotFoundError(f\"ERROR: {HP_FILE} not found! Place it in the same folder as the notebook.\")\n",
    "\n",
    "with open(HP_FILE) as f:\n",
    "    HP = json.load(f)\n",
    "\n",
    "print(\"BEST HYPERPARAMETERS LOADED:\")\n",
    "for k, v in HP.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Optional: Reduce for quick test\n",
    "# HP['rounds'] = 1\n",
    "# HP['clients'] = 2\n",
    "# HP['local_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f55e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved HP found → STARTING TUNING WITH EPOCH LOGS...\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:06, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:13, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:36, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:36, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8716\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:32, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:32, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:48, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:38, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:46, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:36, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8765\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:15,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:29,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:05,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:30,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 9a38d35d-d5f8-4396-bb7d-7f090bd2c112)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "11/01/2025 08:29:47:WARNING:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 9a38d35d-d5f8-4396-bb7d-7f090bd2c112)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "11/01/2025 08:29:47:WARNING:Retrying in 1s [Retry 1/5].\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 488/1461 [01:31<02:30,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:02<01:15,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:05,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8742\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:36,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:29,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:04,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:36,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:34<01:17,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 488/1948 [01:31<03:54,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:46,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:32,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:38,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:44,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:35,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:42,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:43,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:03,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:34<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:43,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:32,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:37,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:31,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:45,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:09,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:45,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:29,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8722\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:04, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:09, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:30, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:36, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:02, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:06, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:31<01:32, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:31<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8755\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:37, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:43, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:46, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:30, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:37, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:44, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:13<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:48, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:08, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8762\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:00,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 975/1461 [03:02<01:16,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:15,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:31,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:01<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:01<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8734\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 975/1948 [03:02<02:33,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:42,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:40,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:03,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:14,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:34<01:18,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:47,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:33<01:16,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:35,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:39,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 975/1948 [03:02<02:34,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:35,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:43,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:01<03:01,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:29,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:37,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:10,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:35,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:48,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:34<01:16,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:34<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8749\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:07, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:09, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:08, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:09, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:33, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:09, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:36, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:06, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8746\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:45<04:38, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:30<03:04, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:15<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:45<04:37, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:30<03:06, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:15<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:49, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:30<03:10, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:15<01:35, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:45<04:42, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:30<03:05, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:15<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:38, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:37, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:38, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:30, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:38,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:07, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:46, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:42, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:45<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:30<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:15<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:46, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:30<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:15<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8743\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:03<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:06,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:03<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:03<01:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:03<01:33,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 488/1461 [01:31<02:33,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:04,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:07,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 975/1461 [03:02<01:17,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:34,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:01<01:30,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 488/1461 [01:31<02:35,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:01<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:14,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:02<01:14,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:01<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8733\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:01<02:30,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:32<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:36,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:37,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:39,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:45,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:29,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:30,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:29,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:29,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:43,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:30,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:46,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:01<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:32<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:46,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<02:59,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8723\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABD4AAAJOCAYAAABfpccuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnQd4jecbxu/sJZEhiYiIvfeoKkpRq0apPUpVqbZa1Wm3pbTlT6s6qCoddu1VexSlNrFniEgiQyIi0/+63/jSk4jkyDojz++6vovv5IxvnPG993s/92Px4MGDBxAEQRAEQRAEQRAEQTBDLA29AYIgCIIgCIIgCIIgCPmFCB+CIAiCIAiCIAiCIJgtInwIgiAIgiAIgiAIgmC2iPAhCIIgCIIgCIIgCILZIsKHIAiCIAiCIAiCIAhmiwgfgiAIgiAIgiAIgiCYLSJ8CIIgCIIgCIIgCIJgtojwIQiCIAiCIAiCIAiC2SLChyAIgmBSPHjwwNCbIAiCIAiCIJgQInwIgiAA+Pjjj1GpUqUsl/79++fpsWrRooV63YLm8OHDan/mzp372Pv89ddf6j779+/P9vlWrFih7nvjxg21zn3ivj3JY/QhISEBkydPxtq1a9Nu0+e18pqlS5eqbX/99dcL9HWFR+FnMuPntHLlyqhbty66du2K1atXG+U25/V3iSAIgiAIWWOdzd8FQRAKBW+88QZ69eqVtv7999/j9OnTmDVrVtptRYoUydPX5HPn9XPqQ7169VCmTBklIAwePDjT+6xcuRJ+fn54+umnc3QsX375ZeQ1oaGhWLBgAaZMmZLvr5UVf/75JypWrIjdu3cjODgYPj4+Bfr6QnqqVq2KCRMmpK0nJyfj1q1bmD9/Pj788EO4urqiWbNmctgEQRAEoRAjwocgCAKAUqVKqUXD3d0dtra2qF27dr4O2AzFSy+9hGnTpuHChQuoUKFCur+Fh4djz549eOutt2BhYfHEz617HPObgnwtcunSJRw7dky5Zd59910sWbIEI0aMKNBtENJD8TCzz+mzzz6LRo0aKXeRCB+CIAiCULiRUhdBEIQn4Ntvv1V2+ozwNv6NsHyD6xs3bsTbb7+NOnXq4KmnnsLYsWNx7969TEtd9H1MYmKiEiw4qKtZsyZeffVVrFq1Kl3ZyIEDB9Q6B3yP48UXX4S1tXW6shEN3sYcDZYKkK1bt6JPnz5qm6pXr462bdvijz/+eOxzZyw/SUlJUQ6a5s2bo1atWsqlcefOnUcel9XrcN9atmyp/j9q1Ki058/4Wpzt52M6duyojg9fk8crPj4+3fYNHDhQOTfatGmjXqtz587KwZEdfEzRokWVE4aPXb58OZKSkh65H8WRQYMGqZIL3nfkyJEICQlJ51756KOP1MCc+9uvXz8cPXo0bV8zO38Z95XlEu+//756v3Dg/8orr6Q9nk6HJk2aoFq1auo1uB4ZGZn2WJ5fOiLatWunjtPzzz+Pn3/+Wd2+c+dO9fp///13utc/dOiQup2lUpnB7eM28Zg899xzar8GDBiAs2fPprvfzZs31fHg+5vvB96H7ioNbf9/+eUX9R7gfXjcnxQ7OzslXuqKd3wffPfdd+p5a9SogdatW2POnDnqPZpVCVrG0ix+1nnMeKz4XuN7iO8HfhYz7isFRLqsGjdurPZJEARBEISCR4QPQRCEfIL2e19fXzXop0DBAeEPP/yQq8eMHz9elXtwoMwBXLFixTBu3Lh0z8HBLp0IHPQ/Dk9PTzRt2hTr1q17JCyUuQj8m7e3txrYvfnmm+o5uU0c8LEE5rPPPsPx48f1Og5Tp05V29qtWzdV3sPSg//973/p7pPd63h5eaWVHQ0bNixdCZIuPD4shWnVqpU6bn379sXvv/+uxBbd/Tx16pQa6FM04LZZWVlh+PDhmQoyGhQ41qxZgw4dOsDGxgZdunRBWFgYtm/fnu5+HMTz/HCQ/dVXX+HTTz9Vr8fzyeeIjY1F7969lUD1wQcfqH3hIJ1CydWrV/EkUChzcnJS+8qypbi4OFX6Q2cK30vcR66vX78eM2bMSHsct4sLB/k//vijOjcUiCgC8NzzeGfMx+CgvnTp0moQ/zjOnDmjXoeDfZ53ii08FhR6SEREhCopCwgIUO9bvg8oOvA8cZt14XvgtddeU9tJ0eBx8LzyuGoLj/vly5eVQMZjTVFLux9zWejW6d69u9pvCiBff/11ulIZfeG55/uTx5fHrWTJkkrM0vaDgiX3/fz585g4caLa32XLlqUJXIIgCIIgFBxS6iIIgpBP0F7PgRDhrPvevXvVAP+9997L0WMCAwNV9gb/rs3uc5B6+/btdLPzj7P+Z4SDXYoNnMGvX7++uu3cuXNq4E6hgFy8eFEN8MeMGZP2OM7kN2zYUA3cORufFdHR0fjtt9/U9nIwrG0zB8Isp9HQ53WqVKmSVt6SWZkQn4NCEY/VkCFD1G0cMHMQT8cDHR1ayUNMTIyaxddKZRwdHdUg9Z9//lEz95nBx3OwqzlheMwoBCxevFg5BzQ4oKa4M2/ePCVoEG4Dt4ulRTzeQUFB6lxq+0RnCF04//77rzrv+kIBhsIKnQ2a8FC8eHF8+eWXSjgidJxQPDp48GDaOfn111/V/lJ4Ic8884zaN77+0KFD1bngeaNwQGHl/v37SmTRjuvj4HHl/mvvJ7pJKELx9ehOoWgXFRWFRYsWKYGP0L3Uvn17fPPNN5g5c2bac9GNwpKs7OA2UzDThS4P5rDwOek+0c7fvn37MH36dLzwwgtp7w97e3t1PwoYGcu+soIi0+eff552vvhe4Gvt2rUL5cqVU+eXjg+Ki+XLl1f34fuYThFBEARBEAoWET4EQRDyiYziAwekHPDm9DEUADhrzVlqXehAyFiWoA90hNAxwtIWbaDKWX3eprlFtPBTDoCvXLmixJeTJ0+mdVnJDpZ8sDxHG3zqDmp1hY/cvg7RBvbaoFaD65z95/HThA9muOjmg/A4a4PZx8FyC4bC8nEUDwjPxezZs9X2as9HYYOvo4kemoijOUM0d4AmehAHBwfVSYc8SaebsmXLpokehM+5cOFC5aKge+TatWtKEKIDQivJ4Tnh/3XFGsKyKg0KDtyvLVu2KEGG/9LBwP9nBfdLey9pgg/3neIEYZcgbiPdRNr2WFpaKvGDbhpddI9PVlD0oPhDKKjRwcH3HP/l8dF9f7C8K+Pnp1OnTkr44N+fRPjI+HnV3kNaaRpLg/ie0EQPwiDc/MwNEgRBEAQhc0T4EARByCc4mNWFA7yMZSVP8hiWCRAPD49098m4ri8cBHLQR+cDB718LYogLA2gk0B7TZYBMH+Ds+j+/v5pA9vs9oVopSNubm6PlNroktvX0X2tjM/N/eTr043wuOOs5UDoZj1kDHzlTD4H1A0aNHjk7ywt0twTdDRkdU6y+/uTQDdGRpgjQdcFX4ciFvMnuL/a/vN2Tfx5HDz+zOCgEEaxg//SFULBIisy+zv3laUt2mtTjMno0NDQFZ7owtH3GDCvQ4OuCr6vWTrE97a2n3x/8H3AsiZdtPeL7vtDX3TfR/z86L5ftdfLCF+PLi1BEARBEAoOET4EQRCeAG2AzBBNbQBFl0JBoA0qOWgqUaJE2u2aIJITWO7Ckgw6Rrg/LHfQLS9geQLdAgzC5Mw93QUcnC5dulSv59cGfhQOdGfftcF3Xr0OYego4T5oZRSEYgWzJjIbhOoL3Qh0KDAPxNnZ+ZEsCg6w33nnHbXd/Htm54TCCV0M/Htmro4jR46ofWDphfYe00U35PZxULj64osvlAjDkhxt0M9t0xw0Li4u6l9uo+45YVkGnSvM8KDwxffB6NGjVWYFnRrMAMkO3QBVDb5fNaGH+05BhaVHmaHrXskpFHuY9cJ9ZimKlifDY8vt0/3sEi1/RPf9kZNjnxE+H0WejGR87wuCIAiCkP9IuKkgCMITwPwMcuvWrbTbHtflIq/hgJQDNpYd6LJ58+YcPyezCCg08DmY4cCsCd6mu28siWDWhjYo1bqfPM4doQufmwP5TZs2pbt9x44d6db1eZ2MM/UZ4YCaMMhTF65zIJtVKGd2UNhgiQLzKriNukuPHj2UiKCdFzpVmM2iW6LD3BTmY9D5wL9fv35d5X1oMJCT4arMKNHeY7pdYCjenDhxItvt5HGksMHSIU30oDDH27XjyNwNChsZzwEFMHZb0Y4zs07oaPjkk0+Uq4L7nh0sr9ENKeU+MMxTy8HgOWIpE0uG6NLQFgapct+zO8f6wnIWLbxXK4Hia1O8yvhe1EpstPcHj7/u5zunn3Fmq1Dg0gQnwvcJS40EQRAEQShYxPEhCILwBDC7gV1DOKPMLh3BwcHKBZBZyUFew7BKzsIznJED4cqVK6vBtjaA1az2d+/eVbkOzBfIqpxBg8+pzeZrwaoaHCTTRcDSBGYY0JXAjAo6X7LKw9DgcWFQKvMWOIjmYJDOh4yDbn1eR3Na0H1AcSZjsCqzFBjKyYBMPoYlKQz7ZNcUChQcCOcECg7szJGxe44Gwyq5nww5ZZ4I97dnz54qJJSBmQwG5f5zHxmmSUGEwaHsTsOuMnQGMPyT55TtfOlMoGDE+7DkhOv8O58nu/IPvgaDQ+n6YK4K3Qzs7ELXheaI4XuC20V3DUUmCgIMP+Xj6MTQ3kc8X9wflvGwC40+bgytc8q7776rRAwee74u29wSthGmyMF/WYrCfd+wYYNy9jCHJS+hW4UlL5MmTVJBo8wR4fuAZV0UZPj5oSjy008/qfeNlsXB48Z8Ey58jzGbhaG3TwpLxnjeGOrL40FBhd139BEMBUEQBEHIW8TxIQiC8ARwppodMziTyxl8DmzYqpIhjgUBB99sB8rZeQ6wOTPNATTRBsV0FXDgzW4w+sCgUQ7GOfDOGPzIATQHf9xHdoDZtm2bCpJs0qSJCm/UBwoAHIRypp3bys4xGQUWfV6HA0d2h2EOCNuccnszwtIGPp4iCs/PH3/8oQb5HNxqA/onhaGmHMRnPDYaFAjojuAgmm4HdpyhaEF3wYgRI9TAm24CDqQpHnA/2GJX21/eh4Nhvpe0Tiw8Hszm4CCdggAFoQEDBmS7rRzAc//p3uExoghEhwnbrrLEQnNjsBSG7g46InicKEbwvZXxNbSQW62TTXawBIuCxuTJk9U517resMuNVq7FdZYi0UlCkYTCEs8bxZC8hGU8FFz4fqOoQxGN54CfH4o+3G++J3kcuL2671e2u6VgxPcrS6e4fU8KzzW72FCA4+N5POh8yRj0KwiCIAhC/mPxQN/UOEEQBMGgcODK8g86F3TzCCjEsBSDXUsEIS9h4CzdIAw3zY6PP/5YiT9a9xpBEARBEARjQUpdBEEQTAQ6CzhzzIBMzszT4cG8ALoHOEstCHkF3ScMm2UJytSpU+XACoIgCIJg0ojwIQiCYCLY2dkpiz7zIji7zhwL5niwbKRv376G3jzBjGB50Z49e5TA1qFDB0NvjiAIgiAIQq6QUhdBEARBEARBEARBEMwWCTcVBEEQBEEQBEEQBMFsEeFDEARBEARBEARBEASzRYQPQRAEQRAEQRAEQRDMFgk31YOUlBQkJSXB0tISFhYW+X9WBEEQBEEQBEEwaR48eKDGEdbW1mocIQiC4RDhQw8oepw8eTL/z4YgCIIgCIIgCGZFjRo1YGtra+jNEIRCjQgfeqAptPzSsrKygjGox9HR0XBxcREHipkh59Z8kXNrnsh5NV/k3Jovcm7NF2M7t8nJyWryVNwegmB4RPjQA+2Lk6KHsQgf/ALlthjDl7qQd8i5NV/k3Joncl7NFzm35oucW/PFWM+tMW2LIBRWpNhMEARBEARBEARBEASzRYQPQRAEQRAEQRAEQRDMFhE+BEEQBEEQBEEQBEEwWyTjQxAEQRAEQRAEQcg0oDUxMVGOjGCU2NjY6J3BKcKHIAiCIAiCIAiCkC4o9tatW4iKipKjIhg1rq6uKF68eLYhwiJ8CIIgCIIgCIIgCGloooeXlxccHR2lM41glOLcvXv3EBoaqtZ9fHyyvL8IH4IgCIIgCIIgCEJaeYsmenh4eMhREYwWBwcH9S/FD75fsyp7kXBTQRAEQRAEQRAEQaFletDpIQjGjvY+zS6LRoQPQRAEQRAEQRAEIR3ZZSYIgim9T0X4EARBEARBEARBEATBbBHhQxAEQRAEQRAEQTBpbty4gUqVKql/c8u1a9dQs2bNXD9PZGQkhg8fjjp16qBFixZYvXp1ur8PGzZMbbPusmPHjgLZ10OHDqFr166oXbs2OnfujH379qGgOHnyJHr16oVatWqhTZs2WLVqVb6/poSbCoIgCIIgCIIgCHlOcsoDHLwSgdCY+/BytsdTZdxhZWncJTTBwcEYOnQo4uPjc/1co0aNwv3797FkyRIcP34cY8eORZkyZdJElUuXLmHq1Klo1KhR2mOKFi2K/CY8PByvv/66Wig8rF+/Hm+88QY2bdqkWsPmJzExMXjttdfQpUsXte9Hjx7F6NGj4efnh3r16uXb64rwIQiCIAiCIAiCIOQpm04F49O1pxF8537abT5F7TGhY1W0rZ5161FDsXXrVowbNw6enp65fq7AwEDl3ti2bRtKliyJihUr4tixY1i4cKESPhISEpRjo0aNGnnyek/CkSNHVAeUwYMHq3UKIL/88ovavrZt2+a7sPTss8/iww8/VPkcFDz42tym/BQ+pNRFEARBEARBEARByFPRY9jvR9KJHuTWnfvqdv49v2EpyDfffIOGDRuqgf233377SFmJtmjs3LkT77zzDsaMGZPpcy5evFiVrLB0pX///jh37txjX58ODx8fHyV6aHBgT4cDuXz5ctrAP6fQoUERoW7duhg/frwSU0h2++rq6qpaFm/evBkPHjxQgk9sbKwSZ/QhOjoaH3zwgXrdJk2aYOLEicrZQlasWPHY16bQw9f46quv1L6npKRg+/btuHLlCho0aID8RBwfgiAIgiAIgiAIQpZwgByXmKxXecuENQF4kNlzsAsHgE/WnEbj8sWyLXtxsLHKVXcZOi4WLVqkBtgUIZgrkRWTJk1S/x44cOCRv3GAPmvWLDXIZ7kKcylefvllJR5kVp4SFhYGLy+vdLd5eHggJCQkTfgoUqSIcj4cPHhQlZgwD6RZs2Z679/SpUsxY8YMJCcnq+eZPXu2eo5BgwZlua/169dH37598fbbb8PS0lI9fsqUKShbtqxer0thiO1jeWxZEsTj9tlnn2Hy5Mlo3749mjZtmunj3N3d0/5PkYbCCZ+H28qskfxEhA9BEARBEARBEEyblGTg2l7YhFwBvMsA/o0BSytDb5VZiR7dftyPw9cic/9cdH5E30eNTzZne9/6/m5Y9nqjHIsfPXv2TDeYd3JyQk6ZO3euyv547rnn1PqIESOwe/durFmzRrk/MhIXFwdbW9t0t3Fdc2VQ+KBLgo6JIUOGYMuWLSrslHkgLH/RB2ZjaOUhdKpMmzZNCR/cz6z2NTY2FtevX8dbb72l9ofiDcULho2WK1cu2xIeOkQo1jg7O6vbKAa9+OKLKtOEt9nb2+u1/dxXHgeKJqVLl8Yrr7yC/EKED0EQBEEQBEEQTJfTa4BNH8Ei+ibShnouJYC2XwJVOxl228wI444kzRxfX9+0///444/KEZEZWvlJVmhBpNOnT0+7jW6Hq1evqg4pDOzUoEBiZ2eXJnJocF0TBRgmSsFEc4tUrlwZAQEBysWhr/Ch23mmatWquH37Nu7cuaOcGFnt69y5c5WYReGDVKtWDSdOnMCvv/6KTz/9NNvjQAcNS2x04W3shkMhY8KECZk+liGqJUqUSBOB+LpcQkND8dtvv4nwIQiCIAiCIAiCkKnosfTlhz4CHaKDU2/v8auIH3kAHRd0XuhT6sIuLgN/+Tfb+81/pYHq8pKfpS4UHzRYTtGuXbscPxfLQeiw0O3AQliuQneFbktWihl79uxRQoQuXNeCTFlikrFEhu6Uixcv6r1NfA4NChnExsYm230NCAhQQosuVapUwYULF/Q6DnR1/Pnnn4/8zdvbWzk36BzJDJb+0GlCsUi3HKZ8+fKq9W9+Io4PQRAEQRAEQRBMs7xl00ePih66aRKbPgYqvyBlL3kABQhH2+yHj00reKruLQwyzezMUMYoXtRe3a8gW9sy0JNLTmGux61bt+Dv7592G0s7WrVqhZYtW6a7nTCzIigoSD1GaxF7+PDhtCyLjz/+WB1TZmtonD17Vu+AUXL+/Hk89dRT6v90bPB1HB0d1ZLVvnp5eT0isNCpoRvEmtVxYEtabnupUqXUbQx5nTlzptoXFxcXJQY9Dm4nHSF///13mvvl1KlTeueL5BTp6iIIgiAIgiAIgulxbR8QfTOLOzwAooNS7ycUGBQz2LKWZJQ1tHX+vSBFj7yA+RMLFixQzg7mXLDsZePGjY/NxGC3FuZ3sPsJBY1ly5Zh3bp1KlSUsDvM2rVr1fOxRITBqRRG+vXrl5bDERERkeU2MVuD3WP27t2rhIeBAwfqtS/du3dX+STz589XDgz+SyGiT58+6u/MHmE4a2Zwf+nWeP/995WIQfcIBaB79+4p0SM7mjdvrhwj7ELDbi48Biy9Yb5JfiKOD0EQBEEQBEEQTI+7IXl7PyHPaFvdBz/0q4tP155O19KWTg+KHvy7qcFuJSxVocDAf1me8cMPP6jSjsfBtq3sgNKjRw9V4sKuJ1ouR+vWrZXzgc9x8+ZNVKhQQQkAmuti3rx5WLlypeom8zh69+6tBAN2RuFrDBgwQK99qV27tmp5y31hy1+6OObMmaO2gWzYsEGJGY9r18v9YhgqhRZra2slhIwdO1av12ZZEPeTok3Xrl3h5uamSojonMlPLB5oxUBClnVMx44dU28QKyvDp0PzlDG0hjVhual5E4wPObfmi5xb80TOq/ki59Z8kXNrRlzZAyzokP39BqwDymTeXrMwjSH0hbP9nInnYFjf7hxZtbZl5kdozH14OdurTA9Tc3oYEralpQBS2F47P96v4vgQBEEQBEEQBMH0KFEHsLYHkv5zFKTHIrW7i/8zBbxhggZFjkblPOSA5AC2ya1bt65Bjt2hQ4fScknMBRE+BEEQBEEQBEEwLe6GAot6Zy16kLZfSLCpYJKwKws7tBiC2rVro169ejAnJNzUxEhJScb1gJO4dHCf+pfrgiAIgiAIglBoCAkAfmoBBB0CHNyA50anOjt04bq0shVMGEOJHoS5HeYWqSCODxPiwoF92D5/Du5G/NcPuoh7MbQYOAQVGoqFTxAEQRAEQTBzLmwBlr0CJMQA7uWAvssAj3JA0/fx4Npe3Au5AkfvMrDwbyxOD0EQ0hDHhwmJHmumT04nehCu83b+XRAEQRAEQRDMlgNzgIU9UkWP0k2BwVtTRQ9iaaVuS6zcOfVvXBcEQXiICB8mAMtZ6PTIih0L5kjZiyAIgiAIgmB+JCcBGz4ANn4APEgB6vQD+q0AHN0NvWWCIJgIInyYAEFnAh5xemQkJvw2Ak+dKLBtEgRBEARBEIR85340sKgXcPDhJGCrT4BOswBrWzn4giDojWR8mAB3oyL1ut+qLz+Df83a8K9RG/4168Ldt6TZhdIIgiAIgiAIhYSoQGBhTyD0NGDtAHSdA1TtZOitEgTBBBHhwwQo4uqm1/2SkxJx+ci/alGPc/eAf806qUuN2nB0KZrPWyoIgiAIgiAIecCNQ6ntamNDgSLFgd6LAN+6cmgFQcgRUupiAvhWqaa6t2SFs0cx9J3yNZ7t+wpK1agNKxsb3I0IR8DOrdgwcyp+eK0vfvvoHexeOB/XTh5DUkJCgW2/IAiCIAiCIOjNqRXA/BdSRQ/vGsBr20X0ELLlxo0bqFSpkvo3t1y7dg01a9bM9fNERkZi+PDhqFOnDlq0aIHVq1en+/uwYcPUNusuO3bsKJB9PXToELp27YratWujc+fO2Lev4JtlJCUlqdf+9ttv8/21xPFhAlhaWqmWteze8jieGzAExcuWV0uDTi8hMSFeZYNQ5Lh2/AjCAq8i9Ooltfy7ejmsbe1Qskq1NEdIMT9/KYsRBEEQBEEQDMeDB8DuacCOSanrFdsCL/0M2BWRs2KqpCQD1/YBd0OAIt6A/zNG33EnODgYQ4cORXx8fK6fa9SoUbh//z6WLFmC48ePY+zYsShTpkyaqHLp0iVMnToVjRo1SntM0aL579IPDw/H66+/rpY2bdpg/fr1eOONN7Bp0yYUL14cBcW8efNw9uxZtGrVKt9fS4QPE6FCw2fQaeRo1d1FN+iUTg+KHvy7Lja2dihdq65a0G8QYqMiU0WQE0fVwvWrx4+ohTi5ucO/ei3416qrymKc9CyvEQRBEARBEIRckxQPrHkbOLE4df3pN4HWE41+kCxkwek1wKaPgOib/93mUgJo+6XRZrVs3boV48aNg6enZ66fKzAwULk3tm3bhpIlS6JixYo4duwYFi5cqISPhIQE5dioUaNGnrzek3DkyBFYWVlh8ODBap0CyC+//KK2r23btgWyDXTV/PrrryhfvnyBvJ4IHyYExY1yDRrixukAhN28Ac8SJVGyajXlCMkOChlVmz6nlgcPHiD8+jUlhFw9cRQ3Tp9CbGQETu/ZoRbiWao0StWsg9I166hSGwopgiAIgiAIgpDnxIYDS/oBgfsACyvghWlA/UFyoE0Zih5LX6aNJ/3t0cGpt/f4Nd/FD5aC0MVAoYGlJtWqVcOsWbMyve+5c+fUvzt37sQ777yjXBkvv8ztT8/ixYsxZ84cVcJSvXp15eDg62QGHR4+Pj5K9NCoV68eZs+erf5/+fJl5bj38/PL8T7SoUHx4O7du+jQoYPaHltbW1U6ktW+urq6IioqCps3b8bzzz+vxJnY2FglzuhDdHQ0Jk6cqB7n6OioXCMffPAB7O3tsWLFCuV0yQxNBCLjx49XZUDr1q1DQSDCh4lBkcOvWg24lCylbFA56drCxxQrVVot9V54UeV93Dx/RjlBKISEXrmkSmO4HF63UuWF+FaupkQQlsVQFLGwlHgYQRAEQRAEIZeEnQcW9gAirwB2RYEe84FyLeSwGmspUuI9/cpbNn74qOiR+iQcjaQ6Qco2z97RY+PIwUuON5mOi0WLFiElJUWJEL169cry/pMmpZZZHThw4JG/bd++XYkJHPBTGFm1apUSRygeZFaeEhYWBi8vr3S3eXh4ICQkJE34KFKkCD788EMcPHhQlZhQCGjWrJne+7d06VLMmDEDycnJ6nkoqvA5Bg0alOW+1q9fH3379sXbb78NS0tL9fgpU6agbNmyer3umDFjkJiYqI4tS4J43D777DNMnjwZ7du3R9OmTTN9nLu7u/r3zz//VI/r0aOHCB9CwWFta4tS1WuppWmfgbgXfQeBLIt56Ai5G35brXPBH7/Asairum/ph2Ux7B4jCIIgCIIgCE/E5Z2ps//37wCu/kCfpYBXZTmIxip6zGsDXD+QF0+WWv7yhR5OB7+ngUGbcix+9OzZM91g3snJCTll7ty5KvvjueeeU+sjRozA7t27sWbNGvTv3/+R+8fFxSn3hS5cZ4mLJnww/6NJkyYYMmQItmzZosJOmQfC8hd9GD16tHKREDpVpk2bpoQP7mdW+xobG4vr16/jrbfeUvtD8YbiRa1atVCuXLlsS3hYEkSxxtnZWd1GMejFF19UTg/eRudHVvki06dPV6U1OZnEzyni+BAegW1vKzduphaWxUTcvJGWDXI94CTu3YnC2b271EI8SpZ6GJJaG35VasAmize6IAiCIAiCIODwAmD9SCAlCfBrCPRaCDhl3cVQMDQFN0jNK3x9fdP+/+OPP6aVmWTk6NGj2T6XFkTKQbsGXQtXr15VHVJee+21tNspkNjZ2aWJHBpc10QBluFQMNHcIpUrV0ZAQIBycegrfOh2nqlatSpu376NO3fuKCdGVvs6d+5cNc6j8EFYBnTixAlVNvPpp59mexzooHn22WfT3c7bmNtBQWfChAmZPpYhqhRn2E1G37KavEKEDyFLqMJ5+PqppW67TkhOSsTN82dx7QSDUo/g1uWLCL8RqJYjG1bDytoaJSpWSesW412mnJTFCIIgCIIgCP+VQWydAOx72L6yRneg0yzARibOjBrOzNN5oU+pC7u4/NEt+/v1XZ7a5SUfS10oPmiw9KNdu3Y5fi6Wg9BhoduBhbBche4Klr5oUMzYs2ePEiJ04boWZMoSk4wlMnSnXLx4Ue9t4nNoUMggNjY22e5rQECAElp0qVKlCi5cuKDXcaCrg+UqGfH29kbp0qWVcyQzWPpD8YPiz++//65uo+uFYgzzSvi3/EKED+GJsLK2gV/VGmpp0qs/4mKiEXjqBK6dTHWERIeF4vrpk2r5e/GvsHd2SS2LeegIcSmWvs5NEARBEARBKCQkxAJ/vgacezi4aT4aaPZhrga2QgHC82SrR6kIM1rYvYVBppnmfFik/p33K8CuPQz05JJTmOtx69Yt+Pv7p93G0g62Ym3ZsmW620nt2rURFBSkHqO1iD18+LC6nXz88cdqkpnZGhps7fokTojz58/jqaeeUv+nY4Ovw7BRLlntq5eX1yMCC50aukGsWR2HmJgYte2lSpVKC0ydOXOm2hcXFxclBj0OltXo8v777yuh5JVXXkF+IsKHkCscnF1QqVETtVBljLp1U+WC0BFyPeA47sdE4/z+PWohbiVKqlyQ0rXqKPHE1sFRzoAgCIIgCIK5w0yHRb2A4OOAlR3w4vdADT1cAXqSkpKco86HQj7A486Wtaqri0UG8eOhyNX2C5NrVcyBOUM96WioW7euyuLYuHGjKmvJDHZrYX4Hu53wcSdPnlRBnprToUWLFhg5ciQaNmyous6sXbtWCSMMCdVyOFhKowWCZgazNZjNwa4uFB5effVVvfale/fu6NOnD+bPn69EG3Zb+fvvv7Fy5co0FwbFjcza7DIDhOGlFCzYRYZtcdkCmO4Vih7ZkVEgovuDj9UtS8oPRPgQ8gyqfm4+vmqp06YDkpOScOvi+VQh5ORR3LpwHpE3b6jl2F/rYGllBZ8KldO6xXiXKy8/UIIgCIIgCObGzWOpokdMMOBYDOi9CPBLnaXOCy4c2Ift8+fgbsR/ZQVF3IuhxcAhqNAwm1IKIX9gq1q2rGX3FopeGnR6UPTI51a2+QG7lbBUhQID/y1fvjx++OEHJYQ8jq+++kqJHuxeQhGBXU+0XI7WrVurLAw+x82bN1GhQgWVvaG5LubNm6eECHaTeRy9e/dWgajssMLXGDBggF77Urt2bdXylvvyzTffKBcH2/RyG8iGDRuUm0Vr85vZflFwGThwIKytrZUQQhHEmLF4oBUDCVnWMR07dky9QahoGRqeMobW5LSdraG4H3sX1wNOPAxKPYaoENrf/sPeqQj8qtdE6Zp1VVlMUa9US1hhwlTPrZA9cm7NEzmv5oucW/NFzm0Bc3Y98Ofg1GwIz8pAnyWA2+MHijkRPdZMn/zYv3caOdpg4oexjSH0hbP9V65cUYPhrLpz6J3pwsyPuyFAEe/UTA8Tc3oYEralpQBS2F47P96v4vgQCgwKGxWeekYtJCrkVlq3mECWxcTeVT9eXIhrcR/416gD/1p1UKpaTdg55rz9lCAIgiAIglCAcG51/yxg87jUUgfmOXSfD9inD3PMbXkLnR5ZsWPBHJRr0FBcxYaCIkeZpgZ7eVOGbXJZUmMIDh06lJZLYi6I8CEYDFfv4nB9vh1qPd8OKcnJuHXpQlpIavCFc4i6FayW41s2qM4wPuUrKSeIf8268ClfUZXKCIIgCIIgCEZGciKw/j3gyILU9fqvAu2+Ykp+nr5M0JmAdOUtmRETflvdz6/af20/BcEUYFcWdmgxBLVr10a9evVgTojwIRgFFDFKVKyslkYv9Ub8vXuqM4zmCIkMDsLN82fUsn/5IhWKWqp6zTRHiKu3j5SGCIIgCIIgGJq4SGDpAODKLsDCEmgzGWj4er50brkbFZmn9xMEY8JQogdhboe5YX57JJgFdo6OKF+/oVoI2+SmhqQeQ+DJY7h/NwYX//1HLcTF0zutZa5f9VpwKOJs4D0QBEEQBEEoZERcBv7oAYRfAGyLAN3mARXb5NvLFXF1y9P7CYJgvojwIZgELp5eqNmyjVpYzxl65XKaGyTo3BlEh4XgxLZNarGwsFQdYpQQUqMOfCpWgpW14RRTQRAEQRAEs4cBlov7AnERgEvJ1BDT4tXz9SW9ypVX13jJSYmPvY+zRzH4VqmWr9shCILxI8KHYHKwJ3vxchXU0rBLDyTcj8ONM6dw7XiqIyT8RqBqo8vlnxVLYGPvAL+q1VU2CB0h7iVKSlmMIAiCIAhCXnF8MbBmOJCcAJSom9qu1jl/gxEpdqyf8WWWogd5bsAQCTYVBEGED8H0sbV3QNk6DdSihVhRAFGOkJPHEBd9B5eP/KsW4uzh+TAktQ5KVa8FR5e8SxcXBEEQBEEoNKSkADs+B/ZMS12v0gnoMhuwdczfl01OxoaZ03Dl2GFY29qpibDjWzamCzql04Oih6Fa2QqCYFyI40MwO/hDV715K7U8SElB6LUrOmUxpxETHoZTO7aohUFb3mXKwb9GareYEpWqwNqAQUKCIAiCIAgmQWIcsGoYELAydb3JSKDFOFpz8/VleW3314/f4PyBvbCytkbnD8aq8uanXuyGG6cDEHbzBjxLlETJqtXE6SEIQhoifAhmDdvgUtjg8lTnbkiMv69aml196Ai5HXgVIZcvquXg6uWwtrODXxWWxTAotQ48SpaSshhBEARBEARd7oYCi3oDQYcASxug4zdAnb75fowePHiAbb/Mxund29U1XocRHyvRQyuF9qtWAy4lS6Fo0aJy/SYIQjryV5IVBCPDxs4epWvXQ/P+r2LA1FkY+uOvaPfmSFRp+hwci7oiKT5e2SZ3/joXC95/E3OGDcCm72fgzJ4diJVWaIIgCIIgFHZCAoCfWqSKHg5uwMurCkz02LNwPo5vXq8cu7x+K9/g6Xx/XcF0uHHjBipVqqT+zS3Xrl1DzZo1c/08kZGRGD58OOrUqYMWLVpg9erV6f4+bNgwtc26y44dO4xiXw8ePIjOnTujVq1a6NGjB86ePYuCYs2aNWjTpo3arl69euHEiRO5fk5xfAiFmiJu7qj6bAu18AeVDhA6Qdg6l86Qu5ERCNi1TS3E07+McoKUrlkXvpWrwtrW1tC7IAiCIAiCUDBc2AosGwgkxADu5YC+ywCPcgXy0gdWLMG/a/5U/3/+tTdRpUnzAnldIXckpyTjSOgRhN0Lg6ejJ+p61YWVpZVRH9bg4GAMHToU8fHxuX6uUaNG4f79+1iyZAmOHz+OsWPHokyZMmlCw6VLlzB16lQ0atQo7TF0LBl6X69fv47XXntNLR06dMDPP/+MN954A5s2bYJtPo9/Dh06hDFjxmDSpEmoW7cuFi5cqLZj+/btcHJyyvHzivAhCA+xsLBQwgaX+h27IikhAUFnT+PayVQhJOzqZYRdu6KWQ2tXwNrGVrVHSxVC6qBYqdJiqxQEQRAEwTw5MAfY9BFDNoDSTYEevwKO7gXy0ofXr8bepb+r/zd/eTBqtmxbIK8r5I6t17bii4NfIOReSNpt3o7e+Pipj9HKv5VRHt6tW7di3Lhx8PT0zPVzBQYGKvfGtm3bULJkSVSsWBHHjh1TA3kKHwkJCcqxUaNGjTx5vbzc199//11t41tvvaXWR48ejY4dO+Ly5cuoXLlyvm5XWFiYElnoNiFvvvkm5s2bp0Si3LhwRPgQhMd9OGxtH3Z/qY1n+76Ce3eiHnaL4XJEuUG00NTdgCqVUdkgKii1jnKTCIIgCIIgmDTJScBfo4CDc1LXa/cDOszghVKBvPyJbX9h568/qf8/06Mv6r3wYoG8rpB70WPkzpF4gAfpbg+9F6pun958er6LHywF4QCaQgNLTapVq4ZZs2Zlet9z586pf3fu3Il33nlHuTJefvnlR+63ePFizJkzR5WwVK9eXTk4+DqZQYeHj4+PEj006tWrh9mzZ6v/U0TgxKufn1+O95EOjF9//RV3795VzgxuDx0Z3377ba729eDBg+jatWvauoODgxJK9OX8+fOYOHFi2jHg8/ftm1oS9/HHH2PlyoehyDr4+voqV0e7du3SbqNbZv78+fDw8EC5crlzl4nwIQh6QmGDtkouLIuJCLqOq8fZMvcorp8+qYQRZoFwIcX8/NNCUktWqabyRQRBEARBEEyG+9HA8kHAxS2p660+ARqPUBkbBcGZvbuw5afUwRvduE937VUgrytkDq9/45Li9CpvmXJwyiOih3qOh7fRCdKweMNsy14crB1y5aim42LRokVISUlRA3DmRWQFyyvIgQMHHvkbB+UUEzigp1iwatUqNaDfvHlzpuUpdC54eXmlu40D+JCQkDTho0iRIvjwww+V0FC8eHGVB9KsWTO992/p0qWYMWMGkpOT1fNQVOFzDBo0KFf7ev36ddjb2+Ptt99WpSfly5fH+PHj1b/ZQbGCpSldunRRx4r7SWcJy1RefPFFVcby3nvvPfI4K6v074X9+/er/eD7btq0abkqcyEifAhCDuAXMDu+cKn3QmckJSYi+PwZVRJDR0jIlYu4ff2aWg6vX6XarTEThC1z6QjxKl1WpZELgiAIgiAYJVGBwMKeQOhpwNoB6DoHqNqpwF7+4qED2Djrfxxto9bz7ZX7NjcDYCF3cPD58saXcSzsWJ4cSpa/PLP4mWzvV8erDha0XZDjc9+zZ0+ULVs2bT03g+e5c+eqPIznnntOrY8YMQK7d+9WQZz9+/d/5P5xcXGP5GFwnSUuhIIARYImTZpgyJAh2LJliwo7ZR4Iy1/0gSUodJEQujcoEFD44H7mZl/v3bunnoulLtxnukoGDhyIv/76K9vnXbt2rRJ4eHxI6dKlERQUpJ6Dwoezs7NasqNChQpYsWKFEq/oEqFzpnbt2jneJxE+BCEPsLaxgV+1mmpp2nsA4mKiEXjqeKoj5MRRxISHIfDUCbXsoXrt7IJSNWqrbBA6Qpw9isl5EARBEATBOLhxKLVdbWwoUKQ40HsR4Fu3wF6ek0jrZkzBg5QUVG36HFoOel1EDyPAFIUnlk9o/Pjjj2llJhk5evRots+lBZFOnz497TaGgl69elW5Iuhy0KBYYGdnlyZyaHCdTgrCMhwKJppbhNkZAQEBysWhr/Chm3lRtWpV3L59G3fu3FEul9zsq5WVlepCowk6dG40b95cuV6Y9ZEVFHTYAYblRRp0pGiODjpHKI5kpESJEli/fn3aerFixdRSpUoVVTLDMiMRPgTByKCwUalRU7VQIY8MDkrrFnM94KQSRs7t260W4u7rl5onUqMOXHxLMc7Z0LsgCIIgCEJh5NQKYNUwIOk+4F0D6LMYKPpfRkF+w2D5VdMmIjkpCRUaPoM2w0aIS9ZIRA86L/QpdTkcchhvbHsj2/t93/J71PNOdSvkV6kLxQcNln7o5kc8KRy802Gh24GFsFyFLgiWvmhQzNizZ48SInThuhYmamlp+UiJDN0pFy9e1Hub+BwaHHMQGxubXO+rp6enKufRdapQRGIXmOxISkpSx4gCR2bQmfLqq68+cru1daong61rKZIwk0WD+R4UnnKDOD4EIZ/hl7V7iZJqqdO2o/ohD75wNjUo9fhR3Lp0QeWFcDm6cS0sraxQomKVtG4xXmXLwdLI234JgiAIgmDicNC0ZxqwPbXuHxXbAi/9DNgVKbBNCLl8ESu++ARJ8fEoXbseXnj7A3VdJBjPNa2jjWO293umxDOqewuDTDPL+bCAhfo771eQrW1dXV3VklMoBNy6dQv+/v7p2tW2atUKLVu2THc7oTuBJR58DPM7yOHDh9NcCyzf4DGdMmVK2mPolGD3lycJEX3qqafSBAO+jqOjo1pys6+1a9dOC0HVnCrM/dANas3qOGmdbDSXx+rVq3Hy5EkVvsoyGC6PY/ny5eq4sYWuBp0wdLTkBoOGDNAaRNWsfv36qraJbWoeB2ueqFrRMtO7d2+184QtgJikm9ny77//qvvQ7sMAFT722WefVfVFgmAomPdRskp1NO7RD30+/x/emLsQHUeOQs1WbVHUyxspycm4ceYU9i75DX+MGYkfXuuHtTO+wIltmxAdFionThAEQRCEvCUpPtXloYkeT78J9FpYoKIHc9GWTx6PhLh76jqp08hRsLK2KbDXF/IOihlsWauJHLpo6x899VGBih55wSuvvIIFCxYoZwdb1bLsZePGjY/tNsJuLRzjfvDBB0rQWLZsGdatW5fW3YSlJCz54PNdu3ZNBadSGOnXr5/6e2xsLCIiIrLcJq1zyt69ezFz5kyVw5EXDBgwQOV5sCMOS3k+++wz5Z5huQuJiYlBVFRUpo/t1KmTyi6h44MujV27duHzzz/PUuzImMvyzz//qGPN1+Z+UdTJ7b4Z1PHx1Vdf4dSpU2qnbt68iY8++kjV9rRtm74394ULF5RwwQNet25d1dKGdVMUQ5jO+/fff6e7/xdffKHePJqaxsfy5DAohjVHTLylEtW0adMC3V9ByAz7IkVQsWFjtdCidv3ieURcvqgcIcwJuX83Buf/+VstxM2nxMO2uXVUpoidY/bKuyAIgiAIQqbEhgNL+gGB+wALK6D9VKDBozb0/CTy1k0s/3wc7sdEo3j5iujy0XjphmfisFUtW9ayewuDTDXo9KDokd+tbPOD9u3bq1IVDsT5Lzuc/PDDDyq8M6vxLruY9OjRQ5WPTJ48OS2Xo3Xr1pgwYYJ6Do6FGebJAFXNVUFTANu+MlfjcdAQwEDUxMRE9RoULPKCWrVq4euvv1YBp3SksHUvt41OEkIhg66M33777ZHHsvTnp59+UvvKMFM6Tyj2cPyuD1rbYWap/O9//1PHhe4Pb2/vXO2TxQOtGKiAYVLs008/rQ5Kw4YN1W3ff/+9aluT8QBS6GBaLlNdCfsUM72WNpiMwS9HjhxRbYVop6H6RnWNPYipWGk9kimgsJ6K9UX61nMdO3ZMCSkZ2+wYAp4yuli4D6YYMiTof27p/rh16fzDtrnHVIkMg7402BnGp0LlhyGptVG8XEWxhBop8rk1T+S8mi9ybs0XObc6hJ0HFvYAIq8AdkWBHvOBci0K9HxE3w7D4gkfIuZ2GDxLlUb3CVPgUCT7jg+mcG6NbQyhL5ytv3Llipoo1oI4cwpb2x4JPYKwe2HwdPREXa+6Juf0MCRs55pVVYShSEhIUK1uGRhrKu9Xgzk+KEgw+EQ37ZViBg8e+yzrBrVQJWLIC60/vD8FECpJpUqVeuR5qQpR7dIsR+yJzIRcTfQgjwtaEQRjQ8v74PJM9z6IvxerwlEZkhp48igig2/i5rnTatm37A/YOTopF0jpWqmOENfiPobeBUEQBJOD1yF0joaEhKgZJtZt616XCIJZcHknsPRl4P4dwNUf6LMU8KpcoJsQGxWJ5ZPGKtHDzccXL42ZmGPRQzBOKHI0KN7A0JthknDin9UOxsi8efOUY8WUMJjwERYWBjc3t3S9jdmuhrkfrBdyd3dPZyuixadPnz5KLeXFB9vzZEzBpTBCVVW3xZAWwkJ7zB9//KFej/VBTLoVBFODwkb5Bk+rhdwJvaVavrFjzLVTxxAfG4uL/+5XCynqXRz+qm1uXfhVrwl7p4Kr1RUEQTBFTp8+jU2bNiE6OjrtNhcXF1WGm9tgNUEwGg4vANaPBFKSAL+GqXkeTsUKdBPi7sao8hZ2vnPx9EK3sZPg5OpWoNsgCMYM8y3ZocUYefXVV41224xO+IiLi0snehBtPWO/48jISCWU0KnBeiP2JWaCLmuedENS2PP4+eefT1f/w5Kaffv2KXfJN998o5JvWepC0aVNmzZPbJ8zUGVQptthDNsiGPbcunh6o0bLNmpJSUlGyOVLqSLIyaMIPn8Wd0Ju4UTIJpzYugkWFpYoXr4CSikhpA6Kl6+kglaFgkE+t+aJnFfz4syZM+paIiMUQXg7HaVVqlQxyLYJeUeh/tymJANbP4HF/m/V6oMa3YFO3wLW9qldXQqI+Hv38Ofk8bgdeBVObu7oNmYSnD2K5fqcGNu5NZbtEEwTYxYWbIx42x6HwUY9TIXNKHBo6xlrcxiqwrY+WgIu02upgP35558YMmSIuo3CBtvmMEBGFzpEWF/H52AYCzNBWGbDoNMnFT544WMMVld+iVLQIcZQvygYz7l19PRGlZZt1ZJwPw63zp9F0OmTCDpzCndu3UTwhXNqObBiCWzs7eFTqSp8q9SAb9XqcPEqLu+nfEQ+t+aJnFfzKm/ZsGFDlvfh39kq0BiuBYScU2g/t4n34LTxHdhc3qxW454eifiGbwOx8ZQiCmwzkhLi8dfMqQi5dAF2TkXQ5u2PYOHgqLI5zO3c8ntFEIRCLnzQlUEnBwUL64ezznR1UPSgpVQXtq7t379/2jovOJjbwfRbDZa48LkaN26c7rFeXl5p/Yw1GHySsROMPnC7jCGYSFOPjSW4STDSc1u0KDy9i6NG04dtp26HqYBUrSzmfkwMAo8fUQtxKeaFUjVT3SB+1WtJjW0eI59b80TOq/nAlnkMT88K/p2Ds6wS/AXjp1B+bqNvAit6wyL4OB5Y2QGdv4N9jW7IXWzlk5OUmIg130/HrQtnYevgiG5jJ8K7THmzPbecfBUEoZALH7SKUvCgYFG/fv20jA46MjLOpFC8YA9gXZjcqtvRhf2L2fqGThJdWBozZ84c1c7W2Tk1LIktbX19fZ94m/kFagxforrbYizbIxj/uWX9bI0WrdXCzjChVy+rkFQKIQxHjb4dilPbN6sFFhYoXrZ8atvcmnVQomJlWFmbnqXN2JDPrXki59U8yE700AgPD1cTKIJpU6g+tzePAYt6ATHBgGMxWDDPo1RqR8WChJ3qNsyciqvHj8Dazg5dR32K4mUrmPW5NYZtEATBwMKHg4OD6uv7ySefqB6/oaGhKh2WfYI19weFCjpAWFP78ccfq/7B7OqybNky5fbo0qVL2vNduHAhrZOLLs8884y6QPnoo4/w3nvv4dy5c+rxugGoglDYYBtc77Ll1dLwxe5IvH8fN86cUtkgbJ0bfiMQty5dUMuBlUthY2cPv2o1VFCqf826cPctKT/mgiCYFfqWr7DcJTg4GE8//TQ8PT3zfbsEIVecXQ/8OViVucCzMtBnCeBW8I4lTrj89cPXKnyd+WIvvj8OvpUkL0cQhILDoMmGDCil8DFgwADVnnb48OFpbXGaNGmiRJCuXbuqri6xsbGqk8utW7eUW2TBggXpgk1v376daeAYS1Po+JgwYYJ6LoaaUkRp2bJlge6rIBgzzPsoU6e+WsjdiPD/ymJOHsO9O1G4fORftZAi7h5pbhCKIY4u6TssCYIgmAq0xp88eRLr16/XSxxhzT4dqlzKly+PRo0aoWzZsiIGC8YFSz72zwI2j+MKUK4F0H0+YF/UIJ+xbfN+wOk9O2BpZYWOI0fBv2btAt8OQRAKNxYPJG5Yr/o8luTUrl3baDI+WGNsLPWLgnmfW87ShAVeTRNB6AxJTkxMdx+v0uXgXytVBPGtVBXWGTo2CcZ5boXcI+fVtOGkyrp161Q3F+Lq6oqoqKjH3p8OVGaG7d+/XzlIdUty6QBhCa4pJt0XNsz+c5ucCKx/DziyIHW9/qtAu68AK2uDHOvdf/yCQ2tXqDLaF4a/j8qNmxWac2tsYwh9uX//vooVoGs+Y9MJQTDV96v0shQEIduyGK/SZdXSoNNLSEyIR9DZ06lCyImjCLt2BaFXL6nl39XLYW1rh5JVqqU5Qor5+RvFxYcgCIIuFDvWrl2rOkDQydGsWTPlNqWgsWnTJtXJTTfcvG3btqhatapaZ7gpsz4OHDiAo0ePqnLdNWvWYOvWrWjQoIFa6GQVhAInLhJYOgC4sos/4ECbyUDD15XoYAj++XNxqugBoPWQ4fkqegjCjRs3lKufnT5LliyZqwNy7do1dOzYESdOnMjV87CZx/jx41VjDVYevPPOO+jcuXPa34cNG4bt27ene8yPP/6I5557zuD7evDgQXz++ecq/LtSpUr47LPPVIORgoT7yW3jMWnYMHfZRCJ8CILwRNjY2qnOL1xIbFQkAk8eSw1KPXkMsZERKriMC3Fyc4d/9Vrwr1VXOUKcXN3kiAuCYDDi4uKwcePGtAs8ujWYGebj46PWKW7wwo4XgiEhIaoLnb+//yMZICy3ZSkuL06PHDmiLhA507xr1y51gUv3B10g7CwnCAVCxGXgjx5A+AXAtgjQbR5QsY3BDv6hdSuxb9kf6v/PDXhNhasLhY8Hycm4d+gwksLCYO3pCcf69WBh5O4X5jgNHToU8fHxeRLtQEfCkiVLVDOOsWPHKmdCzZo11d/ZwGPq1KmqbFKDjiVD7+v169fx2muvqaVDhw74+eef8cYbb6iJAdsCdHYzFkNrUZ1bRPgQBCFXUMio0vQ5tdBiGn79mhJAKITcOH1KCSGs6+VCPEuVRqmHwolvlWpKSBEEQSgIGIROZwY7vdGJ1rhxYzRv3lx1mdOFIgddHZydy84yz7B2Pg9FDrpI/vnnHzVDRXs7F17g8m8VKlTQO0BVEJ6Ya/uAxX2BuAjAxTc1xLT4f90PC5oTWzdh128/q/837tkfddv/N8MtFB6iN29GyOQpSLp1K+026+LF4T16FFwe5joaG3TujRs3Lk/CqwMDA7Fjx440V0bFihXV78LChQuV8JGQkKB+LyiUGyIse2sW+/r777+rbXzrrbfU+ujRo5Xzgt1RC8r1wd9rlqTmFSJ8CIKQZ3BwUKxUabXUe+FFJCUmqla5LImhEBJ65ZLKC+FyeN1KWNnYwLdyNeUEKV2rrhJFWFojCIKQl3Am66+//lLODM2twc5yfn5+efYarN9n9zkunCmjAHL69GlVd8zF3d1dCSCs9S/I2TKhEHB8MbBmOJCcAJSoA/ReDDgbzml0Zs8ObJn7nfp/g87d0LBLD4Nti2BY0SPonRGpQbs6JIWEpN7+zdf5Ln6wPIMuBQoN7AxarVo1zJo1K9P7arlNO3fuVOUoFK1ffvnlR+63ePFi1TiDJSz8vqeDg6+TGXR40E2oW4pSr1491bCDUETgtXNufovowPj1119VS3Y6M7g9/I359ttvc7WvBw8eVI1BdEV+CiX6cv78eUycODHtGPD5+/btq/7GRiMrV6585DG+vr5pZT88vnTCsOsr9ysvEOFDEIR8w9rGBqWq11JL0z4DcS/6jiqL0Rwhd8Nvq3UuexbOh4NL0Yctc5kPUhvO7sXk7AiCkCsoOqxevTottJQ1wqyLzk/xgRexXPiavHhkB5iIiAjVCpcXdbzwfeqppwrUziyYISkpwM7JwO6pqetVOgFdZgO2jgbbpAv/7sfG72eowW7tNi+gae8BkvNlRtDZ+yAuLvv7JScjZNLnj4geD58EsABCPp8Mp0aNsi17sXBwyNV7iI6LRYsWqY5cHID36tUry/tPmjRJ/csMp4zw+5tiAgf0FAtWrVqlBvSbN2/O9Ps8LCxMlVPqQuGdZZSa8ME8qA8//FD9VrA0kl1OmTmlL0uXLsWMGTNUkC6fh6IKn2PQoEG52tfr16+roNC3334bhw4dUl3MmFXCf7ODpT0skWEZKY8V95POEicnJzXpMGbMGLz33nuPPE43APiLL75Qj6dbMq8Q4UMQhAKDbW8ZbMaFP54RN2+khaReDziJuOg7OLt3l1qIR8lSaSKIX5Uaqu2uIAiCPtBCTHuxdkHHji0MlOPFakHB12zdurW6iKW9mS4QzmLt3bsX+/btU7OPdIHkNphOKIQkxgGrhgEBD2dNm4wEWoxjnZbBNonZXuu//lJ1g6vWrCVaDBwqoocZweu2a336Iu7o0Tx4slTnx/kGT2V7V4e6deH/x+85fi/17NlTtRzX4OA7p8ydO1flYWjBoyNGjMDu3btVSUb//v0zzZTKKLJznb9PhIIARQIGaw8ZMgRbtmxRYafMA2H5iz6wBIViOqF7Y9q0aUr44H7mZl/v3bunnoulLtxnukoGDhyo3JPZPS+Dwynw8PgQlo4GBQWp56Dw4ezsrJbHwd9HThiw61peIsKHIAgGgT9gHr5+aqnbrhOSkxIRfP7cw5DUo7h16QLCbwSq5ciG1bCytkaJilXSusV4lyknZTGCIGQKZ6poo6XLgvCikAKEnZ1hMoX4unSasNsL7b9sh8vw1FOnTqmF7hAKIKybNqWWl4KBuBsKLOoNBB0CLG2Ajl8DdfoZ9HSw1f3qaZ8jOSkJFRs2Ruuhb8tvtDligl36WD6hwc4gWplJRtihKzu0INLp06enK6Vk1xO6Iuhy0KBYwO9+TeTQ4LrWcpVlOBRMNLcIfwMCAgKUi0Nf4UMLSdXCuW/fvq2Ctulyyc2+WllZoUWLFmmCDp0bzMSi64VZH1lBQefs2bOqvEiDjhTt943OEYojGSlRogT+/PNP9fcJEybkeStlET4EQTAKrKxtULJqdbU06dUfcXdjcP3U8VQh5MRRRIeF4vrpk2r5e/GvsHd2USU0pR86QlyKpbcSCoJQ+EhKSlI1y3RUcHaSM0qdOnXKU6tsbmC4KS9suTBJnw6QkydPKqGGCy9+KZDUrVs3zy/4BDMhJABY2BO4cx1wcAN6/g6UbmLQTeJExcovP0VSQjzK1KmP9m+/D0sR8MxyworOC31KXe4dOoTrQ4Zmez+/ObPhWL9+vpa66AreLP1o165djp+Lg3c6LHQ7sBCWq9AFwdIXDX6f79mzRwkRunBdCxPlb0LGEhm6Uy5evKj3NumGZvN3j9jY2OR6Xz09PdM5JOlUoYjE3y59fot5jChgZAadKa+++uojtzNonB3X+HvIEhtdKCrRLcKWujlFhA9BEIwShyLOqPh0E7Xwizzq1k1cO5GaDXI94Djux0Tj/P49aiFuJUo+DEmtA7+qNWDrYLgaZ0EQCp6bN2+qi87Q0NC0WTBe9DGQzRhhrTnrl1u1aoV///1XLZylY604xRvOlFEEYSiqICgubAWWDQQSYgD3ckDfZYBHOYMenNuBV/Hn5PFIiItTv70dR45SExmCeUIBwsIx++srp8aNVfcWlrNkmvNhYQFrb291v4JsbcvyQy45hULArVu3VItz3Xa1/B5ndpTu7YRh1izx4GO01uYs4eDtWsgnj+mUKVPSHkOnBLu/6AtdhMyMIhQN+DqOjo5qyc2+1q5dOy0EVXOqUJDQpzSTx0nrZKO5PJi1RaGf4assg+GSGbydv4O60LHJPBJ2UMsNInwIgmD08EfBzcdXLQxLo5X21sXzqiSGQsitC+cRefOGWo79tU7NNPlUqKycIKVr1oV3ufKwtBT7uCCYI5yB46wa66wZXseLPdpwq1SpAlOArhTaiZs2baouWukCYSAes0m40B3CmbNSpUpJXkJh5sAcYNNHwIMUoHRToMevgKNhRbHI4CAsmzQW9+/GwKd8Jbz44ThpUS8oKGawZa3q3kK3hq748dC9wb8XpOiRF7zyyisqmJOZFXTmMYtj48aNqqwlM1jGyPyODz74QD2OA3/mVrBVLOF3/8iRI5XITbGb5R8URjRXA1u5spQmKwGcJSgUBdjVZebMmZk6KXLCgAEDVBcWloo+88wzKt+E7hmWuxC2hefvb2biCp2WDIGl44Mhq2zZ+/nnn6vjlx10O2YUkIi3t/djxRJ9EeFDEASTg3kfvpWrquWZ7n1xP/YurgecUI4QlsVEhQQj6GyAWvYt/QN2Tk6qLMa/Rh3lCCnqZbg2f4Ig5B10dzDLQ7PeUuxg27vcBLoZClqTeYHJi2nWkTMHhP9y9o8LHSIUQFjDTTuwUEhITgL+GgUcnJO6Xrsf0GEGYG3YlsjRt0OxbOJY3LsTBU//Mug66lNxWgrpUK1qv/kaIZOnIOnWrbTb6fSg6JHfrWzzg/bt26tSFQoM/JcdTn744QclhDyOr776SokePXr0UOUjkydPTsvloJOBWRZ8DroWWZZJgUFzVbCVK3/jtBavmdG7d28ViJqYmKheg4JFXlCrVi18/fXXKuCUjhS27uW2cXKBUMigm+W333575LEs/fnpp5/UvrI8heIIRZTHCUQFhcUDrRhIeCxUs5jGTsuPMYSO8ZTRDsuasNzUvAnGh5zbvCEq5FZqt5iTRxF46jjiY2PT/d3V2yetWwwFETvH/B8kybk1T+S8GgY6OygM8GKQv9GcIXrhhRfUhVle/S4aw7mlsEMHCJ0grJnWHCK0NVMk0S5ABdM7t3pxPxpYPgi4uCV1vdUnQOOHM+gG5G5kBJZ88hGibgWrMtNen3wBx6I5t9Sb87k1tjGEvrDTCFuBs2Qht3lDbG1779BhJIWFwdrTE47165mc08OQ0DFBAcTYSEhIUDkcDIw1lferTBkIgmB2uHoXh+vz7VDr+XZIYS/5yxdx9cQRJYYEXzinHCFRW4JxfMsGlTpPiy5FEP+adeFTvqKEsgmCERMeHq6yPFhrTDhDxtIWFxcXmBteXl7KMszacXYMYA4I7cWsnd61a5eakWM3GC0oTzAjogJTQ0xDTwPWDkDXOUDVTobeKsTFRGP5pLFK9HDx9Eb3sZOMRvQQjBOKHE4Ns29bKzwK2+TSBWiMzJs3TzlWTAlxfJigWmtsaraQd8i5zX/i791TnWGUI+TEUVWjrAtDUUtVr6nKYvxr1VHukLz4nMm5NU/kvBasy4OD/y1btihLLxPm27Ztq+qi8+O30BjPLV0fbH9LFwjD8jRot2YZDLsBGMu2GjPGeG7TceNQarva2FCgiDfQezHgW9cofj+XTRyDkMsXUMTNHT0//UpNNBgTxnZujW0MYQjHh5Bz+FvHMkhjJNGItk0cH4IgCJlg5+iI8vUbqoWwTa5qmXvyGAJPHlMhbRf//UcthDNaWstcv+q1VLcZQRAKlqioKJUIzwtxwnpqrW64MMFsDw6g6PS4evWqEkCYus/Wh1zoEKEDpEaNGkZzQSo8IadWAKuGAUn3Ae8aQJ/FQNHsuyjkN4n372Pll58o0cPB2QXdxn5udKKHIJgbxvw9bmPE2/Y4pNTFxHiQ8gDxV6KQGHIH8d4PYFfGFRaWhle0BcFUcfH0Qs2WbdSSkpKM0CuX09wgQefOIDosBCe2bVKLhYWl6hCjhJAadeBTsZJebfv4vDdOByDs5g14liiJklWrSZcZQdBz9vbo0aPYtGmTqifmwP/5559HgwYNYGlpWWiPIWeyORPLhaU/7P7C48RMEFqjt27dqo4RF4bMCSYAI/f2TAO2T0pdr9gWeOlnwM7w5y8pMRGr//c5gs6eVplYL42ZCI+SfobeLEEQhCdCSl1MyKYWd+o2otZeQvKdhLTbrIrawrVjOThUL2aw7RLM16JZ2Em4H4cbZ07h2vFUR0j4jcB0f7exd4Bf1eoqG4SOEPcSJR85bxcO7MP2+XNwN+J22m1F3IuhxcAhqNDwmQLbFyF/kM9s/hEdHa1a+124cCGtLSBdHrltZ2eu5zYuLg5HjhzBwYMH1XYTXrPQ/UEXSPHiMjtvtOc2KR5Y+w5wfFHq+tNvAq0nAkbQhp3t49d9/YVyQdrY2aPb2IkoUdF4W0Ub27k1ljHEkyKlLoIpoe/7VYQPE/nSougR/vuZx/7do18VET/MAGP7wRbSExN+WwkgqR1jjiEuOnVwoeHs4fkwJLWO6hYTdCYAa6ZPfuxh7DRytIgfJo58ZvPnmDLHYv369epihr+7LVq0UBkWBenyMNVzy2uWM2fOqDKYGzdupN3OC0IKIAyDLcxuGaM7t7HhwJJ+QOA+pkAC7acCDV6FMUC34sZZ03F27y5Y2dig68efqN82Y8aozq2RjCFygggfgikhGR9mVt5Cp0dWRK29DPuqHlL2Igj5iLNHMVRv3kotD1JSEHrtik5ZzGnEhIfh1I4taiGW2Vzk7FgwB+UaNJSyF0F4SGxsrBI8Tp8+rdZ9fHzQpUsXlV0h6AcHV2zry4WdbyiA8HhyNowLHTMNGzZUAzEGxAoGJOw8sLAHEHkFsCsK9JgPlGthNALC1rnfK9GDv2UU6o1d9BAEQcgKyfgwAeKv3ElX3pIZyXfi1f3syxWuoDdBMBRsg+tdppxanurcDYnx95XD4+pDR8jtwKuqlW52DhI+xq9azQLbbkEwVuhSWLdunRI/6Eh49tln0bRpU5OaJTU2WB7EheGwLIE5fPiwygTZsGEDtm/fjnr16uGpp55Ss+NCAXN5F7C0P3D/DuDqD/RZCnhVNhrRY9dvP+Pktr9UtlX74e+jbN0Ght4sQRCEXCHChwmQEpOQp/cTBCHvYe1z6dr11EKObV6PbT//kO3j7kZFyukQCjXMpti4cSNOnDih1j09PZXLo0SJEobeNLOB3W9at26NZs2aKds9XSCRkZHYu3cv9u3bh2rVqqkymJIlDd89pFBweAGwfiSQkgT4NQR6LQScjCerbf/yhTi8fpX6f+uhw1GpUVNDb5IgCEKuKdxFniaCpbNtnt5PEIT8x8NXv8T7Iq5u+b4tgmCssAXr999/r0QP1uM3btwYQ4cOFdEjn7Czs1NlLsOHD0evXr3g7++flqkyd+5c/PzzzwgICFC5BEI+kJIMbB4LrH07VfSo0R14eY1RiR7/rl2B/ctTQ1afGzgU1Z973tCbJAh6w1yjSpUqpcs3elIoDvP7sU6dOmjTpg2WLVuWqzNAkZnfuXw+5lWxNbsuw4YNU9usu+zYsaNA9vXQoUPo2rWrKn3s3LmzEsILipMnT6rjzPbsPM6rVqWKrfmJOD5MALsyRVX3lqzKXSwcrNX9BEEwDnyrVFPdW3S7uWTEydVd3U8QChvx8fHYvHmzKr0g7u7uyuXBsgwh/2EpUeXKldUSHByM/fv3K/GDmSBcWPpCgaRu3bpZJuQLT0BCLPDna8C59anrzUcDzT5kb2KjOYzHt2zA7t/nqf836fUy6rbraOhNEsyAlJQHCL4QhdjoeDi52MGngissLY3nfa9LWFgYXnvtNfTu3RtffPGFEoJHjRqlnIjNmzfP0XPy8QzfXLJkCY4fP46xY8eqsOmaNVPLnC9duoSpU6eqAG+Ngig/DA8Px+uvv64WCg/M13rjjTdU+/j87gIWExOjjjN/97nvbMc+evRodQ3AEsz8QoQPE8DC0kK1rM2qq8uDuCRErrgAt87lYWEjRh5BMDSWllaqZW1WXV0SE+7j1sXzRt0aUBDymqtXr6qZHeZOEA6wW7ZsKUGbBoIBspzxe/7551UOCGcA2RWDwtTOnTvVLCXPEcUpIYdE3wQW9QKCjwNWdsCL3wM1uhnV4Ty9ezu2PizPfOrF7mjYpYehN0kwAy4dDcWeJRcQGxWfdpuTqx2a9qyAcnWML7R669atKFasGEaOHKnWS5cujQMHDqjW6jkRPgIDA5V7Y9u2baqUsGLFispRsnDhQiV8JCQkKMcG245TXClIjhw5ojK0Bg8erNYpgPzyyy9q+9q2bZuvr03BnTleH374oXJ7UvDga3ObRPgQVKtatqxldxdd5wedILZliiLueBjuHQpBYnAsPPpWgbW7zNAIgqGp0PAZlYS/ff6cdM4PJzd3WFnbIDosBEs/G422w0agcuNmBt1WQchvEhMT1cUf8yW0Ga0XX3xRzXwJhsfZ2VkJULwY5awkz9Pt27fVRT8FEVqqOSNZqlQpo2gTajLcPJYqesQEA47FUvM8SjWEMXHhwD5s+v5rppqiTtuOyu0hCHkhemyafeqR2ymC8Pa2Q6vnu/jB7y26GCg0UMRlntGsWbMyve+5c+dUoHaVKo9ORt29ezft/4sXL8acOXNUCQu7Z9HBwdfJDH6XUlzWzU/iwH727Nnq/5cvX04b+OcUOjR+/fVXtY0dOnRQ28OOXd9++22W++rq6qomIChyU/jm7zPDxSnO6EN0dDQmTpyoHufo6KhcIx988IFyCa5YsUI5XTKD9+drfPXVV2o9JSVFiezsOtagQf6GKIvjw8TED7asjb8ShZiQO3D2Lgq7Mq7KEXK/njciFp1FYtBdhM46CvdelWFfUbIDBMEYxA+2rL1xOgBhN2/As0RJlKxaDUkJCdjw7TRcOnQA62dORWTwTTz9Ui8ZUAhmCWe0Vq5cqay1hCUUDNuUMgrjw8bGBvXr11cX58xgoQBCK/bZs2fVwot4CiBVq1aFtbVcRmbJ2fXAn4OBxHuAZ2WgzxLArTSMiSvHDmPdN1/hwYMUVGveCs8NeE1+h4THwkygpIQUvcpb9iw5n+V96AQpWdk927IXa1vLXL0n6bhYtGiRGmDz+4u5Eo+DAoWuSMHfLJaAMKODsBsWxQQO+Cna07348ssvK/Egs/IUls5kbMfOluIhISFpwkeRIkWU84ECM0tM+FoMotaXpUuXYsaMGSqbic9DUYXPMWjQoCz3tX79+ujbty/efvttVf7Ix0+ZMgVly5bV63XHjBmjJjR4bFm+OmnSJHz22WeYPHky2rdvr0SkzNB1D9LxwusBPg+3lVkj+Yn8YpkYFDnsyrrivocF7IoWTfsisK/gBq+366hymMQbd3H7l1NwaeUP5+f81GMEQTBs2YtftRpwKVlK/TDyc2tr74BO743G7j/m4/C6ldi37A9EBgeh9dC3YW0rQcWCeZCUlKRmctg9hBfMvMBjgFqFChUMvWlCNvB7iueJS2hoqBJAGEJLizJn87Zs2aJa4VIg4WyfoMODB8D+WcDmcVwByrUAus8H7I0ri+366ZNYM+1zpCQnoWKjpqqDC1u1C0Jm8Dt8xdQjuHX5Tp4cIDo/5r67O9v7+ZQrii7v182x+NGzZ890g3knJye9HsdcDgoILH3hcxCGQDOA+7nnnlPrI0aMwO7du7FmzRr0798/065ldF/ownUO+DXhg6/TpEkTDBkyRH2vMuyUeSAsf9EHZmNo5SHvvPMOpk2bprab+5nVvsbGxqpMp7feekvtD8UbihcMGy1Xrly2JTwsC6JYQ7cgoRhEFyedHrxN34kN7iuPA0UTlha98soryC9E+DAjrF3t4TW0liqHiT14C9FbriHhegzce1SEpaONoTdPEIRMBJHm/V+Fu48vtv78Pc78vRN3wkLR+f0xcHQxrgtkQXhSOECmy4ODZsKLuHbt2skg2QThjGWnTp1UKQwzQP79918VTkfL8q5du9SFMtvhFnSNulGSnAisfw84siB1vf6rQLuvACvjuuQOvngOK7/8DEmJCShbtwHavzVS/SYJQlaYYpWbr69v2v9//PHHtDKTjDBgU1cUYIkMM6lYJuPg4JAuiHT69Olp96XbgffjdyMDOzUokLCTliZyaHBdEwX4GhRMNLcIA6cZqEoXh77ChxaSSujEY4kic5roxMhqX+fOnavELAofhGVAFLdZNvPpp59m+Zo8DnTQsDRSF9527do1JWRMmDAh08fSQaO1q6cIxNflwmuF3377TYQPQX8YbOrWtQJsSzkjctVF3D8bgZBZx1Q+iG2JInIoBcEIqdmqLYp6FcfaGVNw89xpLBwzEl0+mgCPkqUMvWmC8MTQLvv333+rATEvgugGYN0xL8gE04azh7Rgs+0wu8DQBXLr1i3VnYdL+fLlVRkMZ1cLZQ5IXCSwdABwZRctukCbyUDD141utBh27QpWTJ6AxPtxKFW9Jjq+O0rlTglCVvAzTeeFPqUuNy9EYd2s49ner8NbtVCigmu+lrpQfNBgOQUF+KxgVgYDP+lqWLBggXIh6P6+0WGh24GF0M3I70fdlqwUM/bs2aOECF24ronELDHJWCLD70+WGeoLn0ODQoZWspjdvgYEBCihRRfmm1y4cCHb1+RxoKvjzz//fORv3t7e6phREH+ckE6nCcUi3XIY/n4wNyU/MS75WcgznOoXh41PEYT/fhrJEfcR+v1xuHUpD6d63nKUBcEI8a9ZG70nTsPKrz7FnZBbWDTuA3UxytsFwVTgjA0v/G7evKnWeVFF0YMXhYL5wGwP1mLzwpYXrxRAGJbHi3UuvLClA4QzlrwALxREXAb+6AGEXwBsnIBu84BK+dsZISdE3AzC8s/H4X7sXfhUrIzOH4yT8kpBbyhA2Nhl7wzyq+quurfodnPJSBE3O3W/gmxty0BPLo+DYj0dEMylovsgY8kHcz0o9vr7+6fdxtKOVq1aKUec7u2E35NBQUHqMVqLWIrEWpbFxx9/rI4pszU0mKWkb8AoOX/+vCo7JHRs8HU44cAlq3318vJ6RGChU0M34+Rx8DjQ9cdtZ+A14W/AzJkz1b64uLhk+bvP7aQjhJMkmvuFYrq++SI5RQr5zBhb3yLwHl4Hdgw5TUpB5LLzygXyICl7pVYQhILHo6Qf+kz6H3wrV0X8vVj8OWU8jm/ZKKdCMHp4sbhv3z5lq6XowQsZtkhlXbSIHuYLL3p5Ady7d29VU86LbwodFMBY887APQYL6nZEMEuu7QN+apkqerj4Aq/+ZZSix53QECybNAb37kTBs3RZdP34E5U3JQh5DcUMtqzNiiY9KhSo6KEPy5cvV52smHXBwTvDSblo7deZP0EXCAV+OkJY9rJx48bHZmKwWwvzO9jthILGsmXLsG7dOhUqSlq0aKFa5fL5WCLC4FQKI/369UsruYmIiMhym5mtwe4xzNKi8DBw4EC99rV79+4qn2T+/PnKgcF/KUT06dNH/Z3ZI9z3zOD+0q3x/vvvKxGD7hEKQPfu3VPHLTvYGpiOkfHjx6tuLjwGLL1hvkl+Io4PEyM55QEOXgnH1ZBIlPZOwlNlPGCVxZcGsz2KDayG6G2BiNkWiNh/glXnF/d+VWBd9D/rlyAIxgGzPbqN/RybZ8/EmT07sHXud4gMvoFn+w2S+mvBKGHqPS/aeOGk2VWZB6HPxY9gPrBTAZP8GZJ35MgRNXhgu0OWPPFimu4PukC0WU+z4fhiYM1wIDkBKFEH6L0YcDa+fbwbGYHlk8bibvhtuPv6oduYibB3EieWkH+wVS1b1rJ7i67zg04Pih753co2J/z1119KyGc+hy4UdekA4XccS1UoMPBf/t798MMP6cphMsK2reyA0qNHD1Xiwq4nWi4Hu5vR+cDn4KQBw6QpAGiui3nz5qmsLHaTeRwUnikYsDMKX2PAgAF67Wvt2rVVy1vuyzfffKNEbLbp1cLHN2zYoMQMOjket18UiCi00AVIIYStdPWBZUHcT4o2nCRxc3NTJUR0zuQnFg+0YiAhyzqmY8eOqTeIlZXhgp82nQrGp2tPI/jO/bTbfIraY0LHqmhb3Sfbx8edjUDE4nN4cD8Jlk42cO9dGfbls66rEwoWfhwZSKR1/hAK77nl/f9ZsRj7lv6h1svWewovvP2BzM4ZGYX5M8uLQ4a5MYWeF1wMKWvTpo1qTWcOx6Iwn9u8unY6c+YM9u/fr6zeGry4pgDCi2vd2nSTO7cpKcDOycDuqanrVToBXWYDtsbX4eZe9B0s/XQUwm8EoqiXN3p++iWc3YvBHDG2z62xjCGeFM72cyaen9fcth1na9vgC1GIjY6Hk4sdfCq4Gp3Tw5hhW1oKIIXttfPj/SqODxOBosew34+wKVo6bt25r27/oV/dbMUPh8ru8B5eO7XlbXAsbv98EkXblkaRZ0saxY+DIAj/wc9ko5d6w83HF5u+n4HLhw9i8YSP0OXD8XD2MM8LVsF0oO2XpQysByac7WKbWs7aCALhIK969epqoRuIOSCnT59WF6dc6BBp2LChGhBmbPdo9CTGAauGAQErU9ebvAu0GE9/P4wNVTY5ebwSPYq4e6D7uM/NVvQQjBOKHL6V5LchJ/B3lpMJhuDQoUNm59ATx4cJqLUsb2ny5fZ0Tg9dKFkUL2qPvz9qkWXZi0ZKQjKiVl3EvSOpLQYdqnnArXtFWNqLDmZojG2mQjCOc3vz/FmsnjZJ1WU7ubkr8cO7bHk5PUZAYfvMcn/5e7hp0ybVwo/2VlpTaQM21Ox9flHYzm1BCWYHDx5UNex8/xDOztWrV0+9hzJ2NzDKc3s3FFjUGwg6BFjaAB2/Buqk1uMbG4n372P55PGqW5iDS1H0/OQLePj6wZwxts+toccQxuD4EHIO3ZSGCohOSkpS71lj+Bzl1fvVvK5SzJSDVyIeK3oQukD4d95PHyxtrZTQ4dqlPGBlgbiAcITOOobEkNg83GpBEPKKEhUrq9BTtreNjYxQzo8LB/fJARYKFCa4L1q0CKtXr1aDVtYgv/7666pswdxEDyF/YIcB1rSPHDlStVmkQ4gXrAzlY405gwV1y2KMjpAA4KcWqaKHgxvw8iqjFT2SEhKwatokJXrYOTmpTA9zFz0EwdwwZFcsa2trkxA9ngSZ4jcBQmPu5+n9CN/IRRr6wMbHCRF/nEHS7TiEfncMbi9VhGOt1N7SgiAYD6zLZrvbdd98iavHDmPN9Clo2nsAGnR6yex+mATjg23m1q9fj7i4ODUDxADLZ555RgQPIUfY2dmpMpcGDRqoVozMAWFHA77PuLATAgU1tkM2mlnyC1uBZQOBhBjAvRzQdxngkXknB0OTnJSkfisCTx6DjZ09un78KbxK52+bSEEQBGNHhA8TwMvZPk/vp4tdKRd4Da+DiEVnEX/pjvo3ITAaRduXgYWVzOAJgjFh5+ioylx2LPgJx/5ahz0L5yMyOAitBr8BK2vDzQoI5gtb6VHwYDYDYb1vly5d4O3tbehNE8wAOoUobnBhRwPmgFD4YCYIFzpEWALDGneD2u0PzAE2fQQ8SAH8mwA9fwMc3WGMpKQkY+N303Hp0AFY29iiy0fjlWtQEAShsCPChwnwVBl31b2FQaaPa8HjZGeF2n4569BiVcQWxQbVQPSWq4jZeQN3995EQtBdePSpAisXEwscEwQzx9LKCi0Hva5CT3cu+AmndmzBndAQdBw5Cg5FnA29eYIZcfbsWaxdu1aJH3QVPfvss2oxmhl4wawoUaKEamvIzJh///1XBesxE2Tz5s3YuXMn6tSpo1wi7u4FKDgkJwF/jQIOzkldr90P6DADsLY12nyLrT99h3P7dsPSyhod3xsFv2qpbTMFQRAKOzKlbwIwsJQta8njDO2x8cnoMXs/LoXdzdFrWFhZoGjbMvDoXwUWdlZIuBqNkG+PIP7qnVxsuSAI+UXddh3x4kfjYGPvgOsBJ7Bo7PvK/SEIuYXlLCtXrsTixYuV6OHp6YnXXntNlbeI6CHkNy4uLmjZsiXeffdddOjQAcWKFUNCQgIOHDiAb7/9Vr0vWRbDQX6+cj8aWNTrP9Gj1SdA51lGLXpQDD+5fTMsLCzxwtvvo2ydBihMsG1q0PlIXD0Wof7luiAIgoZ0dTGhRGa2tP107el0Qad0gnSq5YMlh24g6l4iHGysML5jVfRq4Jfjuv/EsHuq5W1SyD3A0kKVvRRpXEJyBAphGrlg/Oc2LPAqVn75KWJuh8G+iDM6vzcGJatWz7PnFwrXZ/bixYuqfV50dLRab9y4MZo3b27QgDVDYW7n1lRJSUnBpUuXVBkM/9Xw8fFBo0aNULVqVRXCl6fnNioQWNgTCD0NWDsAXWcDVTvDmNm75Df8s2KJ+n/bN95FtWYtUZi4dDQUe5ZcQGxUarcg4uRqh6Y9K6BcHS8U9jHEkyJdXQRTQt/3qwgfJvalxda2B6+E42pIJEp7u+GpMh7KEcIymJFLj2HfpXB1vzbVvPFF15pwc8rZzARb3kb+eQFxx8PUukPNYir41NLOdL60TRG50DZf8vPcxkZFYtXUibh18byyN7ceOrzQXfQaCnP5zLJLy5YtW1R5AWE5wYsvvohSpUqhsGIu59acCA0NVQLIiRMnVKtF4uzsrHJA2BLX0dEx9+f2xqHUdrWxoUARb6D3YsC3LoyZg6uXq8wn0nLQMNRu8wIKm+ixafapx/697dDqBhM/jGkM8SSI8CGYEtLO1kyhyPF0WQ+0q+qp/uU6KV7UHr+/2hCj2lWGjZUF/goIQdtvdmPvxds5eh22vHXvVQlFO5ZVro+4E7dV1xe6QQRBMC6cXN3QY8IUVHy6CVKSk7Dp+xn4e/GveJCSYuhNE0yAq1ev4scff0wTPTiIZJvawix6CMaJl5cXOnXqpMpgWHpVpEgR1WZ527ZtmD59OtatW4fbt3N23aM4tQKY/0Kq6OFdA3htu9GLHsf+Wp8mejTtM7DQiR4sZ6HTIyv+XnpByl4KCTdu3EClSpXUvzmFQlWvXr1UrlCbNm2wbNmyXG1TZGQkhg8frp6vRYsWqiW8LsOGDVPbrLvs2LGjQPb10KFDKluJwlznzp2xb98+FDQUsfnaLGXMbyTc1IywtLTA0Gbl0Lh8Mby9+Cguh8Wi388HMKRpWYxsXRF21k+mNHMWxLmxL2x9iyD8j7NICr2H0FnH4N69IhyqF8u3/RAE4cmxsbVDh3c+xF4fXxxYuQQHVi5F5M0gtH3zXdXOUBAykpiYqAaMnEEnnP3mxUfZstL2UjBunJyc0KxZM1WKxS4wfA/funVLXcRzqVChgmqHy/eyXm4d5oXsmQZsn5S6XrEt8NLPgF0RGDMBu7Zh27wf1P+f7toTT3XuhsJG8IWodOUtmXE3Ml7dz7eSW4Ftl5C+01DQmQDcjYpEEVc3+FapBktL43S/hIWFqUyr3r1744svvkBAQABGjRqlsq5Y9pkT+Hg6EpYsWYLjx49j7NixqiSjZs3U4GGW8E2dOlWV7mnw9zi/CQ8PV5McXCjwsIPbG2+8gU2bNqkObgXFvHnzVJg6g63zGxE+zJDqvkWxbngTTFp/BgsPBGL27sv4++JtfNOrDsp7PfmPuF3povB+uw7CF55BwpVolf/h3KwkXFqXVqGogiAYBxaWlmjSqz/cfEpg8+xvcf7AXkTfDsWLH45XrhBB0OAMEQNMeeFDtJktg7YMFYQnhNkenKmsVauWci5RADl37hwuXLigFjpEKIDUqFHj8Tk1SfHA2neA44tS159+E2g9kS20jPp8nP/nb/z1wzfq/3XbdcIzPfqhMBIbHZ+n9xPylgsH9mH7/Dm4G/GfE6uIezG0GDgEFRo+Y3SHe+vWrSpQeeTIkWq9dOnSKliZHc5yInwEBgYq9wYnGUqWLImKFSsqR8nChQuV8MHgZv4e8zuK4kpBcuTIEVV+NXjwYLVOAeSXX35R29e2bdsC2QYGVf/6668oX758gbyedHUxUxxtrTG5Sw3M6V8Pbo42CLgZjQ7f7sEfB3KWhG7lbAvPwTVQpImvWo/ZdQO3fz6J5LsJ+bD1giDkBuZ7dB87SYWd3rp0AX+MHomwa1fkoArKUsoLsJ9//lmJHiwV6NOnj3J6iOghmCp0dXAGlbO0tJSzXItCBzNBGNY7Y8YMNfi4ezdD57t74cCvL6aKHhZWwAvTgbaTjV70uHz0X6yfOQ0PHqSg+nOt0XzAa4U2h8bJxS5P7yfkreixZvrkdKIH4Tpv59/zG5aCfPPNN6oVNgf2LKfIWFaiLaRp06aYMmXKI8+j+93BzlIsWeGEQf/+/ZXY+jjo8GAQM0UPDeYRHT16VP3/8uXL6rPr5+eX432kQ4Ot5uvWrYvx48crMYVkt6+urq5pLcNVK+ytW1UnN4oz+sAQ9A8++EC9bpMmTTBx4kTlbCErVqx47GvrluZwe/mdXVBtysXxYea0rlYctfxc8f6y49hz4TbGrDyFnefC8OVLNeH+hMGnFlaWcO1QFralnBG5/DziL99B6MyjcO9XBXalXPJtHwRBeHLY2aXP5//Dyi8+VW1uF43/UJXClK1buNobCv/BUgC6PEJCQtQ6Z5jatWundyCkIJgCHh4eaN++vcoA4YwmZ2t5gb5r1y78/fff6n1PF4jjvRvA2sFA5BXAzgXosQAo1wLGDtuXr/3fFJXnVOmZZ/H8kDcLrehB3Eo4wdLaAilJj5/UK+JmB58KrgW6XeYKB8hJ8fF6lbds/2V2lvfZPn82StWolW3Zi7WdXa7e4xQ9Fy1apDpEUYRgfsfjoEChK1JwgoAlIBycq23evh2zZs1Sg3yKratWrcLLL7+sxIPMylNYOkPnWcbvKO13mMIHJyA+/PBDHDx4UJWY8LVYyqcvS5cuVeIug3T5PLNnz1bPMWjQoCz3tX79+ujbty/efvttWFpaqsdT9NG33HXMmDGqZJbHlgHpkyZNwmeffYbJkyer72CKSJmhiRx//vmnelyPHj1UPlNBIMJHIcDbxR4LXnkK8/ZewVebzmHL6RAcu74b03vUQtMKT26rcqzpCRtvx9SWt2FxCJt9Aq4dy8KpoU+h/vEVBGPDrXgJ9Jn0P6ydMRmBp05g1VcT0XzAYNRp21E+q4UIXszs3bsXO3fuVBd+FDpeeOEFVKtWzdCbJgj5hoODg8oAochx5swZ7N+/H0FBQcrGzaW0xU00egBUKOoPy75LAa/KRn82gi+cw8qvJiIpMQHl6jdEuzdHGm1WQkEQFXIP678/kaXoQZr0qKBy8ITcix6Lx3+Im+fP5MmhvBsRjlmv9Mz2fiUqVUWvT7/M8XVLz5490w3mmRGkD3QvUEBg6Qufg8ydOxdDhw5VwioZMWIEdu/erZxldH9kJC4uDra26Seaua65Mih88HXomBgyZIjqrsawU+aBUKTVh9GjRysXCXnnnXcwbdo0td3cz6z2NTY2FtevX8dbb72l9ofiDcULlg6WK1cu2xIeOkQo1rCzFqEYxG5wzDThbVm5SCkoMZCapTUFOXYU4aOQwC/8wU3LolE5D7yz+Bguht5F/58PYnCTMvigbaUnDj618XaC15u1lfMj7lQ4olZdQkJgDFxfLK86wgiCYBzYFymCrqM+w9a53+PUjs3YMX8OIm4GqfpaSxNqrSfkDM420eVx8+ZNtV65cmV06NBBzTAJQmGANezVq1dXCy/y929YjDPBMbj6oASu4kV4WLqi4dVo1HZNeGSAYkyEXr2MP6eMR+L9OJSqXgsd3vkIVtaF9zI+6HwkNs4+ifjYJBRxt0OtFn44tvV6uqBTOj0oehiqla1ZYoITnL6+qWX6hB3M6IjIDK38RBMFGPTJ7CDmcVBI1Q0i5aBdg64F3o/BygxG1aBAYmdnlyZyaHBdEwX4GhRMNLcIf6MZqEoXh77ChxaSSqpWrao6W7FdN50YWe3r3LlzlZhF4YNwMoStwpm58emnn2b5mjwOnEhhiY0uvI25HRR0JkyYkOlj6aChOMNuMvqW1eQVhfcbs5BSrURRrH2rCT7fcBq//xOIuX9fwd5L4ZjZqzYqeKcqdvpiaW8N975VcHdPEO5svIJ7R0KReDMWHv2rwNoj9QtCEATDw4vj1kOHw72EL3YvnI/jm9fjTkgwOoz4CHaO+s18CKYFLz5o8WeeB3M9ePFF6ykvkMSZJxRKUlLgd2YO/IJnIgrO2O/WDcfueSE8MgobNmxQFnbOmjIfpCA6KjwJ4UHXsfzzcYiPjVWz3y9+MA7WRizS5Ddn9wdjx+9nkZL8AF6lXdB+WA04FbVDzRZ+uHkhEreDo1DMxxUlKriJ0yMP4W8HnRf6lLrcOHMKK774JNv7df34E5SsUj1fS134+6fB0g+WeGYF8zwY+ElXw4IFC1TAqa6Dkg4L3Q4shJMJdFew9EWD3yN79ux5pMU217UgU5aYZPy+oTvl4sWLeu8fn0NDy3FkxlF2+xoQEKCEFl2qVKmigqGzg8eBrg6Wq2TE29tbHTM6RzKDpT8UPyj+/P777+o2ul4oxjCvhH/LL0T4KIQ42Fph0os10LyiFz788wTOBDP49G+MfaEK+j3t/0RfLqrl7bMlYeNbBBELzyLxVixCvj0K956V4FDFI1/3QxAEPNFntUGnl+DqUwIbvp2Gq8ePYNG4D9Dlowko6uUth9KMiIiIwOrVq9WsC6FltVOnTkY3mBOEAiMhFlgxBDibWkdetNmbaFT7dTzn4KDCB9kNJjIyUpWEsSSGs6Yc2OjOFBuKO6G3sHzSWMRF34FXmXLo+vEE2BTS7ksPUh7gnzWXcWTTw++2ul5oNbAKrB86jelu9q3ohiLeqYNJEXnzHh5Tfd5//rXqqO4tGYNNdXH2KKbuV5DlWgz05JLVpAEdEAzg/O233x4p+WCuB/Oy/P39025jaQdbsbZs2TLd7YRdp1hix8doLWIPHz6sbicff/yxOqa6gaps7fokTojz588rwZbQscHXYUkrl6z21cvL6xGBhU4N3YyTx8HjEBMTo7a9VKlS6jaGvM6cOVPti4uLS5bOUpbV6PL+++8roeSVV15BfiJdXQoxrap6Y9OIpni2oifik1IwbnUABi84hNt3n7zll305V3i9XUcFnz64n4zwBadxZ/NV9SMlCILxUKFBI/T65EsUcXNH+I1ALBz7Xp7V6wqGhTM9//77L3744QcletC2z7KWfv36ieghFF6ibwK/tEsVPazsgJd+Bpp/rCz7nAlmtwfWw3N2lIMWDnxOnTqFn376SXU/On36tLrNEMRE3MaySWNVFoJHyVJ4afRnhdall5iQjL/mnkoTPeq180ebwdXSRA/BuKCYwZLarHhuwBCjy6hZvny5cksy64KDd5aLcmH3E8KBOV0gdHbQEcKyl40bNz42E4PdWpjfwe4nFDSWLVumgjwZKkrYHYatcvl8/N1mcCqFEf5uayU3nMzICmZrUMClcEvhYeDAgXrta/fu3VU+yfz581UZIP9lADQ7vWkuDO57ZnB/GV5KwYJiC90jFIDu3bunjlt28LtWd6H7g2JlfovN4vgo5Hg522P+wAaYv+8qvth4FtvOhqLt13swrXtNNK/0ZDWR1kXt4DmkJqLWX0bs/mDEbL+OhBt3lfvDyskm3/ZBEIQnw7tsefSZPB2rvpyI0KuXsPSz0Wg7bAQqN9Y/RVwwLljPS5cHZ2sILyQYMubm5mboTRMEw3HzGLCoFxATDDgWA3otBEo1pEr4iFWclm8uzMOhA4TiBwcDXDhrSoGE7SsLqu3zveg7WD5xLO6E3IKrtw+6jZkIR5fC6dqKvROPDd+fQOi1GFhaWeC5/pVR+WkfQ2+WkA0VGj6DTiNHY/v8OemcH3R6UPTg342Nv/76SwmdzOfQhY4KOkBYMspSFQoM/Ld8+fJqskG3HCYjX331leqAwu4lLHFh1xMtl6N169YqC4PPwe+eChUqqOwNzXUxb948ldPFUrzHwTbeDERlhxW+xoABA/Ta19q1a6uWt9wXtvyli2POnDlqGwhLAClmPK5dL/eLAhGFFmtrayWEjB07FsaMxQOtGEjIso6JCeB8gzAky9DwlPEiN69tfCx5eWfxUZwPSe1V/Urj0viobWXY2zz5PsceCUHUyot4kJgCK1c7ePSrAtuST5YhUhjJr3MrGB5jPLcJ9+NU2culQwfU+jPd++Lpl3oZzfaZAoY+r3x9zvRwxokBa7z4oOWWF2m6db+CeXxmhSfg7Hrgz8FA4j3AszLQZwngVlrvc8sWuHRQMbCQnRkIXVR169ZVIkh+ior3Y+8qQTrs6mUU8SimXHqFtSTx9o27WP/dcdyNjIedkzXav15DZXeYyufW2MYQ+sLZ/itXrqjBcG7FPra2DToTgLtRkSji6gbfKtWMzulhzLAtLQWQwvba+fF+FceHkEYVHxeseasJpmw4gwX7r+GXvVex/1I4vulVB5WKP5lo4VTXGzY+RRD++2kkh99H6I/H4da5PJwapNa3CYJgeGztHdDpvdHY/cd8HF63EvuW/YHI4CC0Hvp2oQ7OMxVYX0vLrDYbQ4toly5dVOs9QSi0cD5v/yxg8ziuAOVaAN3nA/ZP5pagXZs1+5zFpJWbLhDO8PJfWuErVaqkckBY356XA2wK0gyFpOjhWNQV3cd+XmhFj6snb2Pz3AAkxifD1dsRL7xZE65ejobeLOEJocjhV+2/ziOC/rBNLsVWQ3Do0KG0XBJzQRwfJqjWFoSaveNsKD5Yfhy37ybA1toSo9tVxoBnSj/x66XEJSFi6TncP5Nan+b0VHG4diwHCxuZiTSFmQqh8JzbE1s3YevP3+NBSorqGtD5/TGF1lZtCueV9bQUPTgTTWfHc889h2eeecYofqPMBWP/zAqZkJwIrH8POLIgdb3+q0C7r9jaKtfnlvZ3tnCk8MF/NUqUKIGnn35atYLM7ecvKSEBK7/8BIGnTsDeqQh6TJgCT/8yKGzw/JzYcQN7l11QOpZvJTe0HVId9nqUTRvb59bYxhCGcHwIOYflK+zQYgiSkpLUe9YYPkd59X4V4cMEv7QK6ks9LCZeiR87z6UG2zSv5Imp3WrB0/m/tlD6wIDTmJ3XEb3lmpp8YQcYlr5Yu8kXqbH/YAuF69xeO3EMa2dMQfy9WDXD2OWjT+BR0s/Qm2XUFPR5ZXAYW71R+CCcjWGWh7nNyhgDpvCZFXSIiwSWDgCu7OLlLdB2CtDwdRVimtfnNjQ0VAkgLDPjNSJha0eWmLElLrspPCnJSUlY87/PcfnIv7Cxd0D3cZPgU75SoTvFKckp2LP0Ak7tClLrVRr7oFmfSrCysjTJz62xjSH0RYQPwZQQ4cOMv7QK8kudr/Xr/mv4fMMZJCSlwMPJFlO710SLyk9uu7x/PhIRi88i5V4SLB2t4d6rMuwrSvCeMf9gC4Xv3IbfuI6VX32qAvXYPaDju6PgXzO17Zpg2PPKkhamv9+9e1e9Fi34zz77rMr1EArvZ1ZgD+fLwMKewO3zgI0T0G0eUKltvp9bdlygHfzgwYPq/4SfR14v0gWib9kZMxDWz5yG8/v3wNrGFl1Hfwq/qjUK3amNj0vC5p9OIfB0hNKuGnUphzrPP1kpkbF9bo1tDKEvInwIpoQIH2b8pWWIL/Vzt2JU8OnZWzFqfUAjf4xqX+WJg0+TIu8j/I8zSLxxV/2ouTzvD+fmfrCwNPyPkzFgbD/YQuE8t+wmwJnHoLOnYWFpiZaDhqHW8+0MvVmF9rzyB33Tpk3qd4hwMMUsj/xu+1bYMaXPbKHm2j5gcV8gLgJw8U0NMS1eo0DPLS3h7AKzf/9+hISEpN3O7ggUQMqWLfvY12F54V+zZyJg51ZYWlnjxQ/HoUzteihsRN+Ow7rvTiAyOBbWtpZ4flA1lK3tafKfW2MbQ+iLCB+CKSHChxl/aRnqS/1+YjK+3HRWhZ6Sit5FVPApQ1GfBHZ6iVp7CbEHb6l1+yrucO9RCZYOMmtpbD/YQuE9t0mJidg8eybO7Nmh1uu90BnP9hskSewFfF6ZJcA2tewwQZjjwTwPQ9X8FiZM7TNbKDm+GFgzHEhOAErUAXovBpyLG+zc8nmvXr2qymB0W0B6eXkpAaRGjRrpPru8/475c3B001olMncc8bFRtvjMb25dvoMNP5xAXEwinIra4oU3a8GzlLNZfG6NbQyhLyJ8CKaEdHUR8hy6OyZ0rIZmFT3x/rITqu1t5+/24uO2lTHwmdKw1NO1wWBTt64VYOvnjMjVF1Xwaciso/DoVxW2Pk5y5gTBCLC2sUG7N0fCzacE9i39A4fXr0bkrWC88PYHqhuMkL+wNe3WrVtVO03C1pnM8vD395dDLwgpKcDOycDuqanHokonoMtswNawHT840Ga4Hpfw8HDV/eXo0aMqE4TdGbZt24b69eujQYMGKFKkCPYu+U2JHqTtsBGFUvS48G8Iti04g+SkFBTzK4IX3qiFIm5PliUnCIKgDxJuaoJqrTGo2bfvxuOj5Sew7WyoWn+2oiemdasJL5cnCyxNuBGD8N/PIDkqXgkirl0rwKmOFworxnBuhfzBlM/t2X27sen7GUhOTIRn6bLo8uF4OHtIy9T8Oq/Xrl3DqlWrEBkZqdY5SHr++edhKy2GCxRT/syaNYlxwKphQMDK1PUm7wItxrNnplGeW3ZeOnLkiBJBNOcWryWLuzgj8vBeWMXHoeWrb6B26/YoTPAcHNpwFQfXXlHrpWsWw/ODqsLW3tqsPrfGNobQF3F8CKaEvu9X6Skq5IhiRewwd0B9THyxOuysLbH7fBjafrMHW0//V9uqD7YlneE1vA7sKrqpEpjIJeeUC+RBUoqcGUEwEio/8yx6jJ8Cx6KuCLt6GX+MGYmQyxcNvVlm2bbur7/+wi+//KJEDxcXF/Tv3x8vvPCCiB6CQO6GAvM7pIoeljZA5++AVp88kehR0Dg4OKBx48Z455130K1bN5XNw8FwUGQU7pWtBtunmsOxdHnVLrewkJSYjK2/nE4TPWq38kO712vkWvQQBEHICuP9pRCMHirp/Z/2x7rhTVTOR0RsAgb/eghjV51EXEJqezd9sHKyQbGB1eDcspRaj90fjLA5J5B0Jz4ft14QhCehRMXK6DPpf/AoWQqxkRFYPOEjXDi4Tw5iHhEUFITZs2ercETC2cE33ngD5cqVk2MsCCTkNPBTSyDoEGDvCry8CqjTz2SODWf7q1evjkblS8Px6hlYR0eo28Nj7mLhwoX47rvvVGlbQkICzJm4mASs+foYzh8MUcH2zftWQuNuFfQulxaErLhx4wYqVaqk/s0pdOj06tULderUQZs2bbBs2bJcHXROZAwfPlw9X4sWLVRuly7Dhg1T26y77NiRmq+W3/uq6zStWbMmMsKOVZ07d0atWrXQo0cPnD17FgUFywN5/LldPB8nTpzI9XOK8GFiPHiQjMjIfxARsUn9y3VDU8HbGavefAaDm5RR67//E4iOs/5GwM07ej8Hf/yKPu8PjwFVYWFvjYTAGIR+exT3L0Xl45YLgvAkFPXyRu+J01C6dj0kJcRjzfQpOLh6ubIWCznvBrF9+3bMnTsXt2/fVnX/vXv3VnkeWdk1BaFQcWEr8HNr4E4g4F4OGLwNKN0Epsa5/Xuwefa3sIqLRZPaNZQLpFGjRrCzs1OZIOvXr8f06dOxZcsWVa5hbkTcjMXyLw8h+NId2DpYo+PwWqjWVLpTmTsPUh6o6/l7x0LVv1w3VsLCwvDaa6/hqaeewsqVK/H2229j4sSJ2LlzZ46fc9SoUYiJicGSJUuUyDF27Nh0g3iGmE+dOhV///132kKXWEERHByMoUOHqmwxXa5fv66OBUttKdZQZOGETEGIs2wTPmbMGPV6/F6kaMRt0dqG5xTxlJkQoaF/4fyFzxAfn9oNhdjZFUfFCuPh5dXGoNtmZ22FsR2qqqyP95Ydx8XQu+jy3T582LYSBjUuo7eS71DFA97Da6vcj8TgWNyeexJF25ZBkWd9jaJWUxAKO3aOjirjY8eCn3Dsr3XYs3A+IoOD0GrwG7Cylk4jT8KtW7dUlgf/JZwNbt++PRwdDRvQKAhGxYE5wKaPOHoC/JsAPX8DHN1halw6fBAbvp2GBw9SULNlWzTrP1hd13BGs3nz5ioElTkgnB3eu3evcn9VrVpVCSPm0Lr6+pkIbJpzCglxSXApZq86t7hLoL3ZE3fqturkmHznv8GyVVFbuHYsB4fqxpcVxlBxtowfOXKkWi9durT6XK5du1Z9Tp+UwMBA5d5gsHHJkiVRsWJF5Sihy4tOBooIdGyw45On55O3b86L/R03blymr/3777+rbXzrrbfU+ujRo9GxY0dcvnwZlStXzncBiqIH3SbkzTffxLx585RIlJkzRV9E+DAh0ePkqTepm6a7PT4+RN1eo/p3Bhc/CIWPv0Y8iw+Xn8DWMyGYtP4Mdp0Pw7TuteCtZ/CptYcDPIfVQtTKi7h3NBR3Nl5BQmA03LpXhKXUfwqCwbG0skLLQa/DzccXOxf8hFM7tuBOaAg6jhwFhyI5a0FYmGB9/759+9TFEOv6mQHAHA8KH4IgaB+UJOCvUcDBOanrtfsBHWYA1rYmd4gCTx3H2hlTkJKcjMqNm6Hl4GHpJnPo+GC7W84ysw0u2+HSen7q1Cm1+Pn5KQGEgw1LI84zeRyndgdh9+Lzaqbfp1xRtBtWAw5FTO88Ck8uenAiMyMUQXi7R78q+S5+aC4FCg10DVSrVg2zZs3K9L787DVt2hRVqlR55G93795N+//ixYsxZ84cJVLyd5sODr5OZhw/fhw+Pj5K9NCoV6+eKm0lFBH4XcDPeE7ZtGkTfv31V7WNHTp0UNvDMPRvv/02y30ldLLQecZQ0JdffhkZy1y6du2ats5rFQol+nL+/HnlltGOAZ+/b9++6m8ff/yxctRkhCIvXbDt2rVLF1w6f/58eHh45Lr8V4QPE4DlLHR6ZBQ9Hv6VhSI4f2EiPD1bwcLC8InR7k62+Onlelh4MBAT153Gngu30fbr3fjipZpoU624Xs9haWsFtx4VYevvjKi1lxEXEI7E0GPqS9LGW1reCoIxULddR7gWL451X3+F6wEnsGjs++jy0XgliAiPn8Wgy4OZHoQXS5xBYYmLIAgPuR8NLB8EXNySut5yQmr3FhN0ft48fwarvpqoumKVq/802r7xLiwtM79Wo6jBQReXmzdvKgGEwgct51xcXV3RsGFDNYAzhVK4lJQH2PfnRRzfdl2tV2zojRb9qsDKxvTEGyEVlrayGUF2UOSKXHMpy/vw77blXVW5e1aw62NuXN+cZFi0aJGaaOAAnHkRj4MCha5IoZWgMaODcFBOMYEDeooF/D3ngH7z5s2qk1Bmv/leXum7VXIAHxISkiZ88Pf/ww8/VEJD8eLF1Ws1a9ZM7/1bunQpZsyYoSZV+DwUVfgcgwYNynJfyaRJk9S/dLVkhN85/J5huQ9LT8qXL4/x48erf7ODYgVLU7p06aKOFfeTzhInJydVyssylvfee++Rx2XsfETnG/eD77tp06apx+cGET5MgKiof9OVtzzKA8THB6v7ubk9DWOAX1B9G/qjYRkPvLP4KAJuRmPob4fR+6lSGNehChxtrfV6jiJPl4BNiSKI+P0MksLiEPrdMbh1qwjHmgVvBxME4VHK1mmA3hOnYuWXn6qSl4Vj30fn98agZFVxL+jCCy5eWNDuylwPzvByRoOBYVLGJwg6RAUCC3sCoacBaweg62ygaqrd2dQIuXIJK6Z8gsT4+/CvWQcdRnwEK2v9Lr1LlCihZltbtWqlQk858IiKilKdnziQq1u3rhJB3NzcYIwk3E/ClnmncfXEbbX+VMcyqN++tHzfmTAcfIb9eAIJ11LbMueWlOgEBH+SGuidFbb+LvB8vWaO3zs9e/ZE2bJl09b1HTxz8E4BgaUvfA7CPC7mYTz33HNqfcSIEdi9e7cK4mQXtszaWWdsRc91LSeDggBfp0mTJhgyZIjK92EOCPNAWP6iDyxBoYuE0L1BgYDbzf3MjVBw79499VwsdeE+01UycOBA9R2U3fOyNIgCD4+PVjLECR8+B4UPZ2dntWRHhQoVsGLFCvWdR5cIRSmGv+cUET5MgPj4UL3uFxd33WiED43yXkWw4o1nMH3zeczefRmLDgbiwJVwzOxVB9V9H1VGM8OulAu83q6DiIVnEX/5jvqX4adF25WGhZXMGgiCofEsVRp9P5+OVVMn4tbF81g2aSxaDx2Oas1aGnrTjALaYTkrROs64QUY61Yzmx0ShELNjUPAot5AbChQxBvovRjwrQtTJPzGdfz5+TjE34uFb+Wq6Pz+GFjbPHkOEttat2zZUlnwGYhIFwiDkPkvxVSWv7BMplSpUkYjKtyNvI/135/A7et3YWVtiZYDq6BCfW9Db5ZQSNHNyPnxxx/TykwywpwdDYZoskTm6tWrqkyGZR66QaQMIdZgKCjvR3GSLgcNigWc5MgYBsp1zbHF16Bgol0P8PMcEBCgXBz6Ch+6mRfMBeL3A8OR6XLRZ18fB90X7EKjCTp0bjDnhK4XOlWzgoIOO8DQnaZBR4rm6KBzhOJIZoIvHTYaFJ240AXHkhmWGYnwYebY2aW3SD2Oc+c/Rey9i/ArOQD29iVgLDD4dFT7Kir/Y+TSY7gcFosu3+/F+60r4bWmZfUKPrUqYotir9ZA9OariNl1A3f/DkLCjRh49K0CK2epExUEQ+Pk6oYeE6Zg03czcP6fv7Hp+xnKAdK4Rz9YmGBNel7Njh0+fFjNjiQmJsLGxkYFGXJmxlgGKIJgNJxaAawaBiTdB7xrAH0WA0X/s5ybElEht7B80hjExUTDu2x5dPloAmzscleawlni+vXrK6cHB18UPvjvmTNn1MIBAwUQZhhktIsXJKHXopXoce9OAhycbdB+WE0ULysirznA3y06L/QpdYm/cgfhvwRkez+PV6rBrkzRfC11ofigwdIP3fyIzGBWxuDBg1Uw6YIFC5RbQXfwTocFM3d0YbkKXRCc5NCgmLFnzx4lROjCdS1MlOVtGSdBODly8eJFvfdPN/dH67LH6w199jUruI0s59H9DqKIxC4w2UFnK48RBY7MoDPl1VdffeR264eOOIq8/B7j95kG8z34nZcbxPFhAri6NlDdWxhkmnnOB7FCSkocAgPn4vr1X+Dp2Qal/AahaNH/lDZD07h8MWx651l8vOIE/goIwZSNZ1Xw6fQetVG8aPYXBBZWFijargxs/ZwRsew8Eq5GI2TmUXj0rQy70vKjKgiGxsbWDh3e+RB7fXxxYOUSHFi5FJE3g9D2zXdzfdFvanC2hdZX7Ueas7G0d7q7m143CkHIV3ihvmcasD211hwV2wIvzQXsTDMoOSb8NpZNHIO7kRHwKFkKL43+DHaOeZdNxkEO7d9cQkNDlQDCmVBmgtASTqs8Q1IpsBZ0h6hLR0Oxdd5pJCWmwL2EE154oyZciqXOlAvmAQUIC9vshTX7Cm6qe4tuN5eMWBW1U/fLLuMjL2FODpesylJZ2sFOK7/99tsjYZoUAtiJzd/fP127Wpak0ZmlezuhO4ElHnwM8zsIJ0Q01wLLN3hMp0yZkvYYOiXY/eVJQkT5mdcEA74OP/tcstrX7OA2aiGomlOFuR+6GSiPg8dJ62SjCbFsiXvy5EkVvsoyGC6PY/ny5eq4/fzzz2m30QlDR0tuKJzTcCYGA0vZsvbhWsa/qqV69W9Qq+ZPcHNrpMJQQ0M34NDhbvj3UDeEhKxHSkoSjAE3J1v82K8evuhaAw42Vth3KRxtvt6NTaeyVw81mADt9VZtWHs5IiUmAWFzTiJmb1CayikIguGgu6NJr/6pAX5W1jh/YC+WfjoKsVGRheK08HuIreq+//57JXrwB58uD9bFiughCBlIik91eWiix9NvAr0Wmqzoce9OlCr1iw4LgWtxH3QbOwkOzi759noMTezUqZNqvcnMAc44x8TEqAEHww7XrVv3yGxzfn3vHfnrGjbNPqVEj1LV3PHSB/VE9CjEUMxgy9qscO1YtkBFD33ggJslZAz9ZJkZw0m5MF+HvPLKK8oFQmcHHSEse9m4ceNju42wWwvzOz744AMlaCxbtkx9LrXuJiwlYcmHVg7L4FQKI/369UsruYmIiMhym7XOKWyDPXPmTHW9kRcMGDBAOVZZ6sNSns8++0y5Z7S2vvyu0Y5LRvi9xOwSOj54LbRr1y58/vnnWYodujBThaIujzVfm/tFUSe3+2bxQEaL2UJbEy9kqXwZ1D4Y+pfq7qIbdGpn54OKFcala2UbE3NGuT5uhazFgwepSqu9XQmU9HsZJXx6wsYm/36En4RLYXcxYvExnAy6o9Z71vfD+I5V4WSnnxEpJT4ZkX+eR9zD4CyHWp5we6mC6ghjqvDjyJli2t7ECm9eFMZze+P0Kaz+3+e4fzcGzh6equOLp/9/tklzO6+8QOEFjDZDQksoXR6apVUwLQrjZ7ZAiQ0HlvQDAvfR0gm0nwo0eNT6bCrn9v7du1j62SiEXbuivu96ffolXDz1K1XOK2gvZxcYdkLQukYQukNYBkMLfV6/l5OTUrBr4Tmc2Zc6gVWjmS+a9KgASwNlsBnb59ZYxhBPCgetV65cUTP3uekgxJa2UWsvpXN+0OlB0SM/WtnSqUHnheY2YOc0BmoyCFgfWH7x999/P3I7HRV0gBA+H9urUlRkhxOKGhlLX3RhZxh2MWEbe14PvPvuu6rtrAbFEIam0rXFzyodJA0aNFB/Y0tatn1lrsbj9nXChAlKMGFJbY8ePVS3lCdte33gwAHVnUbX4UHYvpYBp3RfsHUvxQ9uo+ZW4e3acckIHRqTJ09WggWdJ926dVOhq/puGwNNmaVCQYivyWPIUr/cvF9F+DCxLy26OSIjDyIq6hpcXf3h5vbUY1vYxseHISjoD9wI+gOJialqoZWVI3x8usGv5EA4Oqa3YxmChKQUzNh6Hj/uuqTcrmWKOeGbXrVRs6Sr3j9wd/fexJ0NV4CUB7D2dkxteetZsPZOc/3BFvKOwnpuI2/dxMovUju+2Ng7qFKYsnVTf9DN6bzyx5+zOExw5486Z0QaN25s8N8MIecU1s9sgRB2HljYA4i8Ati5AN3nA+Vbmuy5TYi7h+WTxiH44jk4FnVVooch23pz/zhLSgGENnhdhwgFEIYmMgMgt9yPTcSmOScRdC5KdRqm4FHzOT8YEmP73BrTGMIQwofW2paZH3RpWzrbqkwPY3N6GDNs5zpv3jxDb8YjsPSFrW4ZGGtoRPgw4y+tJ/1ST06OR0jIagRe/wWxsdoPoAWKFWupckBcXSmeGPYLaN+l2xi55DhuRd+HtaUFRrauiKHPloOVnl+MKkRp4RmkxCTCws4K7j0qwqFa3ivJhe0HW8g7CvO55Uzo2hmTEXjqBCwsLNF8wGDUadvRLI4D272xblWbJfH29lZ967VaXsF0Kcyf2Xzl8i5gaX/g/h3A1R/osxTwqmyy5zYxIR4rp3yC66dPwr6Iswp5ZqcrY4GzzbSM8zqWM8KEJTEMSuWsMkMZc0JUyD0VYsp/beys0HpwNZSuYfjrLmP73BrbGMIQwoeQc5gVxpIa5o4YGz/++KMSU9l229CI8GHGX1o5/VLn4yIj9yHw+jyEh+9Mu925SDX4+Q2Et3cHWFoarkNK1L0EjF55EhtOppbyPF3WXQWflnDVLxgrOTpBiR8MPSXOzUvC5Xm2vDX8D5+p/mALeUdhP7fJSUnYOvd7nNqxWa3Xav0CWgwcAksj+E7NKZxJ5UUJE+B5Ttlu8tlnn01LJRdMm8L+mc0XDi8A1o8EmDvm1zA1z8OpmMme2+SkRKye9jmuHD0EWwcHdB83GcXLpdrAjQ260ZgdcPDgQURHp14n8ZqW7g/a9Cna6kvQ+UhsnH0S8bFJKOJuhw5v1oKHb84EFHP/3BrbGEJfRPgwDrSOcMZIohFtmwgfZvyllRdf6rGxl3D9xnwEB69ASsp9dZutrSdK+vaDr28f2Nq6G2zflh2+gU/WBOBeQjKKOthgcpcaeKGmj36PT07BnY1XVbtbYlfeFe69Kql2uKaAsf1gC3mHnNvUY3Bo7QrsXjhfdXIoXasuOoz4KE87HhTUDywDv44eParW3dzc8NJLL+mVdC6YDvKZzUNSUoCtE4B9M1PXa3QHOs0CbOxN9tymJCdj/TdfqQBna1s7vDT6U5SsUh2mcE17+vRp5QJhiZ4GZ/YpgDCzIKsa/LP7g7Hj97NISX4Ar9IuaD+sBpyK/tcu1NAY2+fW2MYQ+iLCh2BKiPBhxl9aeWrRTIxEUNBi3LjxG+ITUoOwLC3tULz4i/DzewVFnAwzc3HldixGLD6K4zdSg0+71yuJCZ2qoYiewaf3joep4NMHCSmqnZZHv6qqDa6xY2w/2ELeIef2Py78ux8bvp2GpPh41e6xy0cTUNRL/9lGQ3L58mVV2sLPKWG9PC3jTCqXz6x5IZ/ZPCIhFlgxBDi7LnW9+Sig2UdsWQdTPbcPUlLw14/fIGDXNlhZW+PFD8ahdO16MDXYmpI5IGfOnEnrjMfvMn6v1apVC7a2tulyGv5ZcxlHNl1T6+XqeqHVwCqwNrJAeWP73BrbGEJfRPgQTAkRPsz4Sys/vtRTUhIQGrpRlcHExJxKu93dvanKAeG/Bf0Dkpicgq+3nsf3O1ODT/09HPFNrzqo7adf8GliSCzCfzuDpNtxgFVqWy2nhsWN4ofQVH6whbxDzm16Qi5fxKqvPsPdyAgVBtj5/TEoUbGK0b7lGOK1ZcsW/Pvvv2kuD3ZsKVWqlHxmzRT5zOYB0TeBRb2A4OOAlR3w4vdAjW4w5XPLx27/5Ucc+2u9at/dceQoVGjw+I4OpgBbUrKrw5EjRxAfH69uY64DRV12s3Cwd8K2+adx6UiY+lu9dv5oaIStSI3xc2tsYwh9EeFDMCVE+DDjL638/FLnc0fdOYTr1+chLGwLb1G3OzlVUJ1g6ASxsipYa+o/l8Mxcskx3LxzX4WdvtuqAoY1L69X8GnK/SRELDuP+wHhat2xrhfcupSHhY3hz6Mp/GALeYec20eJibiNVV9OROjVS7CysUHbYSNQuXEzo3vbMViM7eQiIyPVOgcDzz//vOpnL+fVfJFzm0sodizsCcQEA47FUvM8SunXUtKYs9L2LFqAf1cvV46V9m+ORJWmz8FcoOjBEj6KINr3HctenFEcFqHesHvgguf6V0blp/UrPzYExva5NbYxhL6I8CGYEvq+Xw3TZFswWvgj4ebaADVr/IBnGm1XYoeVlRNiYy/g7Lkx2LuvKS5dno74+NAC26any3pg4zvPqpyP5JQHmLb5PHrP+QdBUXHZPtbS3lq1ty3argwb2eDekVCEfn8cSeHZP1YQhPzF2b0Yen76BcrVb4jkxESsnzkV+5cvSrNcG0Nw1+bNm1UbOQ4CXFxc0L9/f3To0EGJHoIgPIazG4B5bVNFD8/KwGvbjEb0yA0HVi5NFT0APD/4TbMSPQi/11jmMnz4cPTs2RMlipdESkoK7qTcRFSxo7CoegEpLpHqNkEQBFPD0tDK8ujRo9XsWZMmTbLsUUyLcbt27VCnTh307t0bAQEB6vYbN26gUqVKmS6aJXn+/PmP/O3LL78ssP00VRwcSqFixXFo0ngvKpQfDXt7XyQmRuDq1e+wd9+zCDj9PmJiThfIthR1tMGs3nUwrXstONla4eDVCLT9ejfWHr+pl5jj3Kwkir1aA5ZONkgMjkXIt8cQdzaiQLZdEITHY2vvgE7vjUa9Dl3U+r5lf2DjrP8hKSHBoIeNoX9z5szBvn371Dpn64YNG4Zy5coZdLsEwaihaLnvW2BxHyDxHlCuBfDqZsDNeNq75pQjG1Zj75Lf1P+b9X8VNVu1hblCl4dDkidwpgJcb9eB84MS6rZbYTexdOlSzJw5U2WDcJZVEATBVLB4YMCptYkTJypxYsqUKbh58yY++ugjTJ48GW3bpv8xuXDhgkrM/+yzz1C3bl0lZHAWjmIIg5ciItIPYL/44gtcu3YNixYtUm12xo4dq/5944030u7j4OCgd+9yY7OpGcrGl5KShLDbW1QZzJ07R9Jud3VtqHJAihVrAQuL/NfSroXH4p3Fx3DsepRa71rXF592qgZn++xbKiXdiUfE72eQcD1GrTu3LAWXlqWMpk7V2CyaQt4h5zZ7TmzdhK0/f6+CA0tUqqpyPxxdihbo2zApKQl79uzB7t271TlzcnJCx44dUbly5UzvL+fVfJFz+4QkJwLr3wOOLEhdrz8IaDcVsLI2+XN7cvtmbJ6d2pGmUbc+eKZ7H5grPDYndtzA3mUXlI7lW8kVbYfUQEJynLpmP3TokGqNS3gNzuvyhg0bqtwjY8DYPrfGNobQFyl1EUwJoy91uXfvHpYtW4YxY8agWrVqql568ODB+OOPPx657969e1V7LS1IbuTIkQgLC8PFixfVl4inp2fawoRqthmko0PrLXzp0iV10ap7P31FD+E/LC2t4e3VDvXrLUP9+ivg7dUBFhZWiIo6gBMnh2L/P61w/cavSEqKzdfD5u/hhGWvN8LbLcqDesWKI0F4YebfOBKYWo+aFdZF7eA5tCacHtanxmwLxO35AUi5l5iv2ywIQvZwBvWlUZ+p9rY3z53GwjEjEX7jeoEdupCQEMydOxe7du1SF8/8baJg/jjRQxCEh8RFAr+/9FD0sADaTAFemG6UoseTcnbvLmye8636f/2OXdGoW2+YKynJKdi9+Dz+XpoqelRp7IOOw2vD3slGlfq1bNkS7777rir3K1asmAp9ZltcOkCWLFmiJh2NpVRRKJxolQD8N6dQqOrVq5eqMmjTpo0ar+YGlsqyfIzP16JFC9UZThe6STNWJuzYsaNA9lWDn92aNWsiIwcPHkTnzp1Vl6cePXrg7NmzKGi4fzx2zB7KLQYTPnjgOLPGHdGoV68ejh8//kjtoKurqxI5Dh8+rP62YsUKJVxQBMnI//73P3VidO3IbD9YurTp2yyNiaIutVC9+jd4ptFO+JcaCmtrF8TFXcP5859i774muHDxC9y/n30ZSk6xsbLEyNaVsGRoI/i6OiAw4h66/7gf32y9gKTkrGtPLawt4fZiebh1rwhYWyL+fCRCvj2KhKC7+ba9giDoh3/N2ug9cRqKehfHndAQLBr3Pq6dOJavh4+/K3///bcqbbl165ZyBHbr1g3du3dXjg9BELIg4jLwc2vgyi7AxgnovRho9IZB29XmFRcPHcDG76arEp5az7fDs31fMQoXQX4QH5eE9d+dwKldQUq7atS1HJ7rVxlW1umHCnR5sESdonDfvn1RtmxZJXawJe4vv/yCn376CSdOnFBOB0HQfmM5G3/y5En1rzFnxHBi/bXXXlPdjBhq/vbbb6sKhZ07d+b4OUeNGoWYmBglDlLkYCUCPyManKCfOnWqug7RlsaNG6OgCA4OxtChQ9M6OmnQTMBjQXMCxRqKLPzcU/AsSD755BNlmMgLrA35xqItTrdHONVjHnS21XJ3d0+7vX379ti+fTv69OmjHB6sM5w9e7ayselCYYQq3fTp09Nuu337tno+vnn5xmNwEy9oBw0aZLY/XgWJvX0JlC//IcqUeQvBwSsQeP0XxMVdRWDgT6okxtOzjSqDKVr0P4ErL2lQ2h0b3mmKcatOYc3xm5ix9Tz2XAjDjJ614efumOVjnep5w8bHCeG/n0FyxH2E/nBMCSJO9Yvny7YKgqAfHiX90GfS/7Dmf58j6Oxp/DllPFoOGqYGHnkNfyNWrVqVNmNSsWJFVdri7Owsp0sQsuPaPmBxXyAuAnDxBfosAYrXMIvjRsF13YwpSElOViGm/A4y1+vG6NtxWPfdCUQGx8La1hLPD6qGsrU9s3wMr8UrVKigFrrlOBvLyUuWrnOCkuXoHDxyUtPRMevrMcF8OX36NDZt2oTo6Oi02+geYqxB1apVYWxs3bpVjUdZXUA4cc739tq1a9G8efMcdYWje2Pbtm0oWbKkusbgWHXhwoXKYUERgdcfNWrUUBUJhtjfcePGZfrav//+u9rGt956S60zl5PXRzQUFJQTds2aNYiNzbtKAoMJH6wP1BU9iLaeUUmiRYhCyfjx45XVhtkdFDEoZnh4eKTdj4FLVKW8vb3TbuPJIbzfDz/8oBTpSZMmKQFl4MCBT7TNVLSNwcKnbYcxbIuGpaUDfH37okSJ3ggP34nr139BZNR+hIZuUIuLS234+b0Cz2JtVMlMXuJib41vetVG80qeGL86AIeuRaL9N3sw8cVq6FzbN8vHUvjweqs2IpacQ/y5SEQuv4D4a9Fw7VgOFjYFb4gyxnMr5A1ybp8MB2cXvDRmErbMnokzf+/E1rnfIeLmDTzb7xVYWlrlyfngxQwvRug+pCjOCzH+xnBwo+9nUM6r+SLnNhtOLAHWDIdFcgIelKgD9FoEOBdPDTg18XMbdO40Vk2biOSkJJRv0AhtXn9HOVjM8bf51uU72PjjScTFJMKpqC3av1ETnqWcn2hfvby81ICINn5mgDALhDPc/H5lXhK/V5kDwgFlYfvcGst2GEr04NgsIxRBeDsd+vktfmguBQoNrDJgCeusWbMyve+5c+fQtGlTVKlS5ZG/3b37nyt88eLFyiHK8Wn16tWVg4OvkxkUA318fJTooUExkBP42jiV1xx+fn453kcKS7/++qvaRpahcXs4pv7222+z3FdCJ8s777yjsjFefvllZCxz6dq1a9o63bAUSvTl/Pnzyi2jHQM+P11i5OOPP1bj+Iz4+voqswPh8aUThs1PuF8mLXzwIjOjwKGtZwwlmTZtmlLItIPFg8gOL3/++SeGDBmibuOFK79gv/rqq3SPpdrM+kMtdIlvTIahUjx5UuGDH1Qq3MbwJapZfoxx9sHGph7Klq2He/fOIzR0ISIiqfQeQ0DAO7C1LQ5Pz54o5tEF1tZ5O6PaomwRVHqlFkatPY8TQTEYseQ4tpy6iY+fLwtn+6zf6tYv+uLBPlsk7AnBvX9DcP96NOy7lIJl0fTiXGE/t0LOkXObMxr1exUO7h44suZP1VXh9o1ANH/1TdhkEV6VHQy+42yk5vJg2WSrVq3ULJTurJQ+yHk1X+TcPu7ApMB+/3TYH0zNvUgo3xb32nwNpDjwwwVTP7e3A69gw/8mIyk+Hr5Va6DJgCGI0Rn0mBNXj0dg/7JrSEl6ADcfBzQfWA62RVPUd2ROYYgnB4Mc9Bw5ckS56iiGcOHgioNPDvLy6xrH2D63xlzWkdPjy1bv+uz3xo0bsx2ws1Qqu7EVMxtzcy7puOC4j9vEATjzOx4HBQpdkSI8PBzr169XGR2Eg3KKCRyL8v1MxygH9Gy6kbESgXDinsKgLpyMp0tKEz4Y3/Dhhx8qoaF48eLqtZo1a6b3/lFEmjFjhiov4/NQVOFzsLohq30lNAOQzPIzWOrCMTnLffj5Zd4mTQj8V5+wUZbJdOnSRR0r7iedJSwfZmYnMz7fe++9Rx6nGwDMZiV8PF1leYXBhA+6MqjkULCwtrZOe3PwAPPiUxe2ru3fv3/aOj8gtNjQTqdB2xCfK7OaqIxJ08z/0N5wTwK3yxgSmTX12FgSqx9H0aIN4OPTAPHxoxF08w8EBS1EQsItBAV9g1u35sKn+Eso6TcAjg7+efiaRfHnME98t+MSZm6/gPUBYTh+8y5m9KiF+qX/K5/KlPauuF++GCIWn0PKrTjcX3AJbr0qwb5CwSWVm8q5FZ4cObc5p3mfgfApXQ6bfpiBwBNHsXHGZLz4wTg4exR74nPAC3FeoFBo58UUXYKsV8/p503Oq/ki5zYTEuOA1W/AIiB1pu5B43dh03IcihZAR7eCOLe3r1/DXzO/QuL9OPhWqYauH42HjV3ORVZj3v9DG67i33VX1XrpmsXw/CtVYJPNJNGT0KhRIzz99NO4evWqmoCkEMJ8By4cA9ABQnu/NgYw18+tOWWd8Nhy9p0D4ryAEw0c3GYHhbLcRBT07NlTCSwa+mZ3cfBOAYFOJT4HYQA68zCee+45tT5ixAjlamJJhu5YNbsKB22yn4IAX6dJkyZqMp+TMswBYR4IPx/6wBIUukgI3Rs0DHC7uZ+5ySm7d++eei6WunCf6SqhaYBNRLJ7XpYGUeDh8dFKhoKCgtRzUPhgOXFWJcX79u1TERbr1q1DXmIw4YM2In7ZUbDgRSfhDvIkZ1T+qJQx+EUXfnHqviFoo6F9iU4SXZjEyzcpVUXtA8NyF90PgL7w8cbwJaq7LcayPVlhb++FcmXfRWn/NxASshqB1+chNvYCbgT9ihtBv6FYsZYqB8TV9ak82R8bayuMeL4imlYsptre3oiMQ885/2B4iwoY3qI8rK0ef4HmUMkd3sPrIPyPM0gMuovwXwLg0tofzs38CqzlrSmdW+HJkHObcyo3fhYunl5YPW0Swq5exsKx76HLh+PhXTb7mQftAosXJgzK1lwe/PHVzZPKKXJezRc5tzrcDQUW9QaCDgGWNkDHr2FRpx/M5dxG3QrGn5PH435MDIqXq4AuH06Arb0DzI2kxGTs+O0szh9MnQCs3coPjbqWh2U+XOPw2PJ6mwtnzimA8Lqfk4/8PqZTu0GDBmockJfdFo3pc2sM21DYYfmExo8//phWZpKRo0ePpv2fuRIskaFwxzIZlnnoBpHq5kkyn5L3oyuCLgcNigWPq3DQqhv4GhRMNLcIJ/Y54U8Xh77Ch243FpYO0WVF1xZdLvrs6+PgZD/L1zRBh84N5pzQ9cLStqygoMNGJrpNTCgCagYCOkcojmSkRIkSqqKDf58wYUKWrWlNSvjgG4gXnUxqnTx5MkJDQ5WKOGXKlDT3B5Ug7jBrwFgLROscDyDFDLo9aH/RuHDhQrpOLhrPPPOMek62t+3duzdOnTqlEqd58oSCxcrKDiVK9ICPT3dERO5V4afh4btw+/ZWtTgXqaZyQLy9X4ClZe5LTOr5pwaffrI6ACuOBuGbbRdU8OnXPeuglMfjg7as3e3h9XotRK6+iHuHQhD91zUkBMbAvUclWDqYfms+QTBVSlSsrEJPV375KcJvBGLxhI/Qfvh7qPDUM1nOUDE9nZZbzqrwR5ctGTkTaQyli4JgEoScBhb2BO4EAvauQM/fgTJNYS5E3w7DskljEBsZgWKlSqPraLbVNr9AzriYBJXnEXzpjprMada7Iqo1zToLLa/g7O8LL7ygBlKc6KStn4I0Mwb27NmjBm/8XtbN6ROMC4o4dF7oU+rC9qh//PFHtvdjjIG/v3++lrroToqz9INxCVnBrIzBgwerYNIFCxak6wzKwTsdFnQ06ULhji4Ilr5oUMzge5tChC5c18JEeR2SsUSGQqE2SaMPutcymuOJx0yffc0KbiPLeXSdKhSR2AUmO1iFwWNEASMz6Ex59dVXH7mdpghes9FVxBIbXSgqUTv47LPPkFMMOopjQCmFjwEDBqg3DG05rVu3Vn+j5YeCBUNV2NWFyhtVK7YapFuEb0TdYFO+iTILo+EJYgAN1TkqX3zM+++/r55TMAz88vJwb6KW2NiLuH59PoJvrUTM3QCcPvM+Ll76CiVL9oNvid6wtc3dbKyLvQ2m96yNZpU8MXblKRwJjEL7mXvwWedq6FLH97FfpAw2de9WEXalXBC55iLun4lA6Kyj8OhfFTbFpb2lIBiKol7eqt3tum++xNVjh7Fm+hQ07T0ADTq99MjnmRcvtElqfec5k0DB3BDJ6YJgslzYCiwbCCTEAO7lgD5LgWL6Oa1MgdioSCyfNBbRYaFw8ymBbmMmwqGI+XV1irgZi/XfH0f07fuwdbBG2yHV4Vcl9463nEx88hqfgyKGX9IFQgs8Z6C5cKDFvzFHQMRp44O/sxlLNzKDk9HZ5Wbx77xfQZ5nV1dXtTwO5oCwtIMZYL/99tsjk+p8f3IsqivWcDzLnDBOqmQUcZh5w/c3H8P8DkLhj7cTTuzzmGoT/4TXLMy21BeWkTHTklA04OuwkxKXrPY1O7iNWgiq5lShIKGbgfI4eJy0Tjaay4MtcdnSmOGrHI/rjuN14e0sSdaF+gDzSHLb5tegwge//OjE4JIR3QNNunfvrpbHwXKWx0ELHWulBOPDyak8KleehHLl3kNQ0CJcv/EbEhJCcfnydFy9+h2KF++CUn6vqPvlBnZ3qVvKDSOXHsO/VyMxculx7DwXhokvVkdRB5vHb99TxWFTIrXlbVL4fYR+dwxuXSvAsU76oCJBEAoOzsSyzGXHgp9w7K912LNwPiKDg9Bq8Buwsk79PPOCmqIHa1R5UcWgMF5sG0NOkyCYDAfmAJs+UoGm8G8C9PwNcCz4wXJ+EXc3Bss/H6e+P5yLeaLb2Elwci24XK+C4vqZCGyacwoJcUlwKWaPF96sBXcfw07i8LuYVn66uTmYogDCUnQtB4SDHzpA2BFGn4G2YFzwd5ed0jLr6qLBvxubuLV8+XIV9MlOoBRmWIGgOSgoIrzyyisqmJMukLp166rxJR2lLGt5XD4Jrz0++OAD9TgO/HltwlaxhA4ots5l5g2rGlj+QWFEczVw4p+lNFmV5bKKgaIAJ3tmzpyZqZMiJwwYMEA5cpgfwgoKjrXpntHa+rJzEx0wmYkrnTp1UiGwdHzQJUQh6fPPP1fHLztY7fF/9q4COqqrDU5WsnF3J4q7FApFijvFrVD+lhZqWIHiDi20VGlLKVooVhxKkVK8uAeSkBB3181a/vPdx4YlRDayyW6yc84j+x4rz9+9c+ebKU4FRGqwksgSdaHX7euhFRAKreHlNRUeHu8iIfEEK4PJynqE2NjdbLK1eQPu7pNgY9OxwnI3dxsT/PHea9jwbygrezlyLxa3ItKwfmRztK1X8g3F0M0cDh+3QOruJ8gPSeeibyMzYdXPGwYC7bph66FHXQGPSlYmfQBrZ1f8u+1XPDx3GhmJCeg+ZRrOXbjIGhdKjyhSeZCTux566KEm5DLg73nA9ef14c3HAf3XA4La0wGViPNw/Lu1SI4MZ2TH8IUrYWFX+wY1Hl6IwYXdwShQFMDZxxJ9pjSBsZn2HEdq05HnEk0UekAlMGRCrUzToFFjGsCkEe2i4Qd6aDfIb4LsCshnUVX5QceRSA9NR9lWBGTcSaqPokQGnX+kAKGKAaoyIIKB/pIyiUgS1XKYoqDEUSI9aF+Q4pQsHpS+HKRkIC8L+g6ycaAEEyIYlKoKsoGg2FdlxGtxICsHMkSlEiT6DSIsqgLNmjXDN998wwxOSZFCJCWtGylJCERkkJqF9ktRUCUHWUvQtlJ5CpEjRKKURBBVFwwK6nLAtJogNovMmEjyow2jhXTIyLRGWxyrNbWN6ek3EBW9BUlJp2kJW25q6sd8QJwcB4HPr7jhze3INEzbfReRqbkgP68Pu/rikzf9ICzF+JQaDZlnIpD1D+dmbehhDtuxDcC3fNlQtzKoC8e2rkJ/bDWHsDs3cOybL5HHN4TEzRtyHp9dPzTKQkqPqk4NUIX+uNZe1NljK84E9k8CntKzF8Cbi4GO06mHitpEeuxbsRDxIU9gZG6BkYtXw8696hLmtAEKRQGu/PkU985ybRb/do7oNq4B+ELtH7ChEW4qe6GRdyJDCKQMoBADUoGomlVq+3WrbX0IdUGeWKS8oZKFyhpMEpFAnh+kSKAOMY3ma5vSQ5tBigkiQLQNEomE+XCQYayunK964kPHblpSuRxHgsIQmpoGHxtrDAzwhlCHbqQVQV5eJKKitiE2bh/k8hy2TCi0gavraLi5jodIVLF6/SyxFEuOBOLP29Fsvrm7Fb4d1RyetqXLP/MCU5C6NwgFYjl4ZkLYjK4PI5+K19Bp8wNbj6qD/thq9oF35MCfCAwOYfN8aT769e6Nlp06Q9PQH9faizp5bNMjORPTxEBAYAy89QvQcBBqE2RSKQ6vXY7we7dhaGyCEYtWqZ0OpSuQiGU4vTkQ4fc5U8W2A+qhdV8vnTuPqcNMpe9UBkMdZyVIHUIECCVgqHaglR1sSo0hWbw2dLC1qQ9RU8SHHhUHpR+RySr5jmgbfv75Z6aqJT/Omoae+KiFN62fbz/EV0nZyDJ8cQMyl4gx094MH7RsjNoOmSwLsbF7ERW9DWJxDFtmYCCEo2N/Fodrbl4xydzRe7GYd/ABssQymBrysWRgIwxr5VZqA0GWnMd8P6TxOQAPsOxdD2adSjZLVRd1sqFdR6A/tpoBRaaRYRZdNwQreT5kIQ/B5/HR8/2P0ajzm9Ak9Me19qLOHdvom1xcbU4iYOYIjN4NuLZEbYJCLsexb75AyPUrEBiKMHTeUrg1qF3tp+w0MY5vuI/kqGzwBTy8ObEB/FrrflIKlQEQAULpjERwEEg+r/RGoGeBNpZUaEsforzQEx/aASpfIX8RbYRUi9ZNT3zUspsWkR5L0p/HR6k2wJ5XKi2xEtYJ8oOgUMiQlHya+YBkZNwuXG5l1Y4RIHZ23WBgUD6GPyY9D9P33MX1Z6lsvl9TZ6wa3ASWJiVf0AqJHOkHnyL3TiKbN25iB+thfuCJKi6rr3MN7ToE/bGteonlmTNnWD24sgFMdaSuLs44+eN6BP93iS1vN2QEXh8xDgYaGvXTH9faizp1bB8eAA5NAWRiwLEJMGY3YFm2c78uoUChwMkN6xF48Rz4AgF6fDQLDV97vVYd28SITEZ65GZIYGwuRN8pTeHk/XJUpq6DiI0bN27g5s2byMvLY8uonJHiM0sC+R7UFPmhDX2IikBPfOihS9ATH7XopkXlLQ3P3ECWUFR8jW1BAcyl+Qjs3qbWl70URUbmPURFbkZi0l8oKJCzZcbGnnB3nwhnp6EQCNR3LZcrCvDz+VCsPx0MmaIALpZGLAr3NW/bUhvGOf/FIf1YGCAvgMDemIu8deCMf8qLOtXQrmPQH9uqA8k+Dx06hNRUjqgkx3EyCCO3cbavFQpc3rsT1w5yaV7+7V5H7w+nQyiqermu/rjWXtSJY0uDJxfXAf+s4Ob9ewNDNwEi81p3LM/+tgH3Tv/FSNABMz6HvV+DWnVsQ+8k4szmQMikCti4mKLf1KawsDNGbSa/Kbrz6tWrzAi1NJDyY9q0aTVS9lLTfYiKQk986KFLUPd81TvL6ADI04OVt5T0cDYwYP9P76trsLRohsaNv0WH9v/C02MyBAIL5OVFIDh4KS5f6YiQp2sgFseq9V18ngEzOd0/pQO8bE0QmyHG6F//w5cnn0Aq52SVRUENJrP2LrB/vyn4FoaQJeUh8Ye7yL3PxV/poYceVSurPH36NLZs2cJID3Nzc4wbNw4DBgwoJD3YdcnjoeOo8eg9dTp4fAGCr13G3qWfIyedM8nTQw89qGYzn1N5KEmP16YCo3bVStLjws4tjPSg9lKfj2bCt/VrqE3bd/vvCJz85SEjPTwa2uCtz1rVatKDQBG3lPbSr18/tVQiqh4heuihR92EnvjQAUTn5qr1vr+uXWfRX1T/qFrjWBdgZOQCX985eL3DJfj7L4GxsRdkskxERv6KK1e74MHDT5CRcVet7yKT0+OfdMKI1m5sMIzib4f+dAXPkjlj1eIg8rCAwyctIPK2RIFEjtRdT5B+PAwFcn1okh56VFV998aNG3H58mXW0KeYtalTp7IouZJA/h7DF6yAkZk54kNDsHPeDCRFPNMfED30yEkBtg8G7v0BGPCBfl8DvVdTTnSt2zf/HdiNm0cPsNc93vsIDV7XvOlxdUEuU+Dcjie4ejCUzTfp7Ip+HzaFyFhzSVbahpyckttmqqBEET300KNuo+7cGXUYbpSXnFX2jd0gPQ03IkJY7aOy5p0crcn9mv7a2trWGklnSaDSFne38XBzHYvklHOsDCYt/T8kJh5nk6VFC7h7TIK9XU/weCWf/qYiAb4c1gyd/R3w+YH7uB+dgX7fXcSSAY0wvHXxxqd8M0PY/a8JMk6FI/t8NLIvxkASnQ3bMfXBNzfU8JbroUftBMmEL1y4gIsXLzJDO1NTU6bwIDd/deDWsDHGrPwKB9csRVpcDP5YNBv9p82Gd4s2Gl93PfTQSiSHADuHA2nPAJEFMHwr4KtZE+Cawq3jh3Bl7072usvb76Hpm71QWyDOkeLkxgeICUpnguCOI/zQtKs76hooHrUq36eHHnrUXujjbGuDx8dzDBABfTLikRgRzqK8aFRUFSYmJoUkCP11cnLSqXrDiiIrKxBRUVsQn3AMBQUStszIyBVubm/D1WUkBILSZb2x6XmYsfcu/gvj/AT6NHbC6reawMqkZDIj90Ey0vYFM/UHz9wQtmPrQ+RVtsFYnagpr6PQH9vyg+5j5OURFxfH5smcjmTNRH6UF+LsbBxdvwqRD+8z8+MuE95Fi94D9ElMetStazbsPLB3PCDOAKw8gTF7AQf1SERdw/2zJ3F64w/sdYcRY9F+6Ohac2zTE3KZiSn9FYr46PluI3g1sUNdBBHi33zzTalKZ73HR/mh9/jQQ5egNzetRcSHOqkuymUuIiG+8HdDJzMRoqOjWU0jGQHSa9qOovWRbm5uhWSIq6srW1ZbkZ+fhOiY3xETswtSKUdi8PmmcHYeBne3CTAx8SzV+HTjhTB8dSqIGZ86WZDxaTN08Cm5oSFNzEXK74GQJeYBPANY9asH0w4upTaydL0xpkfJ0B/b8jVkr1y5gnPnzrH7FhlVEeHRuHHjSl0XcpkMZzZtwMNzp9h8s5790G3iZPAqcV/XH9fai1p3bG9tA47PABQywK0t5+dhZo/aiMeX/sWJH75ibaQ2A4ei05iJLx1DXT62sSFpOPHzA+TnyGBmLUK/D5vBzq1uqxkCAwOxd+/eEv9fn+pSfuiJDz10CXrio5YRH0ry46ukbM7o9DnMJWLMtDdDQy9PzAqKQqSYUzS85WiNZb6usDPkyjko5otq5IkEITIkKiqKnSSqILdrFxcXRoQoJ1KJ1DbI5WIkJBxBZNRm5OSEPF9qAHu77nB3nwQrqzYlNoQeRGfg0913EJacw7im99/wwYwe/jAUFG+Xo8iXI+3PYOTdT2bzxs3tYf2WH3iGxZ9HutwY06N06I+teiB3/oMHDzKyluDn54eBAwcyI9OqOg5U739h11bWKfJq1hL9p82ByMS0wt+nv2ZrJ2rNsVUogDOLgSvfcfONhwGDfgSEVZ9ypA0IuXEVR79ezdKdiNx8c9IHrxw/XT22T67G4dzvT6CQF8DBywJ9pzSBqeULY+e6Tn6cPHnyJeUHKT169+5dY1G22tSHqCvEB7Ud3nzzTZw9e5YN7lYEVFq7du1ahIeHw8vLCzNnzkTnzhX3BkpLS8OiRYtw6dIlWFtb49NPP8WgQYMK/3/KlCn4559/XvrMzz//jK5du2p8W2/evIlVq1YhLCyMDYLPmTMHHTp0QHXgwYMHWLlyJR4/fsyqEGg/DB48uELfpSc+aulNi8peKL0lNDUNPjbWGBjgXRhhmyOX48tn8fg1KgmUQWIj5GO5rysjQYo+2GlENTExkREhSjIkKyvrld+zt7d/ySeEGgm1BdTwSU27jKiozUhJOV+43Ny8Edzd3oGjYz/weK8qYHIlMiw7GojdN6LYfGNXC3w7qgV87M1K/J3sS7HI+CsMdGAEjiZc5G0xjuu62hjTo2zoj23poHsS+RNRagsRtaQ+69OnD7vvauJaoM7Rie/XQZafD1s3DwyZsxiWDo7l/h79ca29qBXHVpIDHJgMPDnGzXf5HOg8p9SyWV1G+P07OPTFUqbuavhGN/SeMo2lPOn6sS1QFODakTDcOsklk/i0dED3iQ0gKGEQpS4/R6g9S2WSjo6OrN1aExG22tqHqCnio6BAjvT0G8jPT4RI5PB8gFEz+6KyZACdPzTYMn36dPY9Z86cwVdffcVItYqSCx988AHbn/PmzcO9e/ewbNky7Ny5E02bNmX/37NnT3z00Udo37594Wfo3lSWCr+y25qSkoJevXqx9aO/FJBBhAttKxERmgT1OXv06IEhQ4ZgzJgxuHPnDts/27ZtQ6tWrcr9fXrioxbftMp6YN/OzMHMJ1F4nMMpOrrZmOPLAHe4GRmW+p3p6emFpTH0t7hcdPpNVZ8QIkZ0odFQFnJyniIqaivi4g9CoeD2m6GhA9zcxsHVZTQMDW1e+czJh3GYe+AB0nOlMBbysWhAQ4xq417i/sgPy0DKrsdQZEthIOLDZkQAjBvZ6nRjTA/1oT+2pY+GHD58mI2uEKihRaMhZNCsSSSEPcWhL5chOy0VJpZWGDRrPlz8G5TrO/THtfZC549tZizwxygg7h7ANwQGbQCaDkdtRfTjh/hz1WLIJPnwa9cB/T+dU2IZmy4dW6lEjrNbAxF6O4nNt+rjiXYDvGHA0+71rilo27HVtj5EdRMfiYl/IzhkGfLz4wuXiURO8PdbBAeHqjcbriwZcO3aNUZ2zJ8/v3BZ27ZtsWTJEvTt27fc30d9Kurgq64PfTedF2vWrIFEImHnBpEOtK+rc1tPnz6NBQsWsG1Wol27dli6dClTSmkSwcHB2LRpE7744ovC65RIENrH7733nsbOV32qSy1ESwtT/N3aHz9GJmJ9eAL+Sc1C5+tPMM/bGe+42oFXzIOATjqSX9FEF6AyIkxJgtBfMhikhwlJk2giGBsbF5bFEBni7OysUzd2JUxNfVG//gr4+MxETMwfiIreAYkkEWFhXyM8/Ec4OQ2Bh/s77H1K9G7sjObu1pi57y4uP03B5wce4N+gRKx5qymsTV8lmSjq1vGTFkjZ+QSSiEyk7AiEeRd3WPT01Ddg9KizDdTbt2/j77//Zg9/oVDIGgitW7eullE6R29fjFn1NQ59sRyJ4aHYu2weGyGuX4viLvWooyCyY9dIICsOMLHj/Dw82qG2guKqD36xlJEe9Zq3Qr9PPquUd4+2ICcjHyc23EdiRBZ4fAN0HVcf9ds71/Rq6aGH2qTHg4cf0tP+peX5+QlseZPGP2qE/FBFQEAApk6dil27dqFFixZo1KgRfviBMz0uiqCgINbxp4kglUqZwTq1T5TqDMLu3buxceNGNmhD3mNEHtDvFAdSeFDfSJWYIEXDL7/8wl5TiQn1wdzdK57IRAqN7du3s8jm/v37s/Uhtcj3339f6rZaWVmxQe9Tp04VkjPU9/P391frd6msbPny5exzZI1AqpHPPvuMEQ8HDhzA559/Xuzn6P30G19++WWhUuvff/9lxEWbNppN3NMTH7UUhjwepns5oZ+9FVN/3MjMwfyQGBxKSMdX9d3hb1o2e0vJCQ0aNGATIT8/n7GLSjKEXufl5bGLhyYCdVyUhqk00WuRSHfqT4VCa3h5TYWHx7tISDzBymCysh4hNnY3m2xt3mA+IDY2HdmNysnSCDsmtcOmS2FY+3cQ/n6UgLtRF/DV8Obo6Peq8SnfQgT7yU2QceIZsi/HIuvfKEiis2Azuj74psIa2WY99KgJ0APzyJEjePr0KZunhz7VdlLsdnXC3MYOI5euYWUvoTev4fh3a5EWF4vXho7SitFCPfQoN56cAP78HyDNBezrA2P2ANZetXZHJkeG489ViyDJy2Px1QNmzgNfoPvP0+TobBz/8R6y0/IhMhWg7wdN4OJnXdOrpUcdBw1YKBR5arxPjuDgpa+QHs//l3nrkRLExqZDmWUvPJ5xpZ7HZJT+xx9/sA42kRCjRo0q8zPUz6FyW1JmkMeHkrggLw4iE6jDT+oCIkbefvttRh4UZweQlJQEBweHl5ZRO4fKsZTEB0Utz549G9evX2clJh9//HG5PEXI2Hf9+vVsXel7iFSh75g0aVKp29q6dWuMHTsWn3zyCRtsos+vXr0a3t7eav0uKVeIHKJ9S33EFStWsDIe8gwh5UanTp2K/ZyNzQsVPZFKLVu2ZN9D66ocfNcU9MRHLQcRHIdb+mJLTDJWhcUxAqT7jSBM83LERx4OjCBRF0Rg+Pj4sIlAdfikAlH6hNBERAgxdjQR6EZFNxllaQxNFYmirG6Qt4ez02A4OQ5idYlEgCQln0FK6gU2mZr6wd39Hfb/fL4RJr/hwxJePiHj06QcjPvtGia/4Y2ZPf0hErx8Qzfg82A1wAeG7uZI+zME+U/TkfjdHdiOawBhHXdm16NuNJpIMXbixAkmTSSFWLdu3Vhta03VYhsaGWPgzHm4sHMrbh07iCv7diItLgY93/8EglqcdKVHLQOlvF39ATi1kOtY+HQDhm8FjGqPN1dR0HW6f+VCiLOz4OwbgCGzF0FoqDuDLSUh/EEyTm16BGm+HFaOJuj3YVNYOdQ+s3k9dO/5fev2CGRk3K6Kb2PlL+cvlN3RtbRshVYt91SY/Bg5cuRLnXl1+iHUOd+/fz/znqCSFOrHkKKByjPef//9QuPRadOm4cKFC2wgZ/z48a98D/WLinp10Dx1+JXEB7WFOnbsiMmTJ7PyEzL53LNnD5o0aaLW9pE3htIXg4xT161bx4gP2s7StjUnJ4eFXZC/CG0PkTdEXjRr1qywr1cSqM9HJUFE1ijN54kMogEsUnrQMnVLpGhbaT8QaUJmsu+88w40BT3xUQdApS3/c7NHLztLzA6KYqUvZIJ6NJFTf1BpTEUgEAjYKC1Nr7/+OmNSk5OTC0tjaKLSGEqToenq1avsc3Z2di/5hJDUSltHVrkSoLZsys2NQFT0NsTF7WdpME+ezENo6Dq4uo6Bm+s4NHa1x/GPO2H58UDsuhbJ4m8vP03Gt6Oaw9fh1UQKk+YOEDqZIuX3x5Al5yHx53uwGuiDAn/dcc/WQ4/ygB6yx44dYw7eBCJFqaaz6GhITYDH46PL+P/BxtkVZ37bwOIwM5ISme+HiUXt7TjqUUsglwLHZwK3t3HzrScBfdYC/NrbzMtMTsS+5QuQk54Gew8vvPX5Uhgam+h8x/L+uWhc3hfCeCzXACv0ntwERnpFqB5aA+1sr5cGV1fXwtdk3qksMykKIjmUoI47pQHRFBoait9//50RH/SaEl++/vrrwveS2oE8yighRdWfgggSGjRWkhxK0LySFKAyHCJMlGqR+vXr49GjR0zFoS7xoVqGQ+tLfTHqf5ESo7Rt3bRpE7vnEPFBoDKg+/fvs7IZ8vkoDbQfqN/3xhtvFGswTETG4sWLi/0s+ZlQiqiSBKLfpYlCN3bs2KEnPvRQPaPkQMRlCBOeAY71AM/XAZ56daxkbrqzqTcOJKRh4dMYZn7a/1YI3nOzx2xvJ5hWsh6WRmupA0OTskaLasdUfUJI8kUXJE1U26+MG1P1CSHD1Jp24S4OJiaeCPBfBB/v6YiJ3YPoqG0Q58ciPPwHRERshJNjf1YGs2pIE3Txt8ecP+/jUWwm+n9/CQv6NcTYdh6vEDxEfDh81Bype4MhDkxB+sGnEDSxRsFwcxg8jyLWQ4/aACI7jh49itzcXHZ9k4yTRji0zROoaffesHRwwtH1qxEbFIhd82dgyJwlsHWreP2tHrqHArkcOTdvIi8iAgJPT5i2bg0DLTtXC5GXBuydADyjdDIDoNcq4LUptTa5hUBkx77l85GVkgRrZ1cMnb8cRma6rZhUyBW4uDcED8/HsPkGrzuj8+gA8AXa1x7So26C2rCkvFCn1CUt/Qbu3ZtU5vuaNdsMa6s2Gi11US25p3IKKmEpCSEhIYw0oDIQJUj9QMoGApWDkMJCNYGFQOUqpK6g0hcliMygaFzq86iC5qmvw20b75USGVKnKMuA1YFqn4mIDKX1QFnb+ujRI0a0qILsDWgflAXaD0QO/fnnn6/8HyUqkXKDlCPFgfqJpDQhski1HMbX15f5pmgS+p6VLiHwCHByDgwyY1Go0bBwAXp/ATQcqNZX0I1jqJMNOttYYNHTGEaC/BKdhL+SM7AuwB1v2LyqTKgMSM1Bk5KNpE6PaoQulcpQrf/Dhw/ZRCAWVEmE0ESsIKlLtAUCgTk8Pd6Fu9tEJCWfQlTkZmRk3kFc/AE2WVu9hhYek/DXpx3x2f4HuBiSjAWHHuLfoCR8MbQJbM1eluHyjASwHd8AWeejkfl3OGQP0pCUch+24xpCYKNXf+ih2yCZ519//cVGEZQPPFJ5kNpDW+HZtDlGL1+Hg18uRUZCPP5YOAsDpn/OlutR+5F56hQSVq2GLJ5LIUin+76TExznfQ6Lnj2hVUgN40xMk4MBoSkwbDMQoFk3/ppGXlYm9q9YgPT4OFjYO2L4wpUwtdJt74v8PBlO/foQkYGpjLtqP8QHLXq8Oliihx41DTon+fyylVW2Nh1ZegsZmRbv82HA/p/ep6lo29L6JaX5gZAxJ7VblNcfEQTKUhny9YiPj2cDtUpQaUf37t1ZworqcgJ5VsTExLDPKCNib926VehlMXfuXPY75K2hxJMnT9Q2GFUmpFDyDIHaWvQ7ZDZKU2nb6uDg8ArBQkoNdRJiaD9QJC2tO/XVCOT3+N1337FtoUFtIoNKAq0nKUIuXbpUqH6hfqC6/iIVhZ5G1iXSY+/bXDydKjLjuOX0/+WAnaEAGxp6YkeTenAVCREplmDEvVBMexyJdKkMmgJdhMQuUmY1ycHogidToC5durCTnRhKqnWji5hqxzZv3sxq67Zs2cIMhegCJUmZNoDHE8DRoS9at96P1q3+hINDP3bzTkv/D/fvT0ZY4ACs6BmMeX18YMjn4czjBPT+9iIuBHORdKqgG4dFF3fYTmoMGPMhjc1Bwvd3kBeUWiPbpoceVQEaNdiwYQN7wNE5rqxh1WbSQwlSeIxZ8RVc6zdEfm4O/ly9CPdO/1XTq6VHNZAeMZ9OKyQ9lJAlJLDl9P9ag4grwK9vcqSHhSvwv79rPemRn5vLImuToyJgam2D4QtWwNz2VSNxXUJmch4OrL3FSA+BkIc+k5ugJaW96UkPPXQY1B6myNrnc0X/l/3r77ewWkkPdTBw4ECmTiefDFIk7Ny5k/l3UNkKgfwntm3bxpQdNIhLZS9EkpTkiUF2ANT2obQTIjT27dvHSn7JVJRAHmekhqXvowFhMk4lYmTcuHGFJcKpqaX3Bchbg9JjLl++zIiHiRMnqrWtw4cPZ/4kW7duZQoM+ktExJgxY9j/U3+M9kVxoO0ltcasWbNYG4/IISKAaICbSI+yQP0+UowsWrSI+ULSPqDSG/I30SQMCpSaGD20N4Obylu+afwq6VEIA075Me2B2mUvqsiWybEyLI4ZoBLsDQVY7eeG/g4ls4Sa3NfEiqr6hNBFpAqWpuLk9JJPSGmsYnVCLI5FdPQOxMTuhkyWyZYJBBbIE03E2ouNEZosZsv+17EeZvcOeMX4lC7HtKgkSI/EQBqdzR3aNz1g3s1DH3mr46BjS/JJkjTW9gYtkZMUUassZyMHczK8qkxcW01BJpXi1C/f4fHFc2y+Vb/BeGPcO8wTpK4d17pQ3vL0ze6vkB6FMDCAwNERvmfP1HzZy709wJGPALkEcGkBjN4NmHOjibUV0nwxIz1injyCsbkFRi5ZA1s3bqSxvNCW6zY+LAMnfrqPvCwpTCwN0W9qUzh4lt1p0EP7j63W9CEqCOr0UoeURvbVNaksKdKW0lvIyFQJkciZkR6aiLKlxElSXlBkKikXKGaWPCuUEbXqgI4XJZOQgoH8QSjVhb5TCfo+IgmoZIXKM4jUKFr6ooqUlBSWgHLlyhVW4jJ9+nQWO6sEkSHU6Sc/RD8/P0YgKC0DKJL24MGDbPC3pG0l5QQRJpSMMmLECLa+6loGnD17lpEl1N+iY01ERocOHdj/KSNplcmdRUGEDJmhUhQtKfOJCKEoXWtr9RR45BOiJG3oM0R6EBmjyfNVT3zowk3r2UVg24sLpETU6wLY+wNGVoCxNWD8/C+bV3ktLP6EuJ6ejZlBUQjJ5RQVfe0sscrfDU4iYY0+wOjGouoTQr4hRUEdK1WfELqAavKBJ5PlsLKXqKgtyMuLYMskCiMci/wIx4O5hlp9J3N8N7oF/B3NX3lgW5iaI+P4M+T8F8eWGwVYw2ZkAHgmuh/RV1ehbY0xTYEePIcPHy68TqmxQQ/moq7munbs/juwG1f27mTzPq3boe/Hs1gaTF05rnUBOdeuI3LChDLf57FtG0zbcbLiaodCAfy7CriwlptvMAAYshEw1G1TT3UIyENfLkPE/TsQmZiy8hZHb98Kf582XLchNxJwdttjyGUK2LmbMdLDzFpf3lpZaMOx1ao+RA0TH8poW0pIzM9PhEjkACurNlqn9NBmUCwtKeDr2m9r4nzVHuMEPUpGNpf1XCae/ctNZUFgpEKIPCdIjKzQ1tga/4gscS6PhyNZQGqKOT6KsMTb3r4Y4OEFA3pvNTvE00OL2FGalFFN9EBT9QkhF2BiU2lSOjKTAkRVEUJGO9VpmCoQmMLdbTzcXMciOeUc8wGhEpi3vNbBx7QRtj6agCfxwIDvL2F+vwYY/9rLslYDAQ/Wg325yNuDTyEOSkPCD3dhO7YBDF21Q92ihx5FXcpp5ODatWtsnupKBw0axB5Cug66NtsPHc1MFE9uWI/Qm9ewe/EcFp1pZmNb06unRxVBVoKkt6Lvq3JI84BDU4BHB7n5jtOBbouo7hK1GXKZDMe//YKRHkKREYbMXVIp0kMbOuY3T4Tj+tFnbN6rqR16TGoIQyN9k1yP2gkiOaytX6vp1dBJUJlNy5Yta+S3b968WehLUltQbsUHlR2QT0Ndgs4oPii+ztiGc3gXpwN56S+/pr8Fisqti6H5c/WI1SvESbGvlQSLyEJjjTMyT6TaNKUihEyEKE6pqKMzyeyVRAgZppKfSHUiKyuQKUDiE44iXWyEzQ/H4WFKA/Z/XQNssHZ4S9iaGr4yUiGJzWaRt/JUMfCcEDFt7Vit665H7RuFqkrQ9UdSTGUdKpGU5OOj6qReWxAb/ASH161AbkY68xgY/NlCGNna18rjWteQffUqot6ZpJ2Kj+xE4I/RQMxNgCcABnwLtOBqwGszChQK/PXj1yxemi8UYsicxfBs0lxn78cyqRzndjxB8HVuQKtZd3d0eMsXPJ7+3lFbn7U13ofQAsWHHhUHla9Ud39FCZlMxs5ZbbiOaqzUhS5cMiSh2iTK7tVl+bLueXzEleiMrJbHB5EBkiyODFESIcW9fk6WFOSlIys7hS2zkOdUbhsMeICR5atlN+oQJ0KTcsXy0U2CyA8lEUKdsqIZ2nQcqW5PqQohUqS6buz5+UmIjvkdUdF/4GRoY+wPHgRZgQDWxlKsHuKD1zzcX3lgK3KlSN0TxJQfBNN2TrAa4MOUIXroBrStMVZVD0Wq7SRDLdo+MqoiYzCqUa3NyEhMwMEvliIlOhICQ0N0njQFzbp0rzXHtS5CGheHmM9mI+/mzVLfxzM3h/9/V6vX4yMhkEtuyYjkno8jfwfqvYgArK2ge8qZTT/i/pmT4PH5GDhzHnxatdPZ+3FelgR//fwAcaEZzLOr82h/NOrkWi2/XZegbc/aGu9DVBB64kMPXYLGiA+Kmjl58iSbqIabarf79u3LHGt16YLWuZvW81QXOlgGKuRHAQw4b+QR29WOtC0vwvPyMTvwGR6mxMNSmo02hvmY4SiCl4G4VOKk8LWs7LzvUsETluxXUhZxIhCx45eQkPCSTwi5JBcFlcMoFSH0lzpxmoRcLkZ8wmFcengE317rgtgcF7a8r+9TLBzUDk527V56aBcoCpD1TyQyz0Yy/kvoZgbbcQ0gsNIz8boAbWuMVRYURU0qDyo1I1BkNeXFGxsboy6A0iWOffsFwu/eYsRsp9ET0Gbg0FpxbOsaMk+eRNyixVBkZgI0mENEOR3HEppH9tM+hd0HH1TPyoWcAfZN5AYtbHyAMXsBO90t8yjP/fL8jt9w6/ghdiz6ffIZ6nd4Q2fvx6lxOTj+4z1kJothaCxA78mN4d7ARuO/W9dAXhJpadeRnh4BKyvye2tb414SWtGHqAD0xIceuoRqMTel+JpTp07h/PnzLO6GpM2kBFFmCdcWaMtNK/74DphfXwJTAy59hZBdYIfstkvg1G+8Rn+bTpM/4lOx9GksMmRy8A2AD90dMMPLCUb8MlQHsvwihIh6ihP2WiGt3IqTWqQIWVJgbAkxjJEmLkBStgyxablIyZEjD0bIgwhiGEEMESytOcNUJRlCBqqaaCDRvo1NuIhVx2/jeAg3Uu5qFovpr13C642HsMhcHu+FsooiblN3B6EgTwaeqQA2o+rDyE89B2U9ag61hfig++HFixdZBBqVlFHp44ABA9CgAVe2VZegkMtxbtuvuPv3MTbfuGsPdH93KvgCvQmxLkCenYOEVauQceAAmzdq0gSu69ZCHBSEhFWrX0p3ETg5waR1K2QeO87m7T76CPYffajZFby2ETg5hytR9ewIjNwBmNSNzvKVfTtxdf8f7HXPDz5Bk649dfZ+HPU4FSc3PoQkTwYLOyP0+7AZbJxNNfqbdRHFp4c4sUhVTaSH6FoforzQEx966BKqhfigh8aZM2dYxA7l/lKmL9V40w9SDFBNmbHUxptW6J1EnPzlIQwgh7PhY5jy0pCjsEacpAEKwEfv9xvDp4WDxtcjIV+KeSHROJ6UweZ9jEX4qr47XrPSgOEmnZqSnGL8StQhTmj9KpfULIYhI0PEzwkRKd8MAnM7GFs7wczeHWb2buCZ2L6qMiE/kwo2pE7cvYPPD4UjQ2wIAU+KEf6H0dvnCTzcx8PVdTSEQo7gkKWKkfJ7IKSxOVylU08vmHd200feajFqA/FB6g5SeZDag0BkB5Hdpqamdfq4Xjm4D9f2/o6CAgXcGzXFwBnzYKQlEdt6FI+8e/dYaYs0MpLdr23fnwz7Dz+EwfNaaoq2zbl5E1kRETD39IRp69asvCX511+R9NXX7D12U6fA7uOPq/56lsuAv+cB13/h5puPBfp/Awhqf2kx4ebRAzj/O5ci0HXiZLTsM1Bn78cPL8Tgwu5gpth09rFEnw+awNi8bhzH6iY9Hjz8sJh2H3dsmzT+scbID23oQ1QEeuJDD12CxoiPtLQ0RnZQqQu599NoeL9+/Vjjl0bF6etWrlzJlCA0IlgbUNM3LYWiANvnXUFOOhczWxzMrEUYv7JDtRlknUhKx9zgaCRKZGz+bRdbLPRxgblAS27q5GeSn1mC0WtJxMnziSTFlfYzKVqSo16pToHACGFxyVh2MgTnQ7g40Ma2gZjUeCfzAHF2GgJ393dgauqDAqkcaYdCkXuLM0kzamgLmxH+4Omd4bUSukx8kLLj6tWrjOSm+yE9VKjEsUmTJjq3LZo6rilhITj+7ZeQivNY+suQuYth7cSVr+mhPSBCI4XIi+9/oIc7BM7OcP3yC5i0aaP2NZuyZSsSv/iCvbadPBn206dV3XUgzgT2TwKenubm31zMpbfUkevs3ukTOLNpA3vdcdTbaDdkhE7ej6ndduXPp7h3NorN+7dzRLdxDcAX6n25NFHecvnKGy8pPV6GAVN+vN7hfI2UvdR0H6Ki0BMfeugSNBZnS14e5IVAjd7PPvsM9evXf+n/6QHSqVMnBAcHV2zN9XgFcSHppZIehOy0fPY+14DqKXnoa2+F163MsCw0FjvjUrE9NgVnUjKxxt8NPe0sUeOgBBll+kx5IZdyihEVskSWnYzM+AhkJkUiLyUW0qwkGCpyYcyKZvKZLoT+CiHjZMl5qdxUXvANUU9kia0mNkhyMsbDVB7SMk2Q9583nOyfwiBqM8LvbIGxTVPYug2BVec3IHKyQtrJZIgDU5D4/R3Yjm8IoVPdHYHXo2pBMdGHDh1iJsEEMi6l0hYLCwv9rlaBd4vWGL18LTM9TYuLwa75MzFo5ny4NWys309aAmlMDGLmzEHezVts3qJvHzgtWQJ+Oc9l23cmMvUHlcmkbNyIArkMDrNmVb4DnR7JmZgmBgICY+CtX4CGg1BXEHjxHM789hN73XbQMI2RHpqGRCzD6c2BCL/PlSW3HVAPrft61XmSWFNIT79RCulBKEB+fhx7nz5SVQ896jbKTXzs2LGDlbBQSoYy0SU2NpbFgyrRuXNnNulRNcjJzK/S91UVLIUCfFXfA0McrTHzSRQixBK8/eAZBjtYYbmfK+wNdbTOnS8ETO24SeVCocpqG5URcJL9K81S6W92djYEkDEyREmEOFmK4GJtAgcLEWyMDWBUkFey4kQhg4FcAoPcJCA3CVS41E11cIjaUIX2LleeTwBRHKZCQCE0giLbDAU/mUFu5wC+vYOKmqQUxQml7ZSWBqRHnQSd45Thfvr0aZaURPf73r17o0WLFvoGfAmw9/DC2JVf49Da5Yh/Gox9Kxag5/sfo1HnN6v34OnxCjKOH0f8kqVQZGWBZ2ICx0ULYTloUIXPZZu3xwN8HhKWr0Dqb5sBmRwOc+dU/NqIvsnF1eYkAmaOwOg/ANdWdeZIhly/gpMb1rMS1+a9+qPj6AnQRWSniXF8w30kR2WDL+DhzQkN4NdGHz+vSeTnJ1bp+/TQQ4/ai3ITHw4ODhg2bBjatWvHFB+EoUOHsjKXb7/9Fk5OTppYzzoNUwtRlb6vqtHR2hzn2tbH2mdx+CUqCYcS03E+NQvL/FwxzNG6VnaSeDweO9dpomuBZLNUBqaaHBOZkoJIshrh7FAYrKwoQrc9POpzpql2dnbc/mF+JtkoyEtDdmIUzAQyGDDVSRqkOam4FhiGiOgYWBrkwNkwF76mSTCUJEEgk0Mgo2wfgAcxeJS0Q+xISjiQUo4NElm+UMgUjRMujTgRmdcZCXZdAiV2HT58mMkGCV5eXhg8eDCsrCqgoKpjMLWyxojFq3Hyx/UI/u8S68yRAuT1EeNgQEo0PaoV8uxsRk5kHD7M5o2bNYPL2i9h6OFR6e+2GTsWBnwB4pcsQeq2bayMxnH+vPI/8x4dBA5+AMjEgGMTYMxuwNINdQXP7t7CsW++RIFCgUadu6PbxMk62W5IjMhkpEduhgTG5kL0ndIUTt5aoICt5ZDL1UsOFIk074OnR80jOjqaJY6ePXsWbm4Vu4+SgfvatWsRHh7O2j8zZ86s1IA+9Q8WLVrE/DCtra3x6aefYtCgF2q+KVOmsFJiVfz888/o2rWrxrf15s2bzJczLCyM9UvmzJmDDh06oDohk8kYl9C9e3d8/PHH2kV8LFmyBK6urpg0aVLhshMnTmDx4sVYunQpfvqJkynqUXVw9rOCqZWo1HIXoYgPh3o1Jz034fOw2NcVgxysMeNJJAJzxPj4cSQOJKThywB3uBvVbjMvaqTZ2Niwieo4CaQAYQTIczIkPj6edShpokQkAiViEGmoTI9xdHSBHBaApWUhoUC6mY5vALKgRMzadx/J2fkwFPMwq6cXenhdRmzUVshyYiCUFUAo58EmvylMH9eDKN8IQmspTAKE4CmyXpi+qqpMJNncBuRncFN6RDk3nF96nHBpxImwbsSe6hKIwLtz5w7zcCJVn0AgQI8ePdCmTRtG9umhHoSGIvT/dDYuO7vi2sE9uHZwL9JiY9D7w+kQivTx09WF3Dt3EDt7DqRUpsXjwe6D92E3ZUqhgWlVwHrUSBgI+IhbuAhpv//Oyl6cFi5Uj+QiwvviOuCfFdy8f29g6CaOUK4jiA58iCPrVkIhl8H/tY7o+cHHOkkQht1JwunNjyCTKmDjYop+U5vCwk7/jNMkZLIshD37FlFRW8t4J+fxYWX1qo+PHtUDeUEB/kvPZr6ADoYCFojA11Jyk9rrH330EaZPn85IBfK1/PDDD1m7qKLkwueff848KPbs2YN79+5hwYIFzIuiadOm7P9DQ0MZ0dK+ffvCz5D/UHWUMn/wwQds6tWrF44fP46pU6eyba1OIcPmzZvx5MkTRnxoGuUmPm7dusVGAinaUwlir+gEIbZGj6oHGZZ2GunHUl1KgjRfjkNf3Uav9xrX6MO2uYUJ/m4dgA2Rifg6Ih7nUrPQ+foTzPN2xjuudlp7o9MEzMzM0LBhQzYR8vPzmU+CkgwhpjY3N5dd7DQRhEIhu9l4e3szIoRussqSsi4BDvh7WifM3n8fZ58kYtVfYbjk3xRfvvU3DCTnERW5GRmZd5Bp9gDo+AAmaQ1gHd4T5vdaw25MI4iKG3mSSTgypKQ44dLMYeX55BQI5KZwU3nBFxVPlqhDnFA5ki5BIQciLkOY8AxwrAd4vq515UVZWVk4cuQIQkJC2Dyde0OGDHnpXq+H+qDOW8dR42Ht7IJTv3yP4GuXkZmciMGzFzFViB6aQ4FMhuRffkHyhp+YganQxYWpPExaaaZ0xGrYMHY9x82fj/Q/drOyF6elS0rvwFPM+9FPgXtcZCtemwr0XKF19wVNgsrBDn65FDKpBN4t26DvxzPB07HtZ2TxqUhcPRTKAkU8Gtqg53uNITIud/Naj3Ls88TEEwgJWYl8CWfubmHREpmZt5+nuKhmNnBtTn+/hTVibKoHcDwpHQtCYhCXLy3cHc4iIVb4uaKfvfapSGmQcsSIEZg4cSKbf+edd9igPg1YVoT4oPb+uXPnClUZ/v7+zOx2165djPigQSbqD5BZvL29PaoTt2/fZoa77777LpsnAmTLli1s/ai0ubqIpu3bt8PX17dafq/cd2YiOQIDA9kItSpIIkMdPT00A4qqpcjai3tCXlJ+UJqLf1tHPLoYi8SILOxZeQPd3q5fLdG2JUHIM8CnXo7o52DJvD+uZeSwm97BhDR8Xd8DAaZ1c8RTJBKxC1t5cZO0i2JBC0tjIiMZI0zkiNJIkkbZnZ2dCxUh9HfThNb4/VokVhwLxIXgJPT9/gq+GNoKPVr3RUbGXURGbUZS0knkWj9mkzDHEakne8C98ThYdvJ9WUJM8Yhm9txUXkhL8CspkzhJ5wgTIk6y47mpvDA0K0KWWKpHnFBJT3WPJgYeAU7OgUFmLPNjYbBwAXp/ATSs+pjGijQiHz58yJh+Ov/oIUjySpI66lUelQf5e1jaO+LwVysRHxqCnfNmYMicRbD3rFcF365HUUiiYxA7ezbyblMnCLDo3x9OixeBb65ZFYXVW0OY8iN27udI37ePlb04L1/GTFBfQU4KsGccEHmFU831XQu0+V+dOphJEc/w56pFkOTlsQjo/tPngi/QLUJbLlPg/K4gPL7CxXs36eyKjiP8wOPrnmJFV5Cb+wxBQUuQmnaJzRsbeyLAfylsbTuxSNvgkGUvGZ2S0oNIj5qKsq3rINLj3Yfhr4QMx+dL2fJNjb00Tn4EBAQwFQMRDeRR1qhRI/zwww/FvjcoKIiVr9NEIH8zMncnckKpziDs3r0bGzduZCUsjRs3ZgoO+p3iQAoPaserkiatWrXCL7/8Uth/pna5u7t7hbeRFBpEHpDSnFJWaX1o0PT7778vdVutrKyYCp2SWEndS+RMTk4OI2fUQWZmJpYvX84+Rwp2Uo2QDQalqhw4cIApXYqDamkOlQBRecuxY8eglcTH+PHjsXDhQibLoZOHQKPVW7dufan8RY+qB5EZ9ZrZIzYkDclx6bBztoKLnzVThDR6wxWnNj1CwrNMpgxp0sUNrw/1rdHoNF8TIxxs4csSX1aExuJWZi663wjCp56O+MTTAYY6KGetSlAZAd3olDc7MpNMSkpi1xP9JSKEbioxlEQQE8PiRAnECBMBsq6nM76/mY3gxBy8t/0mxrbzwIJ+TdCk8XcQi2MRFb0dsTG7ITVNQGL935GcdwB2R/vAp8vHMLGo+A22EFSqQhN14ssDknfnZ5UcLVwicZLOleMQqESHpszocq60AWBkoVa08CuviWwpr2KJSI+9bxcZgaKnRRy3fMT2GiU/6AFHhAeR2QR6OJOXByV36VF1oGSXMSu/wsE1XOLLH4tmo/+02fBuoZdeVyUyjh5F/NJlUGRng2dqCqcli2E5YACqC5YDBzLFBhEvGQcOMLWJ86qVL5MfySHAzuFA2jNAZAEM3wr41i3z29TYGOxfuRDinGw4+wVg8OyFrDxMlyDOkeLkxgeICUpnjwUiPJp2rYLnqh7FQi4XIzziJ0REbERBgQQ8niE8PafC02My+KQeZR6EvWBv3x1padeRnh4BKytPWFu31Ss9NDBYkqtQqFXeMj845hXSg33Hcy0ODYp2si677MWEx6uU7w8pLv744w/WzqZ2zqhRo8r8DA1K9unTh8URk8eHsqNOXhxEJlCHn8pViBh5++23GXlQXHkKtefJH1MVpKRNSEh4STgwe/ZsXL9+nam+iQgoj6fI3r17sX79erau9D1EqtB3UL+8tG1t3bo1xo4di08++YQNdNHnV69ezVTn6mD+/PmMHKJ9S6r2FStWYNmyZcwzhNJfKeW1OJAtAOHPP/9knyOFjdYSHyT5MTY2Zjt506ZNrPNGI9HE6qgateihGRDJ4epvDTNH3kv58xa2xhgyqyWuHQrDndORePBvNOLDMtDrvUawtDepscPBMzDARFc79LC1wNzgaJxOycS68HgcTUrH+gB3tLTUx66+OLY8dnMkZYjy5klMrKpPSHJyMruJ0kRoV2AAU2Nv3Mmzwc5rkbgckogfxrRCYzcX+PnORT2vjxEXtx8RTzcjXxiNROGfSLxxEPZWveDp9x4sLZpV/0lh8Jx8oMnKo/wlI0qfkhKJk/TiiRNpDve4ZaU9Ko6z6oInKB9ZQnX6J8gAupTH/sm5QP1+NSJvf/z4MXvQEPlB594bb7zBHlKk+NCj6mHt5IIxK77C0fWrEPnwPg59sRxdJryLFr0H6KSRozZBnpWF+GXLkXn0KJs3btGCMzCtYD12ZWDZvx8M+DzEzPqMGaqS8sNlzWoYCARA2Hlg73ju/kP3vjH7AIf6qEvITErE/hULkJuRDnsvb7w1dykMjXTLCyM9MRfHf7yP9IRc5q/W891G8GryIgVOj6pFcsq/CA5aijxxJJu3semEAP8lMDHxeuW9VM5CkbU8XoOX2sh6VB3pMfD2U9zIzKn8dwGs/MX/Ysll/Eq0tTTF4RZFFMvlwMiRI1/qzJualt33oM75/v37me/ZmjVrWF+XFA3U933//fcLjUenTZuGCxcusFJhEgcURV5eXmHJuhI0TyoSJfFBatuOHTti8uTJLEmPzE7JD4TKX9TBvHnzmIqEQMap69atY8QHbWdp25qTk8MU5uRpQttD5A2RF82aNYOPj0+pv0n9EvI/IbLG/LmiksggGjwjToCWkfKjNH+Rr7/+mpXWVOd1WqEiRGKP1GHL9Khe8Pk8dBjqCxd/K5zd+hhJkVnYu/IGuo5vAN9WNetm7WpkiO1N6uFwYjrmh8QgKEeMfrdD8J6bPeZ4O8FU39l6BXQjoNIymugmpLxJKYkQmihKullBKOyFSbgorYfwVGDgDxfRyzkfY1o5wcvTE87OY+HmNh5xj48hIuhX5FoGIinjLyTd/AuWli3h7j4J9nY9wKOOvbaDCAITG24qL5ifSQlkSVmKE7mExQ0jN5mbqgQFQGYMcOQTwLlZySQKv2qPCz2E//rrr0KDXVIQkZeHaiS5HpqBkZkZ3vp8Gc5s2oCH507h3NaNbPSbUix4+ntghZB7+zZiP5sNaUwMZ2A6dSozMWVEQw3Bok8fdq+KmTkTmTSKpZDDZVQTGJycxd1H3NoCo3ZVrMRQh5Gdlop9y+cjKyUJNi5uGDZvGbsmdAmkuD3x8wPk58hYqXG/D5vBzk23tkFXQMrV4JCVrHRXtWzF3r6XntCoQegil0ShHKppKcoyk6IgkkMJ6rgrffqoyuH3339nxIfSiJQ67UqQaoESYCgh5b333itcTgQJDWYqSQ4laF5JClAZDhEmygHP+vXr49GjR0xgoC7xoVqGQ+tLg6QZGRlMiVHatm7atImRWUR8EKiSg9qGVDZDgSWlgfYDKWho0EwVtIwGaonQoeCT4kBKYyJn3nrrLbXLaqoK5W4Z0A6i2hwywCNJjOpBJLk07UQ9ahY08jByQRtW+hIXmoG/f32ImCBXvD7cFwIhv0Y78oMdrdHJ2hyLn8Zgf0IaNkYn4a/kDKwNcEMXm5pLpdEVEHPboEEDNhGUpkh0k2keFoU9zwSIkFnirzhj3D0RiU7C87AQFjCJHpXHuPuuA+/GQ6QaHkam03/IyLjNJiMjV7i7TYCLywgIBLU0UYD5mThwU3lLc5R+JuUhS7ISnqtMysDd37mpJBiaFx81XJYhLMnoi5STPX36lJlTk5EpXY/k40EsPyn39Kge8AUC9Hz/Y9i4uOLCrq24d+o4MhLi0H/aHIhM9Aq4chmYbvgJyT//TC0tCN3c4PLllzBp2QLaAItePWEg+AbRn05D5om/UPDgAFzby2DQdBgw6EdAWLe8rnIzM5jSIz0hDpYOjhi2cAVMLLXP2LA0PLkah3O/P4FCXgAHLwv0ndIEppa6VaKjC1AopIiK3opnz76DXJ7LVBzubhNRr94nEAj0JFNNgtoNpLxQp9SFUlzG3n9W5vt2Nq3HUl40WepC5IMSNHBPJSwlgfq3RBpQGYgSpH4gZQOB+r6ksFBNYCFQuQq10an0RQkiMygal4gIVdC80siUFLdFS2RInULtNXWh6sdG/XRlWEJZ2/ro0SNGtKiC+hdKk/vSQPuByCEqVykKKpemGGDloG1RkLqdyA8if4hQIpDqRZkqSP+nKZS7tUsyFpL+EKNErBAZxdDIMx3E0aNHa2Yt9Sg3zKyNMHhGC1w7+gy3T0bg4YUYxD/LQK93G8PKseZKXwi2hgL80NATbzla47OgKESJJRh1LwwjnKyx1NcV1kJ9J0xdkFyObpA0kepuskyGX848wrcXoxEnt8RhSWN0UDyDLDycsdEEeng4mLSBQ1gr2Lg8AjyuQyyOQcjTVSwazsV5ONzdJ8DYuJxlKLUV9LA1NOEmyxejBmXi2UVgW/+y3+fXi+sEFS3Vyc/k/l+SxU0ZUeVcbx5n+mpkBYXIEsm5cogz8/EGjNgy3yZtYG0bD4T89SpxIjTRzWEdHQFdg20GDoWVswtOfL8O4fdu44+Fn2HInMWsU6hH6ZBERSF21mfIu3ePzVsOGgjHhQvB1zL1gHmn1+A23BMxe54iK8oYMbYBcJ2/AQbCutVZzs/NYUamKdGRMLO2wfCFK2FuozulIQWKAlw7EoZbJ7m4d5+WDug+sQEEhvqywKpGevpNPAlaiJycYDZPqtSAgOUwN6tbJWHa/vxSR6VNg5mU3kJGpsUV/FILg/6f3lediY9k6ElTaX4gZMxJylgl2UIEgbJUhnw9KPmFSl+UoNIOimKl+FvV5YTmzZsznz76jDIilhJSaTlh7ty57HfIW0MJ8vorjxIiODgYbdu2Za+pb06/Q2ajNJW2rQ4ODq8QLKTUUCe9hvaDchBNGXhChqnfffcd2xYLC4tSQ0+orEYVs2bNYkQJWWpoEuXuYZ44cYLJU3r27MmibpYsWcI2ng4cGZzooT0gZ/H2g33g6meF01sCkRyVjb2rbqDLuAD4t6m+fOaS0M3WAufb1sfqsDhsjknG3vg0/JOShZX+rhhob6WXMlYANHL/Ye9m6NXSB5/uvoNHsZk4J/VDDzdjdLNJR3x0BGOyE3JSwGyVol3Ai+0PT4dYONd7DCCRjbRERW+DvX0PVgZjZdlafywqAs8OnPErGZmW9Nin/x/9R/EeH3LZq1HD6ipOZHnUWn/+/2mgsQDSuRRqXcQAblwoed15wlLihMtIzxHUrU5dZeDXpj1GLfkCh75cxjqFuxbMxKBZ8+Hizym69HgZNJKVeeQI8/NQkDeNuTmcFi9mvhpah8xY4I9RMC+4B7c3TBF92RZZdyMRPW06XL/9BrwiNd+1FVKxGAfWLEXis1AYm1tg2IKVsHSo+faHupBK5Di7NRChtzlfrVa9PdFuoDcMeHpiuCohkaTgaeiXzJOMIBRaw9dnLpyd34IBkfh66ByIzKDIWkpvKT5kGFju51qtpIc6GDhwICsPob7u8OHDcfnyZebfQZ4bBOqYk6knKRpatmzJlhNJQmUtxYECDMi/g9JO6HMPHjxg/mpKpUO3bt0wY8YMliRDYoKjR48yYoRMQpUl7lRKozQELUmUQN4clOpCxMP//qdeStjw4cMxZswYFlBCpA1VdFy6dAkHDx4sVGEQuVFczC6pYMgXjggLSpEhfzgKPyH1CpEeZaEoQUTqD/qsalmSVhAftFMpuodAbBQxS35+fuyAq7uj9aheeDSyxcj5bXF68yPEhqTj9G+BzIm80wi/Gh+xMBPwsdLfDUMcrTH9SSRCcvPx/qMIHLBLwxp/NziL6kbjsKrh62CGA1M74OtTwfjlQhhOP8tDaLYNvhv1JtzNOLdqZpgaFo6k1GQ8i/fAs3h3WFnHwdX1MWxsYpGUdIpNRkYBqOf1Hpyc+jEndT3UBJEZFFnLUl1KeOz3XlOysSl5e5jaclN5IcuHNCsJ/507ieD712AMMWyMeWjd2A92JrzSiROFlJtykripvCC1SKlkSTHL2TxFDde9EVRHb1+MWfU1MztNDA/F3mXz0HvKNNR/XX1H97oAeWYm4pcsReaJE2zeuFUruH75BYQabiRVCHH3gF0jgaw4wMQOZvN2wS1ShugPP0T2uXOI/vhjuH33HXgq8uvaCJlEgkPrViA2KBAiU1MMW7ACtm66k3ySk5GPExvuIzEiCzy+AbqOq4/67Z1rerVqFQoKFIiN3YOnoWshk3Gm4y4uI+Hr8xkjP/TQbVBULUXWUnoLGZkqQUoPIj00HWVbEZBa4rfffmPJJEROUEf822+/LUwypbQSqnIggoH++vr64qeffmJESEn48ssvGelB6SVEItB3K305SEhAXhj0HeTbR31qso1Qqi42b97MiAhKkykJVHFBhqgkQKDfmDBhglrb2rx5cxZ5S9tC20hCBorppXVQih1IzUJKjpK2iwiXiRMnsoFXIkKIBNFmGBQoi4HUBNUKUawPSXpoZ9FBJwMUktmQa66qMUxtAdUx3b17l50g2pB4QIeMRu3L61itkCtw43g4bv4Vzvpgtq6m6PVeY1g7aUddeb5CgW8jEvB9RCKkBQUw5/Ow0McF41xsWTpMXUBFj21puPw0GTP23kVCZj6EfAPM7BmAyZ28WUIQISc9C4/3XENEVCQSeBlI5mXByCQVLq5P4OAQBj6f8/KRy81hKOwJT8/xcHdvoPeFUBenFgJXf+AUGErQCFb7j4Cey6EJkO8LPSjJNZtAoxL0cC3NYZuBHgeSnAqawFKjtVyPk1dBviSlESQlqUzoczV0j6iqa1YizmNlL6E3r7H5DsPH4rWho/RqK/KHuHkTMbNnQxYbRy7esP/oQ9hOnvxyTKy2HNsnJ4A//wdIcwH7+sCYPYA11yDOuXoVUVOmokAshmnHjnD74XvwyromdRRymQxH169m57NQZMRIDxd/7SlXKOvYJkdn4/iP95Cdlg+RqQB9P2gCFz99R7wqkZX1CE+CFiEz8y6bNzNrgPoBy1h5i7a1o2pTH0Jd0Gj/s2fPWGe4zLaDGtG25PmRKJHBwVDAPD20TemhzaBYWiJA6tpva+J8LTfxsW/fPqxcuZKxVQEBAcyRddiwYYzwIBlObTQ31babVmVv6lGBqTi95RHysqQQiPjoMiYAAe20R3r6ODsPM55E4U5WLptvb2WKdQHu8DGpnQ3E6nhgp+VIMPfAffz9iMsN7+Bji69GNIOzpXHh72ZfikHGX88gU8iRapuPjMZ8xKQ8hUz2DxwcAyES5bH3yuV8JCX5QCHvBheXlpxpqrt7pR+MtRKBR54rPkoodRmxHWg4sMp+TiaT4d9//2XSTDqmVF9Jss1qcc0mszPyJSnNBLak2GHyMKkMDPicYkTdqGHV9wmNK0WaVOU1q1DIcWHnVtw6xslMG3Tsgp7vfwJBHSmLKIoCqRRJGzYg5ZeNnIGpuztc162FcQmGaVX+++U5ttSUIoKTiE663r27AiO2ceelCnKuXUfUBx+gIC8Pph3aw+3HH8Ez1q04V3XO479++BpPLp8HXyjEW3OXwKNxDUSnV/DYhj9IZubw0nw580Tr92FTWDnUrDdabYJMloWwsG8QFb2dzhbw+abw9p4ON9fxVZIupyc+tI/40KPioDIbUmgrk1eqEzdv3mR+J9Tnr7PEB+HGjRvMMIVkP+RWS2QImadQZnBxdUC6jtpGfCglnFT6QiUvhAYdnNFplD+EWmLWRezwb9FJWB0WjzyFAiKeAWZ5OeEDdwcIa3FtrSYf2PTde25EYenRQORJ5bA0FmLNW03Qp8kL6W5+WDpSdj2BIlsKAyM+bEYEwDDACvHx0QgL24vc3CMQCGML35+a6oKY6AbIyHCBo6MTq9kjIoQmZa53nYVCDnzTmKv1LxbPPT6mPaiSEo+4uDim8khMTGTzFINGCj26V2s95FJOMfKSkkRNxYmMDEsqAb5h+ckS5XKBoUau2ftnTuLMbxtQoFDAJaAh8/0wsXi5A13bIYmIQMxnsyF+HrtsOXgwHKmO2Kz6FIpqH1s6f4/PBG5v4+ZbTwL6fAnwhSUqWCInv4+C3FyYtGsH9582gKcL16ma++z0xu/x4J9TLKJ50KwF8G7ZBtqG4o4tLbt/LhqX94UwHss1wAq9JzeBkWnxx1GP8u/zxMTjLKJWIuGeUw4O/eDnNw9GoqobfNMTH1UDPfGhHaDyFUpoqQnIZDLW79UG5VSNER+UN0ylLmRqUldQG4kPgkJRgJvHn+HGCa70xcbFlKW+0F9tQURePmYHReN8Gjci3MTMGF/Vd0dT89rRSKyJB3ZYUjY+3X0XD2K4etqRrd2xaEBDmIq4kRZ5Rj4jPyQRXKqIeVd3WPTwZGZutH5padcQGvYLMjMvFioZcnKsEBNTH4kJ3igo4K4RUoARAaIkQ2heF26eVQZ1U118uwPW9ThTUFIfCIy4iZJeBMYlL2d/jSDnGeLSjXs4f/Eyy08noqN///4seatOgEUNp1esPKfgRSR7hSA0RYGxFRSGFuCZ2sBAXeJEDT+TiPt3WakAJWJQ0suQOUt0yh+hUvfAg4eQsGIFFLm54FlYwHnJYlj07aud92M6j/ZOAJ6d58jMXquA16aUqSLKvX0bUe9NZiatJq1bw/2Xn8Ez1Z5nb0X317/bN+H2icPMkLLfp7MR0L4jtBFFjy2VAl/cG4KH52PY/zd43RmdRweAL9Aba1YFcnOfIShoMVLTLrN5Y2NPBPgvha1tJ1Q19MRH1UBPfOihS9AY8fHaa68xB9uibqy1GbWV+FAi+kkqTm8ORG6mBAJDHt4YFcAUINoC2l5KfFn8NAbpMjn4BsAUdwfM9HKCMb92NUqq64EtkSmw/kwwfj4fyka26tmZ4puRzdHMnTOaKpApkHHiGbKvcGoFkZ8VbEbVB19l5Cs3N5ylv5ALu1zOlSUVFJghNaUJQkJcIZW+LN+msgulGoTuH5TzrZo9XuvwYD9X669BJMEGB9ELseBGy+ojDP1F/8GMDhMjSZ4TJypEyYvlahIsqsuL+74SRrW1HszPJLtiKhNxZiX9TAwAI4syVSZZuXJcOHgIKcmZKDC0QNcpc+HRsn2tjRqWZ2QgbvESZJ08yeaJEHAhA1MXF+28H6eGcSamycGMBMOw34CAPmp/f97du4h89z0osrNh3LIl3DdurFZFS1Xj8t7f8d+fu9nrXlOmoXGX7tBWqB5biViOU78+RGRgKrs02w/xQYseHnWLqNcQ5HIxwiN+QkTERhQUSJhBuqfnVHh6TAafrxlzXz3xUTXQEx966BI0RnyQ8yvVkI8aNQouLi4QFXElb9NG+ySNlUVtJz4IRHpQ6Uv0kzQ2H/CaExvtEIpqfnuVSJJIMS84BkeTuPIcb2MR8/7oYF1yTrSuobof2FdCkzFjzz3EZ4oh4Blgeg9/fNDZB/zn5US5dxOR9mcICqQK8K1EsB3bAIbuL5ewSKWZiI3bg+io7RDnc0SJgYEQxsZdkJPdDhER5Noey64jVRgaGjJvEKUihJyza0rOV6OKj5ZvA2ZOXAStLJ9TMFD5Bk1S5d/n/0fvkYqhkObjP4kvzspbQw4BjCBGX5xDEzwpjImrNpC/RqkEi6jqyRaaarJTQmVMz6OGC/LSkZMcDVOeFAbiMrxMaJk0p1I/XWDAh0FFvEzoNe1LLUXO9euInT0Hsvh4yuWG/ccfw/bd/2ncwLTC9+OIK8DusUBeKmDhCozeDThzLv3lQd6DB4j837tQZGbCuHlzuP+6EXwdLBO8fng/Lu7ayl53e+d9tOg9ANoM5bE1kBnixIYHSI3NgUDIQ49JjeDdovaVbNcEklP+RXDQUuSJI9m8rc0b8PdfAhMTzQ6c6omPqoGe+NBDl6Ax4qN+/ZJdualh8PjxY9Q21AXiQ1n6cuuvcNw49owNhlo7mbDUF1tX7SIWTiZlYG5wNOIlXDTWeBdblv5iIaj5Y6OLD+z0XAnmHXyAEw/i2Xy7ejZYP7I5XKy4TpI0PgcpOwIhSxFTMDusBvnAtI3TK+unUMiQlPQ3IqO2IDPzRbqTtXV7uDi/DbHYD5GRUcykKSoqiuWSq4KuLSJTlYoQIkWMddn078ZvwPEZpbyhYh4fqampOHToENuPBCiJpggAAQAASURBVF8fHwzs8yYsjIQqhMnLREnJpIqay4t+n/zlY1cjYARIaWSLcfkIlmLKiF75PooYruw1K5M89zNRX2VSkJcGRU4K+KhkaQ5tT3nJEmXUsIaUPczA9PsfkPLrr0yFI/T0gOu6dTBu0kQjv1eudSvp2N7bAxz5CJBLAJcWHOlhXnGPgryHjxD5v/9BkZEBo6ZN4bHpV/AtLKAruPv3cZzd/BN73XH0BLQbPBzaDjq2T+/H4OLvz5jRu4mlIfpNbQoHT93Z79oKsTgWwSErWHuAIBI5wd9vIezte1VLu0ZPfFQN9MSHHroEjZqb1jVoE/Ehk8pw59g5JD+LgF09T7To3xUCYeVdsFURE5yGU789Qm6GhI2AkOkplb5ok+wzUybH8tBY7Ijl4jqdDIVY4++G3va6bQBYUw9s+t19t6Kx5Mgj5ErksDASYPVbTdGvKVfypBDLkLo3GOJAbn+btHaE9SAfGAiLvx4yMu4gMmoza/gUPPdRMDGpB3e3iXB2fgsGBkZISEhgnfeIiAj2Nzs7+5XvoXIYVZ8QC13pDFyhdIf5KgvoWKreap8f23KkupB/Bzlsnz59mpldkWKmV69eLKq22q9NSnAh8uMVgqUk4kV1eWnESxkkTGU9OSoLShwoQogUkM+KgRB8I1MYaIJsob8GBszo9PqfO3D30O8Q8WXwaeiH1/r2gVCeo155jmqcckVgaFaEECmLLFFGDZOfSfElbZLwcMTM+gzihw/ZvOXQt+A0b552eF3IJCi48Svy44Igcg6AQZv3uOP/7yrgwlruPQ0GAEM2AoaV95wSP36MyHcmQZ6eDqNGjeDx2ybwrbjSQ23Go/NncXLDeva63ZAR6DiKUqy0H8HX43F2+2MoZAWwczdjpIeZtT65ojJQKKSIit6KZ8++Y+WvBgZ89syvV+8TCATVN4CmJz6qBnriQw9dgsaID5KslwYasa1t0Bbi4/ymPRBs+AY2uVypByHVxAqyqdPQ+d2RVfpbVPpyZmsgi74l+Ld1ROcxATA0qlqSpbK4kpaNmUGReJYnYfMD7K2wyt8V9oa6WTJR0w/s8OQcfLr7Du5Fc8anw1u5YfHARjATCVCgKEDW+WhknuLMcIWuZqz0RWBjVOrID0XWxcbuZhF2BIHAEq4uo+DmNh5GRs6F201KBiJAlGQIzRcFpUcpSRD6a2trq1WEHJNKnf+S6xwRXp8GuLYETs59Od2FpPG916hNeqSnp7NIs7CwMDbv5eWFQYMGwdraGnUKlJ5RIbKlEuoXrVG3cITIk3QrnAyxhbzAAPbmBRjSRgBzC5PSCRaqpTd4TlgppIBCxm0rKRakudw209/8bC5amDxMGHmSAeRz94LK+ZlYvqQsKTC2hiQuFVn/3YU8R4ECgSksho6FSfsuLxMnhqY1U9JEkbQUTatKFhnwABtvIOUpN99xOtBtUYmkTkUgDgpG5DvvQJ6aClHDBvD47TcItPgaD752GcfWf4GCAgVa9BmArhMma9f9uBjQs+bmiXBcP/qMzXs1tUOPSQ21rm2ja0hPv4knQQuRkxPM5i0tW6F+wHKYmQXUuXaUtvYhygs98aGHLkGjpS50I1F+rOhNRV/qojnSw37dEm6fqyxXPJ9PmrWkyskP6ujePhWBa0eesdeUZ0+lL3Zu2lX6kidX4KvwePwUlQh5AWAl4GOJrwtGOuleiog2PLClcgW+PROCH/99yvrxnrYmzPi0hQfXABeHpCF19xMocmTgmQhgMzIARgE2pX6nTJaDuPg/ERW1FXl5EWwZjQY52PeBu8ckWFo0e+UzWVlZLxEhpBAperuiBBNVRYiTk1PNNSxo3U4vBK58z813WwB0msV13BRyFERcRm7CM5g41oOB5+tqlbfQ9lKD6eTJk6w0SCAQoHv37mjbtm3tNobVJrykbnmVSCmQiZGTkQJTQx4MykXIlEHClKLQiM0zx+GohsiVG8JUkI8hboFwNH5VMVV5dctzAoUif6nUhZax89bgBSFB60lKHPI9ISKFyCnlttDrSq2DsJwlOSqvab0rSnpc+a6UNxgAg34AWoyDJpAfEoKIie9AnpICUUAAPLZshsCm9PtrTSDszg0cXrsSCrkMjbv2QM/JH8NAy+9JMqkc53Y8QfD1BDZfv6MDuoxuCH4tM0mvTkgkKXj69Av2fCcIhTbw9Z0DZydSdvLqbDtKFXrio3oRHR2NN998E2fPnoWbm1uFvuPixYtYu3YtwsPD2UATpZl27ty5wuuUlpaGRYsW4dKlS2zA6tNPP2WDV0pMmTIF//zzz0uf+fnnn9G1a1eNb6sS1M4eMGAA7j+PkFfi+vXrWLlyJdsXAQEBWLZsWam2F1UJGvD78ccfERcXx5IK582bh6ZNm1Yv8RETw0V9qV7Q1DH5/vvvWdRtZU4MbUVN37SovOVau06wzk0v1riQmsdpJlZ47drFKi97IcQ+TcepTY+Qk57Pot06jfRDw44uWvFAUcX9rFzMfBKFB9l5bL6ztTm+DHCDp7FmnMNr+wP7WlgKpu+5i9gMMTM7nd7dD1O6+LLXsnQxUn5/DGl0NmdV0d2Txd5S5G1poLKX5ORzrAwmPf1a4XJLy5Zwd58Ee7se4FHnqoSbGt3klaUx9Lo4w1S6+SvJEDJMpWXV0jk+MRO4uZmbJzUHRVpW4tgS8XP06FEEB3MjaLRdgwcPhp2dnWa2QQ/tuWbpsUyqjFJUKRlJiTi44whSktIgEPDRt09z+HlZV1D98vw1ERcahDhNgPQwE3bP4BsqYOaSDyNrqWZEHUTWkGLE0BwwosnyBWliYgMY2wJm9oCpPWBiyy0XmgDrG5ZeFkSdufkJgEBz95X80FBETJwIeVIyRH5+8Ni6BQJbW2gLoh7dx4HVSyCTShDQvhP6fjILvHL4FNUE8rIk+OvnB4gLzWDPqTdG+cOtqalWPGt1EaTyiY3dg6ehayGTcaowF5dR8PWZBaGwZlVK2tSO0oY+hDYoPuSKAlx/lorELDEczI3Qtp5NoYl+VaOyZAC1MQcOHIjp06ez7zlz5gy++uorNgBVUXLhgw8+YPuTOu737t1j5MHOnTsLO/E9e/bERx99hPbt2xd+hs7fstqvVUV8xMXF4Z133mHHOygoqHA5+fH1798f7733Hvv722+/4fLly2xfaLptTaXdtE4rVqxgJd27du3CgQMHGEFkWkw5bLV7fBBD9Nlnn+Hvvzkzo9qEmr5p3Th4Gmaff1Lm+7JXf4c2Q3poZB3ysiU4u/UxIh5yHg9+rR3QZWx9GBprlzxUqijAz1GJTAEiVhTAmMfDXG8nvOtmD74WPAB17YGdkSvFvEMPcPx+HJtv62WDr0c2g5u1CYu8TT8aipxrnCmqUX0b2IzwB89EvTKjrKxHzAg1IeEYCgq4kWEjI1e4u02Ai8sICASlJxvIZDJWeqdUhNANmm58qiBVhNIwVTmRSqRKIZcBh6cC9/dwo8EDv+OSWipxbB8+fIjjx48jLy+P3XOI9e/QoYNe5aGFqMlrNj83F8e+/QLhd28xBUan0RPQZuDQiq8HEXiycniylKpmefEdBfliJJ1PRMoNLtHG0BJweSMfxlb0OSKqdcxqrNcqoP2HGv2J/LBniJw4EbLERBj6+sBzyxYI7Gs+bSQuJAj7ViyAVJwH71ZtMXDGPPAF2tUOKIrUuBwc//EeMpPFrM3Se3JjuNW31qpnrS6Bnt1PghYhM/Mumzcza4j6ActgadkC2gBta0fVdB+ipomPkw/jsPRoIOIyXrTPnC2NsHhAQ/RuzJU7VyUqSwZcu3aNkR3z57/waSOV7ZIlS9C3b99yfx+1UXv06PHS+tB303mxZs0aSCQSdm5Qm4/2dXlQFcTHmTNnsHAhmQ/bM9JDlfhYvXo1AgMDsWPHDjZPbVJShfzwww8aV3389ddfTGVCahgC+QC2atUK+/btK1b1oe75WmVPK7q5kBRdj6pHVmw81CkuuXv3KZw6vw43a+Mqv9kbm3GO53fOROK/Q2EIuZmIxIgsVvpi76E90XtCngE+9nREP3sr5v1xNT0Hi5/G4nBiOr4KcEcDMx1OCakBWJoI8cPoFugW4IBFhx/iengq+nx7ESuHNMHAZi6wHuIHQ3cLpB16CvGTVCT8cBe24xrA0KXsM9bcvBEaNVwHX5/ZiI75HTExuyAWxyDk6SqEPfsOLs7D4O4+AcbGHsV+nso+lGRGx44dmflnYmLiS+UxpJqgBwNNV65cYZ+jm7uqTwg1jioM6vTtnwQ8OcaVAQz5BWgyrMJfl5OTgxMnTuDRo0dsnkp3hgwZwkxe9dCjKEQmJhgyexHObfsVd/8+xuJE0+Ji0P3dqeALKuBzRKUKZNRZBWadqh342FmzIA7kSA+r4cPh+Plc8JQEJI29sPKYCiQPFadmKfQqyeZeS3JekDOUqKP0OKmM2WtaODQNkXc9eO7YjogJEyF5GoqItyfAY+tWCB0dUFNIDA/Dn6sXMdLDo3EzDJg2V+tJj6jHqTi58SEkeTJY2Bmh34fNYONs+krZpB5lg3y6QsPWIzqaOkEK8Plm8PGeDlfXcSUqNfWo2yDSY8rvt1+htuMzxGz5T+NaaoT8UAWVZ1BFAikGWrRogUaNGrGOe3GgTn+7du3YRCAjeUrRI3JCtbO9e/dubNy4kZWwNG7cGAsWLGC/UxxI4eHs7PwSMUEd+F9++YW9Ju826rNRkmFFQQqM7du3M3KAlBm0PqTIoGqM0raV8O+//7LSGyIM3n777VfKXN56663CeUpaJKJEXZBiefny5YX7gL5/7Nix7P/mzp2LgwcPvvIZUmqTqqNPnz4vkRpbt25lvn4+Pj6oDMp9pypuB1JjnXb666+/XqmV0aN4mLuoF5N3JFqClV+eg5OFEVp7WTMpWRsvGwQ4moNXBZIykoe27OkJZx8rnNr0EBlJedj/5U10Gu6HRm+4agWzroS3iQh/NvfFzrgULHsai9uZueh5MxgfezrgU09HiLS8FlmbQMd1aCs3dk5N23MXdyLT8ckfd/BvUCKWDmwE89aOEDqbImXnY8hTxUjccA/WQ3xh2kq9zrpI5AAf7xnw8pyK+PhDzBU+JyeE/SVjVHv77qwMxsqydannGKk7iCigidh5atiSKaiyNIb+pqSkICkpiU0koyMQ8aHqE0LEiFrnsiQX2DMOCD3LyeqHbwPql380QIknT56w0ha6n9Lvv/HGG+jUqRMjePTQo8Tzns/Hm5M+gLWzK/7d9isenjuNjMQENhJvZFZzfkzs+tu7DwmrV6NALAbf0hJOK5bDokcRVSJda1Q2osHSkWJBniSMEFFRttzYDPxXfCPxJVh7VccawtDT8zn5MQGSZ88Q+fbb8Ni2FUKnikfnVhSpsdHYv3Ih8nNy4OLfAIM+WwBBdZQRVgIPL8Tgwu5g5lHm7GOJPh80gbG5dq+zNoKu5YTEYwgJWQWJJJEtc3ToDz+/eRCJ9KR8XTwf8qRytcpbFh95VKyej5ZRK2vJkUC87mtXZtmLsZBfqT7GuXPn8Mcff7ABMuqAjxo1qszPUJuROt+kzCCPDyVxQZ1y6gtTh57IAiJGqEN/6tSpYgfSqL3p4PAyYU0deKVYgIgPMzMzzJ49mxEN1Ib9+OOPy2UdsXfvXqxfv56tK30PkSr0HZMmTSpzW1esWFGodCkKUlKTeuKTTz5hbWZfX1/mVUJ/ywKRFVQiQ4N3tK9oO0lZQmUqVLZNqhfar0VRVBV19epVth103q1bt67YMpfyoNylLuPHj3/5CwwMIBQK0aRJE1aLU6nRUy2Ftnh8WOWmo6TuOh3EM20H4BenDsghQzgVUDRpay8bjgzxskETN0uIBJXbDnG2lEXBhd9PZvM+LR3QdXx9iLSs9IUQly/B3OBo/J2cyeb9TERYX98DrS21IDJRyyWaxRmffn82BD+cewpFAeBuY4xvRrZAK09rKHKlSN0TBHFQGnuv6WvOsOrvDQNB+UgmLuHlIvMBob9KmJs3hof7JDg49AGPV7HGK5EKqhG6VNdY9BZIjLZSSUJkCD0kX7nuKfXij1FAxGXOF2DULsCna4WOLUkHiTgmRpxAxAs9FIj11kP7oU3XLBlOHvvmSzYiT0TIkLmLYe1U/UlrsrQ0xC1ciOwzZ9m8SfvX4LJmDYTarlwiRchKx7LVIDNDAPPqU15IomMQOWECpDExELq7w5PIj2pM0MtIjMfuxXOQnZoCBy8fDF+0Ekam2mVyrgqFogBXDjzFvTNRhal03cY3AF/I08rrVpuRkxOGoODFSEvjFJPGxl4ICFgKW5uO0FZo27Gt6T5ERVFc6QDt22E/X8WtCK6dV11o7WmNfR+0V+t4Fi3/ICUGlamMHj26XL9JimHq+N+5c4eVpFCnu1evXhgzZgwjRFT7w6SKoA5+0T4ygcw5qfP++++/Fy6j+f/973+sjIRIlF9//RWLFy9mBp6nT5/GTz/9hD179rC+tTrbSkRHly5d2DJSUdC6khdHeXDt2jVG4KiWutD6mJubM/8R8tkgVQl9L9lalEVAUEkKkU3ky6EElczQ+qkuKwvJycmMPCLyasOGDWw/0rVUbaUuyjofShgQiTjTSKqzr40xttoCMiylyFqDdUuYkalqN1LZZaNbQY/rR9Hb+SYyJnyAq27NcSMijd2cMsUy/PMkkU0EkYCHZu5WjARpU88GLT2sYG5UPlm0kZkQfac0wb2zUbh6IBShtxORFJnJSl8cPC2gTXAWGWJr43o4kpSO+cExCMnNx4DbIZjkaod53s4wrSQJVJcg5PMwo2cAOvnbY9ruu4hKzcOIX67ik25++LCrD2wnNELWP5HIPBuJnP/iIInJ5iJvrdQ3mKUHm63tG2zKJuVH1BamBMnKeohHgTOYgzxF4bq6jiq3iRrdqBs0aMAm5X2MHhxKMoReExGhWudIxK7SMJUmN1tTiPaOBmJvAyILYOw+wOO1Un+XRhmUyTRUtkKECilUnj59ylyrMzM5Uo58PMjPg35TDz3KC+8WbTB6+Voc/GIpK3nZNX8mBs2cD7eGjattZ+ZcuYLYOXMhS0qiiwcO06fDZuIErU/8YCDVSfuPWKqLckRSiZfmt/QCRu8G7KsnqtPQzRWe27extBdpVBQixpPyYxtbrmkQ2UGeHvTXxtUdQ+cv02rSQyKW4fTmwMJBmbYD6qF1Xy+t6ADrEuRyMcIjNiAi4lcUFEjA44mYKtPT8z32WlshLyjAf2nZeJaejXoKPl6zNtMJfzddgi7uTdWBJEpLUZaZFAWRHEpQh586/jSFhoayDjcRH/SaEl++/vrrwvdSW5L8KEgVQSoHJd5//33WV6ZSGVXQvLJzTmU4RJgohQPknUHlzqTiKIv4UEK1DIfWl8gCIv+IeFBnW0sCEXXdunUrJHRIuUEEC6leyOujNJDCg5TMVF6kSgIqyT9SjpDKuSiITyC/EyXI0J8marfTACGVGRVHfKiLchMflOpCtUBU/0RmpoShQ4eyDsG3337LJDp6VD0oqvY8HbAN38AmN71weaqJFeRTp6GFizkS1q6DLC4OZmsWY2DrVpg8bx4EE9sgMC6TuSnfDE/DjfBUpORI2DxNOAeQwqyBswUri1GWx9ibl/1go4ZE8+4ecPKxxKlfHzHjsD/X3sLrQ33RpIubVjU0aF0GOVijk7U5ljyNwd74NPwWk4yTyRlYG+CObrbaRdZoO+gcOfFpJyw89BBH7sVi/ZlgXAxJwvqRzeHe3RNCd3Ok7g6CNCoLid/fhs3o+jDyLb/Tu5mpHxrUXwUf71nMA4S8QPIlCQgNW4dn4T/A2WkI3N3fgalpxWr+6IFE9YLKmkEyTCUViNInhCYiQohFpolgAAWcEQBPgR08Or8DD9smKI33JkafFB1KckP5QCXpIz1ACTY2NkzlQfdRPfSoDOw9vDB25dc4tHY54p8Gs05rz/c/RqPOb2p0xyokEiSt/wapW7aweUNvb7iuWwujhg2hU+i5HLckhnC9vwVOEs7Mm5BgaItU335oGPMvkBoG/PomMHQTENC7WlZL6KokPyZCGhGJiLfHw5PIj0rUhZeF3MwMdv5kJMTD0tEJwxesgImF9qp6s9PEOL7hPpKjslkC3ZsTGsCvjZarjLQQlLwWFLwUYjGnmLG17YwA/yUl+m1pC44npWNBSAzi8p/HaEckw1kkxAo/V+b7pkfVtKVJeaFOqQv1MSZuuVHm+7a+04b1PTRZ6qIcqCdQ6Yeqf0RRhISEMNKgdevWhcuojUhlKMrOO6WzqCawEKhchQbXqPRFCSIzKBqXiAhV0Dypewk0CFa0WsLb25sNjKkL+g4llCpmGkAra1vLAq2jquEq+YYQiUTt5LJA7WnaR0RwFAfiEkj1UhTK8m4KTSGShDxZVI+Dst1cbcQHbQBtNNXbKEFmfCTRWbp0KZPn6KE58kM2YSjuHDuH5GcRsKvnidf6dy2MsDXr2hUpv21GyqZNyLt5C8+GDoPVsKFo+OmnaNrJG+924i6IsOQc3CDiIzyVESE0av8oNpNNW69wpm317EyZtIwUIaQM8bQ1KfGm41TPEiPmt8E/2x/j2b1kXNwTgpjgdHSj0hc1Ez6qCzZCAb5r4Im3HK3xWVA0osQSjLkfhmGO1ljq6wpbQ+0r1dFWWBoL8R0Zn9Z3wIJDD3EzIg19v72I5YMbY3ALVzh+1JyLvI3LQfJvD2HRywvmnStGiBka2qBevY/YaFNCwnGWBpOdHYiY2D/YRA0z8gGxsX69Ug9HuuGSwRRN5FlESg16QLHSmNAniAx+gAyFCWLhhFiZE66eug6cus7YaFWfECsrK7YeRHoQa1+chJImAvmRdO/evXpid/WoEzC1ssaIxatx8sf1CP7vEk5uWM8UIK+PGKcR5QXFr8bM+gz5jx+zeatRI+E4Zw54xrpnJk2dp3dNB8Dgtb54LeM+HCQpSDS0xTXLplAY8LH9tWnocfYTIOISV+7WbQHQaSbnVaJhCJ2d4bl9OyLJ8DQ8nBmeem7dwrxAqhrinGz8uXIRUmOiYGZji+ELVrK/2orEiExGeuRmSGBsTorUpnDy1l6SRhshFsciOGQ5kpJOsXmRyAn+fotgb99TqwaySrxuH4a/aqKZL2XLNzX20pMfVQQ6F0zUaCt38rNn6S1kZFqcpwKdUU6WRux9moq2LQ7UPqOpJFBJBZViUKqI8rwnBQaREQQiAuLj41l7T4nPP/+cteOo7ER1OYHUCSQaoM8oxQG3bt0qVC2QySf9DiWoKEFKCX9//3KZiFJbUkkY0O9QgiFNpW1rWaB1VC19IaUKlf+okyBD+0lZbqRUeRw+fBgPHjxg5qvkc0JTSdi/fz/bbxShqwQdB1K0VKvHB0lWaMWLjkzSaCgpP27fvo3aBm2rzyurflEaF4fEdV8h87lUiGdqCrupU2EzfhwMiulc0U2JCBCaiKENSshiRvuqIAVI2+c+ITTaTwqRojcqWq/756Jx5c+nUMgLYG5rhF7vNoZjPe1UU+TI5PjiWTx+jU5iN2VboYCNDAx24DqtNQFtq01VF1Gpucz4VFn3Obi5C5YNbgxzPg9pB58i9zZXZmXUyBY2w/3BM6ocwcQZl15nPiDJyeQjwJ2wpqb+8HB/B46Og8DnV6EcNyUU2D4IyIhCunkAItuvQkRKHlOEUO1hUVhYWDDyhJjpohG7qqCH0qxZs/QxtToMbb5mCxQKXN67E9cOUtQy4N/udfT+cDqEIqOq+X66DvfsQcKaLzgDUysrOK9cAfM3Nasu0aRMvvXVwBcjxkVAR5dGkG+09QP/78+BG5u4/2g0BBj0I2BYPb5RUkqvemcSJKGhEDg6wmPrFojKGYNYGiTiPGZkGhf8BCaWVhi5ZA1sXCoWlVgdCLuThNNbHkEmUcDGxZQl0FnYGevsdVvdUCikrKSU0tQUijwYGNAAwDuo5/UxBALt80Kr8HXbvmGNlL1oWx+iOuNslakuBNVuhfIoaCLVpTiPD/KmUCa1lAUiKPr168fUEsOHD2eeFkRKkOcGqQ9osJ+MOWnAn3wvaPnOnTuZ0sPLq3jja1I2EGlAn6OOP5WMUOkMlaiQKeqMGTOYySj1san8gzw/qNyD1p+86aiUhpTBJW0rkST0eUp1mTNnDvs98t2srMfHvXv3WAoLKVyoFHvTpk1MwUKkELVfaQCPzu/iyBVal549e7LybRJL0LpSpQitlzKitjQQyTFixAhm1kpGr1QWvmXLFqagLi7pUN3ztdzEB9X60Er07v2yvJNOMFJ8XLhwAbUN2nbTUveBnXv7NhJWroL4eTQmjQo5zJ0Dsy5dSv1cRp4UtyKICEljypD70RmQyF82ezMXCdDS80VyTFM3SxgJuX2TEJ7JUl+o9IXHN0D7IT5o9qa71jYubmfkYHpQFIJyuA5qD1sLrPF3g6tR9Y/A63JjTCZXMNPT786GMONTilX+ZmRzZnyacz0e6UdCqYUCgZ0xi7wVOlVNgyo3NxxR0dsQF7cfcnkuWyYU2sDNdSxc3cZBZGhXuR9ICAR2DAayEwBbX+Dtw4Dli05Abm7uSxG6JAEkpYi6mDBhQrmz2/XQHujCNfvo/Fmc+uV7KOQyOPn4YfDsRUwVUhnIUlMRN38Bss+dY/Omr78O59WrICziXq9LuJyWhaF3y5bRtrc0hZ2hEJ3C9mPMndUQFMgQaRWAHzt8i1QTzUYzKlEgyUfu9RuQZ2eDJxLBpG0b8KrAe4PIspgnj5CbmQ4eXwD3Rk0gMtFWT48CpMXnIiU2m/WqTCxEcPK2AI+vjqqpgEVVcn5K2nndVgek0hRkZj2CXJbN5sk3i4zEBQJz6AqSJVJczeDiskvDn8198Lp19W+XtvUhqpP4UJIfS48GIi7jxSAQKUEWD2iokSjbyhIfBDpeq1atYiQAVTlQ+gh9pxL0fRSvSopgSjihDn3R0hdVUKIgkR5Xrlxh5SPTp09nsbOqRqBEKpBnpp+fH1OQtGnThv0fRdKSISj5apS0rUTCkEkq3dOILKD1VS1/qSjxQaD4WjJLJfUFRfcuW7aMraNSrULLlf6fxZEXtB9JhULkyLBhw1jajLrrRuob8lKhtjX9Ju1DIpuKg8aID2JbyFV14sSJhXU3JMmhE4AYncmTJ6O2QdtuWuVpaFMjJuPgISRSzNHzGjNqoDp+PhciNeKICGKpHPei0p+rQjjD1Ox82UvvMeTzGPmhLI1p7GCOW/ueIvQONxru1dSO1dsamWpX6YsSEoUC30ck4puIBEgLCmDG52GBjwvedrEFrxo7M7rQiSoLRJqR+oNKqEgU9FE3P3zSzReK2BxW+iLPyIeBkAfroX4waV51nSSpNBOxcXsQHbUd4vxYtszAwBBOjgPg7jEJ5mb1y/+lsXeAHUOAvDTAsTEw/iBgVvo6E6tPDwKqB338XPpfGkgpp66BlR7aB125ZqMDH+LwVyshzs6Cua09hsxZBHvPihFu2ZcuI/bzuZAnJcOADExnzYT1+PG6YWBaCg4mpGFKYES5PtMu/R5+C1wEO2k6koVW+F/DZbhm1Uxj66iHHnpUDD819MQQx8oRvrWhD1HdxIcy2pYU5YlZYjiYG7FB0+osb9F1UP968+bN0DZIJBIWdUuGsTUNjREfBHJUpbp1+gGqiad6JnJ8HTRoEGojtO2mVZGGNo0KpfzyC1K3bkOBVEpWvbAeMwb2H05l8uTy3sAex2WqlMekITk7/6X30GrVdzTHGzwjWDzJAUkAzGxErPRFm+tun+TkYeaTKNzK5JQDr1maYl19d/iaVI00vLZ0ospClliKxYcf4cCdGDbfwsMK345sAVeRgJme5j/lDHrNXneBZd96MFBrhE49KBQyJCX9zXxAMjNfuFZbW7dncbi2tqR4UuP3Iq4Cu0YA+ZmAaytg7H7ApHQDLlXQ/XHbtm1lvk+v+NBt6NI1mxYfi4NruMQXoZEx+k+bzZJg1IUiPx9JX3+N1G3b2byhrw9c162DUf0KkIpaBKmigBldfxsej4fPlX+l4X+udvA2eVFKZ5odi+6nP4BdSiAUBgJc6bAYQQ3KF51YUShyc5G2cxdk8fEwMDWFzbixEFRAdVNQoEDgv/8g4dlTpvRo3rMvrJy1M61PJpEj8HIsMhLymFjDp6U9XPzK2aEtAPLEeTA2Mq5bgg8qT8u4xUpEFQruXLe0bAV7uzfB4+ueJw8hLDefmdWXBb3io+aIDz0qDirxIEUxRcpqG37++Wdm1E9xvrWa+CCn1vT0dGbop4zEIfVHbTXnqw3EhxISitT8ci2yz5IvAsC3tITdp5/AesQIGDx30q3I+kSk5HJmqc84MiQ8hSMOCA4yAwzMNYS1gocCA8C0tS069feGj4OZVnYUqF50S0wyVoXFIVeugIhngBmeTpjq4QChhhlqXepEqYPDd2Ow4OBDZOXLYCYSYNmgRhjczAVZpyOR9S/nGG/oacEib/kWVX//yMi4w3xAiAgpKOBcyE1M6sHdbSKcnd8Cn29S/AdD/wF2jwWkuYBnR2DMbkBUPokslbt88803L6W5FOcFMm3aNL3Hhw5D165ZcXY2jq5fhciH9xkB2GXCu2jRe0CZ654fEsIZmD6XwRJx7jD7M/B0uEFM5tY7Y1OwKy4FiZKXVYzl9gqQ5AKHPwQeHeDmW08Cen/BReRqGPL0dERO+h/EgYFsIIM8P8pDRpEy9NTG7/Hw3GlGegz+bAHqtXiRaKBNSE/MxfEf7yM9IRdCER89320EryZ2tf66rQpkZj1EUNAiZGbeY/NmZg1RP2AZLC1fxE3qIpQeH2RkWpKJpt7jo/zQEx/agRcledoHqRatm8aID5Juf/DBB8z4hbw+CFRfRF9DWcHKup/ahNpEfCiRc+UKElavRn4IF5ck8vOD47zPYVpKjVp5kJgpZikf158TIaGxmeiRI0R9KUeuhArkuGYPNPG2KSyPaeBsDkEVjvxXRaN4dlAUzqVy6RuNzIzwdX0PNDMvobNcBaiNjTEyPp2x9y4rkyIMaOaCFYMbwzAsE6l7g1CQLwfPTAjbMQ0g0pAaiNzqyQckNnYPZDLueAoElnB1GQU3t/EwMlKpM31yHNg3EZBLAN/uwIgdgGHFjnlJqS5KUC1mZR2q9ahZ6OI1K5fJcPa3DXjwD5fe0KxnP3SbOBm8Yp5vtH1pu3Yh8cu1KMjPB9/GhjMw7doVutpJ+iclE9tjU3A2JRNKNx57QwHGOtuyDtLc4OgSzfhKTYeg5tSlr4Gzy7lPe74OjNgOmFbSZ0gNyDMyEPnuexA/eMAGNNw3/wZjlRjAkkDH99y2jbjz11FGhPWfPoeZ4GojYkPScOLnB8jPkcHMWoR+HzaDnZtZnbluKwp65oWGfY3o6N+JkgefbwYf7+lwdR0HHq92JNkpU10qdN3WsT6EutATH3roEjRGfIwePZqpO8g1Vsny0Mim0gSmJIMTXYa23bSq6oFdIJMhbc8eJH/3PWs0Ecy6vwnH2bNhWCS1pypKH26Gp+Luv9EQ3MsArwDINFDgmKkUMQKu6WlqyGeGqWSWShOVRygNU2tyX+9PSMOikBikyeQgWuYDdwfMqucEEw2QNLW1MUblURvOPcU3Z0PYa1crY6wf2RwtzI2RsiMQsoRc0M617OMNs44uGtt2mSyHmaBGRW9FXl4kW0YO9g4OfVgZjEVEMHBgMkDqkAYDgKG/AYLKpcMQ+UEu1KrKD1J6kEG0nvTQfejqNUvrffPYQVzYuYV12L2at0L/T2dDZPLCdFiWkoLYefOQc54zLTft1Akuq1ZCYG8PXUNivpQpO3bEpiBGJf2hk7UZ3naxQ287y0JFH3WiFoTEvJQS4SISYrmfq3qdp6CTwJ/vApIswNIdGLULcG4KTUOelYWod99D3r174FlYwOO332DcpHGpn7m0ezuuHeTI2d5Tp6NRZ+1M5HlyNQ7nfn/CEuMcvCzQd0oTmFqK6tx1W95tTEg4ipCnqyCRcH5rjg794ec3HyKR7poQl4TVgRfwY6wCMv6La1QoT8NUFz4+b/hGja2XtvUh1IWe+NBDl6Ax4oMuXIraoahGVVD9EXl8UNlLbYO23bSq+oFNMtmkH35E2h9/0MYyszqbiRNh+/774JtVfZRZUlQWTm58iMwkrj432s0QxyQ5rBxCFUK+AZq4WhYSIRSla2VSM+VUSRIpFobE4FAi503hZWyIdQHu6FjFDuG1vTF2JzINn+6+i8jUXGZ8+mFXX3zUyRvZh0ORd5drmBk3tYP1UH/wRJq71qjsJTn5H+YDkp5+rXC5ZYYU7jF5sHcZDN6gnwB+1YyGETlMrtQJCQkshot8kcrruK2HdkLXr9mQG1dx4vt1kOXnw9bNA0PmLIalgyOyL1xA7OfzIE9JYTHoDrNmwXrcWJ0yMKVjczk9G9tiUvBXcjpkz1s7VgI+RjrbYLyLbYn+TaQM+S8tG8/SM1DPyhKvWZuVLwozKQj4YxSQGgYIjIHBG4DGmq+DJj+vqPcmI+/OHfDMzeGx6VcYNyvebPXaoX249AfnQ/TmpClo3qsftA0FigJcOxKGWyc501mflg7oPrEBBIb8On3dloWcnDAEBS9GWtqVwhLPAP+lsLHRTjVPZXEm4gxm/DuDKbikogAo+FbgydNhmB8MAxTg6y5fo7tn9xpZN23rQ6gLPfGhhy5BY8RHnz59WAYvSbRVQfnFP/74I06fPo3aBm27aWnqgU013Amr17AyGALf3g4O02fAcvCgKm/sSsQy/LszCCE3Eti8e0MbePZ1x72krMLymITMlw1TCQGO5mhT74UqxMWqes24TiVnYE5wdOFI4FhnGyzycYGlsGo6yLW9MUagRCAyPv3zNicnb+ZuhW9GNIN9cAbSjz9jRrgCB4q8bQihg+bKipTIynqEyNtzkSB9hILnI75GRm5wd3sbLi4jqizWry4c27qI2nBcE8Ke4tCXy5CdlgoTC0t0tHOH4ODhwjJIFzIwDfCHriBNKsPe+FRsj0lBaN6L50hrCxO87WqHAfZWMFZDsVfpY0tpUPv/B4RynlroNAvoOh/QMHkkz85B1AfvI+/mLfBMTeH+668wafmyj8Odk0fxz5ZfuNUaMxFtBw2DtkEqkePs1kCE3uZI8Va9PdFuoDcMqsBrqzZct8VBLs9DePgGRET+ioICKXg8Ebw8p8LT8z32ujZCrpCj15+9kJDLtSeLwgAGcDRxxMmhJ8HnVX8bXtv6EOpCT3zooUvQGPFx+PBhlqM7YMAAluerjLMl11nKEdYGZ9faftPS5AObvjv73DkkfPEFpBFcKYBR48ZwnDfvlYZTVfxW4KVYXNwbArlUAVNLQ/R8tzFc/KzY/1EcamFyTHgqwpJezWmnkgmKxeKIEGv4VoNhapZMjhWhsdgWm8LmHQ0FWO3vhr5VUD9aWxtjxeHovVjMO/gAWWIZK3NaMrARBtiaI3VXEBRZEhiI+LAZ7g/jxhqsj6fb34W1wLmVyDc0QHTbNxAjioVUyvmRUC20i/MwuLtPgLFx5cq/6tKxrUuoLcc1KzUZB5bNR3JcDHgKBZpGJaHRgCFwmDlDJwxM6ThQGte22GQcSUxHvoJr2pjyeRjqaI0JrnZoZGZc/cdWIQfOLAaufM/N+/cB3toIGFlU7PvU/dncXER9MAW516+DZ2IC9183wqRVK/Z/D/89g79/+oa9fm3oKLw+Yhy0DTkZ+Tix4T4SI7LA4xug67j6qN9exYupkqgt160qkpPPISh4CcRiblCBEswC/BdX+tml7bgRfwOT/p5U5vs299qMNk7qp1jV1j6EutATH3roEjSa6nLx4sVi42xbt9ZOF/DadtOqjge2QiJB2o4dSN7wExQ5HOFg0b8/HGbNhNDJqUp/Kzk6G3//+pC5tNPmtB3gzUZ2io7qUGTuzefxuTcjUvEoNpP5RajC2kSI1l6cWSqZpjZysYBQQ4ap/6Vns+hb5YhiP3tLrPZzg4Oo4g7HtbExVhpi0vMwfc9dpvIh9GvijOU9AiA7+BSSZ5wnhllnN1j29IIBv4r3B936Ti8CrnzHzXddALwxC3JFPuLjDzEfkJyckOdv5sHevjvc3SfByrJ1hY5NXTu2dQW14bgyA9MdvyP2q69wx9kaiZZciWOH4WNZx1ibtytbJsefCWnYHpuMR9kvomjJjHqCix3ecrSGmYBf88f23m7gyCeAPB+wr8/5ftj6QJNQ5OUhaupU5F79DwZEfvz8E6LlEhz/9ksWX9uy7yB0eftdrTu+1CY4vuEeslPzITIVoO8HTcofV1sHrltV8+7g4GVISuYU1yKRE/z9F8HerqfOb1tpkMqleJTyCDsf78TJ8JNlvv+LTl+gr3df1PU+hLrQEx966BI0SnwUh8TERKYGee+991DboG03rep8YMuSk5H4zTfI+PMA6ygaGBvD9r13YTtpUpWOAlLpy4U/ghF0LZ7NuzewRvd3GsGklIhTKpkgzwiK0CVFyN2odIilSo9+DsZCPjNJJUUIKUPotYlh1bmYi+UKrI9IwA+RCZAXAJYCPhb7umC0k42+c6wmiLz6+Xwo1p8OhkxRAGdLI3w9vCkaBGUh+2IMew+lvdiMqQ++WRV5vCgUwIlZwM3fuPleq4D2H75ynaWmXmRxuPRXCXPzJvBwf4cZovJ4hnWyoa1H7TmusqQkxM6bj5yL3Dlu8kYnhLVuittnuY5Eg45d0PP9TyDQsrj6R9l52BaTzEiPHDl33zfiGWCggxUjPFpamFT6eFT5sY25xcVkZ8UBRpbAsC2Ar2bNRBViMaI//Ag5ly8j0dYStz0cmOdQk2490WPyx1p3zoY/SMapTY8gzZfDytEE/aY2ZX+rGrp+3RIUCimiojYj7Nn3UCjymFG3u/s7qOf1MQSCqvdnq2nkSHNwN/EubiXcwp3EO3iQ/AD5RCSqCb3io3zQEx966BKqhfjIz89nnh4HDx7Ef//9x9Qf9+5x+eC1CXWZ+FAi7+EjJKxahbzbt9m8wMUZjp99BvPevatsHWi7yLmdCBCZVAETKn2Z1AiuAeqN9EhkCjyMzWBECFcik4aMvBeu/Gy9eQZo5GqJtl7WTBlChIiNaeUb9A+zcjHjSRTuZ+cVJgWQ+amnsajONcYqintR6fh09x2Ep3DKnymdfTDZ0Ro5B5+iQKIA38IQNuMaQORRSYm4XAYc/hC4v5sLuxvwDdBqYqkfyc4JQVTUFqYEUSi4hpbI0JFF4bq6joZQWHaZU10+trUZunxcs86dQ9z8BZCnpsJAJILD7M9gPWYM2477Z0/i7G8/QSGXwyWgIQbNms/8P2oSeXIFK2MhdQeVtSjhayLC2y62GO5kA+sq8lvS2LHNigf2jAOibwAGPKDnCuC1qRQvBU1BkZ+P21Mm42JWEhQ8Hnz9G2LA0tXg1YDfQWn7+v65aFzeF8LEeK4BVug9uQmMTIUa+z1dvW4JaWnXERS8qFCVaGXZBgEBS2FmFoDaguS8ZEZw3E64zciOoLQgKApeHtyyFlmjuX1z3Ei4gWxpdrHfo/f4qFvER3R0NN58802cPXsWbm5uFfoOqmxYu3YtwsPD4eXlhZkzZ6Jz584VXqe0tDQsWrQIly5dgrW1NT799FMWCKLElClT8M8//7z0mZ9//hldy4iNr4ptVYIM+MnG4v79+1DF9evXsXLlSrYvAgICsGzZMtSvXx/VCdpOWjfaJ+3atat+4uPmzZvMzJQiGnNycljCy8iRI5m/Bx3Q2gY98cGBTpWsv/5Cwtp1kMXFsWXGrVvBad48GDVsWGX7OyWWSl8eIS0uh7UF2/Svh1Z9vMArp6GZQlGAkMTsQp8QIkRiM15IoZUgXxBOEWKN1p42cLM2rlBDiNQKv0QnYe2zOIgVBTDmGWBOPWe8526vdhqArjfGKoucfBmWHn2EvTe5GuWmbpZY16M+LI6FQ0YpQHwDWPX3hulrzhXbPzIJ8Of/gMdHAAM+V2vfRH1TP4kkBTExfyA65vfCeEAezwjOzm/B3e0dmJp6l/jZun5sayt08biSCiDxy7VI27WLzYsCAuC6bi0zMlVFxIO7OPr1auTn5sDS0QlDZi+GrdvLiW7Vgae5YuyIScGe+FSky+RsmcAAzFeJCI/XrTTj7aSxYyvLB47NAO7+zs03GwP0Xw8INdO5iA1+jP0rFkKaL4ZDRg5axabC48cfYNapE7QBCrmCeX09PM8p/Bq87ozOowPAF2jOBFYXr1uCRJKMkKdrEB9/kM0LhTbw8/0cTk5DdGo7ijse0VnRuJV4ixEdtxNvIyKTS/JRhauZK1o6tERLR26qZ1GPbbcy1YV9FwpeIj0I+lSXGiY+yOso4gqQnQCYOQKeHQANEa+VJQOIABg4cCCmT5/OvufMmTP46quvWJ+3ouTCBx98wPbnvHnzmECAyIOdO3eiaVMu5rxnz5746KOP0L59+8LP0L3JsAylZVURH3FxcSy4hI53UFBQ4fKoqCj079+fVXPQ399++w2XL19m+6KsdatKvPvuu4yM2r59e/URH7RzieygchbaEU5OTujevTv++OMPtszX1xe1FXri49W64ZTfNiNl0yYUiMVspMpq2FDYT5sGga1tlexzkrle2BOMJ1c4goVUHz0mNYSpZeVcyaPTcgvVIESEEDFSFFRqwcxS63FeIX4OZuUiXZ7l5mNWUBSLUSQ0NzfB1/Xd0VANYz1dbYxVNU48iMPnBx4wxQ6VKy3qUx89wnIhfsgZypq0cIDVEF/wyhNpKMkF9o4Hnp4B+IbA8K1A/YrFN5LqIyHhOIvDzc4OLFxOZnIe7pNgbd3hpeNH8bk0QpeeHgErK09YW7eFAREveug8dO2aFT95gphZsyB5GsrmbSZMgP2M6eCJir+3pkRH4eCXS5GREA+RiSkGTP8cnk2ba3w9JQoFTiZnYntMMi49v5cS3IyEGO9sh9HONpXyUyoLMpkCl69GIiouA+7Olni9vQcEVdkRp6bXtZ+Bv+cDBXLAtRUwcidgUXUGnoTE8DDsXfo5I688GjVFm/h05P1zjsXWu37/Hcy7dEFNIj9PhlObHiLyUSoT4LUf7IMWPT00fi3p2nVLz5CY2D0IDV0LmYz8rwyY2tDHe6ZaikNtTGIJSQ9hSg4iOkjZkZTHDSaokha+1r6M6Gjl2AotHFrAybRkjzkiP9ZcX/NSuouTiRPmtJ1TY1G22tiHqHbiI/AIcHIOkBn7YpmFC9D7C6DhQFQ1KksGXLt2jZEdFOShRNu2bbFkyRL07Vt+j5jIyEj06NHjpfWh76bzYs2aNZBIJOzcOH78ONvX5UFVEB9nzpzBwoULYW9vz0gPVeJj9erVCAwMxI4dO9h8Xl4eU1788MMP1ab6oPAU4hpu375dfcTHuHHj2A/6+/szqQ/tZCVL1ahRIz3xUc3Qlge2NC4Oieu+Qubx42yeZ2YGu6lTYTNuLAyqiAl88l8czu8KgkyigLGFISM/3OvboKqQmiNhhqlcckwaHsVkMOWGKiyNhWjtac2IECJEmrhawrCMBjAdo11xqVgaGoNMmYKNTn7s4YhpXo4QlRJlqC3HVhsQm56HGXvv4r8wzvi0d2MnLHCyBf6JAhSA0MkUtuMbQGCrRlJDfhawaxQQcQkQmgCjdgI+3Sq9jnS80tOvMQIkOZkiK7lzx8w0gNVaOzoORErKvwgOWYb8fM6/ptB8zm8RHBx6VXod9KhZ6Mo1W6BQIHX7diR99TUKpFIWV+6yajXMOnUs87O5mRk48tVKxDwJZNHmb06agmY9+mhkPaPEEvwem4JdcSlIksjYMrpjdre1YFG0XW3M1VbQVRSHTwRj5cVQJKrI6h0MeJjfyQeD+lZxrG/oOWDfRECcDpg5cfcmt6oxiifSas/SucjLzGDlSsPmLYOAz0fMzFnIOnWK5AJw+/YbmHer/L2wIshMzsPxDfeRGpsDgZCHHpMawbuFfbX8tq5ct4TMrIcIClqEzEyulNzcrBECApbB0lLzBGRVgbw4HiY/LFRzkFdH0dIUAU+AxraNOTWHQ0s0d2gOS5FluQkVIlMiUyLhYevBCJOaiLB9aZ3qMvFBpMfetwvbRi/w/Jobsb3KyY+iZACVZ0ydOhW7du1CixYtWL+VOu7FQbXTT5BKpWzQn0o9jh07Vkgu7N69Gxs3bmQlLJRwumDBAvY7xeHo0aNMMfLvv/8WLjtw4AB++eUX/P333ywZdejQoUwJQpYRFdnWzz77jJEC2dnZTJlB60OKjO+//77MbV2wYAHbBjrOb7/99kv7YMiQIayagwJMKoLg4GAsX76cbZuzszP7/rFjx7L/mzt3LrPKKApXV9fCsh/av6S+2bx5M9uuaiM+6GJ1cHBgCo82bdqgQ4cOED0fHdITH9UPbXtg5966hYRVqyF+9IjNG3p6wmHuHJh16VIl65cal8NSX6hxRPfK1n290KZfvXKXvqiDXIkMdyPTmVkqkSG3I9KRJ+Wk1UoYCXlo7m7F1CDkE9LS0xpmouJvVvH5UswLjsaJ5Aw272ciwlcB7mhrZaYTx1YbjE83XgjDV6eCGCHlZGGENR194H8hHopsKQyM+LAZEQDjhqUojXJTgZ3DOGNBkQUwZi/g+UJOWFXIzQ1nSTBxcX9CLs8tjMOVy4urO+aObZPGP+rJDx2HLlyz0sRExH0+jxlcEsy6doXzyhUQ2KhPIsukUpz65Ts8vniOzbfqNxhvjHunSnwi5AUFOJuSie2xKeyvslHiYCjAWGdbjHWxhZtR9chqifT49IIyzelVfPuGX9WTH6lhwB9jgKTHnBptwLdA8zGV+sr0hHjsWTwb2WmpcKjngxGLVjHFDoGIr5jZs5H110lAIIDr+q9h0aMHqhPxYRk48dN95GVJmZ8XmZg6eGo24lfXrluZLAuhYV8hOnon6QzZ88THZybcXMdqvWIwS5LFVBxKjw4yIpUqXvZcMxWaMn8OUnIQ2dHErgmMBEa17tjWOuKDuo3SFx5LpZa3/NiWM3MuFgacwm3qtbLLXmjASs1jWRzx0aBBA3z99dfM2Jk64Lm5xa8/qR5US1769OnDjh95fEyePJktp045+XVQh572DREjpEg4deoUO+eKgjrtVBpCaahKnD9/nvl80Hlx4sQJLF26FK+//jrz06CKio8//lgtTxHltlK6KqkzaF1nz57NiBT6DrKjUGdblUqXosQHpbXOmTOHlZmQzQVVd9C2q1PlQedPr169GHkyePBghIWFMWUJkTQ0n5WVxd5TFHSN2Dxvm9BvOzo6YsaMGew4VgXxoRa1dPXqVXagie0iuQsxUnSAaGfTTUUbbix61BxMWrWC1769yDh4CInr10MSEYHoKVNh2rEjHD+fC5FP5SL7bJxNMWxua1zaE4zAy3G4eTwccSHpbHTI1KpypS9FQYkvHXzt2ESQyhUIjM3kFCHPUnEzIo2pREiFoFQi8HkGaOhs8cInxMsGdmbcejmJhNjcpB6OJabj85BohOTmY9Cdp5joaof53s4VjlmsK6B9O6WLDzr62jHj07DkHLzz1yO8184TE2KkKIjKRsr2QJh3c4dF91cjkJGdCOwYAiQ8BIxtgPEHAJcWGllXExMvBPgvgXe9GYiN3Y3IqG2QSF6oPF4Gde0MEByynMXkansjVg/dRdY//yBu3nzI09OZganj3DmwGlX+iFqBUIg+H86AtbMLruzdiVvHDyE9IQ59P54FQyM1VFfFICFfypQdpPCIyX/RKSJzaEpm6WVnCaEGCO7SyltWXORKgEoCKUH69fSt2rIXG2/g3dPAgfeBoOPAoSlA/EOgxzKAX36z1qzUZOxfMZ+RHrZuHhg6b1kh6UFgZS5r1yKWx2eKzZhp04Gv1sGid29UB0JuJODstseQyxSwczdjpIeZte6YJ2oa1HFPSDiKkKcrmacHgdSD5OUhEjlAG5GUm/TCnyPhNoLTgl/y2iDYGNkwBYbSo8Pf2p+pPPTQIRDpsbkXEHWtKr6MK39Zo4ZvlPtrwKSTFTaBJh9Kb+8XHmympmWnHlHne//+/bhz5w4rSSFygTrymzZtwvvvv19oPDpt2jRcuHCBlWQUp4yg8pCifhg0TyUuBCIEqNPesWNHRq5QaAiZne7ZswdNmjRRa/vIO6RVq1bsNREq69atY8QHbac621oSiDSh7yL/EdpmIh4mTpzIlCplfS8pXWxtbdn+IZBJbExMDPsOIj7Mzc3ZVBKuXLmCW7duMe6hKqHWHcfY2Bj9+vVjU2ZmJttgYqhIHkPsEkmARo8ezU6C8sp09KgdIPmz1dC3YN6rJ1J++QWpW7ch59IlhA0cxFIC7D/6EPximFB1ITTko+v4Bszr49+dQYgJTseeldfR/Z2G8ChttL+SEPJ5aOZuxaZ3O3mzBkloUjauP0tjJTKkDIlOy8ODmAw2bb78jH3O2870JZ+QfvaW6GhthqWhsfgjLhVbYpJxKjkDXwS4Mwm3HqWjiZsljn3SEcuPBeKP61HY+F8ErrhYYHlzW9jfTUHWP1GQRGXBZlR98JUpABnRwPZBQMpTzkzr7cOAQwON72qh0AKenpNhZtYId++RxLMkFCA/Pw7p6Tdgbf2axtdLj7oF8mJK+OILpO/ew+ZFDRpwBqaVIKKJLGk/dDSsnV1xcsN6hN68ht2L52DI7EUwt+XI4rJA99BLadnYFpuMk8kZkD3vG1kL+BjpbIPxLrbwMdFsJzg7Ox/h4el4FpWBiIRsRKTlISpLjKd5+UguQwRL5S+nTgSjz4CAqh30EZkDI38Hzq8Bzn8B/PcjkBgIDNsMmKivzMnNSMf+5QuQkZgAK0dnDFuwotg0HgOBAC5ffgEDAR8Zh4+w8pcCuRyW/Srme6Tusb95IhzXj3LPSa+mdqx81dBI325UIicnFEHBi5GWdpXNm5h4M0LdxuZ1aAvoOJLxKJWsKD06orM5Q3JVuJu7F/pzENHhYa557xY9qgO6dwypfEIJSgahMpPiQCSHEtQpb9iwIZtCQ0Px+++/M+KDXlPiCylIVFNOKfWEVBFkBKoEkQVUIaEkOZSgeaUqgcpwiDBRqkXIO+PRo0dMIaIu8aG0nyDQ+iYnJzPVEylR1NnWkkDqi27duhUSOqRy6dKlCxNDkNdHaSBCh8p4qLxICeIMlKonUo4QOVIULi4u+PPPP9n/L168uMoThcr9tLGwsMDw4cPZRDv2r7/+YoYsxCwRs0Nur3rUXfDNzOAwcyashg1DwpdrkX32LNJ27EDm0aOw++RjWI8YwRpcFYV/Wycmhz3560OkRGfj6Pf30KqXJ9oOqAceX3MO8ErQQ9vXwZxNY9p5sGVxGXlMDcIlx6QhKCGLKRNo2nMzir3H0ULElCBEgrRyc8b3ySmIEEsw7n4Y3nK0xjJfV9gZ6ht/ZalxVr/VFJ39HTD3wH08jM3E6KRszGntjh5305Efko7E7+/AdlwDGJokAdsGARmRgKU7R3rYVk55VF5IpZwRa1nIyLyvJz70qFKIAwMRM+szSMLC2LzNO+/Afvo08KrIe6l+hzdgYeeAw+tWICk8DDvnz2Dkh6N3yfLXVKkMe+NSsSM2BaF5XCQ0oY2FKd52tUV/eysYV9E9nOTMSQk5CIvMQHhMJiKSshGVLkZUbj6iJVKklj/M7iV8fCUUba9FoquLFbo3c4ZnU0cWt11pkP9T13mAYyPg4AdA2Dng127A6D/UIm3F2dnYv3IhUmOjYW5rj+ELV8LMumTSxIDPh/OqVUxmnnHwIGI/m007D5ZlNGgrAplUjnM7niD4Omc82ay7Ozq85auRklVdhFyeh/DwHxERuQkFBVLweCJ4eX0IT4932euahEwhY1GySjUHER6pYk7xqmpEGmAT8CJxxaEl7E2qx69Fj2oEEVekvFCn1IVSXKjMuCyM3c+lvFRRqUtxUNozEEaNGsVKWEpCSEgIIw2ozEMJHx8fVoai7LyTwkI1gYVgZmbGVBBU+qIEkRlUJkL9ZVXQvLLUhMfjvVIiQ+qUp0+fqr199B1KKB0shEJhmdtaFmgdVQ1XSalCJBKlwJQFmUzG9hERGMWBlCn/+9//XllOAgqK1KUglU8++eSl/yNSidQilIpTUVSqp2VnZ8dYIJqozohUIHroofT5cP/xB+RcuYKE1auRH/IUCcuWI/2P3XCcPw+mr1V8hNvK0QTDZrfCpf1P8ehCDG6djEDs03T0/F+jGpHLOlsaY1BzVzYRMnKluBnBqUEoOYaUIAmZ+Th+P45NBDMTARvtirDk40BCGv5NycRyP1cMcdA9d/bqBpmcksfKzH13cflpCpbejMBlHzvMTAXM0/KR+NNdWBtvg6ksErDx4UgPq+qP4FRXkhwa+gVSUs7B1XUMHOx71ngjVw/dBTMw3bIVid98Q8wbBPb2cPliDUw7lNGorABc/OtjzIqvcPCLpUiJjsTuJXPQ96OZ8Gvb4aUG2K3MXGyNScbRpHTkPzeONuXzMMzRGhNc7dRKuyoOEokMkREZnGojPguRKbmIzBQjOk+CGJkMeWV83pxSMYQCuJsYwsPSGJ52psjMk2LdY5XkgRJArk9X5VJcjUrCqqgkBBzj4Q1TE3T3s0fTFk4Q1bMsX+JUUTQcxN27do8G0p4Bm7oDb/0K1C85UUCSl4sDaxYjKeIZTCytmNLDwr7sexAjP1auYMqP9H37ETt7DgpkclgNGYyqQl6WBH/9/ABxoRmsHLHzaH806vRiBLauIzn5HwQFL4VYzKkmbG27IsB/MYyNq/+5RRDLxMyTQ9WINFf2ckfXkGeIxnYvG5GaG5YsW9ejFoEICEM1yifIQJ7SWzKp3VtQgseHC/e+ajSgtbKyYlNJOHfuHDMfpYF9pUKJFBjKUhkiAuLj41npixKff/4588FU+m2ogrxdqMSDPkP+HQQq4aDlSpNP+h3y6FCClBIUKFIeE1FKniEQaUC/Y2JiwqbStrUs0Dqqen6QUoUICXUSZGg/KX1WlCoPSoF98OABqxghsQRNxYGWk2eKKijyd8WKFcxqozKosiFm2jCl8Yu6IGkQGbrQxpGUZdKkSWwqDlTzRLIiOnFIBkQ7jYxVlcYuxYFkSWTGqso+keELnZykUNFD86AGd72DB5G2Zw+Svvse+SEhiJz4Dsx7dIfD7NkwdK/Yg11gyEeXMQFw9bfCud+fIO5pBvasuMFKXzwba670RR1YmgjxZgNHNhHEUjnuRqUzEoTIkNsRacjOlSH7v3gILYSQNrZGqjnw4eNIrHsYjSlWphjUyASWxtWXka1rcLI0wo5J7bDpUhjW/h2EM6HJuG8mwmInIZrF85CWPQH5pg1gPX4MDKyqNh5SXVhZtWHpLfn5NMJZ/AgzkRwKhQTp6RR1ex3BQhu4OA+Hq+soGBtziiI99FAH0gQyMJ2LnCucRN7szTfhvGI5BNbWGtuBlg6OGL18HY59+wXC797Cka9Xo9PoCajfdzAOJKazKNrAnBfmZY3NjDHB1RZDHKzV8jfKSBfjWXgawmOyEJGYhcjUPERmixGdL0WCQkHhTiXC4HkSi5tICHczETysTeDpYAovFwt4e1nB2takWI+P7QvjX0pzKQr6zq1T2uPMjWicDUrE/cw8BEGBoJxs/Ho3G453w9HRQIiuzpZo39gR5gG2EDqbvuo/VBacGgPv/QvsmwCEXwR2jwG6zQc6zXpl5FMqycehtSsQFxIEI1MzRnrYuLiWq1TVaelS0jWz0qi4efOYMaHV0KGoCnPy4z/eQ2ayGIbGAvR+rzHcG1ZdMpsuIy8vhiV+JSefYfMikTMC/BfBzq5HtZaEZORnMHJD6dHxKOURU3mowkxoxsgNpUdHI7tGEPH1JL0epYDIDIqsZakuBkXaQc/P795rqpX0UAeUIkLlIeRtQdUNVMlA/h3kuUF45513WBwteVa0bNmSLSeShMpaioO7uzvz7yBTT/ocdfzJt4L6qAQqJSHzTjLtpLIQKv8gYkSpaiCDUuovKw0/iwOVoBApQKku3333XbFKiopgwoQJLIWF/EMo2IT8TUg9Q+UuBDIoJQVMceQK7UdKlCHFB/Xtqb9O1hi0/8oCcQJFCSQCGZ2WRJaoC7VSXTQFOlA3btxgLFdsbCxzb121ahV6FzHYItkRERZ0EtBJtnXrVkaWEBlCspvU1Jcld2RCQ268VNtEUh8lKHqIIoXIpKU8xIe2OTJrm2O1upClpSH5hx+Rtns37VRmsGYzcSJs338ffLOKm++kJ+ay1JfkKC49o2UvD7Qd6A1+NZS+VAQyuQKP47IYCcJ8QiJSkWAvgszHHKDGsUwBYUgmGkv5aPc8QrdNPWs4mOvN34rDw5gMZnwampTD5t82CMHEguYwBB9CVzPYjm0AgU3N7LvExL/x4OGHz+cKik11sbBoiti4fYiN3aMSeWsAW5tOTAVCo388vQGc1kIb7seZp08jfsFCyDMyYGBkBMfPP4fViOHVtj4KuRzntv2Kv2/exL2GbRHUoCXEz89ZI54BBjlYY4KLLVpYmLy0TmRuGR+fhfDIDDyLzUJEcjYi08WIYSUpMqSXQBgqQdSwK18AN2MhPMyN4GFrCk8nM9Rzt4SnpyWMjF48/zWV6pKYJcbZe3E4dScWV+MyIFaJQ6enWjsI8IbICJ197eDQwBYiP2sILMvRYZRLgb/nAdc3cvMNBwODNxSOuMplUhxetxLP7tyEobExhi9YCSdf/4qbaq5YibSdlCICRoZYjxyBiiLqcSpObnwISZ4MFnZG6PdhM2ZWXtevWyK7KQL92bPvoVDkwcBAAA/3SahX72Pw+a8SclWN+Jz4QjUHeXQ8TX9VUm9vbF+o5iCyw9fKt8ZjYXXpnqzNfYhqjbNVRtqenMMZmSph4cqRHlUcZVtSqktpaSDFgY4X9UdJ7UClHZTqojrITt9HfVEqWaGEEyI1ipa+qCIlJYWRHmTYSeUj06dPZ/GsSuzbt4+RCtQX9vPzYwoS5cA9RdJS7Ksy4rW4bSUvDCIZKH53xIgRbH1Vy1/UwbViUl0IZ86cYSQQqVYo9pb64rSOSrUKLafgk+JAShnaj6RCIXJk2LBhrP9d3nUjVFWqS40RH+QU+9prr+HXX38t3IgNGzawBJmiO5BOLmLbSHpEIEaL2Cdy2y1q/HL79m124EhOQzVZShARQqwV3QiJWNETHzUHUn0krF7DymAIfHs7OMyYCctBA9nIU0Xrh6/sf4oH52PYvJO3JXq+2wjmNdThLQ/oEnyWnIOjYUnYlJGBpOdtdYO0fAgfpYOXw428eNmaFPqEkGkqzWvDQ10bkBf0D1b8/hd2SjkWuoG1MRbmGcJDXACeiYCZnhr5a27kuyzyg0b1XpAa3Miev9/Cl6JsFQoZUlL+QXTMLqSmXlR5rxNcXEbBxWU4jEScTFIP7UGNdqByc9m9NH3fPjZv1LAhXMjAVMW9XtPIkytwJDGdmZXeznwhh3fMzcT7Ad4Y6miH9NjswpKUiJRcZiQanSdFjFyGly3fXoUVDOBmKICbqQjulkbwtDdDPWdz1PO0gqOTmUYIbiI/KL1FVflBSo/5nXxKjbLNk8hxMSQJp+/E4mxwElIlL0bNqbvTDHx0hACdbc3gU9+ekSCsLEakRmfo1lbg+CyAIkEdmwCjd0Fh7orj361F8H+XIDAUYejnS+HWsHGltp2RH6tXI2071w5zWrwI1qNHl/t7Hl2Mwfk/glGgKICzjyX6fNAExubao2Ksqes2Le0aMy/NyeHINSurtgjwXwozsyqOSFZtX2Q8K1RzULxsTDbXTlKFl4VXIdFBk5u5m862L/TEh5YRH8poW/L8yE7gzObJ00NHiDRtACkmKBZX2yCRSJgPBxnG1jQ0SnwQ8UCmK1Q6UvTjqqUlpYEIinHjxjFWTRnzQ2wTGZfQMlU2iIxiSCqzZcsWJgMiedC3337L2K+ihjBEbhArVNRMheQ6ffv2ZfIiqoPSEx81Czpvss+dQ8KaLyCNjGTLjJo0geO8z2Gi4gBcXjy9lYhzOx5DIpZDZCpA9wkNmZeGrkCuUODn0Gh8FZuGXEUBeAXA/9m7DvCmqv79ZqdtZpuudFM62BtBBRwskeUAZbr9nJ8TEByAKAjO/+dCxYWiuBiKqAwRFUGRvTrpTNqkTdOkabOT/3POLS1ltqXjpr3v8xRybm6Sm3tyfvec3/297xtpcMJ8pBxn1nUTy1xqn5tAbHRD0S1aQe1fOx0yf2JKKb0ubAm/A/NM42CucUMq5OMRmRzjK310AkfsbuVXxzW95LwF4Pd7YTYTOksBVKoEqNWDL2hhW1NTQC1x9SXfwu1mKtrI/hrNtYjRTqcK/zweOyuaOhvaa5JtP3oM+iefhCs/n1Ifwu66E+H//S94LSRgejFkVzuoUOlXpRWw2N3g1XggqvEgyeqGsqgCXhcPRr4I5bzzEb0YkF9xFJ9QUsSIkxNKShASIuRIjFXQ5IZS1T7Ja0J72bW7EEUlFsRFK3HF0PgmWdj6fH4cLK7EtqOl2HKkFDnmhhoJXcDHFRDiSr4IfeLVCE5TQ9pVTavUzhujCnYDX88CqsvgDw7DP+KJ+HN3DvgCIW6Y+ywS+zJ2hi3xmzaueBkVH39M25FPP43QWTMb/b3/WpeDQ9sYYe/UwZG4ZlY3CET8Tj1una5y5OQsQ2kpI3woEoVSe9qoqBta9PPdPjcyTBm0muNUosPsNDfYh8/jIz00vU6ItF9EP2iCAmeedDFwiQ8WJj44NBvkxn9hYSFlK7ANK1euREREBG688caOm/gglRSLFi2ivsRnvRmPhxMnTjTqfYglLimXOd0FhlgEkeQEqfo4nctEMkpPPvkkfQ0pEyNJEcK/OlPghHCiSLUHSYgQHtApEFscUkZEqC/keS7xwR74XC7q+lL+zrvwVTNUBcWECYh44nGIakWAmgpLGaG+HENZYRVt9x0ZhyE3JLOW+nKuC3aVJAhPZemwvcJKt6cFSzArWI4KnY26xxwqssDlbZgJkUmE6J+gxuBENaXHEAteqaiDZ9SPfAus/w9A+Mjp46n1o7HGjye+OYQ/shkV7eGqEMyp5EENPqTpoQidmgp+cNNL4NtjMubzOWnFiE7/JdUAOQWi/xGjnYbo6JsgFrevpk1nR1tPsqmA6Ucfwfh//2METCMjGQHTSxCMbkwSQK+zIqugEj/pKvCHpRolDibZQf9OedKeB0S+NEZIKClixCukiNcEIzFKgcQ4BeLjlRCz1NGqJfs2v7wa204YaCJkb6EZ3tNOWSh4TBIEQgwOkkLRVQ0pqQZJUUF4pmC3pRj+tdPBKzkEr5+HHcauSLjjfw1EZVvqu5e99hpMH6yi7Yin5iHs9tsv+BqXw4OtHx1H/mEm9hK3tYHjEllZOdBW45YkvXW6tcg9+Qo8HnI95yEmZhqSuzwJkehsm+GmosZdUydESqo6Dpcdht3TcH5OtDh6aXrRJMeAiAHoE9EHISJ2UI5aA1zio2XAJT7YAUJfOV22gU1ws+jYGvt7bfJs4/XXX6diL6S0hVj3NBckcXKq0uMUTrXP9Ds2m80oKyujVRx9+vShCQzCfyKcp9NFTojn8ahRoxokPQivioiikmqRS724kWDajpIoZx0HG47lUkF1Pu68kyY7yt74P2qpR6xvq7ZtQ9jddyP0zjvAb2KmWaEJwo1P9sdf63NxZEcxDm4rouKnlPoSxu6s9al+jZGI8FmvRKw3VuLZHB0ya5x4rsaJe5LD8cnIrhD4gEPFFuoeQyx09xWYUeX04PesMvpHIBbw0StWiUG1iZCBCWoogtgRoFoE+1cDPzwCHvzw954KTHoH4AsRLgc+uX0QPv4rHyt+zsTvldU4LhVigUuMwRkVMLx1EGEz0yGKbn78aqtxy+OJERk5gf7ZqrOg161FSek62O2FyMldjtyTryEi4jpaBaJUDmDlAqOjoy3jsbu0FCVPzUfN33/TtmzUKEQvXgyBWnXJn2+vcSEvvxL5xVYUGGwoqKhBEXFJcbqh93rRUOqQoW6cjjAeDzFiEeOSogqGVilExcHf4Cg6AJHfitH3PoQeIxgq2plg67WsJfs2ISwYd12ZRP8qa1z4LbMMW48bsJNSYrz4AW76J7HbMfhIFa44oqfJkHBNCCRdVTQJIumiBF8Rg10hMxFm0aObsgwjI7PhN3wNv2cAIGjZah/NY4/RcnTTe+/B+NJy+D0ehJ1HNM9mdmDzO0dQXmyDQMjHNbPTkTIokrX92xbj1lp1FJmZz6Gq6jBty2U9kJb2PBSKPnXH0FRUOippFQelrhj30+oOj7/h6CTuKqSK45Q+R7fQbhCf8dtgY5901DkyW46DQ2CCLYmFQDu2Fqv4IOI8hC7SGCubC4Eo4BIF2nNVfBDKy+kKsUQ0hljyEAcYAp/PR32JieDpKScZQrshmiErVqygCrmnQJRyTwnTEBDr3eZWfJAsUnMEWVoapMuIRgo5Jx1toePOyIDltdfhPsxMFARRUZA//BCk11zTrO9adLQSe74toNQXsVSAIVMSENeDvZax5+rbCrcXy3QV+MHMVMQQvvuS+DAMldfbQHp9fmSXVeNAkRUHipm/Mpu7wXuTd+saHox+cQr0j1XQ/yPlganKLj7wEYJ3MvHA2Wsm7NcsIdYEZ+2XYbBhwfdZOGli7oBNFUvxH5cIEiEfkjExEPVSB9y49XrtMJu3oKz8W9TUHK/bLpUmI1xzE8LCxkEg4GwFO1o8tv+6A5aXlsFvraICporHH0PQhAlNqB7ywVzhRJHOhqLSahRX2FFkcUJX44LO7UH5RaYCfkJZCRJAJBWiq0SEy0Mk6KEJQWyUDPFxMgSHnD0B8rhc+P2Tlcjbx1Qr9bluIgZMvLnZWk4dsW9dHh/+LbJgZ3YF/Sutqr/xQz6xJwR11SAJPD4cQQ7k6P6FwZ6Ha670IU7/HU3+emIGo/r6d+EP1rQ8LXXVh7B9+CFty++/D7Lbbmuwj6m4Bjs/zYW9yk0ppiNmd0F4QtsmltnUtx5PFfQl76CsjGjv+MHnhyBG+yDCw2++IMXxXCitKcUh0yEcNh3G4YrDyK/KP2ufCGkEeof1rvtLkidROktnBdvmyCT2kjvRnVbclAOHQKa6ECVaIih6PtvZxuKUxgdRehUKmcKTPXv2UDugAwcONEgwkGQISVhMO01g65FHHoFaraa0G4J///0Xd999N02aEKudUyB6H+QEnHo/cmJI4CE2OT/++GOTEh+k2oQNQYttZXyt8f2qfvoZxldehqeEEYQMGjCA6n8Q8b6mwmqyY8uqYzDmM9SX3tfEYiihvjSBr82Gvt1usmJuVjH0TiahcWuUGguTtVCJhOd8n8KKGuzNN1NqzD95Fcg3NeSYE8Spg5hqkERCkQlFl/AQdv+mSLj641XwdrzANIc+DIx6/ix7xzMFB5f9lIHP9hTQdopYhGddYnSBACFDoqG8Pgm8NvgttMa4tVqPUBqMwfADdQcg4PODaIUIcYRRyC9N6JBD+8djQgE0LF0GS624t7RnT2hXrIA4KfGsfd0uL4qLrYyQaAkREq1mqjZqXCj2eHB2BGgIUvweJRLCJxdBrxDAFiyEP1gAf7AQV0QqcVucBmPClBA1QSeHUHP++mYN/l7/NW2nXHYFxj7wKEQS9k+k25zG5PdTxy9SCUJoMUf1DNXxFGJrdUGGQUgTIiQJJYs6BkX5IvA8NvgVscCta4BopqKgJUHoqOVvvkkfax5+GJoH7qePTx4sw7aPj8Pj8lHHlnEP9oIirD4p35n6lgrDGr5HTu4yuFwM3ScyciK6Js+HRBJ+0df7/D7kVubSSg5S1UHoKyTxcSa6KLvUVXQQ+oo2RMvu63YnnyOTNcShQ4e4xAcHDoGY+CBWsWvWrEF6ejpNHpxZ5kKsaRtLdSFuLkSlduDAgXTb22+/TfU9Tnkbn8Ltt99O7YKeeeaZBv7A5I8kOwg+/PBDqu1Bju10EDeX00G0QkgCg/gIk0qQQLSiYltQby347HaYPvwIplWr4Hc46OJWdfNNCH/0UQib6ONMbBN3b8itE1yLSJBjzD09KS2GTbhY39o8Xrx4sgSf6MqpYGC4WIhlKbEYH3HxKpayKidjn5tfQZMhx/VWnOa8SBEWIqZJEGqhmxiKHloFhGzRRiGhatsiYNcbTPuqBcCIuRdMepyO7ScMmPvtYZiqXZDweXjAJ8GNEEESr0AosbxtisUky8at221FqWEDdLov6twCCOTyXoiNmY7IyPFtYpPYGdGa/Wo/cgS6J5+Eu6CQETC95x5Ib7sb+boa5BdbUGC0odBspy4pRQ43Sn1eeC/ynuE8IiTKuKQkqIKREBGCBK0CpaEibKi2YUuFFackO9RCAW6JDsVsrQZdgi9tfBzbuR1b3nsTPq8HUckpmDz3OYSo2sdpKVCutfpKO7ZnGGki5K/ssrp+IVCAh6G1lSBX8koQK3oRIr4Ofp4E7sErILxqJvhBLaudUv7e+yh7/XX6OOz+B1CcPgG7N5yk6rXx3UMx+p6ekLTwZwZK31ZX5yAzcyHMlXtoOzi4C3VrCQ09v/aK2+vGMdOxuiTHgbIDsDgtDfYR8ASUqkIdV2qFSEOl9Rp4HFq/by8VbFtDNHUhmZiYiKAgds2VOXA4V14hPz+/5RMfRFvjQmhs4oOAaHaQyg/i8Ws0GjFv3jz6+tGjR1NND7lcTg9+8+bN1CuYiKESVxciVLp27VoqdnpK44M8TzRCyD4XwqVQXdgStNgW1Fsb7pISGF95FdbaCh2+TAbNAw8gdOaMJjsY5B0qw/ZPT8BZ44E4SEh5yMn9IsAWNLZv/6m04YnMImTXOGl7nEaJpamxiJI0nm9X5XBjf2ElkwzJq8DBoko4PQ0FU4PFAvSPr02EJKnRL06NIHE7jAGfD/hpLrD3A6Y9+kXg8qYrXBurHJjzzWHKqycYyhdhgU+CsBAJQqenQ5qsCuhxy3zGPhTr1sBo/Bl+P1M2LxTKqXsAEURtLdvEzoqW7ldSFm3QW3H0y5+QvT8LpSEalMjCUCJTQef1wXyRSzaJAFqBALFSMeLlUsSHBiMhSobEOCWSEpQICq6PmRVuD74qqaDuLCftTCwhGKwMwWxtGMaHqyBtwcRn8fGj2Pjqi3DYqiAPC8cN855DeEIS2Aq2XGszdu3E+rf+D4XSWFhSh+G4S4lKu7tBn18JJxaJ/ocEwQG6zeqZAkf0A5CkhkGaooI4Tg5eC/Sl6cMPUfrK68hMvQUl0YzAfM8RMRg2NQV8tiTJ27BvCfUwL/9tFBaugt/vBp8vQVLiQ4iPv4s+PlOI9GDZQZrkIFUdR8qOwOF1NNgnSBiE3predYkO8jhYxCWt26NvWwpsW0M05bizsrKoa8fpeoocOLARRNOT5BJSU1MvOM6aZWfbktkZQlXZsmULFUq96667aHXHKYoKSYKcssghyQ5SHVJaWopu3brh6aefRo8ePerei1R+kO2ntDzOBy7xEbio2bcPhheXwnGc0TUQJyRQpXnZVVc16eJ2ivpiyGPKiHtdFYsrburKCru9plywHV4f/q/AgDcLDfROoELIx8LkGEyPDm3Wxd7p8eKozoJ/8sw0GUKqQqyOhqJpQj4PPWOU1D6XqQpRQ3XaQqpV4PUA3z8MHPqCYb2Pfx0YeEez347YLX66O5/SXwi/Xs3n0+THUJ4IyrGJkA2PbZXJUltPxlwuE0pKvqNUGCKGegoq1WCaAImIGHPWxJxD2/Sr0+FBYZEF+YWVjJBoeQ0Kqxwotrug83jQcCl0Nsjd/hiRsFZINAgJmhAkRMuRGK9CjFZ+QRofOd5/rTX4VFeOH8oq4awt+5IJ+Lg5KhS3acPQTdZ6d/fMpXqsf2kxzCU6iKRBGP/oXHTpNwhsBBsWULn7/sb3ry6Fz+tF72vHYuQ9D1JNp38LzNh23ICtJwwoqKUx8uHDXOFa3CfcRNvl3kFwuMmcSAaeREDFUaWpaiqWKtQENes7Oard+GHxVhitUsJjQt8IPYYunskK/bO27tuy8u3IyloMh0NH25qwa5Ca+hyCguJo22Q3MUKkBkaINLMiE15/w5oslURFqziICCn5v1tYN4j4gScYyCawYdx2hMQHQUlJCSorK2nygy2aKRw4nEvThyQ9iD5odHQ0LoRmJT62bduGVatW4eTJk3RAk7ISotcxefJkdESwLWixLai3JQhfnDi/GF9/A95yhkMbcuWViJz/FCTJyY1+H6/Xh783nMSBrcyCMDyeUF96QBkeHHB9e9xmx+MZRThYxUx+r1DJ8EpaHJIusTSdJAiyjFXYm0foMWb6f6n17CVZaqSsjhozKCkUMaoWXDR5XMC6u4HjGwEiCnfDSoA4uLQAMkqt+O+XB5BlsNH2zRDjfkig6qGBekoq+FJhhxi3fr8PFRW7oNN/gfLy7dRekUAkCoU2+mZqrUjscTm0bL9WVpKyy0rk6RiXFEpJsTEuKQafDw1rqxqC5wci/H7EigSIV8to1UZ8eAiSYhTokqSGSt30MVbl8eJbgxmrdeU4UV0/jnvJgnBbjAY3RKgQImyb65vDZsMPry9F4dHD4PH4uOq2u9FvbOOFWjvLtbbgyEGsX74YXrcb3a68CmMffAx8vuCsY8wts2HrcUKJKcWBokpM5P2J5aIPIOW5kefXYq13PtI8cehHdEGoZCogUEnqLHOlXVWNsviuNNbgx7cPo9JQAyHfh+4HV0JTcQyhd9yBiLlzWNd/rdW3drsOWdnPo7x8G21LJVqkpDwLhzSdJjpOJTvyrWcLkRI9jlOUFZLsSFJ2biHSjjhu2b6GaOq5JDecSfKDAwc2gyQ9oqKiLjrmm5z4IBST5cuX00QHoZ2QslxCVyEWswsWLKBWtx0NbAtabAvq7QGvzQbTypUwfbqaCBwAAgHUM6Yj/MEHIVAqG/0++UfKsf2TE/QuFnF9uXpWN3QdEBFwfev1+/FBURmW55XA7vNDyudhTlI0/hMbTqs0WurYis12WglySjA1t4xxmjkdJPFBLXRrq0K6hsvAb84xuO3AV7OAnK2MTePNHwPdxqMl4XB78dJPGfjkL2aC2gV8LEQQ0jQyhM3qBlEkkXvsOOPW4SyFXv8N9Pq1cDrrRfNCQ4dRLZCwsGvA5wcGR7+9QXSDSkurcLKgEln5JpRa3Si0ECFRJ4pdHlioCs/5QdKSMQIhYoNEiJOJEVGaj7Dj/yLKnI+46BAkvbyUVrVdKo5U1WC13oTvDGbUeJl0SxCfh0kRasyOCUM/efvcxfN6PNj+4Ts48usW2u4z+npcc/u94LPgGsuGMavLOI5vlz4Lj9OJroOGYMJj8xt1boiW044MI7IO/o67i59BFK8CFn8wHnY/jH28fhgqleDyGmCIX0grhyh4gChGRhMhlBYTrzhL8FmfbcbmlUfgrPZAppbg+gf7QPDHDyhdzNCL1bNnIXL+/ICZkzSnb30+FwoLP0Je/pvw+UjyUIDqkMvxl12NvcbDMNqNZ72mq6prnQgpSXREhUS1wrfhwLZrLZvXEM39Dm4y1+bAgYUgeqONHVtNTnyMHDkSDz300FnVHevXr8fKlSup7kZHA9uCFtuCenvCVVAAw4qXYdu+nbYFKhXCH/kvVFOmgFfrFnQx2MwOSn0pyWVExXoOj8EVU7pCKBIEXN8W2J14MrMIf5iZKobe8iC8lhaHnvLWqWQx2ZzUOeYUNYa4EJAy7NOhDhZhQEIoBicxWiGEKiO6GBfcWQV8OQ3I/wMQBjFOBV2vRWuBLBTmfHsI5TYXCHGHVH5MEUkRenMagvtcXI0/0Matz+eBybSDiqGaKv6glosEEkkUtNpboNVOhVTCTdAdDjdTtVFkRUFpFXVKIi4pRQ4X9F4v6o1Hzw0VeNR+Oi5EgjhlEBLCQ5ColaNLghqRUSGUHmA/dAi6J+fAXVRELHkQ9p97Ef7AA+CdIRzeFJAEx/dGM0147LfWe7mkBEuoUOmUKPU53aDaGpR2s2k9fl/zMRUvTuw7AOMfmQtJcMslHANxzBpO5uDr5xfAZa9BQu9+VAhW2Izfg8Osh+Pz6VCZDsALPpa5p2GVdxzNdAh4oEmvK30CDLX5EYP6mMwT8yHpomKqQVLUyM2txI7PM+Hz+qkw+LgHeiOkVgza/PXXKH1uIX2snj4dkc8+0+7xrTX61mj6E8cynobPWUzbeS4R1poEMHjqz5uQJ0R3TXcMiBhQV9WhlDT+RgwHdLhrLRvXEBw4dGY0OfFBqjxIkoOo/J4OoqRKXFaIPW1HA9uCFtuCOhtg27ULhmXL4MrJpW1Jaiq1vw0ZMqRRr/cR6ssPedj/M+MCpImTYczdPaGKDA64viXvsba0Aoty9LB4vHSC+2BcBB5PjGpRocJzodrpwYHCSuocQ5Ih+wvNcLgbFvVLRXwqkkoqQoiFbr94FUIkpy3C7Gbg85sB3b+AWA7M+BpIOL8yfkuh3ObEnG8OYUcmI3x6GQRYgCAkXBEL5bikSxYGZOu4JfofOt1a6Eu+gdtdQbfxeALKVyeWuKGhV1I6QkdFhakGJ/Mqka+3oKCsupaS4qSUlDK/74J1G+RqEMXnQysWIl4RhAR1MBIiZUiIUSApUQWl8vzK4n6vF6b330fZW2+TiwyE2mjErFiB4FqXs+Ygu9qB1fpyfF1qpmOfQMTj4fpwJU14DFWx0646e+9ubH7zFVrdEBYbjxvmLYQyIrK9D6tdxqypuBBrFz0FR5UVMek9cNOCxZdm/etxAj8+Dhxg3PKOaa7DPNedOGpsePe2q0KKYVIphlb5kG73g3+qGoTECJ8fRrcf/DgZ+t/RAxJ1w+Op/O47lDzzLE1eqW65BVELnwOP5ZofF3VQc9moEOmhkj8gMm9EsoC5LlR5gY2VYvxbI0CQMBh9w/vWVXP01PSk4qQc2hdsu9aybQ3BgUNnRpMTH9OnT6euKI8++miD7a+//jr++OMPrFu3Dh0NbAtabAvqbIHf44F57Vcoe/NN+CxM9YZ81EhEzJ0LcRwjNnYxFBwzYdvHx+GwuSGSCHD1zHSkDIoMyL41Ot1YkF2MTWXMuUgOkuDV9DgMUcnQVnB7fVQwlaHGmPFvQQUqaxpOuAVEMFWroNUgl0f5MfzveyAsOwYEqYGZ64CY/m16/j/bU4AXfzxBHW7IHfv5kOLqxDCETe8GgULcYcetz+eEsWwLrQKprPynbnuQNB4xMbciOvpmiMWBp+zu8figK7Ygr9CCghIbCkw2SkkpqnFB7/ag6iKUFLKMiREKERckRpxSioSwECREyZEUp0BcvBIikaDJ/erW6aCbOw/2fftoWzFuHKIWLYRAoWjy93P5fNhcZqHVHX9VMpVeBHFSMXVmuTU6FOFi9oslkiqHDSueh81cgWClCpOefBra1G7tekxtPWYrS0uwdtE8VJsrENklBVOefRGS4BZIvpNp3j8fAD8/RTJugLY/isd8gF+KBFQglSSqT6/U0wSLMEwtQ58yN4Y6gZAzEp+UFtOVVISoIUlkaDGVGzagZP4C+lnKm29C9PPPszr5cWbfltvLGRHSWseVbHMmhoS4MF7pRhAf1Pp9nyMEFUHD0DPyMproSAtNg5CjBrIObLvWsm0NwYFDZ0aTEx8HDhygzivdu3dHnz596DYyoDMyMijVZUgj77AHEtgWtNgW1NkGj9mM8rfehnntWnonlZSME/G1sHvvhUB28RJqm9mJrR8dgz6bEXPqPkyLYVNSIGwDG9fW6NvNZZWYn1UMg4txaCGLoWeTtZC3kZDhmYKpRIiPTLSJWCqhyegq7fS5KJiwRrwUyfwSVPBUWJ3yf4hPH0gTIrHq5jkQNBdZhioqfJpRWkXbN0KEh2VyaGd2hyRR2eHHra06GzrdlygtXQePhzkHPJ4YERFjaRWISjmQVd+h2uZCfr4Z+Tor8kttlJJCXFJ0TjdKCDf5Iq8P4xFKiohSUohLChESTdQyVRvh4cEXdKxoar9afvwRpYsWw1dVBX5ICKKeexaKiRObfD4JrW2N3oQvSipQ7mbGNjnKURoFbtNqcFWoHHwW9VFjUFVRjg3Ll8CYnwuBSISx9z+K9CtGtNvxtOWYtZaX4atF82AtM0ITl4CpC5chSN70RNgFcXIn8M1tTFWdLBK4ZQ0QNwiWGjd+yzJiy3EDdmaWweasd/MS+oFBoTKM0cgxuNILRVlDgWueiA9xkpJqg7h1h2B4fi61H1fecAOiX1gCHgvmTOfq1wJrAXbl70JGVQZNdBRW1TtfxYm8mBLqRryYqVb0iGIQnzwf6dFjWRX3OATGtZZtawgOHDozmuXqkpubi6+//pq6ukgkEurqQipBLmYhE6hgW9BiW1BnKxxZWTC+9BKq/9pN24JwDSIefwLKSRMveieKUF/2/piPf3/Kp/IHYTEy6vqijgoJyL61uD14PlePNSUMlUErEeGl1FiM1rQ//5gkPo4fO4QBO29HqKsEOn8YZrgWIN9fH0+iFNJaagxDkUmNkDdPMLWJwqcrfs7ER7vyaDuRCJ/ygjHw+q6QXaFtcv8E4rj1eu0wGDbRKhBrVT2NMSQkhVriRkffCKFQ3urHQUS0y8pqkF9QiXxdFQrKbCistKOo2gmdy4Ny/4U8UgBCpIrmCxArFSFeLkVcaDASI2VIilUgIVEFmaz5DkiN7VciyGxYsgSWjd/TdlCfPtC+8nKjq9Hoe/j92GayUivaHRX1tSqRYiFmaMMwIzoMMdJWtpduZbgcdkp7yf33b9q+fMoMDLnp1nYZM201Zqsrzfhq0VPU4lcVFY1bF69AiErdOh9WkQesnQ4YjzOi0ePfAPrNqHu6pMCKd1fuxxGHA7liH6zEYqgW5BT01SoxIkyOK118RBfb4Lc1tDzniX1w5f4Dj+EYgvrHIWbZonZPfnh9XmSZs2iCg1R1ENcVUuFxOnjgoYc6CeNVHkR6MsGDn8a2Ll2eoMLPhP7HITDAtmst29YQHDh0ZjQr8dHZwLagxbagzmaQc2XbsQOGl5bDXcjc0ZH26kX1P4L79bvo64uOV2Drx8dgr3JDKBHgqulpSLssKmD79k9zFRU/zbczsoyTI1RYkhLTvqXwZZnA6klAVQkQ2gWVU77DXnNInXvMkWILPGcIpiqkQgystdAloqm9YlQQn+FC0FL4LdOIJ79hhE/JWboPEszupUXYzWngSwSdZtxarUdoAqTU8AN8PqZKh88PQlTkBGqJq1D0vqT3d7u8KCqyIK/IgvySKhSaqlFEKCl2F3QeD+olOs8NGXiIEQkRFyxGnEKKBE0IEqPlSIpXIiZWCWEr/T4a0681+w9AP3cu3MXFVMBUc9990Dxwf6MFmEudbnxRYqIVHqSK5RRGqOXUmWV0mBKiVk4EtiV8Pi9+X/MJ9m1aT9vEynX0f/4LobhtkzptMWbttip8s3g+ygrzIdeE49bFy6HQtLKzmNMGrP8PkLGJaV92PzD6BeQfr6RC326nl+pbjbu/F/Q+D7YdN2LbCQOO6Bja5CkkhgXjmoRQXCmWoJvJDV++Ff4zNJ3gt0A2LB3S1DBIkhTgtYFouNPrxJGyIzTRQagrRKuj2t3QgUzEFyFdlY7B2sFUhDSOp0dx3utwu030+ajIyeja9SlIJC0jbs2h7cC2ay3b1hAcOHRmNCrxMXv2bLz11ltQKBSYNWvWBQPJ6tWr0dHAtqDFtqAeCPC5XDB/9hnK33kXvmpmAqSYMAERTzwOUdSFExnVFob6ostkqC/dLo/GsFtTIWoF6ktb9C1xfHglrxQri4wgU1S1UIDnU2Jwc6S67X9PJYeAz24AakxARHdg1npA3rA/7C4vDhSZsTfPTBMhRDC1xsUIN56CRMhH3zgVTYSQipABCWrIThdMbQH3mrnfHcb2E4xd4WAI8FxYKNJu7wlReHCnGreE+lJSugE63RpUV2fXbZfLeyI2ZgYiI8dDIDj3OamyOnEyj6GkFBptKCAuKURI1OFCqc+Hhr16NiJ4fMRKRIgllBR1EBIjCCVFiaREJdShQRekpLQWLtSvRHeofOV7KH/3XUq7E8XEQPvyCgT3v7hujc/vx59mGz7Vl+Pncgu8tVfqUJEAt0aFYZY2DEnBza9UCQQc3v4ztn/4LnxeL7Rp3anuR7Ci7arUWnvMEteWb154BqU5WVTXhCQ91NExaBP4fMDvK4DfltFmlWoIvs66Hw6fAjFpKoy9txekIQ0T4iUWO42BW48bsDvXBFetPTKBMkiEq1PDcZVGhsEOHnBYB1/VGeNRyKNUQeIUQxxjRFEh4LVAws7qsuKg8WCdRscx0zG4fQ0JbiGiEPSN6MtYy0b0p0KkDpsDQmEZMrMWorKSqTAKDk5GWtpihKqHXvJxcWgfsO1ay7Y1BAcOnRmNSnyQpMddd92FoKAg+vhCIFa3HQ1sC1psC+qBBE9ZGYxvvAHLuvVUhI0XFISwe+5G2J13gi+VXlCb4t8f87B3M0N9CdWGUNcX8n+g9u2hqho8nlGIYzaGs311qBwr0uKoKGKboPBvYM0UwGkBtP0YIdPg0Iu+zOP14XiJFf9QjRDiHmOGqbqhsSiZS3evFUwlzjGkOiRcLrnkvvn870K88MNxOL0+KInwqTAYk27tiaCemk43bpnvs49WgRiMP8Hvd1ENRZsnGm7/9aiuGoqSiuB6SorbA/NFLjfkl6cVEEpKbdVGaDAVEk2MVSApQQVpMPtEOs/Xr67iYujnzIX9wIG6RCvR8xDIL0wNMrk8+Kq0Ap/py5FXW5lFcJkyhOrzXB+uanV3Jjah4MhB/PDaMjhrqqGMjMINcxciLLbx9KBLQWuOWbfTgXUvLULx8aOQyuS4ZeEyaOIbuuW1BXxHN8L/3X8g8Nth8UQiI+l1DLztOgguUiFFdED+yCrD1hMG/JphbCBaLRbwMSQ5DFf6K9Fz/QZEy+MhiusH8BsmRPkyESRdGctcohEiUDQuRhuqDQ1oK9nmbPjPECkOk4bVua2QREeqOhUCfv38zeOpQWbmqzAY18Dvd4PPlyIp8SHEx98FPj+w6WKdHWy71rJtDcGBQ2dGk6kuGzZswLhx4yA+o+S0pqYG3377La0O6WhgW9BiW1APRNiPHoNh6VLY9++nbZFWi4i5cyAfM+aC57Q4owJbPzqOGqsLQjEfI6alIX1odMD2rdvnx7tFRryaXwqnz49gAR8LukTjjhgNBK35+URk78tpACk/jh8KTP8akCqafc5yy6qpfS4VTc2vQFEFQ8U4HUmaEAwiGiGUHhOK+NDgZp3jHGMVHv58P04YGQeNyRDhqSuTEXldF/CId3AHH7dOhwcFBZUoKLZQIdECUw0KqqpQ6LKgxC2Ey3fhRYPyFCWFVG0Ql5RwxiUlMUEFbbT8ogsutuFc/Wr54QeULn4ePpsNfJmM2nsqJ0y44HvstVRTZ5YfyirpWCSQCfiYEhVKEx7dZJ3XJtNUXIT1KxbDYiiFJDgEEx6bj4TefVv9c1trzHo9bmx8+QXkHdwHcVAQpjy7FFHJKWhrOO0ebFl1FLbMAxinWgal0AC/WAbeDe8B3cY3+n1IMnpfgZnSYUg1SL6pITGtq0WHIfqjuDoxAoNumAVXvg3Ok5XwuxrSYoSRwYxbTKoakiQl+GIB7YM8ax4OGA7UJTt0Nt1ZxxAvj6eJDpLkIMmOOHncefusrGwbsrKfh8PBvI9Gcy1SU55DUFBso78zB/aCbddatq0hOHDozGhU4qOiogIOB3NX+Nprr6UJDrW6ofAWcXUhFreHD9cL4HUUsC1osS2oByrIebRu3gzjy6/AU1pKtwUNHICoBQsg7d79vK8jSQ9CfSnOMNN2+pAoDJ+WRu1vA7Vvc2oceDKjCHssDA1ogCIYr6XHIy3k/FUwzUbmz8DXswGvE0i+Brjlc0DcspUzpRYHTYLQZEheBTINVbQa4XREyCUMNaZWMDU9SkGtdRsDp8eLl3/OxKo/GeHTBPDxYkw4ht7RGwKZOODHbaXZjrz8SuTprCgwMi4ppGqj2OGG0e+jFKnzgQ8/wsTVCJPpERFUhvBgE6KC7egW0RsDekxCdFTbL/BaE6f3K0l0kISHdROjnRDUrx+ltohjz72gqvJ48a3BjNW6cpyornfL6C0Lwm0xGqrBE9IO7ktsRI3Vgu9ffRG6jONUnPraO+9Hn1HXtepntsaYJbSdTf+3HNl//wWhWIKbFixGbLeeaGtYy+348Z3DqNBXQyjiY8yMaCRmPAHk/8HscNUCYPgcqknTnET0qSQIoSaeHnsjfHaMHpKCkd2iMEAogu+kFY5sM9w6G62mPAUf349iVRl2Sw7iT8k+5EqL4a8VWuXz+EhTp9UlOohGR3jwxbU47PZiZGUvQXn5NtoWi6OQlrYIEeGjmvQdObAbbLvWsm0NwYFDZ0ajEh8///wzTWqcL4CceouJEydixYoV6GhgW9BiW1APdPjsdpg+/AimVavgJwk+Hg+qm29G+KOPQBgWdu7X+PzY91M+9m7Ko5M6dVQwxtzTk7q/BGrfEk2Bz/QmLMnVw+b1QcTj4ZGESPw3IQLiltJOOPodsO5ewOcB0scDN38ECFtfp4DYNe4rJEkQRifkcHEl3KdEE2ohlwgxoLYihPz1jlVCehEhvj+yy/D4FwdQZndT55D7JMF48M7+CEpQsnrcej0+6EuqGJeUkioUlNcKiZLkhtsD6xll42eCpMNihELEBokRJ5ciISwYiVEyJMarEB+nhEQqhNNpgE7/NfT6tXA6mcQiQWjoMCqGqgm7Fnx+y+mwtBdO9asoJwclc+fBrdcDAgEVL9X85z/nFDA9XFWD1ToT1hnNVHOHIIjPw+RINWZrNegrb1v75kCBx+3Glvf+hxN/7KDtAddPxvCZd4B/GoWhJdHSY9bv8+Hnd17H8T92QCAUYvLc55DY5+J6Ly2N0pMWbH73MBXtDlaKcf0DvRGRoAC8buCXp4F/3mN27DYRmPwuIGn+da3c5qRUmF/+PIE/i6vhFNYnhokO05UpoegaY4dElAlPvgEqnQS9q1IQ6Wl47a0WOlARbUdQihpd+vaAIuLitMhT8PlcKCz8EHn5b8Hnc4DHEyI+7i6o1bMQGhrFjbUOBjZda9m4huDAoTOj0VQXvV5PLQVHjhyJb775BqGh9RcdEliI/seZVSAdBWwLWmwL6h0FZMFifOVVWgVCQErUNQ88gNCZM8A7j5uALsuMLR8eQ43FRe+aEdFTIn7a3H5hQ9/qHS7MyyrGVpOVtknVx+tpceivvMSqjP2fAT/8l8z+gV5TgcnvAIL20WwgVrWHiippEuSffDP2F5gpZ/10EJ56nzhlA8FUhfTs462odmHuF/uxLZdxAxgIIVaMSUfSVfEN+rCt+9ZR40ZeQSV1SSk01AqJWh0ocrhQ4vWioSrK2VDzeIgVESFRMeJVQYxLipbR2oiMCmm0kKjP54HJ9Bt0+i9gMv1OzgTdLhFHQqu9BVrtVEilgWuF7nO7oXv9ddg++ZQKRopiYxkB0zNco0iCY6ORVHeYcKCqngqQEiyh1R1TItVQigI/EdTaIONoz7q1+OvrNbSdPPAyjHv4SYilLU8FaskxS96LCLUe2rqZVqxMeHw+Uga1vYBm9l4Dtn96giY/NXEymvSQqc+o7Nu/Gtj0OPlxA5E9gVu/ANQJl/zZpl27sWnR/2F3WAp2x/aCRXj6NcULQXABhLLjUKoKMDqsF4a7ByHZrIW02A+/8wxaTHgQI5JKqDHJSvDPI2ZdYd6NzMyFqKnJpW2V6jIqXhoS3LXdr7UcWgdsmEexeQ3BgUNnRova2brdbohE7BOf62hBi21BvaOhZt8+GF5cCsfx47QtTkhAxPynIBsx4pznm1Bftn1ynFrfEqQOjsSI6WkQS4UB27fkODYaK/F0tg4mtwfkSO6JDce8LlEIac4Y2LMS+Hke83jA7cD1rze5hLo14fX5caLEWmehSypDyJ3K00G6g9BhBtdSY4hoaoRCWne+vtiVj+d/PAGn3w8FeHiuSyRuvL0v5ak7XV58tTkDRaVWxEUpcMu4dEgu0RWIJKIrTHaa3CjQW5FvrEahmQiJOqBzelDm912wboN8ehSfCImKECeTMEKiETIkxDIuKYra79aSsNsLodN/Bb3+a7jdFXXkGI3mGuoIExp6JXg89vwuLgZXYSF0c+bCcegQbSsnTULks89AIKu/Q55V7cBqfTm+Lq2A1cMs3kg11fhwJWbHaDBEGcLF8WYg46/fafWE1+1GeGIX3DD3OcjDLi4y3B7xmLzP72s+xr8/rKOBZNxDT1CL3rYEOYZ/N+fjnx8Yel5ibw1G3dn9/NcpIj791Uyg2ggEhQJTVwNJw5r8uSW2Euwz7qvT6BAdzsb8r70Qu3n4qVscPhzSA157H7gcDfsuJUKGkd0jMbJbJPpqFfDobHBkV8KZbYarqKoBLYaoWYsT5JB2ZdxixLFyuNzlyMlZhlLDRrqLSBSGlJQFiIqcRPuSLddaDi0PtvUt29YQHDh0ZjQ58VFeXo733nsPOTk5dDATkLcgSY/c3Fzs3bsXHQ1sC1psC+odEaQk2bJ+PYyvvQ6vibmTHzJsGCKfmgdJcvI59vdj/5YC/P19Hn2simSoL5pYWUD3bYXbg+eydVSHgIA4vrycFourQpsgRPr7K8CvS5jHQx8CRr/AZBFYDNIPRKBvb61zDPk7U7CPgAikMmKpDEXG6/Xhvx/9ixNWRlx1UlAQ4qPk+CKvDKbTZuph4GFW9yg8OvvCZe4ejw/FRRbkk79aSkqhxYFiu4u6pNguQkkh98BjhULEEUqKklRtMC4pSXFKxMUpW8WSuTHw+Zwwlm2BTvdlnY0kgVQaR2kw2uibIBa37CK2JUHH6caNMDy/BL6aGvBkMkQvWgTl+Ovp806fDz+VWagV7e5KRjeHIF4qpja0t0aHIlzc8W4StDX0WRnY+MoLqLFUIkQdSpMfkV26ttj7t1Q83v3dl3UVKqPueQi9R45FW8Lr9uHXz08g628DbfcZGYfLb+wK/sU0jSzFwNoZQMlBgCcArlsODLr7vPHb5/chz5LH2Moa91Nr2ZLqkrP2u6oiEvd8YoDI6YFgQB8kv7cKOief6oKQv7/zKmgy+hQ0MjGuTY+kiZAru2og8frhzK2k2iAkGeKtqNfH8cMHS5edKOvyLXx8MvZ4iImZgeQuT0AkUrD2Wsuh5cC2vmXbGoIDh86MJic+7r33XhQWFmL06NH46KOPcMcdd9D21q1b8dRTT3GuLp0wqHdkeG02lL/7LipWf0ZKmih3Xz1jOsIffBAC5dk6DvqcSmxZdQzVlU4ICPVlagq6X6ltdD+xtW9/NVkxJ7MIOidjWTg1So3FXWOgvlBpPgkt2xcDf77OtEc8BVz1FOuTHueD0erA3nxGI4T8kQqR0+bmFBqZBAPiVXCbHdhRYrlIWgJ4tHs07r6xBwqIkGixFfmGWiHRKgcVEi3xedGQgHM2NDw+YsRCxBOXFHUQ4jUyJMbIKSVFEx7caEpKe6G6OocmQEpK18HjYehVPJ4IERFjEaOdDpVqEKvGgtdqRemiRbBu/om2gwYMgOyZpxGWno5Chwuf6034oqSCVkoRkLM/WqPAbVoNRoTKwWfRd+kIsBgNWL98MUzFhRBKJLSaImXw5S3y3i0Rj/f9uBG/rf6APr5q9t1Ul6QtYa9y4aeVR1CSawGPz8PwW1PRc3hM49/AbQe+fxg48g3T7n8bMO4VQCiG2+fGCdMJmuAgVR0HjQdR6axs8HIBT4D00HQqQErcVsj/YUFhqDlwAEV33wNfdTUVFY9b+R4EspA6TabfsoxUHHVnZhmqTqMhSkV8XNk1HKO6R+Ca9EhqU+4x2WkCxJz/NwqD3oJDzlS1SCyJiDpxG2SibpDUWuZKklXgS4WsvdZyuHSwrW+5xAcHDgGc+OjXrx9NeJD/b7rpJixYsAADBgzA+++/j3/++QerVq1CRwPbghbbgnpngCs/H4YVL8P266+0LVCpEP7If6GaMuUs8UK7zYXtn5xAwVGmUiRlYASumpEOcZAwoPu22uPFsrwSfFhcThf0GpEQL6bGYGK46uxj9fkYass/7zNtUuVx+cPoSLA63FQbhCZC8sw4WFwJVy2VgUBF9iGn4gLvQc7axQIw+dVoBbWUFLkU8WpGSDQpVomEBBVCzuMiE2jweu0wGH6kWiBWK0MdIQgO7orYmGmIirqxwR3b9kDN3r3QzZsHj76EJkHDH34IirvuwiZ9Gb6ptOO3iqq6/owSizBDG4oZ0WHQSjtGH7EVzpoa6pSSf3AfTawOm3YbBk28qUV0OS4lHh/e/jO2vv8WfXz5lBkYevM0tCUqSqrx49uHYC130OvP2Ht6Iq5740VB60CmiX/9D/6tC8GDH/rQBLyS1Bt/WrNg9zS0DpcKpOgV3ou6rRDXlT7hfRAiOrc+lP3QIRSS5EdVFXVAivvg/QY0MQISU4kz1ymXGF1l/eeRLukbp8I1qUqkyn+AwPYheDw/BHwZYj13QZ5zJdyF1Q2DMB8Qxykg6aqEJ1oEdXo0+AFmoc0hsOZRbFtDcODQmdHkxAcZuJs3b4ZWq8W8efPQs2dPzJo1C0VFRbj55pvx99/1ZcsdBWwLWmwL6p0Jtl27YFi2DK4cRihNkpqKyAXzETJkSIP9CN3lwLZC7Nlwkj5WhgdR6kt4vDzg+/ZfSzUezyhCVg1TXjxGo8BLqbGIltQu7nxe5g7hQVLazQPGvwYMvBMdHcTi9kixhdroEopMaXYFTpBz0QjISTm2SIi4YEJJIS4pMiRoZegSr4I2RgFhJ5uYW6uO0ioQg+F7eL0MxYjPlyIycgJiY6ZDoejdpsfjd7tR9tbbML3/Pl0EiuLjIVi+HOtUUVhTYoK+thKK4Cq1HLNjwjA6TAlhI+2RObSMTeyOTz/AwV8YK+GeV4/CyLsfgEDYfErRpcTjE3/+hs1vvUp/LwMn3IjhM+5o05hedKICP79/FC67BwqNFNc/2Aeh0U0TqK5wVNRpc5CqjtDifVhmNELh86NUIMAjkeEolmvqkhzkr3tod4iaIFptP3IUhXfdBZ/VCmmf3ohftQoCufy8/XGipKqOEnO42NLgeWKffXmiHTcOGYPLuyZCKODD5/DAedJCaTHO7Ep4yhsmangSAa0CIdUgRCxVECZl7bWXQ+PAtnkU29YQHDh0ZjQ58TF9+nQMGzYM999/Pz755BPs2bMHK1euxO7du6nlLZf46HxBvbPB7/HAvPYrlL35JnwWZuIlHzUSEXPnQhwX12BfUl68ZdVR2MxOCIR8XDmlK3oMj7mgNXQg9C3RMPhfgQH/KzDC7fdDLuDj2WQtZkbIwV9/L3B8A8MJJ1aIfW5BZ8RLq/7FyhyGU38h3JWgwbP3X9YmxxRo8HiqUFq6EcW6NaiuzqrbLpf3REzMdERFToBAENyqx+AqKIDuyTlwHDkCH4+HzLv+gx+uHYctlmqcckRWCfiYrg3DLK0GScGtb8/M4fzY/9MP+O3TD+D3+xDXozcmPr4A0jOqCBqL5sbjnL178P1rS6lWVJ9R1+Haux5o03h+7A8ddn6ZRZPu0clKXHdfLwTJxRf9rjqbDgeMB+o0Oohex5kYKFRiua4IETWV8AkkwKS3wO899ZKO137sGIruvAteiwXSXr0Qv+qDc1JJT4etOht/HXgJf+S6cLCsF05UpMPjq19UKoNEuCY9goqjDk/VQF7ryOUxO2gChCRC7NlmwNEwOS0IlUJKnGIINYa4xQRzWjyBBrbNo7jEBwcOAZz42LdvH+677z48+OCDmDRpEiZMmEBtbInd7cSJE7Fw4UJ0NLAtaLEtqHdWeMxmlL/1Nsxr15IfCXgiEULvuANh995bx1UmcNjc2L76BPIPl9N2cv8IXD0rHZJzUF8CrW9P2Ox4IrMI+63MXfmhzgK8emg+ujiNwJSPgW4T0FmxesNxPLfn7IXDmXh+SBJmT+7eJscUqGDGxT5aBWIs2wyfjzHjFQhkiI66gQqiymRpLf+Z69aj9MUXUckT4Oerx2DzuEko5NWP28uUIZitDcMwMQ/h6nNQvji0C04e2ItNb6yA22GHOjoGNzy1EOoobZPfpznxOP/wAWxYvhhejwfdh12NsQ88Ru1r2wI+nx9/rcvBoW1FdQ5j5FojFAnOKUSaU5lDKzlOaXQYa4xn7ZesTKaVHKc0OrQyLeCwAN/dDWRvYXa68jHgmmcBfvPnR46MDBTefge8lZWQdu+O+I8+pJTSM0EqwPLy3kJh0Yfw+z20Eiwp8WGERc7GrlwLth434tcMA8w19VVYIgEPQ7qEYVStS4xWFUT7ttJciWCbgBFKzaqEq9CKumwmAQ/UIUZSWw0ijpeDJ+hc1XeBCLbNo9i2huDAoTOjWXa2NpsNDocDGo0GBoMB27Ztg0qlwnXXXcd6Ib2OELTYFtQ7OxxZWTC+9BKq/9pN24JwDSIefwLKSRPrJrykzw5tL8Ludbl0ckpKjwn1JSJBEfB96/X78WG+DstO6mHniyH1OvFEqAf39728U5f6Ewvby5/7pYGby5kg7i6/PjsSyhBOA6KxcLkqqBCqTvcF7PaCuu1K5UBKgwkPHwsBuRN9CSB3nvULF2F3dh6+HzYSOwcOgVvAJDxIddOUqFDqztJNFhSQY7YzoKwwn4qeVpWXQSqTY9ITTyO2e88mvUdT+7Y44xi+e/E5eFxOKrA6/tF54LfRnMHl8GDrR8frEuyDJyRh4LjEuuN2e904ZjpWV81BKjuqXFUN3kPIE6JbWLc66gpJdqil6nN/IKHxbX8e2PUG004ZDdy0CpBeuFLjQnBkZqHwjjvgraiApFs3mvwQqus/v6xsK7KynofDqadtjWYkUlOeRVBQbIP3IY4w+wrMdbogeeX1zkoEPbQKjOwWgSFxIbgsVVs3b/U5vXDmWahlLqkI8RjPoMWICS1GyVSEpKoh1ARxY56FYFtMZtsaggOHzoxmJT46G9gWtNgW1DkwfWLbsQOGl5bDXVhITwkp2SX6H8H9+tWdotI8C7Z8cAxVFQ7whTxccVNX9Loqtq4fA7Jv7WZgzRQUlBdhbto87FQxFq29ZEF4LT0OveStS0VgM95YvR9vHD/bzvEUuoMPQYwc787sj1h15z1PzQGhMpjNu1Gs+wLl5Vvh9zMl6yKRGtHRNyNGeyuCgxOb/L6le/7Bp999jw19BiMvJr5ue295EG7XajApUoWQ064DATlmOwmqK83Y8PISlOZkgS8QYvR/HkaPEdc2+vVN6VvDyRx8/fwCuOw1SOw7AJOefAZCUdvQJGxmB3585zDKi2yUUnntbd2g7SujLisk0UGSHEfKj8DpdTZ4XZAwCL3De2NAxACa6Oil6YVgURPj0JFvgY0PAh4HEJYCTFsLaJpvKezMyUEBqfwoL6caWvGffAx3UA2ysp9Hefl2uo9UGoPUlOcQHj6yUe+ZW2ajCZBtxw3YV2imWq2nEK2U0ioQYpU7pEsoJML6se2xOGuTIJVw5pjhq27osSVQSuqqQSRdVRCEcLQYNoBtMZltawgOHDozGpX4SE9Pb3TwOHHiBDoa2Ba02BbUOdTD53LBvHo1yt95F74ahv6hmDABEU88DlFUFG07qt34dfUJ5B1i7sx16ReOawj1JVgUeH1bXQ58NhkoPQJIVfDPXIevBUlYmKNDpccLAQ+4Py4CTyRGIaiTlgiT5Mdnx0sbVH5owMPYuFD8aLLSkmxVsAj/u7UfhqeGt+uxBiqcTgP0+q+h06+F01latz1UfSXVAtForgGff+FFyaEKC97bvgub5aFwSKR0G/n3xuhQzNZq0Fdx7gVhwI3ZTga3y4mf334dWXv+pO3LbpiKK6bObBT9pLF9W16Yj68Wz4fDVoXYbj1x4/xFENX+hlobxgIrNr9zGNUWFwTBflRdcwJ7/b8j05xJ6SynQy1R0yoOkuQgtJW00DSILjIuGgX9AWDtDMCqAyRK4OaPgJTGJSXOBefJkyi87Xa4K4xw3KKCZRixDndSm+v4+LuRlPhAs7V9TDYnfs0w0mqQnVllcLjrz1GIWIARaeE0EUL0QVTB9ZV4RC/FXVJdK5JqhjP/bFqMSCtjkiDENjdBAV4nE6VmC9gWk9m2huDAoTOjUYkPYlN7CkeOHMHHH3+MBx54AL169YJIJMLx48fx1ltvYfbs2bj99tvR0cC2oMW2oM7hbHjKymB84w2qEUBuL/GCgqC59x6qAcKXSmkfHt5RjL++y4HPy1BfRt9NqC/ywOlbqx5YPQkozwJCIoDZG4DIHvSpMpcbT2fr8L2xkra7BEnwSlocLlc3T2SwI9BevtqcgaJSK+KiFLhlXDokYgGKzTV4YM1+6k5AuvuJUal44Kqu4HdiitClwOfzwFSxk9JgTKaddWbBEnEktNqp9E8qrdd6qPH6sMFoxqcn9Tjkqhc57GKz4o7uyZgaHwml6MI21Fw8Zj+IyOiur9fg7/Vf0XbqZVdg7IOPXTQ50Zi+NZfo8NWip2h1SVRyCm5+5kVIglu3eoscV3FVMf7cdQimTRLwvAJUBJXgp/T3USWtqNsvRhZDaSv9IvvRqo4kZVLrXVdsRuCrWUDRHoDHB0YuAi7/L+M52wwYT6zHicNPwRPOVFkoQwagW8+lCAlpfjXJmefQUF6BY+UebDthxPYTBhir6itiBHweBiao63RBEjUNHXF8Li9cecQthhFK9RiYGx2nwBPxIemiZERSU1QQRgSz/5reQcC2mMy2NQQHDp0ZTaa6jB07Fs8++yyuuOKKBtuJm8v8+fPx66+/oqOBbUGLbUGdw4Wt+gxLl8J+4ABti7RaRMydA/mYMbTvDPlW6vpiLXeAL+Bh6A3JSBggp5o5rO5bcz7w6USgsgBQxAKzN56zvPmXcgvmZRaj1MUIzREhyGeStVCcVk7cWXC+cetwe7H4h2P48h9GkJBwz1+d2pe6EnBoPuz2Iuj0X9FKELfbVLuVT6s/HGEz8X11Ir4pNcPqZe74Cj0ejDi6H3f2SME1o65q9Pjj4nHg4NjO7djy3pvweT00STF57nMIUamb3bfWciPWLpxHdUQ08YmYunAZgmQXtixvDrw+L7Irsxl9DsN+ajGrze2FIYUTwAMfhcoT2Jb6CeI1sbSS45RGR1QIU2XYZvA4gc1PAvtXM+1eU4GJ/wNEQY1+C6ezDDk5y1Bq2EjbfBsfim94UJZ1QcKnn0IUGdkih3pm3xLtrSM6Io7KWOVmlDbUP+kaIatLgvSNU9HEyOnwWp21lBgmEeKz1Yur0u+hEFNtEGlqLS1Gxuk6tRbYFpPZtobgwKEzo8mJj/79++OLL76g9JfTcfjwYdx55534999/0dHAtqDFtqDO4eL9Zd28GcaXX4GnlCnDDx44EJFPL4C0Wzc4a9zY8VkGcg+U0ediuysx+s5eCGLrxKgsk6n0qCoB1EnAbd8DqnothDNh9XjxQq4eq/XM4jNKLMLytFiM0TRfBC8QcbFx+9XeQjy78RhcHh8SwoKxcuYAdItuKH7LoekgDjBlZVuQV/wVtlr42I7RyOAxlUkE0SYDJuzcjhvcNvRc9FwdJa2l+pUDu1B8/Cg2vvoipaXIw8Jxw7znEJ6Q1OS+JRUeXy2aB3OJnjrH3LLopQsmUZoCosVxtPxondvKIeMh2Nw2+hzfJ8CwvCnoZhxK297uZeg9KRL9ovpBSWgm7Q0ypdy7CvhpHkB0d7T9gFvWAMqYi7zMS22rc3NfhddLvisPsTEzESe9Bfo7HoJbr4coPh4Jn34CUXR0CxzmhcdtUUUNTYCQv79PVsDjO42qKBPXWeUOSwlHkFhw1nu7S2vqRFKdeVbA05B2JIoOqasGkSQqaYUIh5YB22Iy29YQHDh0ZjQ58fH4448jPz8fzzzzDE1+kJcT+ssLL7yAfv36YcmSJehoYFvQYltQ59A4+Ox2mFZ9CNOHH8LvcNASYNXNNyP80UcgCA3F0Z06/PltNnweP2ShEoy5uyeiurBgIns6Sg4zmh41JiC8G0NvkTduofiX2YYnM4tw0s6UE0+MUOHFlBiEiztHZUNjxu2RYgvu+3wfdJV2SEV8LLuxF27o19CxgEPTUGB34jO9CV+WVMDkZsrmeX4fBmAvrsUW9PQcQqijG5KuXAC1ekiTYyoXjwMP5lI91r+0mNJURNIgjH90Lrr0G9TovrVXWfH14vkoLyqAIjwCtyxaDoWm+fo8xF2FCJCSP5LsIEKkbl/DioFgYTAGqAah576x8OsJbQK4YkoKel9dL47NKuT9AXw9G7BXMFTIWz4H4i87565W62FkZD6DqqpjtC2X90J62hIoFL1o21WsQ+Htt8NdXAxRbCyT/Ii5cCKlJcetpcaN37KILogRv2UYUeWsFzmVCPkYlqJhdEG6RSBCfjZ9yu/2wZnP0GJIMoRohTSAkA9JkqJWH0QNURRHi2mrvu2MawgOHDozmpz4IFa2CxcuxM8//wyfj8lgk4E8efJkSoGRSC7NRpCNYFvQYltQ59A0kDtXxldepVUgBHyZDJoHH0TojOkoK3Hgp/ePwGZyUp2HIZOT0XdkHHhs0Hwo2gusuQlwWIDoPsDM9UBIWJPewu714bX8UrxTZKS6cCqhAIu7xmBqlLrD/5YbO27N1S488tVB/J7FVADdNjQBT1/fHWJOKK/RIHdnt5ms+FRfjh0V9SXr0WIhJudlYsR7r0GeXIaakSK4tI6654ODuyI2Zhqiom6ASNS4pCMXjwMTDpsNP7y+FIVHD4PH4+Oq2+5Gv7ETGozNc/Wts6YG3yx5GoaT2bTC45bFy6GOqteNaQzKaspoJQdJcpC/LHMW/GfYXodKQylt5ZQYaZQ7Hj+/ewyVhhqIJAKMvrsHEntpwGoQSuSX0wHjMUAgBq5/Deg/q+5pt9uC3JOvUk0eoscjFMqR3GUOYmJuBY8nOOu6SdxeiGsaoYzGr/4U4tjmJ4WbO25JRd7e/ApKiSF/JEl9CuRtCA2GJEEILSYlQnbO9/ZWueDMrYQjywxHTiV8VleD5/kyUZ1TDPlfoGBp9SdLwbaYzLY1BAcOnRnNtrMlCZC8vDz6OCkpCTJZxxUtZFvQYltQ59A81Pz7LwxLl8Fx/DhtixMTETFvHuzpPbF/Uyly9xnp9oReYRh5W3dIZe1YGXFyJ/DlNMBdDcQNAWZ8DUibX41ypKoGj2cU4YiNmTRepZZjRVos4oM6XuK0OePW6/Pj/7Zn43/bs2m7f7wK78wYgChl2zhFBCpKnC6s0VdgTYkJJc76O+ZXh8oxTeBB+sIF8B5jxptq6lREPjUP1d48aolrMHwPr5cRKOTzpYiMHE8dYRTy3hfsLy4eBy68Hg+2f/gOjvy6hbb7jL4e19x+L/i11/kz+9btdOC7pQuhyzgGqVyBWxYugyYu4YKfQd6jwFqA/cb9dRodxbbis/aLlcXWua0QjY4ERULd706fbcbmlUfgrPZAppbg+gf7QBMbIHMupw3YcD9w4numPfg/8I9+AaVlm5CdswxuNyPGGhU1GV27zodEfP5kjru0lLq9uAoKINRGI+GTTyCOPz/N8kJoiXFL3oNogRCbXEKJOVRsafB8fGhwXRJkUKIawnM4m5H38Bhr6qpBnCcttELkdAgjg2kChNBixElK8M+g1nBo+b7tyGsIDhw6MxqV+Ni7dy+lsQiFQvr4Qhg06Oxy0UAH24IW24I6h+bD7/XCsmEDjK+9Dq+J0cCQDBmC6KcXILckGH9+nQ2vx0cnu8T1JTq5HagvWb8wav1eJ9DlauDWNYC4ocJ9c+/Kv1tkxKv5pXD4/Aji8zG/SxTuig2HoAP+rpszbonTwGNfHYTV4aG88jen9cfQ5KZV2XR0+Px+/G6uwmqdCb+YLHUOk6EiAaZFh2FmdChU32+E4aWXKMVMoFIh+oUlkI9saLfp8VShtPR76HRrYKvOrNsul/dAjHY6IiMnQCg8+3fPxePABum/fzetx+9rPqb6FIl9B2D8I3PBF4uw468NKNHnI1qbiGGDrsfm15cj/9B+iIOCMfW5pYjscrags8fnoVayp6o5SMKjwlHvtELAAw+p6lSa6KB/Ef0RERxxzuPL2FNCNaCI+xdx/Rr3QG+EKAMsQUyqg/94BdjxIm1aNWE4kOKHR8SnVVbpac9DrT43DeZMuA1GSntx5eVBGBWFhE8+pjcNmorWGLcGq4PRBTluwK5cE60OOQUiVn01scrtHokRqeGQS899I8Pv8cFZYIWz1i3GrbedMqdiIOBBkqio1QdRU60QVlSEsghsi8lsW0Nw4NCZ0ajEB9Hy2LVrF8LCws4SNW3wZjweTpw4gY4GtgUttgV1DpcOr82G8nffRcXq1QDRIRAIoJ4xHbwb7sDWL/NhMdrp5GbIpC7oNyq+7SY6x9YD390N+DxA2vXAzR8BopatOjhZ48QTmYXYXcnwnvsrgvFqWhy6yRrvBBAIaO64LTBV477P9+NEiZU6Ccwbm4Z7hnXp9GO/3OXBV6UV+Exfjnx7fan4EGUIbovRYFy4EgKLBSXPPAvb9u30uZDLhyJ62UsQRUZcuJ+s+2n5vdG4mYqjEggEMnpXOjZmOmSytEvuVw7sQvbe3dj85ivwOJ0QKWWoclZB6qjvTy/fD4GPB6FEgpsXLEFMene63eFxUE0OUs1BNDoOGg+ixtPQ2lTEF6GXplddkqNPRB8oxBcWLvb7/Pj7+5PY93MBbSf3D8e1t3eHKEDv9pNqKuPvDyP8z+8g9PphlwpQMea/iO6zAHy+uMl28YT24srNhTAiAvGffAJJl3ML1J4PrT1uq50e/JFdThMhv2YYUVFdH6NEAh6GdAmjlSDXdotEjOr81zpvtbvOKYYkQ7yWestdAn6IEJKutSKpKWoIAy0p1gpgW0xm2xqCA4fOjGZTXToT2Ba02BbUObQcnHl50C1dBucff9A2uTuteuhRHLR3R/Y+RvMhvkcYRt7eDUHyVub9HlgDfP8QmYEDvaYAk98FBKJWu2tP6AnP5+hR5fVBxOPh4YQIPJIQCQm/Y6jdX8q4tbu8eHrDEazbr6Pt63pG4eUpfSCTCNGZQM7h35Zq6hC0yVgJV+3lSy7gY2pUKGbFhCE9hFlE2HbtQslT8+kiCSIRIh57DKG33wZeE35PbrcZJSXrKBXGbs+v265UDqA0mIjw6+iijYvHHQOGkzn44vl58NmdVHODVGacDrIt7OoB6HL9tXUaHcdMx2iVx+mQiWToG9G3TqOjp6YnJILGL0g9Li+2fXIcufuZmD9gbAIum9glIO/skzFbXr4VWVlL4HDqEVLtQb8MNyTV1YAoBLjxPaDbhCa/r8dkQuHtd8CZnQ1BuIbSXiTJyU06rrYat4S6uL/QTCtBtp4w4GRZQ3HT7tEKWgkyqlskesYozns8lBZTboezVhvEmWuB3+VtsI8wIqhOJFVCaDGS9p+zdvY5MtvWEBw4dGY0KvGh1+sb/YZabdNEvgIBbAtabAvqHFq+b4VHj8Hw0jK4cnLpdnFqKqw3z8Hfez3wun0IUYop9UWbomqd0//3+8BPc5jH/WcD498A+II20WiYn1WMn8uttJ0aLMVr6XEYqLx0ak2gj1vy+jV/F2LxD8fg9vqRHB6C92YNQNcIOTo6iCXyN6UVNOGRWV0vRtpHHkSrOyZFqBBSG5t9LhfKXnsdFZ98QtviLl0Q8+or1Dq6ufD7fTCbd0On+xJl5Vvh9zMLXZFIjeiomyCXX4/IyF5cPA5wuD0urLjrBkiI6dYZSY9TiY9qqRffXa2D/7SnNUEaWslxSqMjRZUCQTPjZbXFic3vHoEx3wq+gIerZqSj2+WXbt/aHrDbi5CV9TzKTb/StlQai9TU5xAe3A/45nYgbyez41XzgeFzibhOk97fYzaj8I474czIgCAsjNJeJCkprJ9H5ZbZ6nRB9hWYcZpTLqIUUozszljlElqjRHj+3xGhxbiKquqqQVzFVWfRYsTxCkhTVZB2VUMUIwvI5Fmgz5HZtobgwKEzo9FUl1PB41y7k+fIdo7q0jmDOofW6Vt4vTCv/Qplb74Jn4URTfONvAkHlGNgMbmpgvzgCV3o3cAWncz88RqwfTHzeMiDwJgXGbn6NjwHP5RZsCCrGOVuD11+3BWrwfykaIRcYBLIdrTUuD1QaMYDa/ajxOJAsFiAFTf3xvjeHS/hTHCoqgaf6sqx3lAJe62LGNGCuTFShVlaDfoqghvs78zJge7JOXQhRKCadisi584FP6jlaFNOpxF6/dfQ6dfC6Syp265WX4HYmBnQaK4Bn985LJo7Grb+8Q0Ov/XpRff7e7gL6X2HMImOiAGIlbeMpWx5sQ0/vnMItgonJCFCXPefXohJVSPQ4PM5UVj4IfLy34bP5wCPJ0JC/N1ITHwQAkHtWPR6gC3PAH+/y7RJ1cfklYBE1vTkx113wXn8BARqNeI/+RjStHoqGtvnUSabEzsyy2gi5PfsMtScVsERIhZgeGo4pcRcnRYBdciFqzx9NW44ci1UJJUkQ7zmM2gxwUJIkhmnGEmKCkJ1xxTLZkvfngKX+ODAIcASHzodU17dGMRcorc6G8G2oMW2oM6hdfuWTOzK33ob5rVraTLEK5Uhf9Q8FFSF0ufjuqkx8o4eCL5UyzsSCn5dAvzxKtMeMY+5E9dOvzGz24NFOXqq40AQKxXh5dQ4XB12YW48W9GS47bc5sR/vzyAv3IZQdy7r0zCvOvSITqHa0CgodrrxUZDJbWiPVRVbxWZFiLFbG0Ybo5UQykSnnVuzV9+CePyFfA7nXQBFP3ii5Bfc3WrHaff74XJtBPFxWtgqiB3rplLqVgcAa12KmK0t0Aq7ZgJqY4IQlf5vzULgE2M68+FoL1lFKbd+EiLfn7+kXJsWXUMbqcXqshgXP9Ab/p/oKGiYhcysxahpuYkbatVQ5CW9jxCQs5DQznwObDpMcDrAiJ6MOLZoU3T6/BaLCi86244jh6FQKlE/McfQdqd0WAJpHmUw+3F7lwTpcOQRIixqj5xQe5tDEwMpXQYQotJ0oRc9Pt5TQ6aAKGOMbmV8DvPoMVogmgChCZCuijBl3YM6iTb+pZtawgOHDozWkzjw+VyUWHTPn36oKOBbUGLbUGdQ9v0rSMrC4Zly1Czew9dYhlTRiEjbhK8Ph6CCfXlzh6ISWvm3UFyN/2X+cDfK5n2qOeBK1p2Yt9c7KyowpOZRShyMOJwZOH7fEoMQs9Y/LIdLT1uPV4fXt2ahXd/Y+hQg5NC8db0foiQB+ZdvIxqOz7TmfCNoQLWWjcEMY+H8REq3KYNw2BlyDnPm6eiAiVPPwPbjh20HXLFFYhethSiiPMLmLZ0vxqNJ1Bl20wrQdxuJhkF8Gn1R0zMNISFDgOP1/7XDg5nI9ucje9zv8emk5sgLK7C2L+jLnqaej90G0YNm9Jip/PwjiLq4EVmYzFpKoy9txekIYFVNUQqobJzlsJg+IG2xWINUro+Td2QLhrviv4BvpoJ2AxAkBqY8inQZUSTPt9rtaLw7nvgOHwYfJL8+PBDBPXsEbDzKJ/Pj6N6C7YSXZDjBmqbezq6RshqrXIj0DdOTYWvLwS/10+pMI4sMxVLdRVZgdNdc/lgaDFdVZCkqiGOkYMnYN95aQzY1rdsW0Nw4NCZ0eTEx/79+7F48WLk5OTAV1t6fApkQB89ehQdDWwLWmwL6hzarm/J87Zff4Vh+Qq4CwthC47G8f4PwCYMpYUZg8YnYcB1ieA3hfri8wI//Je580Zw/avAoLvBtiqAFSdL8X5xGU36hImEeDElhmo7BMoYaK1x+/PRUjz5zSHYnB5EyCV4Z0Z/emcwEOD0+bC5zELpLHss9YJ/iUFiSmW5JSoUGvH5E1y2P/6Efv58eMvLwSMCpk8+AfWsWU0SMG3JfvX73Sgr20odYcyVe+r2IdoGMdpbEa2dAolY02bHxuHcMDvM2Jy3mSY8jpvqKzxUIhVG/yJDkIN/Xo0PRxAwb9V6iISXLi7t8/powuPITqaqlmh5jJieBoEwcCq3SOVTcfHnyD35GrxeG11Bx8bOQJekxyESNaE6z6oH1s4A9PsBkiQc+xIw+J4mVRx6q6pQdM+9sB88CL5cjvgPVyGod+8OMY8qqqih9ubbThix56SJ2sGfQliIGNekR1BKzJUpGgRfIGaegs/hoVUgtBok2wyPqV47iYAnFUCazDjFEMcYYVjguKyxrW/ZtobgwKEzo8mJjxtvvBFRUVGYNm0aHnnkEaxYsQIGgwFvvfUWnn32WYwbNw4dDWwLWmwL6hzavm+JgKN59WqUv/Mu3A4PslKmoiR6KH0uNp1QX7ojpDG2dl43sO5e4Ng6gMcHJr0D9J3G2i7db6nG45lFyKgVuBwVpsDy1Fhopa3scMPycXuyzIb7Pt+HLIMNQj4PT1/fDbdfnsja+JBvd+IzvQlflphQ4WbKr8nNxTFhSsyOCcNwtRz8C/3+nU6UvfYaKj5dTdvirsmIefXVRnH726pfq6tzqQ5IScl38HgYjR6idRAePppa4qpUl7G2fzoi3D43/iz+kyY7fiv+rc6JRcgTYnjscEzsOhHDY4Zj408fIv8zpmrh9OQHSXoQJM6agJvH33fJx+O0e7Bl1VEUHqsgH4Shk5PRb3R8QP0mLNZDyMx4FlW2Y7StkPemtBaFolfz3tBtB354BDj8FdPuN4tJxAsb74jjtVWj6D//gX3fPvBlMsSv+gBBfft2qHmUxe7GzixGF2RHphFVjnpXIYmQjyu7aigd5tr0CEQoGlcB6KlgaDFUHyTHAv9p70kgCJXSBAilxSSrwA9ib8Ul2/qWbWsIDhw6M5qc+OjVqxc2bNiA5ORkzJo1C3fffTdGjBiBn3/+GR988AG+++47dDSwLWixLahzaL++JVadxtffgGX9epREDEJm6jT4BGIEyUUYdVcPxKVf4M6/2wF8cxuQ9TNAxBhv/hDoPon13eny+fBmgRFvFBjg9vshE/DxTLKW6j9caLHc0cdttdODp9YdwQ+HGBeuiX20eOmmXo26+9cWIHcot5pIdYcJv5nry7ajJSLMjA7DdG0ooiUXT2ARypeeCJhmZdG2esYMRMx5EnyplJX96vU6YDT+iGLdl7BaD9RtDw5OpjSY6KgbIRIp2/ioOw8yKzKxIWcDrfCocDB6QQTdQrthUtdJuC7pOoRKG8bJbzetRMa3PyDIXt+f9iA/0m9umaSHtdyOH985jAp9NYQiPkbd2QNd+oUjUOB2W5Cb+zJN7JGUkFCoQHLyHKprc8mULjIl3f0WsPU5xko97jJg6meAPLLRb+GrJsmP+1Dz77/gh4Qg7oP3Edy/f4ecR7m9PuzNq6C6IIQSU2yu10Ui6BunopUghBaTGilr1Hf1+xhaDHGKIckQV2EV8Zyv34EHiOPkddUg5DGPRfpSbOtbtq0hOHDozGhy4mPw4MH4+uuvkZiYiIULF1Ix03vvvZda3o4fP55SYToa2Ba02BbUObR/39qPHIVh6VKUZ+pxtPtdqJYRkWE/Bo5LovSXs6gvThuwdhqQ9zsglAK3rAFSRgZUVxJb0ycyCvGvtYa2hyhD8Ep6HLoGs1Pjoi3GLfmMj3flY+nmEzTRkBYpx7sz+6NLeNOcElraovhzvQlflFSgxOmm28i3vypUjtu0GowMU9AqlYuBCpiu+QLGFSvgd7kgCA1F9NIXIb/qqjb4Fi3Tr1VVxykNptSwEV4v87vl8yWIjBiPmNgZ9I45F9MvHSa7qY7KklHBOPwQkATH+C7jMTF5ItJC0y5qbbvjrw0o0ecjWpuIqy+f3CL0ltKTFmx+9zDsVW6qzURETCMSAkOwmfzWS0vXITvnJbjdTBIpKuoGdO36VMtTuHK2Ad/cCTgtgCIGuOVzIKZh8uJC8NXUoOj+B1Dz99/gBQcj/r2VCB40qEPPo8h3yjRU0UqQrSeMOFRU2eD5uNCgWl2QSAxKDG20GLbPSWgxFqoNQhIhnrKGyRWeREDFUaWpaki6qqhoanueU7b1LdvWEBw4dGY0OfHx3//+lwaVZ555Brt378Ynn3xC/zZt2oRVq1bht99+Q0cD24IW24I6B3b0LXmt9cfNKHn1DRyXD0eJ9gq6PTpWjDEPDUKIqrZc2F4JrJkCFP8DiGXA9K+AxCsDshu9ZKGvK8fSkyWo8fog4fPweEIUHoiPgKglLX4DbNz+k1eBB7/Yj7IqJ+QSIV6Z2gdjelxctLGl4PP7qSjtar0JW0wWeGuvMkSbZVp0KGZpw5AQ1PjydU95OfRPP43qnb/TdsjwYdAuXQqhRhOQ/erxVKHU8AN0ujWw2eoX5nJZD1oFEhk5EULhhV0bODSE2+vG78W/Y0PuBkpp8fiZUn0RX4Sr4q7CpORJuDzmctpuzb69ELL3GrD90xPwenzQxMlo0kMWIJaiNlsWMjOfQ6VlL22HhKQgLXUx1OrLWu9Dy3OYBH15FpOgn/gW0LvxorI+ux3FDz6I6r92gxcUhLiVKxFy2eBOM48yWh1UE2TbCQP+zCmHq1Y0mkAhFeLq9AiaCBmRFg6FtPHjwlPpqKsGIckQX80ZtBiVpM4yl4il8oPbVqiXbX3LtjUEBw6dGY1KfLjdbohETOAieh5z5szBqFGjcOutt+KOO+7Av//+SwfzokWLMGVKyymdswVsC1psC+oc2NW35E6X6cOPcGzDfmQk3QyvUAoJz4Vrb0tHUi8Z8NkNQOlhQKoCZn4HxA4M+C4kji9zM4uwo4KhUPSQSfFaejz6yNljB9nW45ZMeknyY2++mbbvvyoZT4xKhbAVS5LLXR6sLTFR/Y6CWheeU9U4t8docF24EpImCo/adu6EfsHT8JpM4InFiJgzB+qZM1gT+y45WWk9gGLdF5QO4/Mx50wgkCEqajLVApHJ2l63JFBAzt+JihPYmLORVnhUOuvvcPcM60l1O65LvA4qEuvaccyS9/l3cz7++SGPthN7azDqzu4QB4B9qMdTjbz8N1FU9DH8fg/4/CB0SXoYcXF3gM9vA20lhwX47h4g+xemTdzGrl0I8Bs3F/M5HCh+6GFU//kneFIp4t59ByFDh3a6eVSNy4M/sstpNcj2DCMqquvjs0jAw5AuYTQJcm23CMSqG3/dJLQYt95WJ5LqLLCSOxL1O/AAUYyMJkIoLSZeAV4ri/eyrW/ZtobgwKEzo1GJD0JvGTt2LKWykMeng7ycOLwoFApERjaegxlIYFvQYltQ58DOvnXr9Ti5YiX2lHeFTRZL+dLdfdsxPHIlBMowYNYGIKonOtK5+85gxnM5OiqYSaZW98VF4MmkKASzgH/cHuOW8L9f+ikDH/7JLLiu6BqG/93aD2GyxldbNOZ7/W2pps4sP5ZZ4Kq9pCiEfEyNItUdGqSFNP2uNlmwGF95FebPGbchSUoKtK++AmlqKtiElupXt9uMkpJ1NAlit+fXbVcq+yNGOx0REeMgELRcvwUyyu3l+PHkj1S7I6cyp257eFA4xiePp9UdyapkVvSt1+3Dr5+fQNbfBtruMzIOl9/YtWnOW+0A8t3LyrcgK2sJnM4Sui1cMwopKc8iKIhQKdsQxHns1xeAP19j2l1HATetAoIal9AiYsi6/z5Ck6g8iQSxb7+NkCsu77TzKK/PjwOFZqoLQhIhuWX1jloE3aIVGNWNuMREoWeMoknnx+fywplngTOLiKRWwmNgKH2nwBPzIemiopQYQo0Rhrc8LYZtc2S2rSE4cOjMaFTi4/vvv6fipX/++SfUajV1bpk4cSK6deuGzgC2BS22BXUO7O5b6569+O3tP1EU0oe21bYcXDtJicgpt6AjoszlxnPZOqw3VtZZo76SFocr1fJOO26J4Om87w6jxuVFtFKKd2cOoKJ3lwKL24NvDGas1pmQVVNvhdhXHkydWSZHqJudcHJkEgHTJ+HMzqZtYlFLrGr5EvYt/Fu6X6mWiXk3dPovUVa2hd5lJxAKVdBG30SpMMHBSehscHqd+K3oN6rbsUu3C14/4wYk5otxTfw1VLdjqHYohHwha/rWXuXCTyuPoCTXAh6fh+G3pqLn8DZOGjQDdnshMrOeh8m0o86OOS11ITSaa9r3wI5+B2x4EPDYgbCuwLS1gCalUS8lTmi6Rx+jdvCkcizmzf/B26cPN4+qdQUjdJhtx434t6CigY5plEJKq0CIS8zlyWGQCJs2B/ZanDQBUkeLsTE6T6cgUIgZkdRUFXWLEcjEHW6OzLY1BAcOnRlN0viw2WzYtm0bTYLs2rULcXFxuP766zFhwgTEx8ejo4JtQYttQZ0Dy/u2LAv+Tybh0LF07BHdDa8gCCJXFfoL9qHXU7dBknzpd0bZiC3lFjyVVQx9raDmjOhQPJeshVIk7JTjNstQhfs+24eT5dUQC/h4bkJ3zLis6faZB601WK0vx3pDJew+hjMexOfjxkgVZsdoLole5Pf5aIUHqfSgAqYaDbRLX4Rs+HCwFa3Zr06nEfqSb6DXrYXDybj1EISqr0BMzHRoNNeC3wTNikADObdHy49iY+5G/JT3E6wua91zvcN708qOMYljoJQoWde3FSXV+PHtQ7CWOyAOEmLsPT0R1/0CLlssgM/nREHBB8gveIc+JvbLCfH3IDHxAQgEQWAF9AeBtTMAazEgUQA3fQikjm7US0lM0T3xBKq2bgNPJIJq6YuIHD+em0edBkKB2ZFhpA4xv2eX0WT5KYSIBRieGk4pMUQfJDSkaUkKSospra7XB8m3AJ6GSxBKi+mqoskQSWLzaDHtfa1l+xqCA4fOjCaLm56eBNm6dStNghCR07S0NJoAmT17Njoa2Ba02BbUObC4b0uPAKsnAzXlQHg6TMM/wc8f5KLSxSxO44u2YcDlckQ+9AAEyo5nqVnl8eKFXD0+1ZtoO1IsxLLUWIwLv7Rqh+aADeO2yuHGk98cwi/HmLL7m/rH4sUbekIqunBcq/Z6sdFQiU/05ThcVa/oTygst2nDcHNUKBRNvBN4Lmtm/fwFlItPILvqKkS/+AKEYWFgM9rGrccLk+l36ghTTu/CM5dtsTgcWu1UxGhvhVSqRUeBodqATSc30eqOk5aTddsjgiNoZQf5S1ImsbZvi05U4Of3j8Jl90ChkeL6B/sgNJrdYrUVFbuQmbUQNTUMLU6tHoq01OcREtIFrIOtDPh6FlC4mxGRGLmI0f5ojFWr2w3dk3NQ9csvpIwKMa+/BsWoUW1y2IEGh9uL3SdNlA5DKkIMVmfdc4SpNTAhlLHK7R6JJE3Tf99+N6HFWOHIMcOZVUmTIqeDJ+JDnKSk2iBEI0QYGXzRcUiSK868SlQZLJBHKiFJUtFqq/YE29YQHDh0ZjQ78XE69uzZg+XLlyMjIwMnTpxARwPbghYbFlAcAqBvi/YCa25ixOGi+wAz1wMhYfC4vfjj4wM4vp+5e6q05KJ38XeIe/B2qKZMAY8Fv/GWxp5KG57IKEKunZm4XR+uxLKUWERIRJ1u3JLjeP/3k1j+cwYtae4ercDKmQMQH3Z2pUZGtZ1SWb4prUCVl6nuEPN4mBChogmPQcqQFvkuVTt2oIQImJrNlIMfMW8u1NOmBUR8a+t+tdt10OvXQl/yNVyu8tqtfGg0VyNGOw1hYcPB4wXeGHZ4HNhRtIMKle4u2Q2fn/m9SQQSXBt/LSZ1nYTLoi6DoJGilu3Vt8f+0GHnl1l0ARadrMR19/VCkLwNREAvoaooO2cpDIYf6pJpKV0XIDJyArvHn8cF/DQH2PcJ0+55MzDxTUB88Yozv8cD3dx5qNq8mUl+vPoqFGMaVzXSWUHGwhGdpc4q90RJffUVQXJ4CE2AjOoWiX7xagiakWzwVrkoLYbRBzHDV9WQFsOXi2kShFJjuqogOGNc2Y+Wo/KHXHgt9cKtAqUYqgnJCOrZfg5gbFtDcODQmdGsxAd5yd69e7FlyxZKfampqcHIkSOp+Onll1+Ojga2BS22LKA4sLhv8/4AvrgFcFcDcZcBM74BpA0rOnL2GfHrJ0fhdgNCtw3dMz5DjMaNyPnzETKkFS0K2wkOrw+vFxjwdqGBVtcqhQIs7KrFtKjQNhlHbBu3f+WU4+EvD8BU7YIySIQ3bulLy5edPh8VKV2tK8ceS/0dOKKVMlurwS1RoQgTtwxdiNhNGl9+GeYvvqRtSVoaYl55mQqZBgraq1+JA0xZ+TZaBUI0QU6B6DGQCpBo7RRIxO1v93uxc3eo7BClsvyS9wuq3IwrE0H/iP60smN04mjIxXLW963P58df63JwaFsRbacOjsTVs9IhvEg1VXvB5/NQO+Xck6/B67XR5Fls7Ewkd3kcQmH76iE1CXtXAT/NA3weJsF/6xeAMvaiL/O53Sh4cg4cpPJDIKBxR3HddW1yyB0BxeYabD/BUGL2nDTBc5owSFiIGNcQq9zukRiWokFwM64XZOwRYVRCiSGOMa48C/zuejteAlFUCCSpxDJXDV+NGxVrM8/7fmEzu7Vb8oNtawgOHDozGp348Hg8+Ouvvyi9Zfv27TTZMWLECEpvGT58OMRi9t7R6GhBi20LKA4s69usLUwZsMcBJI0Apn0JiM9dhmopq8Ev7x9FWRGZ+AJxRduQfHIjlCOvRcTcORDHxaGj4ZjNjscyCusoG8PUMip+mhAk6XTjtsRix/2f78fBokr4gwXoc0UsciR+6opDIOABYzVKmvAg54nfgsftyMiA7okn4crNpe3Q225D+BOPgx9g1xI29Gt19UkqhlpS8h08HgvdxuMJER4+mmqBqFVDWPObIyitLsUPuT9QKku+td7BJjokGhOSJ9CER4IiAYHSty6HB1s/Oo78w0wFzuAJSRg4LpFV5/x0WCwHkZn5HKpsx2hboeiDtLTnoZAHqMtX/p/A17OBGhMQEg7c8jkQP+SifVtZUYGaFS/DunEjwOdDu3w5lBPGt9lhdxRYHW7szCyjdBiiD2J1MILMBGIhH1d21VBKzLXpEYhQNN3hi4AkPZwFljp9ELe+IS3mYhAoJYiaN6hdaC9sW0Nw4NCZ0ajEx5w5c7Bz506a7Bg6dCgVNB01ahRCQtjNWe2oQYsNE20OLO3bYxuA7+4mt7OAtHHAzR8DIulF7RbJncrDO4ppW2HNQ49jHyHYb0PoHXdAc+894HewsU7uTr1fXIaX80pg9/kRxOdhXlI07okLh6DVdBrYN27JefjRaMbzh4ugE9VfCqLEQmpDO0MbhqgWpgMRAdOKT1ej7LXXKN9eEK6BdtlLkF15BQIRbOpXr9cBo3EzrQKxWA/UbQ8O7kITINFRN0Akant9GwK7x47thdspleXvkr/hr9UpCRIGYVTCKJrsGBQ1CHxe+1tPN6VvbWYHfnznMMqLbBAI+bj2tm5IGRQJNsLtrkRu7ivQ6ddSnRihUIHk5DmI0d4SkPSoBjAXMKKnhiMAEfy9/lVgwG0X7VuFTIbShQth+W4dk/xYthTKSZPa9NA7EoiF+t68CmqVS6pBis31mlAEfeJU1CqXVIOkRcqbbxNtc1GXGFIN4jhhgq+mPtlyPmju6QVpctvHP7atIThw6MxoVOJjxowZNNkxduxYhIayW5W8MwQtNk20ObCobw9+AWx8kKwsgZ43ATe8Bwgav2g9eaAMv352As4aD0R+J9KPfoJw02EIw8PpnXjlxIng8dmzKGkJ5NudVPtjV6Wtzor1tfQ4dJcFdehxq3e4sKbEhDX6CpS6GB41OSJBuQO8wmrEe3h4b+YA9IxpWcFbt8GIkvnzUf3XX7Qtu+YaRL+wBMIAvq6wqV9PR1XVCej0X6C0dCO8XubuKJ8vQWTE9YiJmUHv8rf28ZJzs9+4n1Z2/JL/C6oJ9a4WAyMHUt0OkvQIEYUEZN8aC6zY/M5hVFtcCJKLMO7+3ojqomTl9ygtXYfsnJfgdlfQbdFRN6Jr13kQs5wO1SS4qoENDwDHNzDtQfcAY5ed8zp4et+CnJ+Fi1D5zTdUIDX6xRehuvGGtj/+DgZyjrMMjFUuSYKQysLTERcaRB1iiC7IoKRQiJppf159wAjzV+enuZxC6K1pCO4bgc6+huDAoTOjRcRNOzrYFrTYOtHm0I59+88HwOYnmcf9ZgET/g9ohgigtdyOX1YdgzGfES5LqNyLpEOfge/3Qtq7N6IWzEdQ377oaOf8y5IKLMrVwerxQcgDHo6PxKOJkZC0YKKnvcetz+/HbxVV1Ip2S7kVp9jSYSIhpkeHYqY2DNVmJ+77fB8KK2ogEfKxZHJPTB3YMnSnqu3bUfL0M/BWVoInlSLyqaegumVqwMew9u7Xi8HjsaHU8D2tArHZ6sXHZbLuiImZhqjIiRAKZS36mXqbniY7yF9RFaN5QRAji6EWtITOEiu/uA4Dm/uWJIq3fnwMHpcPodoQXP9Abyg0LLF8PQ02WyYyMxei0rKXtkNCUqhbi1o9GB0SZEr7+yvAjheYduIwYMqnVNj7Qn1LKtFKlyxB5ZdrafIj6vnFUE+Z0j7foYPCaHVge4aRCqT+mVMOp6des0MuFeLqtAhKiRmRFg6FtPE3bRy5lSj/4MhF9+MqPjhw4MAlPhoBLvHBgdWLqD/fALYtZB5fdj9zh+sSFmBejw+71+fi0HZmwRIa7EC3v16DpFJH24qJExDxxBMQRbKznLu5MDjdWJBdTIU9CVKCJXg1LQ6DVbKAXiCXudxYW1KBz/QmFDrq1e6HqkJwm1aD68KVDRI8lho3Hv/6IJ2gEkwbHI9FE7tD0ky7WiJganhpOSq/+oq2Jd26MQKmycnoCGB74uP047RaD9IEiMH4I3w+xuFIIJAhKmoSpcLIZenNfv8adw22FmylyY5/Sv+p2x4sDKYCpSTh0T+yP6uoLM3pW7LtwNZCGiMJWyeueyjG3NMTkqCWEfxtKXg81cjLfxNFRR/D7/eAzw9Cl6T/Ii7uDvAJFaSjI+NHYN29gMsGqOKBW78EonpetG8NLy6F+fPPaTtq0SKob72l3b5CR0aNy4M/s8tpJcivGUYqsn0KQj4PQ7qEYWS3CFzbLRJxoRd26iEOSqXL/2ng5nImOI0PDhw4EHCJj0aAS3xwYOUiitzZ2vEi8PvLTHv4HODqpy8p6XE68g6VYfunDPVFLOWjr/AgZJveo8/xgoKo9gfRAOFLmydWxlZsMlbSBIjR5aH0j9tjNHi6SzRkzVz4t8cCmXwWcWT5VFdOEznu2sI+4mQzNUpN9TtSQ6QXdKh4e0cOXtuWRX9mfWKVeGfmAMSomnZH23H8OCNgmpdH26F33onwRx8JOAHTjpD4OFProaRkHaXC1NQwfUOgVPSjNJiIiOsgEFx8XBPL2X2GfdiQs4EmPYiOBwEPPAyOGkypLMSKNlh0cYtRtoGMAX22GeUlldBEq6BNUdMF1s4vM3FiVwndp+eIGAybmgJ+M0v0W+v3WFa+BVlZS+B0MsdJRG5TU56FVKpFp4LxBPDlNMCcB5Df4A0rge6TLjhuyXbjS8tR8emntB357DMInTGj3b5CZ4DX58fBIjO2HjdSWkyOkaGenkJ6lByju0dSXZCeWiX45xAoJVa2ps9PwAs/DsELE/wIAw99IIAAPM7VhQMHDhRc4qMR4BIfHFi3iCKr0Z/nA3+/y7RHLgKufKzFj8dqsmPLqmMw5DHUl269gpDw59twHdhH2yKtFhFz50I+ZnTALPoag0q3B4tz9ZQCQxAjEWF5WhxGhilYvUC2uD34xmCmCY/sGuaOPkE/eTBmx4RhUoQawU1YpO3MKsMjaw+gssYNdbAIb07rjytTNI0TMP34ExjfeIOssiGMiID2pWUI6YB254GY+Dj92M2Ve2gVSFnZFloZQCAUqqCNvolSYYKDk856XZG1CN+f/J46s+hsTCUYQbw8noqUEiqLVha4i+zcA0b88VU2qivrx1CIUgxJiBAV+hqaW75iSgp6Xx3Lqj632wuRmbUYJtNvtC2VxiEtdSE0mqvRaVFTAXx7B3CSOScYMQ8Y8RT8PN55xy1NfrzyCio+/Ii2IxfMR+js2e1x9J0SeeXVlA5DBFL/za/AaU65iFRIaBUI0QUZmhwG6Wl20Rs3Z+HFP3JhJDpntYjg8fH0sGRMGpeK9gLb1hAcOHRmcImPAAxagTzR5tACfevzAj88Ahz4jGmPewUYfE+rnVqv14e/N5yk5d0E4fFyXJ5cBvu7L8NTWkq3BQ8ciMinF0DarRs6Ev6oqMKTmUUoqKWI3BipxvNdY6ARC1k1bg9Ya6h2xwaDmbrUEJAEx02RpLojDL3lzb/jXlRRgwfW7McRnQXkRtsTo9Nw/4jkc951I3AbDNA/9RRqdu+hbdnIaxG9ZAmEajU6IjpKPHY6y1BS8g11/HA46pMZavVQWgUSrByKbYU7aHUHESw9BZlIhjGJY2h1R9/wvgF9Dk4lPX5+7+h5nyfOLWP/0xOJvdgjCkpoSwUFHyC/4B36mMcTISHhXiQm3A+BgH26I20OrwfY+iyw5x2mnT4e/snvwuLwnXfc0sqZ19+A6f33aZsk+MPuvKOtj7zTw1ztwo5MI6XEkER8jYuxWicIFgswPCWcVoKQ/pr77eFar6h6nOrZd2f2x9ie0e1yPtm2huDAoTODS3wEYNDqKBNtDs3oW68bWP8f4Oh3AOHKT3ob6Du9TU5l/pFybP/kBBzVboilAlw1tQtU+zbCtGoV/E4npdiopkyhVIZAduk4EzVeH1bkleD9ojIqCBoqEmBJ1xiaBGnK+GvpcVvt9WKDoRKf6stxuKreMjA9RIrbYjQ06aG4RHrOKTjcXiz6/hjW7mV0X4gS/6tT+0AZ1FArwLp1K0qfeRZei4XSoSLnP0V/Ex05TnW0eOz3e2Ey/U6rQMpNO6jtKYHVy8MemwB/VQth8QowVDuUVndcE38NtaTtCCD0ltUL/mpQ6XEmghRi3P7SFedN/LU1Kip2ITNrYR1lSa2+HGmpixES0qW9D419OLAG2PQo4HXBH9EdVde/B3l8r/OOWzK2y998E+XvMJWVxN1Mc0/r3WTgcPHr0J6TJkqH2XbciFKro1GnjPRulFKKP+ddA0E7jFu2rSE4cOjM4BIfARi0OtpEm0Mj+9btYEp2MzcDRJzuplVAj8ltevpsZgelvpTkWuo47oMvD0bF/70O6+af6Da+XA7NAw8gdMZ08DqQlgOpqngioxDHq5nJ1rWhCixPi0WsVNym4/aEzY7VehO+La1AlZcp6ZXweZgQrsJsbRgGKUNaLS6s/acQz31/DC6PD4lhwVg5awDSoxTw1dTAsGwZKr/5lu4n7dED2pdfhqTL2TSJjoaOGI8LrAXYmLMRO/PXIZlXgiEyD5S1lz4/eJCrLkdy/B0ICxsOHq/9r4ktBV2mGRteP3DR/SY/1g8xae1bweR0GpCV/SKMxh9pWywOR0rK04iMGN9hfoetguJ/gbUzAFspfFIVeFM+BS/5qgu+pOztt1H+5lv0MUnsa+67r40OlsOF4u5RnZXSYTYe0KGgouaiJ+vLe4ZQekxnX0Nw4NCZwSU+AjBodcSJNoeL9K2rmhFpy9sJCKXA1M+A1NHtctp8hPryQx72/1xA25o4Gcbc3RPiouMoXboUzuOMZaY4MZHe8ZeNGIGOAjcR/Sw04LV8A1x+P0IEfCp8SgRQ+RcZi5cybh1eH34sq6QJj78t1XXbk4LEmK3VYGpUKMKaQb9pDg4XV+L+z/dDV2mHVMTH630kSF31Mlz5+bTqJ+zuuxD+8MMdKunVGeJxlasKv+T/QhMeB8sO1m2Xi+QYlzgGYyIiIajaBbP5r7rnpNIYxGhvRXT0FEgk4QhEEBerssIq6HMqkb3XiPKiqou+ZtRd3ZE6KArtAZ/Pg2LdZzh58g14vUQEko/Y2FlI7vIYhEJ5uxxTwMFaAv9XM8DT7YOfJwBvzFLgsv9cUBi8fOVKlL3xf/Sx5qGHEP7Qg214wBwuhI0HdXhkbX3MOh/+79a+mNQ3Bp19DcGBQ2cGl/gIwKDVUSbaHBrZt/ZK4IupQNHfgFgGTFsLJA1r99NXcMyEbR8fh8PmhkgiwNUz09G1vwaW9ethfP0NeE0mul/IsGE0ASLp0nFKr7OrHXgiswj/1CYhBitDqPVtygWcUpozbvNqnFS746vSClS4GW6zgAeM1SipFe2VatlFEy6tgYpqFx79Yh8if/oWs0/8DKHfB0FkJGKWL0fIkMvQmRDI8djr82JPyR5szN2IXwt/hdPLUDyI5ezl2supbsfVcVdDIpDUvYZQKnS6L6Ev+RYeD1P5xeMJqXMIscRVq4aw+jy4HB4YTlppoqMkp5IKN3vc9WKIjUF7VXxYLAeQkfkcbLbjtK1Q9EFa2vNQyOttWjk0Dn63He51D0B8Yh2zod9M4PrXAGH9b/1MlH/wAcpefY0+1jxwPzQkwcvi33pnwe5cE6Z9wGhKXQhcxQcHDhy4xEcjwCU+OLTbIqraBHw2GSg9DEiVwMx1QOxA1nSIzezE1o+OQZ9dSdvdh2kxbEoKeC47yt99FxWrP6OuHhAKKfWFUGAESiU6Anx+Pz7Vm/BCrh7VXh/EPB4eS4zEg/EREPP5zV4gk6qSLSYLVutM2Gmuv/uslYgwUxuG6dFhiJI01NZoa7hLSqCb9xTs//xD239qe+G38Xfh1btGUC51Z0IgJj5OVp6kyY5NuZtgtBvrticrk2my4/ou1yMiOOKC7+H1OmA0/kQtcS2WerFT4gITo52O6OgbIRKp0N6osbpQkluJkmwL/b+syEZtaU+HNESE6K5KRCUrcXBrIexV7vO+n0wtwawXL29TjQ9iP5yT+zL0+q8o2UgoVKJr8hxotbeAR7SeODRv3FZWQnliDXhE+JQ4gcQOAm75HJCfv5rH9NHHMK5YQR+H3Xsvwh97NGDGfUe2w71y+a8otTjOEjcl4DQ+OHDgcApc4qMR4BIfHNplEVVVyiQ9yjKAYA0wewMQ1Yt1nUGoL3t/zMe/P+VTHcSwGBnG3NMD6qgQSn8wLF8B2w4ikggIVCrKkaaClyyonmoJFDtcmJdZjO0VtZa/IVK8lh6Pfop6JxWv3489ZhvyKi1IUikxRC2D4IzJss7hwpoSE77QV6DUxSy8yB5Xh8opleaaUAWELBBUtP78C0oWLoSPCJgGB6Pijofwn/JoVDm90MjE1PK2PXjU7YVASXxYnBb8nPczTXgcKT9St10pUeK6xOswuetkdA/r3qzvUFV1Ajr9lygt3QCvl6mC4vMliIy4nlaBKBRt4/ZC+sJa7qhNdFRCn2NBpeFs7r88VIroFCW0XVWITlZBHRUMXu3YupirC3F0Se534aRQS8Hv96GkZB1ycpfD7WastaOjbkLXrnMhFrPHVSbgx23ur4x+lsMCyLXArZ8DMQPO+9qK1athWLqMPg69605EPPkkq8d+Z8DPR0soBZPg9OQH5+rCgQOH08ElPhoBLvHBoc0nY/5K8FZPBsx5zETstu8BTQqrO6LoeAW2fnyM3i0VSgS4anoa0i5j7pzZ/twFw0vL4MrJpW1JWhoi58/vMLQI0m/rjZV4JruYUlLIPdh74sIxNykKv1VU4ZlsHUqc9XeRoyUivJASg+s0Svo8cWbZWm6lrjEEGpEQ06NDMUMbhoSg85detyV81dUofXEpLOuY0nBpr16IeXkF1XLJL6/GfZ/vQ0ZpFVXNf2psOu4eltQpFgNsTnx4fB78pf+L6nbsKNoBt4/5DQp4AgyLGYaJXSdiROwIiAUto8fi8dhgMPyAYt0XdXQMApmsG02AREVOhFAoQ0uBVG6Y9NWUskKpK9mVqLYw1tOnI1QbwiQ5uioR3VVFEx8XAkl+/PFVdgN3F1LpceXUlDZLethsmZTWYrH8S9shISlIS1sCtWpQm3x+pxu3plxGR6s8EyDUrolvAn1uOe/rK9asgWHJC/Rx6G23IeKpeawb/50x+bH4h+MosdS7vUQrpVg4oXu7WdmycQ3BgUNnBpf4CMCgxeaJNodL79uqvP2Qb5gFnlUHqBOB2RuZ/wMA1RaG+qLLZKgv3a6IxrBbUiESC+B3u2Fe+xXK3nwTPitTHSEfNQoR8+ZCHBuLjoBylwcLc3T4zmCuS2CUuz1n7cervSt15vOXq2TUmWVcuPKcdJn2gv3wYejmzIG7oJARMCUl3g89CJ6onnJjd3mxYP0RrD+go+1xvaKw4uY+kEnaRnS1vcDGeJxtzsb3ud9j08lNKLeX121PUadgUjJDZdEEaVq38sJ6iFriGoyb4PMxCQSBIARRUZMoFUYu79bk9/W6fTAWnNLnINQVC1z2huOLUFDCE+RMoiOFVHQoKZWlOda2+mwzyksqoYlWQZuibhN6i8dTjbz8/6Go6GNqLSwQBCMp6b+Ii70dfOLmxaH1xq3DCqy7F8hiHMpw+cPAyMUA/9zzPvPatShdtJg+Vs+cicinF7AmBnRm2ss/eSbkG8xIjFRjcFJYu1jYsnkNwYFDZwaX+AjAoMXGiTaHloG/9Aj8qyeDX1MOaNIYeotCG1CnlywY/v0xD3s3M9QXcrd1zD09ERodQp/3mM3UGpBMGuHzUfeP0DvugObee8APYfYJdGwzWTE3oxB619lJjzOhEPBxa3QYZmnDLiiO2h7we70wfbAKZW+9RVZkEEZHQ7v8JYQMHnzu/f1+fL6nAM9vOg6314/k8BC8N2sAukZ0XLcJtsTjSkclNudtplSW46b6agu1RE0THROTJyI9NL3Nj9HttqCkdB1NgtTUnKzbrlD0Q2zMdEREjINAcO7fPUlqlJy00EoOkuQgQqTEheV0EGHlqC4KWslBkh0RSQqaaA20viWfVVb2C7Kyl8DpLKXbwsPHIDXlGUilgXUNCASct299PmDHi8AfrzDt5GuBmz8Egs4tZmv+5huUPreQvCFU025F1LPPgseipHVnBFtiMlvXEBw4dGZwiY8ADFpsC+ocWgjF++D//EbwHJXwR/UGb9Z6ICRwedzFGRXY8tFx2K0uCMV8jJiWhvSh9eWmjswsSn+p2c2osQvDwxH+xONQTpzYISaO28otmHkk76L7fdG7C64JU4BtcOv10M+dh5p/mVJ7+XVjEb1oUaPEafcXmvHA5/tRanUgRCyglR/X926/UuOOGo8JdeXP4j9pdcdvxb9RaguBkCfE8NjhVKiUUFpEAhErzlNl5d+UBlNWtgV+P0O7IUKd0dE3IUY7DfDEMJUctdQVU7GNrCcbIEguqktyEOqKJlYGvoAf0H1bU1OArOzFMJl20rZUGoe01IXQaK5utc/s7Lho3x5dB2x4APDYgdBkxk0tPPWc71W5bj1Knn6aSX5MmYKoxYs6xDUsUMG2OTLb1hAcOHRmcImPAAxabAvqHFoA+X8CX9wCuGzwRPeHYPY68M5zhymQQKgvxPK2OIOhfqQPicLwaWn0Lu2p37Lt119heGk53EVFdJu0d29ELZiPoL59EchYbzDj/uMFF93v3e4JuCGSXX1t3bwZJQsXwVdVBX5wMCKffRbKyZOaFG/KbU48/MUB7D7J2BrfMywJ88amQ9hKi9TOFI8zKzKxIWcDrfCocDCilwTdQrvRZMd1SdchVBoKtsLpKode/zWKi76Ey62v215tSEdl7ghU6fsCPoYipdBIa5McTKJDFRncZue5tfuWUIAKCt5HfsG79DGPJ0ZCwr1ITLj/vFUwHNqwb0sOA2unA5YiQKIAbvwASBt7zl0t338P/VPzacWI8sYbEb3k+Q4j4B1oYNscmW1rCA4cOjO4xEcABi22BXUOl4jsbcBXMwCPA/6k4bBctxLKcG2H6VtCfdn3Uz72bsqjd2+JgwKhvhD3l7p9XC5UfPopTO+uhK+GcWFQTJyAiCeegCgyEoGIXeYq3HSQEXO9EL7rm4wr1Oyggnht1TAsWQLLxo20Le3TGzErVkCckNCs9/N4fXh5Sybe28lQHC5LCsVb0/sjXM4OwdZAiscmu4kmOkh1R0ZFRt12kuAY32U8pbKkhaaBzXGAVHAw+hyMRkdNlQMhkcegSt4JWfRh8Pi15R1eNRRBE9ElZSbCIrt0yL41VfyJzMyFsNvzaTtUfQXS0hZTO2AOLOpbWxnw9Wyg8C9GnenaZ4ErH6daR2fCsulH6OfOZZIfkyYheumLXPKjHcC2OTLb1hAcOHRmcImPAAxabAvqHC4BxzcC394FELeF1LHwT/kElmpnh+xbXZYZWz48hhqLC0IRH8NuTUW3y6MbfE+30YiyN/6vzjmEFxREtT+IBghfGlh3QImF7cDdx1HqdDew1zsFXq27y96h3c+ytm0P2A8ehG7OXKbyhs+H5r7/QHP//Q0ETJuLn46UYM63h2FzehCpkOCdGf0xIIG9FQlsicdurxu/F/+ODbkbKKXF42eoLCK+CFfFXUWFSi+PuZy22QaP2wtjvhX6bIa6QrQ63A5vg334Qh4iExh9Dk2SHf6gX2Ao+xYul7F2Dx7Cwq6iWiBhYSPA4wkCvm+dTgOysl+E0fgjbYvFEUhNeRoREdd3uJjPZjSpbz0u4Od5wL8fMe2eNwET3wLE9Zblp2D96SfonpxDJo5QjB8P7UvLwBN2bIFntoFtc2S2rSE4cOjM4BIfARi02BbUOTQTh9YCG+4nnoxAjxuBG9+Hny/s0H1bY3Vh2yfHqfUtQeplkVT7QyxtODG0HzkCw4tL6WKcQKTVImLuXMjHjA6o8/JjWSXuPsrc0T09+XHqG6zqmYjrw1VobwHT8vfeQ/nb79DJulAbTas8ggcObNHPyS2z4b7P9iHbaIOQz8Oz47tj9tCEgOrPtojH5P1OVJygFrSkwqPSyTgkEfQM60ktaK9LvA4qafv+bs6Es8ZNBUhPaXQYCqzweRqm/ERSAXVZqRMiTZRDKGp4TfX53Cgv307FUCvMu+q2SyVaaGNuhTZ6KiSS8IDrW5/Pg2LdZzh58g14vTaS9kFc7Gx06fIohEJ2VHx1JjSrb/d+CPxEKjo8QFRv4NYvAFXcWbtZf9kC3RNPUEFoxbjroF2xgkt+dOI5MtvWEBw4dGZwiY8ADFpsC+ocmoG9q4Afn2Ae95sJTPgftczrDH3r9/mxf0sB/v4+jz4mnH1CfSEihWdZYm76EcZXX4WnlHE5CB40CJEL5kParelWmO2Z/HgmW4cSJyPmSKCViLAkJabdkx6uYh308+bBvm8fbSuuvx5RC5+DQNE6YqvVTg/mfXcYmw6X0PbkvlosvbEXgsWBe0e0pcYssZ398eSPVLsjpzKnbnt4UDjGJ4+n1R3JqmSwBTazEyW5ldRxRZ9jgUlva5jdI+NVIa7T5iCJjjAiRNoEa8mamjzodF9CX/IdPB4mAcTjCRGuGYWYmGlQqy9v1TjZUn1rsRxARuZzsNmO1znapKc9D7m8ewseLYc26dv8XQz1hTivhYQDUz8DEoaetVvV9u0ofvQxYmsE+ZgxiHnl5RapnuNwcbBtHsW2NQQHDp0ZXOIjAIMW24I6hyZi1/8BW59jHl92HzBmGaUWdLa+JVz/LauOobrSCQGhvkxNQfcrz9Y2IZofplUfwvThh/A7nZRbTZTzwx99BMLQ0IChvewx25BXaUGSSokhalm701sIH7100SL4bDZqI0wSHooJE9rEtvOjXflYuvkEvD4/0iLlWDlrAJI0gWllfClj1uV14bei36gF7S7dLnj9DBVEzBfjmvhrqG7HUO1QCPnC9ndkMdTQao5TGh3WcsdZ+ynDgxCdQqo5mKoO0m6J35PX64Sx7CfodGtgseyv2070MIgbTHT0jRCJWl4g+FLjsdttRk7uy9Drv6pzsOmaPBda7VTweB1L5DfQcEl9W1nIiJ6WHgEIzWzcy8DAO87arWrHDuj++wj8JPkxaiRiXn2V2rdzaF2wbR7FtjUEBw6dGVziIwCDFtuCOodGgih77lgK/L6CaQ97Arjm2QYiaZ2tb+02F7Z/cgIFRxnnj5SBEbhqRjrEQWcv9Nw6Ha3+sG7+ibb5cjk0Dz6A0OnTA2IyyZa+9VZVoXTJEli//4G2iXuO9uUVEMedXbLdmvgnrwIPfrEfZVVOyCVCvDq1D0b3iEKgoan9SvY/Wn6UJjt+yvsJVpe17rne4b1pZceYxDFQSi5uG9xa8Hl9KCdCpNmMCCmp7LBX1VcsEZCvSio4TndcCVG2vmhtlS2DVoGUlm6opYyQvLGYamQQLRBSTdFS46u5Y9bv96GkZB1ycpfD7WZofdHRN9Okh1gc1iLHxqGd47GrGtj4IHBsPdMedDcw9iXgDOto286dKH74v/C7XJBdfTVi/u8N8APgehXIYMu1lq1rCA4cOjO4xEcABi22BXUOjUx6/PI0sOdtpn3tQmDY4+fYrfP1LaG7HNhaiD0bT9LH5C4xob6Ex5+b917z778oXboUzuMnaFucmIjI+U9BNmIE2Aw29G3N/gPQz5lDk0hUwPT++6G5/752458brQ6a/Nibz9gdP3h1Mh4flQZBE+gQgdKvhmoDNp3cRF1ZTloYlxuCiOAIWtlB/pKU7ePo4XZ5Yciz1rqtVKL0pBVuZ0MhUoGQj8gkRR1tJaqL8pwJyraCx1MNg+F7FOu+qKOQEMhk6YjRTkdU1CQIhQ3pc20xZm22TGRkPguLhaGPhYSkIj1tCVSqltXM4cCCeEyu63+8Cvz6AqPilHAlMPVTIETTYDfbH3+i+KGHaMViyIjhiP3f/8CXdBxnK7aBDddaNq8hOHDozOASHwEYtNgW1DlcBD4vsOkxYP+nTPu6l4HL7j3nrp25b4kw4pZVR6l2AFlkXTmlK3oMjznneSCCnJb162F8/Q14TUy1SMjwYYh86ilIurSf/eWF0J596/d4UP7uSpS/+y61WhTFxED78ssI7t8P7Q2314dlmzPw0a482r6yqwb/m9YPoSGBcVf0Qv3q8Diwo2gHre7Yrd8NHxEyBiARSHBt/LWY1HUSLou6DAJ+215XHNW1QqRUn6MSZYVV8HkbCnRIgoWISmaSHESQNCJBQSlpbAPVAqo6TMVQDYYf4PM56XaBIARRkRMREzO92VoaTRmzHo8NeXn/Q1HxJ/D7vRAIgpGU9AjiYm8Dn4WuO50dLRqPM38CvrsHcFUBynhg2hdAVK8Gu1Tv3o2i+x+A3+FAyLBhiH3zfwHnVBYoYNs8im1rCA4cOjO4xEcABi22BXUOF4DXzTi3HPkGIJxuYoHXb8Z5d+/sfeuwubF99QnkHy6n7eT+Ebh6Vjok57mzTGgbZEFf8dlnVEQOQiFCZ0yH5sEHW02gs7lor751FRdD/+ScOoccxcQJiHr2WQjk7HKS+P6QHvO+PQy72wutUop3Zg5A3zh2OZc0pl9J+1DZIZrs+CXvF1S5q+r27R/Rn1Z2jE4cDbm47c5/VYWDVnIQEVLyf4W++qx9QpTiWn0OhroSpg0BL4AqbwjcbgtKStdRKkxNTW7ddoWiL6XBEDqMQCBt0TFL9ikr+wVZ2UvgdDIizOHhY6lFrVSqbYFvxSEg4rExA1g7Dag4CYiCgcnvAj0mN9il+u9/UHTfffDb7Qi5fChi334b/KCgS/9sDqyeR7FtDcGBQ2cGl/gIwKDFtqDO4TxwO4Bv7wQyfwSIOOFNq4AeN1zwdHF9y5yDQ9uLsHtdLnw+PxSE+nJ3D3rH+Xxw5efDsHwFbDt20LZArUb4I49ANeVm8FgwZturby3ff4/Sxc/DV10NvkyGqIULoZwwHmxFZmkV7vt8H/LKqyEW8LFoYg9MGxzH6jh3ql/tQnsdlSXfylgYE0SHRNdRWeIV8W1yPOaSmjoRUqLRQRIfZ4K4KVER0tpkhzxMyurz3GQx1sp/UKxbg7KyLfD73XXiokQIlVBhQkK6XPKYrakpQFbWIpgqfqftIGk8UtMWQhN2VSt8Kw6sj8d2M3PNz/2VaQ+fC1w1v068/BRVs/De/8BfU4Pgyy5D3LvvgB8c3DKfz4GV8yi2rSE4cOjM4BIfARi02BbUOZxH+GztDODkDkAgAW75DEgdc9FTxfVtPUrzLNjywTG6aOMLebjiphT0uurc1JfTudSGl16CK5e52ytJS0Pk/PkIGXJZu/9M27JvvVYrSp9fAuumTbQd1L8/tCtWQBwbA7bD6nDjya8PYctxA21PGRCLJZN7Qipq/9h7JuweO7YXbMd3md9hX9k++Gv9XIOEQRiVMIomOwZFDQK/FR08vF4fpapQEdLaRAehspwOUrkRHiejlRxUnyNZSa1mOwOcrnKU6L+FTv8lHI7iuu1q1RBKgwkPH0XFUc8EoauYzf+gsrIAKlUC1OrB4PEEdS4zBYXvo6DgHfh8LvB4YiQm/AcJCfc1qaKEQweMx14PsG0hsPstpp02DrjhPUBan7iv2b8fRffcSxPSwQMHIu69ldRZi0PLgG3zKLatIThw6MzgEh8BGLTYFtQ5nAGHBfjiFqBwNyAKAaavBZKGN+o0cX17xqmsduPX1SeQd4ihvnTpF45rCPUl+PyceWIdaF77FcrefBM+K+OYIR89GhFz50AcG9tuP9e26tuaffugnzMXbr2eCB1Q5xvNvfe2m4Bpc8/Vyp0n8fIvGfD5gR5aBVbOHIC40GBWHNsB4wGGypL/C6rd9bSRgZEDqW4HSXqEkLHfCiCioyQpyOhzWGDIs8DjYrRDTkEo4iOyCxEiVUGbrKKPxdLA6f/WAHFaIZUZhAZTXk7uyDPnTCzWQBs9BVrtrQgKYuKD0UioK8/XUVcIJJIopKY8B4EwBJmZC2G3M1U9oeorkJa2mFrrcggctHo8Pvgl8MMjgNcJhKcD074EQuurjAj1sPDue6idOElMx73/PgQyLvnREmDbPIptawgOHDozuMRHAAYttgV1Dqeh2gR8fiNQchCQKoEZ3wFxgxp9iri+Pfc5ObyjGH99l0MFGBUaKUbf3RORiRfW8PCYzSh/802aBCGCnsTyNvSOO6C59552ubvW2n1LEj5l77wD03vvMwKmcXGIeXkFtasNVOzKKcfDXx5ARbULyiAR3ri1L65Oi2iXY9Hb9JTGQv6KqorqtsfIYjAmZgxu7n4z4hRxrWL5TKo4KHUluxJlRTbqfnSmEOkpS1lS0UEckYhAMIdzw+HQQ6//Gjr9V3C5jLVbeQgLG0FdYQoK3mNcOi4AsTgCqSnPICJiHHcdDkC0ybW2eB+wdjpgKwWkKmDKJ0Dy1XVP248cQeFdd9MEPYnTcR+8zzrtpUAE2+ZRbFtDcODQmcElPgIwaLEtqHOoRVUpsHoyUHYCCNYAs9YD0b2bdHq4vj0/DPlW6vpiLXeAL+Dh8hu7ovc1sRcdA47MLBiWLUPNnj20LQwPR/gTj0M5cSJ4p3GvWxut2beuwkLo5syB49Bh2lZOnozIZ56GQHZpdp5sgL7SjvvX7MehokqQ0/bItSn47zUp4LeB8GaNuwZbC7bSZMc/pf/UbQ8WBlOB0knJk9Avoh+qrFUt0q/kN1JlaihEai6tOWs/mVrCVHOkMMmO0KjAEyJlA3w+N63+II4wFeY/G/262NjbkNzlMQiF3CI1UNFm11prCfDVTED3LyNwPvpFYMj9oMGMJD+OHkPhXXfBZ7FA2rs34ld9wDph7kAD2+ZRbFtDcODQmcElPgIwaLEtqHMAUFkIfDoRMOcB8mhg9vdAeGqTTw3XtxeGs8aNHZ9lIPdAGW0n9dHgmtndIA0RXfS82rZvpwKo7iLmbj2ZZEYtmN9mFRGt0bf0PTdshGHJEvhqasCXyxG9eBEU48ahI8Hp8WLJpuP4fE8hbV+dFo7Xb+kLVXDL61QQy9l9hn3YmLMRWwq2UB0PAh54GBw1mFJZiBVtMHFuuMR+JZUbFSXV0GdXMvayOZXUzvlMqKNDGCHS/2/vPsCbqt4/gH/TJN17l5aWUvZeIgj8RDbIEgVlI+DeE8SJ/hUniqAiKDIFBNkqoKAoiOy9aaEtdO89Mv7POaGlhQIttCS5+X587tPe5DY93kNumjfved9LWR3uPuwEUd3y8s4hMmo6kpJ+veGxbVovgZdXh2ofA90+t/W1VhQ6Fy3tD/1o2m85Auj/OaA11YMpOHECMQ+Phz4jA45NmyL0+++g9rT8jlaWytL+jrK09xBEtoyBDyu8aFnaRd3mpZwFFg4Csi4AnmHAmLWA982t9+bcVu4cHd12EdtXnoFBZ4SrtwN6T2yGwLoeN/xZQ1ER0hYsQOo3s2WgQPAYNBB+L74IbUBAjf5Tru651WdmImHqVGT9+pvcd2rXFsEffwxtLeW20Fy57wJeX30EhToDans74ZuRbdEs+MbzXhmxWbFYF7UO6yPX42LOxdLbQ91CZZHSAREDUMu11i3Nq15nKkQqAx1i6UpkJgrzdOWOEZksfmFupiBHhAh2eMDJ1TYKkZpbQsI6HDv+wg2Pa9rkcwQGDrwtY6Kacdtfa41G4L9vgM2vi4gnENwOeGgJ4BYo7y44dQox4x6GPj0dDk0aI/T776Hx8qr5cSmQpf0dZWnvIYhsmVkDH4WFhZg6dSo2b94MR0dHjB8/Xm4V+f333zF9+nQkJCSgUaNGeOONN9C0aVNcuHAB3bt3r/BnFi9ejDvuuANHjhzB+++/jxMnTiAwMBBPPPEEBg8u31/dmi5alnZRt2mJx0zLW3KTAN8GpqCH+82/8eTcVp54A7lx7lFkJefLN4sd7otAqx6Va31anJSE5M+/QObq1XJf5eQE38cehfe4cbBzrJmuDNU5t7m7dyNu0mTo4uNlAVO/Z56BzyMTLaZ1b006FpcpW97GpuXDQWOH/xvcDEPb3VxtDVGYdPP5zVhzdg32J+0vvd1V64redXrL7I5Wfq2uO1/Xm9eiAh0SokQmR6YMdojlWvriKwqR2tvJoJ2p44oHAsI9oHVQ/jxaovT0/7D/wMgbHseMD+tnttfayD+BFeOAggxTduiDS4CQtvKugtOnTZkfqamyI1noD/Og8fa+fWNTCEv7O8rS3kMQ2TKzBj7ee+897NmzB9OmTUNcXBwmTZqEDz74AH369Cl33JkzZ3D//ffj3XffRZs2bTB//nwZLBHBEHt7e6SlpZU7/sMPP0R0dDSWLhXt6wrQs2dP3HfffRgxYgQOHDiAKVOmYMGCBWjb1vRiY20XLUu7qNusi/uARUNMf8AENgdGrQZc/W7pITm3VVOUr8Ofi0/i7D5TgcI6zX3QfWwTOLpef+lL2eJyie9/ICvsC9rgYPi/8grceveq9udWdcytLGA66yukzpkjP0HUhoYi+NNP4NSiarVkrF1mXjFe+Okgtp40zfuIO0Px9oAmcNCoK7WUZVf8Llm344/oP1CgLyhdytKxVkeZ3dEttJtsSVvVec3PLr5Un8PUVjYlNlt+0FuW+LcpMjlM9Tk84VvbFWo1C5FaAtHCdse//0NhoWilXNGfRirZ3aXTXdtKW9uSdTLra21qpKnoafJJU7v7ATOAVsPlXYWRkYgeNw765BQ41K+P0Pk/QOPjc3vHZ+Us7e8oS3sPQWTLzBb4yMvLQ4cOHTB37lzceeed8ravv/4aO3fuxKJFi8odKwId69atw6pVq+R+Tk6ODFqsXLkSzZs3L3fs/v37MWbMGKxduxYRERE4ffo0vvvuO3z00UelF0ARBOnXrx8eeeQRq7xoWdpF3Sad32FqWVuUDYTcAYxcATjdeloq5/bmztmxf+Kw/aczcimBKPwour6IN5eV/fmsDb8g6bPPoEswta90vuMOBLw+BY6NGt3EiGrmeVt0/jwuvvIqCo4ckfse9w9B4JQpZulQYwkMBiNm/XkWn/9xWgYXWoZ44JtRbVHLs+KARXRWtKzbsT5qPRJyL7cpreNeR2Z29K/bH4EuprTzSv+7ScmXmRzRx5ORGpOHjCRTPZCy3HwcZacVsWRFBDq8Ap153bZgopXtkaNPXdor++eR6TnbvNlX8PfvbZaxUfUx+2ttYTaw6jHg1C+m/Y5PAz2mAmoNCqPOIWbcOOiSkmBfLwJhP/wgi3KTlcythb+HILJlGnP94pMnT0Kn06F169alt4lgxuzZs2EwGGBXptuCp6cnzp49i3379snjRQDE1dUVoaGhVz3uZ599hmHDhsmgh9CgQQN8/PHH8nvxuH/99RfOnTsnl8AQ3ZSzfwDLRgGi6GGdLsDwZYCD9XfPsFbiD5tm/wtGQLg7Ns09isykfKz+bD86DKqL1j1Db9jtQvy8x4D+cOveDanffY/U779H3p49ODfkfngOHQq/5541a7qx/CNu1SokvP8BjKKAqbs7gt6dCvcrMuNsjVje9Gz3+mgR4oHnlh3EoQuZ6D9zO2YOb41O9XzlMdlF2dh0fpMMeBxMNmX1CG72buhbp68MeDT3bV6pP45FoCX1Yo7M5CjJ6sjLLCp/kArwqeVSrrWsq1fNLJ2imiGCGiK4cfrMuygsvBwgE5keDeq/yaAHVQ8HN+DBxcBf04C/PwZ2zgKSjgMPzIND3XCELVqI6LHjUHQ2EtFjxiJ0/nxoA8zTypuISCnMlvGxadMmuXRlx44dpbdFRkbKTAyR9eFd5o1GUVERXn75ZfkzIloqgiLffvstOnXqVO4xRWBEZHts3boVAVcUKhSPIZbJFBcX46GHHpK1RaoarW3ZsqVFRGstLZptU06sB1aOh8pQDGP93sDQ+YC2+joscG5vjaipsG3JKZzZa1oCEdrUG93HNoaTW+WLQxZfvIikTz9D9saNcl90SvF98kl4jRgOlb39bZ1bUeU/4Z13kL1ps9x3bt8eQR9OgzYo6KbHoUSxaXl4csl+HI3Lgp3KgGFdCmBw2YOtsVtRqDd1SbFT2eGuWnfJFrRda3eFg0gxvw5RiyMpOqu0rWxCVJZcWlWWaKvsH+YGrxBH1Gnqj6AIzxt2GCLrWfaSnr4HGRnn4elZB15ed3B5i4JY1GvtsTXA2iehKs6D0bsu8NBSwK8himJjETN2nKzlpA0Lk8tetIGVz0qzVRY1t5feQxw6dIgZH0S2HPhYs2YNZsyYgT///LP0ttjYWPTo0QPbtm2TRUhLJCYm4vnnn0f//v1l8EHU7vjnn3+wevVq+JRZ+yhqhIiCqV988cVVv08EPkStkKioKBlwefLJJ/Hwww9XKfARHh5eLhPFXMSUiaVCzs5Mmb6dtCdWwXnzy1AZ9Siqfy/y+nwBqKu32wLntnrOYeSeVOxdFwu9zggndy06Dw+Hf3jVsnKKDh5E5vTPoTt9Wu6rw0Lh/tzzcLyr42153hbu24eMqe/CkJQkC5i6PfYoXEaOtIkCpjfjdHoU3t2+DOcKd8BOm1V6ex23Ouhbuy96hfSCr5MpE6QiRQV6JEfnIPlcDpLO5yD1Qp7sGnRlIVK/MBf41XGV/558artArVHxeqxQvB4rl6XNrV3ycbiuewR22RdgtHdFbp8Z0NXtAV1cPNKeegr6+Hiog4Ph89UsqBn8sKq5FdnmItOcS12IbHipi4ODgwxGlFWyLzq8lPXpp5/KJSsjR44sLYrat29f/Pzzz3j00UflbWLZzJYtW0qXtVxJFEEVXWDElpSUJOuIVDbwUcLd3d1iMj4ES4lm24S9PwCbXoQKRhhbjYB2wEx42FX/vwXObfVo29MTYY0DsPm7Y8hIzMMfc06j/YBwtOkddsOlL6Xuvhu+nTsjc9VqJM+YAX10DNJffBEuXbrAf/IkONStWyNzaywqQvLMWUj7/ntTAdOwMNQSBUybNavS77MFWYVZ+O38b7JQ6ZEUU+0TOy1g1DujOLMl/NAJH/ccjEZB7lf9bG5mYemyFfFVLGO58mMAJzdtuWUrPsEusLuiECmfs8rFuVUui5tbj47AY3/BuGIsVNE74LJuItDtDaDzi3BftFB2eymOjUX6U0+j9oL5sA8ONveILZalza348JSIbDzwIZaipKeny4CFRmMaRnJysgx6iABDWceOHcPo0aNL90XWhWhpKzrBlBAZGeKxrlz+IrJIzp8/jy5dupTeVq9ePfm7q0pcQC3hIlp2LJYyHkX7dyaw+Q3T9+0fharPR+IfYY39Os5t9fCr7Yahr7XD30tP49SuBOxad04uW+gxrgmc3SuXqaPSaOA1bCjc+/ZByjezkbZoEXL/+QfnxHK8kSPg+9RTUF9xvbqV560oahf3yisoOHZM7nsOfQABr70GO2fnSv8OpdMZdPg37l9Zt+PP2D9RbCiWt6tVanQJ7oKB9QbCCy3x3NKjuJCRjyHf7MS0Ic3QtZb3pW4roj5HpmyDfCV3PyfZUtbUWtYTHv5OlbrG8jmrXJxb5bK4uRVd4casBTZOhmrPd8DW94DEo7Af9BXCFi6Q3V6Ko2MQM2YMwhYsgH3tm2vjbQssaW4tYQxEZObAR+PGjWXAQwQs2rVrV1qjQ3RpuXI5ib+/v6z/UZZIGyvb0UWsnxPZHCKTpKzDhw/j7bffxvbt20szSY4ePYq6Vfy0lmyQ+NTgrw+BbR+a9ju/CHR/S7yKmXtkVEn2jhp0H9cYwQ09ZQAk9ngalr+/G73GN0Vww8p34VG7uSHg1VdkECTxo4+R8+efSFuwEJnr1sPvuedkgOJWlqCIT6gyVqxA4rQPYczPh9rDA4HvvQv3Xr1u+jGV5kz6GZnZsSFqA1LyU0pvr+9VH4MjBqNf3X6lS1lEIdIF97XCtyuPozAhH6fnnMJF4xXPWxXgG+Iq63KUZHS4eF6/7gcRUY1Sa4F7PwMCmgG/vgwcWw2knoX2oR8RtnChrPkhOnyJgqdh83+AfVgYJ4SIyNIDH05OThg8eDDeeecdfPDBB3L5ybx58zBt2rTS7A83NzcZrBBdWiZPnoxmzZrJri4rVqyQ2R6iLW0JUb+jpJNLWV27dpWP89Zbb+GJJ56QQQ/R3vaTTz65rf+/ZIVBD5HlISqtCyLg0eUlc4+KbvLTlsZ31YJ/HXdsmnMU6Ql5WPvFAdzRPxxt+9aR3UEqy75OHdT+5mvk/LMdiR9+iKLISFl8NH3pUgRMmQKXO9tXeXy69HQkvPUWsn//Q+47d+iAWh99CO0VBZptUUZBBn499yvWRq7F8dTjpbd7OXjh3rr3YmDEQDTybiQLkSaez8Les6asnoSoTBQX6FFHHm0KSOlgRI6LHe5sXwv1m/oiMMIDDk5mewkkIrq2dg/LAqdYPhpIOALMuQfaYQsRunABYsY9jKKoqEvdXn6AQ3g4zyQRkSUXNxXy8/Nl4GPz5s2yPe2ECRMwbtw4eV/Dhg1lEGTIkCFyXwQ7RGAkISFBZou8/vrrMsOjxMSJE+XtL7109ZtTkS0i6oKIrBAvLy8ZABk6dKjV9uC2tIrVimPQA7+8COybb9rv+zFw52O35VdzbmtWcaEefy87hZM7TW0qQxp5ocfDTeDiUfVP+o3FxUhfugzJs2bBkGUqpunWqxf8X30F9iEhlXre5u7cibhJk6ETBUy1Wvg//xy8H34YKgsoomwuYunK9gvbZXbHXxf+kktbBI1Kg/+F/E+2oG3v1QEp5/IQH5mBuDOZsvuKQV/+pczeUY3ACE/Uqu+BixoD3vr7DDKKdPB1dcBXI1rjzrqXC2PfCj5nlYtzq1xWM7cZscCyEUDCYcBOI/8e0YUPksteRKtbjZ8fQhfMr3LNKSWztLm1tPcQRLbMrIEPa2FJFy29QY99ifsQkxqDUJ9QtA1oC3UNFNm0WXodsOYJ4MhPgMoOGPAl0OZyfRlbe8FWqpP/xWPbj6egKzLAyd0ePcc3Qe1Gl1toVzVjI2XmTKQvWy7WWMiWtyJ44fvoI7BzcZHHGPV65O7di+zoaLiFhcGpRQukzJqFtHk/yOwi+/BwUwHTMsFcW3Mq7RTWnF0jMzzSCtJKb2/s3RgDAu5DM117ZEXrZI2O1Lhc4IpXLmcPe7lcJehSjQ6fYNdy2TznUnLxxOJ9OJmQDbWdCq/1bYQJncNv+XnG56xycW6Vy6rmtigPWPsUcGyVab/deOjav4qYiY+j8PRpqH195bIXh3r1zD1Si2Bpc2tJ7yGIbB0DH1Z00foj+g98uPtDJOYllt4W4ByAye0no0dYD7ONSzF0hcDK8cDJDaZPVobMAZrdb9Mv2EqWFp+LTXOPIk28iVYB7frVwR33ipbVN3feC06dRuK0acj77z+5Lz6J83/5JagcHWXtDl2CKcvEdKdGtKKS33o++CACJr1qkwVMU/NTZaBDZHecTDtputEIhBnqo5t2AMLyGiE3xojs1IKrftYzwBlBEZcKkdb3gLvvjQuR5hXpMGXVEaw5aCqMfW/zIHz0QAu4Otz8khc+Z5WLc6tcVje34jPK7Z8DW969dJHsBF2vGYh56lUUnjwJtbe3XPbi2KABbJ2lza2lvIcgIgY+rOaiJYIeL/71omimWu52lXjHBmB61+kMftzqJyrLRwKRWwG1AzBsIdCwD2z9BVvpiov02L78NI7viJf7wQ080XNC05ta+lIyfzlbtsgCqKL14I34PDIR/hUsz1OyYn0x/r7wt6zb8c+Ff6A3GOCbG4KQ7PpoWtweHumB0OeV/xnxVPCt7VZahFQEOyrbmaeiOVr0XzTeXX8cOoMR9fxdMXtUW/n1Zh+Pz1ll4twql9XO7elNwM8TgcIswKM29Pd+i5jJ01Fw/DjUnp6m4EejRrBllja3lvAegohMmPFhBRctsbyl98+9y2V6XCnQORAb79/IZS83oyAL+PFBIOZfQOsCDP8RqNsV5mBpL9i24vTuBPy15JSsAeLkpkXPh5uidpObW/oiGAoLkfrDfKTMmGH6pO4aNIGBqLflj1vqCGMNxL/rE2knZAvaTWd/h0OqJ4KyIhCUXRdBOXWh1mvLHa/W2iGgjjtq1TctXQkM94B9NRci3RedhieX7EdiViFc7NX4dGhL9G0eVOXH4XNWuTi3ymXVc5t8Clg6HEiLBDROMPT6FNGfrEPBkSOyI1jted/b9LJJS5tbc7+HIKLLGPiwgovWnoQ9GL9p/A2P83X0RW332vBz8oO/sz/8nP3Kfe/v5A9X+5v7VFOx8tKAxUOAuAOAgwcwaiVQu+qdOZT6gm1LMhLzsHHuUaReyJFLX9r2CUP7/uGwU99codHcXbsRM3bsDY8LXbDgprrBWAPRdnbDsd/w7/4DMMY7ISg7Ar65taE2lr+OOjhrSpetiM0/1E0GP2pacnYhnv5xP3adM9UUefR/dfFq74bQVGHO+ZxVLs6tcln93OanAysnAJFb5K7hzmcRM/808g8dhp27O0K//x5OzZvBFlna3Jr7PQQRXcZeflYgOS+5UselFKTI7XqcNc5XB0WuCI74OvvCSeMExctOBBYNBpKOA84+wOjVQFBLc4+KzETUjHjg1bbYvuIMjv0Th32/RSPuTAZ6TWgGV6+qL33RJSdX63HWIi05C1t378KJY9FQxTvDKz8YLRFc7hgXz5JCpKI+hye8g1ygusnaKrfCz80BSybeiY83ncKcv6PkdvhCBmYObyPvIyKySE5ewMgVwB/vAP9+CbtdXyKsf0/EaJohb99RxIwfj9Dv5sKpJf+mISIqwcCHFRABicqY0n4KfJx8kJSXhKT8JBkwEVvJ9znFOcjT5eF81nm5XY+bvZsMgshgyKXgSMn3chMBEidfaNXlU9SthmgRt3AgkBYFuAUBo9cA/ra9LpYAjb0aXUc2QnADL/y55CTiz2Zi+fu7ZcvbsKZVa38qiptW53GWyGgwIi0hVwaIRKBj58BEAABDCklEQVQjMTILdrkiYKCGNy63V1R76xDeMBB1GvrJYIebj6NFfBIniOyOKf0ao1VtT7yy4hD+i0pD/5n/4OuRbdE2zMvcwyMiqpjo6NfrPSCgGbDuGagif0fonfVx0b4hsneeQsz4Cag9dy6c27TmGSQi4lIX66rxIQIaVxY3LSlwKrq73KjGR15xHpLzk+XjyKBIme9LgiNiv0B/dQeFa/F29C4XFKkoi0QcoxFdUixFaiSwcBCQGQt4hgJj1gHe4bAElpaiaetLXzZ9dxQpsTlyv03vULQfWBfqSi6DEC1sz3bvAV1iYsV1PlQqaAICrKrGh15nQHJMNuLOZsigUNzZdBTl6csdY4AeGe6J8AzTol3rpmjVvAGc3G6uEOntdjYpB48v3ie/atUqvHFvE4zpGHbd5yKfs8rFuVUuxc3txX3AspFAdjyMDh5IOt8UadvOy25htefOgXPbtrAVlja35n4PQUSXscaHlXV1EcoGP6q7q4t4wcguzi4NglwvUKIzmNpx3oidyg4+jj7lltNcFShx9oOng6c8tkYlHjcFPXKTAJ/6wJi1gEf5NHxzsrQXbFunK9bj35VncWTbRbkfWNcDvSY2hZu3Y6V+PmvzZlx87nnTTtngx6W5DZ7xBdx79YKlKirQITEqC3GRItCRIb/XFRvKHVNsV4RE1/NI9ohGcH0v9GjfCXeFdrDaQss5hTpMWnkYvxwxdfoZ3KoWPhjSHM72FQdv+ZxVLs6tcilybrMTgOWjgQu7YVTZIT21KRI3p0Dl7ILas7+BS3tl1pKy9Lm1hPcQRGTCwIcVXbRE8OPD3R+W6+4iurlMaj/ptreyNRgNyCzMLA2OiGCIGFfZ7BGxiZoj4tjKEFkhpdkjFQRHSgIkblq3m3sxu7jfVMhUFAULaG6q6eFqWcsMLO0Fm0zO7kvCn4tOoKhADwcXDXqMa4I6zX0rHfxI/GAadAkJ5bq5BEx5zeKCHvnZRZcyOUyBjuTYHLmcpaxCTR7i3CKR4B6JeLco1A73xYD6A9CrTi+5RE4JxPPw++3nMO23k9AbjGgU6CZb3tbxdanwWD5nlYlzq1yKnVtdIfDLi8CBxXI3JzcMF34pAuydTMGPDh2gdJY2t5byHoKIGPiwuouWWPayL3EfYlJjEOoTirYBbS36k1Ux3rSCtHJLaUoCJWUzSsQxleWodqywY82VgRJnrfPlH4r+F1gyDCjKBoLbmbq3iOJgFsbSXrDpsszkPGyae0wu9RBa9QxFh8GVW/oilr3k7t2L7OhouIWFwaVdO7Mvb5HZXakFpiDHmQzEnc2Uy3uu4lqMOLezOON0GAlukUh3SkKQayAGRgyUW6h7KJRqV1QqnvrxAFJyCuHmqMH0Ya3Qs0lAuWP4nFUuzq1yKXpuRXbhrm+BTVPEiw8Ki7wR86sWeqMzQr7+Cq6dOkHJLG1uLek9BJGtY8aHFV60LO2iXh2K9cWy9eWVAZIrl9lkFWVV+jFdtC6mTBFo4Bd3BH7FRfD3CINfp5fg7xFaml3ioLac7g1KnFsl0Rcb8O+qszj85wW5HxDuLpe+uPs4WfzcisyN1LhcmclRUqMjN6PwquM8g5ygC8jCUe0e7NBvRrZDurxddHrqGdYTgyIGoV1gu5pflmYhErMK8OSS/dgXbToPT99TDy/0bAD1pS405p5XqjmcW+WyibmN+gv4aSxQkAG93gkxW11QmO2KkK9mwbVLFyiVpc2tpb2HILJlDHxY4UXL0i7qt1OBruByxkiZIMmVS27ydfmVfkwPB4+KW/te6l4jvhfdcrR2Nd/Bxpbn1ppEHUjGloUnUJSvg4OzBt3GNEbdVn4WNbciSJMUnYX4SNPSlYTITBTmla/LY2engl+YG4IiPJDvl4bt+s3YmPALcotzS49pF9AOg+oNkkEPEUy0RUU6Az749QTm/2vqhtWlvi9mPNQa3i72fM4qGK/HymUzcys61y0dASSfgNFoh/hd7si66IGQWTPhevfdUCJLm1tLew9BZMsY+LDCi5alXdQtkXjjlnRgAZL/fBdJdiok12qBpHpdkVyQWi5YUmQoqtTjiSKyojtNSVDkWstsvBy8bmnpEefWemSl5GPT3KNIijYtfWnZrTY6DomAWmNnlrkVQZiEqJL6HJlIPJ8lgx9laRzUCAx3R636nrKtrMEvF7/GbsC6yHWIzY4tPS7YNVhmdgyIGIAQt5BqH6u1WnvwIib/fAT5xXoEezrhm1Ft0DzYg9djheL1WLlsam4Ls4HVjwMnN8jd1FMuSDrmg5AvZsCtWzcojaXNraW9hyCyZQx8WOFFy9Iu6hZp7w/AhhdkDxy0HAEMnAmoNVedR7F0pqKWvmWzSlLyUqAzVq6DjVqlltkhor1whW1+LwVKRJZJRXPHubUuor3rztWROLTFFDTwD3ND70eawd3XqcbnNi+rCHFnTEVIRbAj9ULOVV1zndy0CIoQQQ4PGezwDXFFgaEAf8T8gbVn12J3wu7SY501zrJAqQh4tAloYzNLWarqVEK2bHl7LiUX9mo7TB3UFH0buPN6rEC8HiuXzc2twQBs+xDY9pHczUlwwMVdvgj6eAbce/aEklja3FraewgiW8bAhxVetCztom5x/p0FbH7d9P0djwB9PxY5/Tf9cKIrTXpBevl2viJj5IpASWp+arlWw9cjls2UBESuKspqcEa4X7j8Xiwt4BxbvnOHkrFlwQm5lMTeSYPuYulLa79qe97Kn03OvxTkyJRfM5OuXs7l7usoMzlq1TMFOzwDnOXvEv+GRVFkEezYHL25dCmYyGRqH9ReBju6h3YvXxCYrimroBgv/XQIvx83ddga3MIf0x5oDadrtLwl68TXWuWy2bk9vhbG1U9AVZyLomw1Yv/1g9/bM+Depw+UwtLm1tLeQxDZMgY+rPCiZWkXdYshPu7e9jHw1wem/U7PAz3eAW7TOdIZdDL4US5AUhIcKdPiN73QVCSxMkRByXIBkgq614h9cRyZV1ZqPjZ/dwyJ50wFeJvfE4JOQ+pBrbWDwWBE3Jl0pMRnwDfIE7Xqe8n6GtcijhcZHPGRGYg7Ywp0iAyPclSATy1X1KrnIYMdYnP1Kl+oNzYrFuui1mF95HpczLlYenuoW6jsyCKWstRyrVXdp8ImiDma/XckPt10CqLjb7Na7vhmVFvU9mbwSCn4WqtcNj23CUdhXDYcqowY6ItViNvtA/fnv4THvfdCCSxtbi3tPQSRLWPgwwovWpZ2UbeYoMfvbwL/zjTtd3sT+N/LsERF+qIKW/qW7CfkJCCtMA3ZxabaEZXhpnUrV5S1okwSXydf2Kvta/T/zdbp9QbsWhOFA7/HyH2/UDc0visI+zZGl+ug4uLpgC4P1kdEa3+5ryvWI+l89qX6HKZCpEUF+nKPbadWwT9M1OcwBToC63rA0UVbYX2bzec3Y83ZNdiftL/0dletK3rX6S0Llbbya8VrRzX550wynv1xP9LzdfB01uKLB1uha0PTvJJ142utctn83OamwvjTGKiit8vzkXTEHQ5jv4LHwIGwdpY2t5b2HoLIljHwYYUXLUu7qFvE2tVfXwL2zjPt9/kQ6PAErFHZuRXLEWSL3wqCI2WX2RToCyr9+KL4qizOWjZ7xMnf1MHmUuBEFHHV2DFl/1acP5KCLfNPoCC3+LrHhbfyQ0F2ERKjs2DQlV8mpXVUI6iuKcghgh0i6KGxr/j6I5ayiHodYinLH9F/lP6bEEtZOtbqKJeydAvtBkeN4y39f1HFz9mTMUmYtP4MDl/IlAlmL/RoINveXi+rhywfX2uVi3MrW3/BuPE1qPbMleckK8YJhn4z4PnAg7Bmlja3lvYegsiWMfBhhRctS7uom5VeB6x9Cji8zJT7P/BLoM0Yc4/qts2tOD6nOKfC4qwlgZKS74sN138TXkIUtfRx9CkXHKlomY2XoxcLYF5HZko+fnz7Pxj0lav74uRuX7psRdTo8AlxveEb5+isaBnsWB+1Hgm5CaW313GvIzM7+tftj0CXwEr9frq156yjiyve3XACP+4yZft0a+SPz4e1godzzbfBpprB11rl4tyWORd75wPrX4BKZUBBuhZFHd6H+/DHYK0sbW4t7T0EkS3jx7pkvXSFwM8TgBPrAZGhcN+3QPMHYEvEi7qbvZvc6nrWvf4fAoWZSMxLvPYym/wkWaNEb9SbjslPxnEcv+ZjiqyQa9UeKXubu727RfzxcbvlpBZUKujRqmdtNO0cDA9/p0qdp+yibGw6v0kGPA4mHyy9Xfwb6Funrwx4NPdtbpPn3JwcNGp8cF9ztK7tiTfWHMXWk0kYMGu7bHnbtJaHuYdHRFQhVbtxMPo1hP6HIXD0yoPm0GRk5yfBbfybPGNEpCgMfJB1KsoDlo8CIrcAagdg2AKgYV9zj8piiTfBno6ecmuIhtc8Tm/Qy+KrFbX4LRsoSStIk8Vc43Pj5XY9DmqHcoVYS74vXV5T0s1GYR1FcrMu1/S4HlEHRHRfuR4xL//F/4e1kWuxNWYrCvWFpdk5nWp1wsB6A3FP7XvkuSbzGtquNhoHueOJJfsQk5aHIV//KwMi97cN4dQQkUVShXWE3fO7UTyjO7SOiXA9/ylyv74Ilydnm3toRETVhoEPsj4FWcDSh4DoHYB4szx8KVC3q7lHpQhqO7Usgio2+Fz7OLFsRmSHVBQgKc0iyU+WWSbiTfqFnAtyux7RurdsgKSiZTbifmupU+Hi7nDLx0VlRmHd2XVyKYs4pyUiPCJKl7KI80KWpVmwB9Y/3RnPLz+Iv04l46UVh3AgNh1v9m8iM0OIiCyNyrM2NK8dQP6HPeGEY3BJWoqC6bFwfHY1oGFhdCKyfgx8kHXJSwMW3w/E7Qcc3IGRK4DQDuYelc3R2mll7Ygb1Y8o0BVcXlpTpqXvlYES0YmkZDufdf66j+nh4HE5QFJBoETs+zj5yDGaU1B9T9m9pWw3lyuJ9rPiuLJEsGjjuY1YF7kOh1MOl/v/FktZBtcbjCY+TbiUxcJ5Ottj3tg78OXWM5ix5QwW/xeDIxez8M3INqjlyfbTRGR5VPYucHxjO3I+fAAuhVvgmLUdxZ/cCe0zmwFXBtmJyLox8EHWIycJWDgYSDoGOHkDo1cDtVqZe1R0HSI7o7Zbbbldjwh4lC3Eeq1lNiJ7RAQGxHY24+w1H090MxHFV68KjojlNWUCJKLLjchyqQmiMKloWbvx26PXPKbzsPryOLFs6N+4f2Xdjj9j/ywtRKtWqdEluItcynJ3yN1sR2xlxNw+36MBWtb2xPPLDuJQbAb6z9yOmcNbo1M9X3MPj4joKio7O7i89jMyP30Kbuk/Qoso6D9vB/XEdUBQS54xIrJaDHyQdciIBRYOAtIiAddAYMxawL+RuUdF1UQsc3HxcEEdjzrXLdCaVZRVPnukgkCJ2HRGnaxDIraTOHnNxxSBBZEdcmVx1ivrkXg6eN5UhkVEa3/UGmLA2V9y4FzoXnp7nkMm6t3rBkOdTHy2dxE2RG2QrYtLNPBqIFvQ9qvbz7TsiKzaPQ39seGZznh88T4ci8vC6O934ZXejfD43XWZuUNEFke83nm8/BXSZ/jBJWYmHNwzYPy2O1QPfAs0u9/cwyMiuikMfJDlS400BT0yYwGPUGDsWsD72h1MSMF/iDl4yK2eV71rHmcwGpBRmCEDILKLzTWW2aQWmDrYlGSUIPXav1ssmynXseYay2xcta7l3sj+Ef0H3o5/EWgNBGVFwLnYHXnaLMS7R8IYbwTWXf4dIvvk3rr3ytodjbwZ1FOa2t7O+PmJu2THl5X7LuCjjSdxMDYdnwxtCXdHtrwlIssiXsu8n5+KlFnuKD78EVxrFQIrxwMJR4FubwA1lC1JRFRTGPggy5Z0whT0yEkEfOqZMj082B2Brk10OvF29JZbQ+9rd7ARy0tERkhFRVlLAiZiE11uxNKTizkX5XY9Thqn0uCIn6Mf/r74N4wwirU3iPOoeGnOPSH3YHD9wXJJi1bNN8BK5qhV45MHWqBNqBfeWXcMm44l4nTiDswe1RYNA93MPTwioqv4Pv0SUma7oODP9+DbOAfYPh3GxGNQ3T8XcGSrbiKyHgx8kOWKOwAsGgLkpwEBzUw1PVz9zT0qUgiNnaa0pW5TNL3mcUX6IrkMpVxwpIJlNtlF2cjX5SMmO0ZulTW66WjcEXhHNf1fkTV8ijrizlA0reWOJxbvw7mUXAz+agc+vL85BrUKNvfwiIiu4vv440jVanHxp3cRdEcG7M5sgvG7HlANXwb4RPCMEZFVYOCDLFP0TuDHYUBhFhDcFhi5EnD2NveoyAbZq+1Ry7WW3K5HBD1S8lJM2SL5ydgWuw2/nPvlho8vAidke0TB0w3PdsGzSw9g+9kUPLfsIA7GZmBKv8bQqu3MPTwionJ8JkxAqlqN6G/fQ0iXNGhTTsM49x6oHpgH1OvBs0VEFo9/XZHlifwTWDzEFPQI62xa3sKgB1k4scyltntttAtsh77hfXF/g8oVgBPLYsg2ebvYY8H49njqHtMnpj/sOI/hc/5DUlaBuYdGRHQVn3Hj4PHkVJzb7Ie8ZC1UBZkwLhkK7PhSVCDnGSMii8bAB1mWk7+YMj2K80yfIIxcAThw7TtZnzb+bRDgHCBb61ZE3B7oHCiPI9ultlPJDi9zRreFm4MGe6PT0e/L7dgVdZ1qu0REZuI9ehR8X30HMX/6IiPSGSqjAfj9TWD1Y0BxPueFiCwWAx9kOY6sBJaPBvRFQOOBwEM/AvbO5h4V0U1R26kxuf1k+f2VwY+S/UntJ8njiHo1DcS6ZzqjYYAbUnIKMeK7XfjunyjZxpmIyJJ4jxiBgLffRfweDyTs84BRvKYdXg780A/IijP38IiIKsTAB1mGfQuAnycCRj3QcjjwwA+AxsHcoyK6JT3CemB61+mygGpZIhNE3C7uJyoR7uuC1U/dhUGtakFvMOL/fjmBZ5YeQG6hjieJiCyK14PDEPT++0g/64qYrd4wwBGI2w/M6QrE7jb38IiIrsLipmR+O78GNr1m+r7dBKDfp4AdY3KkDCK4cU/te7AvcR9iUmMQ6hOKtgFtmelBFXK21+CLB1uhdW1PGfjYcDgepxKyMXt0W0T4ufKsEZHF8Lz/fsBOjfgpUxC1Xo2w/i7Q5iQC8+8F+n8OtB5l7iESEZXiu0syH5HCve2Ty0GPTs8B937GoAcpjljOIlrW9gjpIb9yeQvdqOXtuE7hWPZoB/i7OeBMUg4GzdqBjUfjeeKIyKJ43jcYtT7+CMX59oj8WYt8fV3TkuW1TwG/TQb0zFgjIsvAwAeZL+jxx9vAn/9n2r/nDaDHVPEXP2eEiEgkwNXxxoZnO6N9uDdyCnV4fPF+TPvtBHR6A88PEVkMjwEDEPzpJzAatTi/Ih9ZRW1Nd+z6xtSlLy/N3EMkImLgg8zAYAB+eQnYMcO033sacPcrDHoQEV3B380RSybeiUe6hMv9b7dFYfT3u2UBVCIiS+Herx+CP/sM0GhxcVU8UvN7wKh1Ac5tA+beAyQeN/cQicjGMeODbi+R8rj2SWDv97K3BQZ8CXR8krNARHQNWrUdXr+3Cb4a0QbO9mrsjEpF/y+3Y39MOs8ZEVkM9z69Efz5dECjQdLa40hM7QmjZxiQfh74vidwYoO5h0hENoyBD7p9dEXAyoeBQ0sBlRq4/zug7VjOABFRJdzbIgjrnu6ECD8XJGQV4MFvd2LRzvNseUtEFsO9Z0+EfDkD0GqR/utuxEd1gDGsC1CUAywfCfz1kSnzl4joNmPgg26P4nxg2QjgxDpAbQ88uAho/gDPPhFRFdTzd8PapzujX/NAFOuNeHPtMbz00yHkF+l5HonIIrh164aQmV9CpdUic/M/uLA3FMZ2j5ju/OsDYMVYoDDH3MMkIhvDwAfVvMJsYPEDwNnfAa0zMGI50Ohennkiopvg6qCRy15e79cYajsVVh24iPu+3oHo1FyeTyKyCG5duyLk66+gsrdHzpY/cWFDLgz3fgHYaU0fgs3rbVoCQ0R0mzDwQTVLVPJeOAiI3g44uAOjVgER3XjWiYhuseXtI/+ri8UT7oSvqz1OJmSj/8zt+ON4Is8rEVkE1y5dEPLN11A5OCDnr79wYe5OGEauBlz8gcSjwJx7gHN/m3uYRGQjGPigmpOTBCwYAFzcBzh5A2PXAWEdecaJiKpJxwgfbHimC9qEeiK7QIeJC/fis82noDcYeY6JyOxcO3VC7W9nQ+XoiNy//8GFDxbAMHYTENQKyBcfjg0Gds8FjLxmEVHNYuCDakbmBeCHvqaIvmsA8PCvQK3WPNtERNUs0MMRyx7tiHF31ZH7M7eexbgfdiM9t4jnmojMzqVDB9Se8y1Uzs7I3bEDsZPeg2H4aqD5MMCoB359GVj/nKkIPhFRDWHgg6pfWhQwry+QehbwqA08/Bvg35hnmoiohthr7PDOwKb44sFWcNTa4Z8zKXLpy+ELGTznRGR2Lu3bI3TuHNg5OyNv53+IffoFGHp/DvR8D1DZAfsXmLKERbYwEVENYOCDqlfSSVPQIzMG8I4Axm8EfCJ4lomIboPBrYOx+slOqOPjjIsZ+Xjgm51YtjuG556IzM65bVvU/v472Lm4IG/3bsQ8/jj0LScAI1YADh5A7H/AnK5A3AFzD5WIFIiBD6o+cQdNy1tyEgD/pqZMD48QnmEiotuocZC7bHnbo3EAivQGTF51BJNWHkZBMVveEpF5ObdujdB538POzQ35e/ch9pFHoA/qADyyFfCpD2RdBOb1AY6s5FQRUbVi4IOqR8wuU4qiKFRVqw0wbgPgFsCzS0RkBh5OWswZ3Rav9G4IOxWwfG8shs7eidi0PM4HEZmVU8uWCJ03D3bu7sg/cAAxEyZA7xAAPLIFqN8L0BUAP08Afn8bMDBgS0TVg4EPunWRfwKLBgOFWUBYJ2DMWsDZm2eWiMiM7OxUeOqeelgwvj28nLU4cjETA2Ztx7bTyZwXIjIrp+bNEPrDPKg9PFBw6DBixk+AvhDA8GVA5xdMB+34Alj6EFCQydkiolvGwAfdmlO/AT8OA4rzgIjuwMiVgKM7zyoRkYXoUt8PG57tghYhHsjIK5YdX77ccgYGtrwlIjNyatoUoQvmQ+3piYIjRxDz8Hjos7KBHu8A938PaByBM5uBud2BlLOcKyK6JQx80M0T6y+XjwL0RUCj/sDwpYC9M88oEZGFCfZ0wk+PdcTw9qEwGoHpv5/GxIV7kZlXbO6hEZENc2zUCKELFkDt7Y2C48cR/fB46NLTgeYPmArkuwcDqWeAud2AM7+be7hEZMUY+KCbs38h8PNEwKADWjwEDF0AaBx4NomILJSjVo1pQ5rj4wdayPa3W08myaUvx+OyzD00IrJhjg0bIGzhAqh9fVF44gRixo6DLk3UjGsNPPoXULsDUJgJLBkK7JgBGb0lIqoiBj6o6v77Blj3DAAj0G48MPgbQK3hmSQisgLD2tXGqifuQoiXE2LS8jDkmx1Ytf+CuYdFRDbMoV49GfzQ+Pmh8PRpxIwdC11KCuDqD4xdD7QZa/q78/e3gFWPAsX55h4yEVkZBj6o8kSE/e9PgI2TTft3PQPcO11U0ONZJCKyIs2CPbD+6c64u4EfCooNePGnQ3hzzVEU6QzmHhoR2SiHunURKoIf/v4oPHMW0WPGojgpCdDYAwNmAP0+Bew0wJGfTC1vMy+ae8hEZEX4jpUqH/T44x1g6/+Z9rtOAXq+B6hUPINERFbIy8Ue88bdgee615f7i/6LxoNzdiI+k5+kEpF5OISHI2zRQmiCglAUFYUYEfxITDT9vdn+EWD0GsDJG4g/CMzpCsTs4lQRUaUw8EE3ZjAAv75iaism9Hof6DqJQQ8iIiuntlPhhZ4NMG9cO7g7anAgJgP9v9yOfyNTzD00IrJR9mFhMvihrVULRefPI3r0GBTHx5vuDO9iqvsR0AzITQLm32uqOycY9MD5f6A9uVZ+lftERJcw8EHXp9cB654G9swFoAL6fwHc9TTPGhGRgnRrFIANz3RB4yB3pOYWYdR3uzB7WySMLCJIRGZgHxKC0IULoQ0JQXFMjCn4cfHS0havMGD8JqDxQMBQbKo7t/gB4PNmUC0YAJeNz8qv+KIZcHwd54+IJAY+6Np0RcDP44GDSwCVGhgyB2j3MM8YEZEChfo4y6Kn97cJgcEIfPjbSTyxeD+yC9jylohuP/uQYFnwVBsaiuILF2Two+jCpULMDq6mjoL3vG7aP/s7kB1X/gGy4oGfxjD4QUQSAx9UMVEte/lI4PhaQG0PDFsItBjGs0VEpGBO9mp8OrQF3r+vGbRqFTYeS8CgWTtwOjHb3EMjIhsklruI4IdY/lIcF4foMWNQFBNjulMU1+/ykqnmR4Uutb0VRfm57IXI5jHwQVcrzDb1Sj+zGdA4AcOXAY3780wREdkAlUqFkXeG4afHOiLIwxFRKbkY/NUOrD90xaepRES3gTYwUC57sQ8Phy4uXnZ7EbU/pOh/gfy06/y0Eci6aDqOiGwaAx9UXn46sHCwqSiUvRswehVQrzvPEhGRjWkd6oUNz3TGXRE+yCvS45mlB/Du+uMo1rPlLRHdXtoAf1PmR0QEdAkJMvhRGHUOyEms3ANU9jgiUiwGPuiynGRg/gDg4l7AyQsYuw4Iu4tniIjIRvm4OmDh+PZ4omuE3J+34xxGzP0PSVkF5h4aEdkYjZ+fDH441K8PXVISoseOQVFWJTu3uAbU9PCIyMIx8EEmmReBH/oCiUcAF39g3K9AcBueHSIiG6dR22FSn0b4dnRbuDlosOd8Ou6duR17zl8vvZyIqAauRz4+CF0wHw4NG0KfnILzr34Jo7O/qfNghVSAezA/yCMiBj4IQNo54Ic+QOoZwD0EGL8RCGjCU0NERKV6Nw3E2qc7oUGAK5KzCzF8zn+Yt/0cW94S0W2l8fZG6Pwf4NC4MfSpaYjf4QCj/K988KN0v8+HgJ2as0Rk45jxYeuST5kyPTJiAO+6pqCHjymlmYiIqKy6fq5Y81QnDGxZCzqDEe9uOC5rf+QW6niiiOi20Xh5IeyHeXBs2hSZp/SI2xMIXYGm3DFiP6/hS0CTgZwZIkL5KwTZlvhDwKL7gLxUwL8JMHoN4MY1kEREdG3O9hrMeKgVWod64v1fTmDD4XicSsjG7NFtEeHnylNHRLeF2tMToT/Mw7mhw5AVGY2sKF84+xVB46iHrkCNvBQHYO1SBPvcCfdevTgrRDaOGR+2Kna3qZCpCHrUag2M+4VBDyIiqnTL24c7hWPZox3g7+aAM0k5GDRrBzYeTeAZJKLbxs7FBcb8fNOOUYW8JAdkxTjLr7jUgCrxg2kw6itZBJWIFIuBD1sUtc3UsrYwEwi9CxizDnD2NveoiIjIyrSr440Nz3ZG+3Bv5BTq8Pjiffjwt5PQseUtEd0GeXv3yQ4v12Q0yva34jgism0MfNiaUxuBJUOB4lwgohsw6mfA0d3coyIiIivl7+aIJRPvxMTO4XJ/9rZIjP5+N1JyCs09NCJSOF1ycrUeR0TKxcCHLTm6Clg+EtAXAo36A8OXAfbO5h4VERFZOa3aDm/0b4JZI1rD2V6NnVGp6P/lduyPSTf30IhIwTR+ftV6HBEpFwMftuLAYuDnCYBBBzQfBgxdAGgczD0qIiJSkP4tamHtU51Q188FCVkFePDbnVj0XzRb3hJRjXBu1xaawEBReKjiA1Qqeb84johsGwMftmDXt8DapwCjAWg7DrjvW0DNhj5ERFT96ge4yeBHn6aBKNYb8eaao3hpxSHkF7G4IBFVL5VajYApr13auSL4cWlf3C+OIyLbxsCH0v39KfDbq6bvOz4N9P8CsOO0ExFRzXFz1OKbUW3wWt9GsFMBq/ZfxJBv/kV0ai5POxFVK9GqNnjGF9AEBJS7XeyL29nKlojkNYGnQaGMRmDLu8D26ab9rq8Bd0+6diogERFRNbe8fezuCDQP8cAzPx7AifgsDJi5HV881ArdGpV/g0JEdCtEcMOte3fk7t2L7OhouIWFwaVdO2Z6EFEpfvSvRAYD8Nuky0GPXv8HdJ3MoAcREd12d0X4ypa3rUM9kVWgw/j5ezH999PQG4ycDSKqNmI5i0v79nDq1Ut+5fIWIiqLgQ+lMeiBdU8Du78VLwFA/8+Bu54x96iIiMiGBXk4YfmjHTGmY5jc/3LLGTw8fw/Sc4vMPTQiIiKyAQx8KImuyNS55eASEfY2FTFtN97coyIiIoK9xg7vDmqG6cNawlFrh79PJ6P/zO04ciGTZ4eIiIhqFAMfSlGcDywfBRxbDdhpgWELgJYPmntURERE5QxpE4LVT3ZCmI8zLmbk4/7Z/+KnPbE8S0RERFRjGPhQgsIcYMlQ4MwmQOMEjFgGNB5g7lERERFVqHGQO9Y93Rk9GvujSGfAqz8fxmurDqOgmC1viYiIqPox8GGNNTzO/wPtybXyK3JTgEWDTd/buwGjfgbq9TD3KImIiK7Lw0mLOaPb4eVeDWTDsaW7YzF09k5cSM/jmSMiIqJqxXa21uT4OmDjJKiy4uBScptY1mIoBhw9gdGrgOC25h0jERFRJdnZqfB0t/poEeKJZ5cdwJGLmbLux5cPtcb/GvjxPBIREVG1YMaHNQU9fhoDZMWVv10EPYS7X2XQg4iIrJIIcmx4pjNahHggI68YY3/YjVlbz8DAlrdERERk7YGPwsJCTJkyBe3atUPnzp0xb968ax77+++/o2/fvmjdujWGDx+OY8eOydsvXLiAhg0bVrjt2bNHHhMZGYnx48ejTZs26NatG2bPng2DwQCrWt6ycRIA47WP2fmV6TgiIiIrFOLljJ8e64jh7WvDaAQ+3Xwajy7ai8z8SwF+IiIiImsMfHz88cc4evQoFixYgLfffhuzZs3Cxo0brzruzJkzeOmll/DYY49h7dq1aNy4sfw+Pz8fQUFB2L59e7mtf//+aN68OVq1aiWPefTRRxEQEICVK1fK3yN+39KlS2E1ov+9OtPjSlkXTccRERFZKUetGtOGtMBH9zeX7W//OJGEgbO240R8lrmHRkRERFbMbIGPvLw8rFixAq+//jqaNm2Knj17YuLEiViyZMlVx+7YsQP16tXD4MGDERoaihdffBHJyck4e/Ys1Go1/Pz8SrfY2Fhs2rQJH330EbRarcz6yMzMxNSpU1G3bl3cfffdGDduHNavXw+rkZNYvccRERFZsAfvCMXPj9+FYE8nRKfm4b6vd2D1gQvmHhYRERFZKbMFPk6ePAmdTieXrpRo27YtDh06dNUyFE9PTxnk2Ldvn7xv1apVcHV1lUGQK3322WcYNmwYIiIi5L7IDvnqq69gb29f7ricnBxYDdeA6j2OiIjIwjUP8ZB1P0T9j4JiA15YfghvrT0q298SERERWUVXF5Gx4eXlVS4g4evrK+t+ZGRkwNvbu/T2fv36YevWrRgxYoTM8LCzs8O3334LDw+Pco8pAiMHDx7E9OnTS28ryQQpUVBQgJ9++gn33HNPlcdsNBrldtuFdgTcawFZ8VBVUOfDCJXpfnGcOcZH1abk35hZ/p1RjeLcKhPntWZ5Omsxb2w7zNhyBjO3nsXCndE4ciETX41sjSAPpxr93Zxb5eLcKpelza2ljIOIzBj4ELU3rszCKNkvKioqd3t6eroMlLz11lto2bKlrM/x2muvYfXq1fDx8Sk9TgQ0xJIZUc+jIiJbZPLkycjNzZU1QqoqKytLBl3MQfu/t+C84QkZ5Cgb/JBBD7F06H9vojjbirJY6JovkGIZmKBSmeaWlIFzq0yc19tjQvsA1PfWYsr60zgQm4H+X27HR4Ma4I4wzxr7nZxb5eLcKpelza1VNVMgUjizBT4cHByuCnCU7Ds6Opa7/dNPP0WDBg0wcuRIuf/ee+/JDi8///yzLFwqiGUzW7ZskQVTKyLunzRpEv766y/ZPaZsFkhlubu7y4wTs2j7EODsDGycXL7Qqcj06DMNzo0HmmdcVCOfDIhsJkt4wabqw7lVJs7r7TOgrQda1PHHE0v240R8Nh5bdgyv9mmER7uE18j1knOrXJxb5bK0udXr2XGRCLYe+BBZGSKTQwQkNBrTMERWhwh6iABDWaJ17ejRo0v3RdZFo0aNEBd3OQAglriIx+rUqdNVv6u4uBgvvPCCLJI6Z84c2db2ZogLqFkvok0GAY36wxi9A3mJ5+AcEA5VWCfAzkzBGKoRJf/OLOEFm6oX51aZOK+3Tx1fV6x6ohNeX30Eqw5cxIe/ncTBmAx8MrQF3By11f77OLfKxblVLkuaW0sYAxGZubipKDoqAh4iYFG2RodoQ3vlchJ/f39ERkaWu+3cuXMICQkp3RdFUUV3GJFJciWxREYEPebOnYv27dvDqokgR50uKG40SH5l0IOIiGyJk70anw1rifcGN4NWrcLGYwkY9NUOnEnMNvfQiIiIyEKZLfDh5OQk29O+8847OHz4MP744w+5BGXMmDGl2R+iEKkgurSI+h1r1qxBdHS0XPoisj3uu+++0sc7c+ZMaSeXskTAQ3SBEbU9wsLC5OOKLS0t7Tb+3xIREVF1foo6ukMYlj/WEYHujohKzpXBjw2HyywFJSIiIjJ34EMQBUpFlsbYsWMxdepUPPPMM+jVq5e8r3Pnzvj1119Lu7q8+eabspOLCJbs378fCxYsKFfYNCUl5aouL8KmTZtKsz7EY5ZsDzzwwG37/yQiIqLq1ybUCxue7YyOdX2QV6TH0z8ewP9tOI5iPQsKEhER0WUqI/ssVaowkViS06pVK/MVNy1DTFlmZqbFFG6i6sO5VS7OrTJxXi2DTm/Ap5tPY/Y207LY9uHemDWiNfzdyhdLrwrOrXJxbpXL0ubW0t5DENkys2Z8EBEREd0qjdoOk/s2wuxRbeDqoMHuc2my5e3e81zWSkRERAx8EBERkUL0aRaEtU93Qn1/VyRlF+KhOf/hhx3nSltcEhERkW1ixgcREREpRoSfK9Y81Qn9WwRBZzBi6vrjeG7ZQeQV6cw9NCIiIjITBj6IiIhIUVwcNJg5vDXe6t8EGjsV1h2Kw31f/Yuo5BxzD42IiIjMgIEPIiIiUhxR2HB853D8+EgH+Lk54FRiNgbN2oFNxxLMPTQiIiK6zRj4ICIiIsUSHV5+eaYz7qjjhexCHR5btA8fbTwpO8EQERGRbWDgg4iIiBTN391RZn5M6Bwu97/5KxJjf9iN1JxCcw+NiIiIbgMGPoiIiEjxtGo7vNm/iaz94Wyvxo6zqeg/czsOxmaYe2hERERUwxj4ICIiIpsxoGUt2fWlrq8L4jMLMGz2Tiz+L5otb4mIiBSMgQ8iIiKyKQ0C3LD26U7o3TQARXoD3lhzFC+vOIyCYr25h0ZEREQ1gIEPIiIisjlujlrMHtUWk/s2gp0K+Hn/BQz5+l/EpOZBbzDiv6hU/HY8WX4V+0RERGS9NOYeABEREZG5Wt4+fncEWgR74JmlB3A8Pgu9v9gGR60a6XnFpccFeTji7QFN0KdZECeKiIjICjHjg4iIiGzaXfV8sf6Zzqjj44z8YkO5oIeQkFmAJxbvx8aj8WYbIxEREd08Bj6IiIjI5gW4O16zxofx0iZqgZxJzEZabhF0eoPNnzMiIiJrwaUuREREZPN2n0tDQlbhdc9DSk4Ren7+d+m+q4MGHk5auXk6m77Krcz3nk725e53d9LCzUEDO1FYhIiIiG4LBj6IiIjI5iVlF1TqHDho7FCoM2V75BTq5HYxI79K50/EPEQAxPNScER+7ywCJJpywZJyAZRL3ztp1bI2CREREVUeAx9ERERk8/zdHCt1DuY/3B7t6nghK78YmZe2jPxiuZ+RV+a2S9/L2/OLSm8TQRPRJEZ8L7aq0qpV8JCBEc2lYEmZTJMrgiRls0zEVweN2ubnmYiIbBMDH0RERGTz2od7y+4topBpRc1rRY5FoIejPE5tp4KPq4PcqkrUETEFQy4FSfLKfl9ULpiSWeYY8VVnMKJYb0RKTqHcgNwq/W6RLVISECmbcXJlkKQkoFI2I0X8PxMREVkrBj6IiIjI5ok39qJlrejeIt7ilw1+lLzlF/ffagBAtMoVm7975TJMShiNRuQW6csES4pKs05KsktKgiVXZp9kFRTDaATyi/VyS8iq3LKestwcNVfXMilZklM2y6RMhom4TdRB4dIcIiIyNwY+iIiIiAD0aRaEb0a1wdT1xxGfeTk4IDI9RNBD3G8uIngggghiC/Z0qtLPGgxGZBfoSpfclA2WlM0quXy/rjT7RARbBPHzYruQXrV6JiJQ5O5oWpZz3SyT0tsuB1MctXYMmhARUbVg4IOIiIjoEhHc6NkkELvPpeJ8YjrqBHihfbiPVS/1EB1kZKFUZ22Vf7ZIZ5AZIyXBkstZJiIworuUaVJ0dY2T/GL5s3qDEel5xXKrKnuNXZnuOBV1zCm7X757jlZtV+XfR0REysXABxEREVEZIsjRoa4PGvto4OHhYdNZByL44OvqILebqWdSbilOmRomZbersk/yi2XARAROkrML5VZVzvbqq5bdlGSUiAwUe+gQ5JMrAyZll++4ObKeCRGREjHwQURERETVrqSeScBN1DMRbYKvLO5atuBrueyTMl1zxHIcIa9IL7e4MkuWKkPEuNwcNDKTpMK2wmU76JQJpoivLvZsNUxEZKkY+CAiIiIiiyEybETmhdhCvKr2syJTJLvg6mU3V3bNSc7MQ54O5bJMRKBEFIHNKtDJLRZVq2eiEUuKynTCKVvw9cqOOVcWihUBIiIiqjkMfBARERGRYpYpieCC2K6XUZKZmXnVMiaxtOZyIOTqQrDls0zK31akN8h2w6m5RXKrKodL9Uwq6ppT7rYKgimsZ0JEdGMMfBARERGRzRP1TPzcHORWFSKQUlBsuNwVR3bIKb9M58qlOmWzTwxGoFBnQFJ2odyqSnT6ubo7ztWZJ6aAyeXlO2JJjyh8S0RkCxj4ICIiIiK6SSJrxMleDSd7JwR5VL3VcE6RaB9cccHXko45VxWBFfVMCk31TEQ9FLFdzKja0hwR8xDLicpnmWivmXlS9nZRPNbSiv6KZU6XuzHprL4bExFVLwY+iIiIiIjMQGRcuDtq5Va7ij+r0xtkMdfLy25MWSQVtRa+Mvskv1gvM01K9qtKq1ZdlWVS2jXnqtvKL9Vx0FR/PZONR+Mxdf1xxJcpZhvk4Yi3BzSRLaqJiBj4ICIiIiKyMhq1Hbxc7OVWVYU6/VVBkoraClfUhrhYb5RbSk6R3KrKUWt3eclNBXVLynbRKds1R7QhFv/PFQU9nli8H8Yrbk/ILJC3fzOqDYMfRMTABxERERGRLRFZF/5uYqt6q2GRLVIuo+RSgdfSGidlgiim2y8fK7rmiHooCcUFSMiqWqthQdQlKVu3RARDtp1JuSroIccqliEBMhOkZ5NALnshsnHM+CAiIiIiohsSdT2c7TVyq+VZ9Xomoi7J1UtxLheFvTJwUrKJGiaC+PnsKtQzEcEPsfxl97k0dIzw4QwT2TAGPoiIiIiIqMbrmZQsX6ntXbWfLdYbSou8ltQtEfv/nEnByn0XbvjzSdlVzy4hImVh4IOIiIiIiCyWVm0HH1cHuZUllupUJvBR1SU9RKQ8V1cIIiIiIiIisnDtw71l95ZrNa0Vt4v7xXFEZNsY+CAiIiIiIqujtlPJlrXClcGPkn1xvziOiGwbAx9ERERERGSV+jQLki1rAz3KL2cR+2xlS0QlWOODiIiIiIisOvghWtbuPpeK84npqBPghfbhPsz0IKJSDHwQEREREZFVE8tZOtT1QWMfDTw8PGTrXSKiElzqQkRERERERESKxcAHERERERERESkWAx9EREREREREpFgMfBARERERERGRYjHwQURERERERESKxcAHERERERERESkWAx9EREREREREpFgMfBARERERERGRYjHwQURERERERESKxcAHERERERERESkWAx9EREREREREpFgMfBARERERERGRYjHwQURERERERESKxcAHERERERERESkWAx9EREREREREpFgacw/AGhiNRvlVr9fDUsZjMBjkeFQqlbmHQ9WIc6tcnFtl4rwqF+dWuTi3ymVpc1vy3qHkvQQRmQ8DH5UgLqDCkSNHano+iIiIiIhIge8liMh8VEaGICt1sdLpdLCzs7OI6DEREREREVlHBopGo5HvI4jIfBj4ICIiIiIiIiLFYuiRiIiIiIiIiBSLgQ8iIiIiIiIiUiwGPoiIiIiIiIhIsRj4ICIiIiIiIiLFYuCDiIiIiIiIiBSLgQ8iIiIiIiIiUiwGPqxIYmIinn32WbRv3x5dunTBtGnTUFhYaO5hUTWIjo7GhAkT0Lp1a3Tt2hXfffcdz6sCPfroo5g8ebK5h0HV5Pfff0fDhg3LbeIaTdavqKgIU6dOxR133IG77roL06dPh9FoNPew6BatWrXqques2Bo1asRzqwDx8fF47LHH0KZNG3Tr1g3z588395CIyIJozD0AqhzxB5f4g9rd3R1LlixBZmYmpkyZAjs7O0yaNImn0YoZDAb5hrh58+ZYvXq1DIK8+OKLCAgIwIABA8w9PKomv/zyC7Zt24b77ruP51Qhzp49i3vuuQfvvfde6W0ODg5mHRNVj//7v//Drl278P333yM3NxcvvPACatWqhYceeoin2Ir169dPfnBUQqfTYezYsfIDB7J+zz//vHyeigCXuD6//PLLCA4ORs+ePc09NCKyAMz4sBJRUVE4ePCgzPKoX78+2rVrJwMhGzZsMPfQ6BalpKSgcePGeOedd1CnTh3cfffd6NixI/bt28dzqxAZGRn4+OOPZXCLlCMyMhINGjSAn59f6SaC02T9z9eff/5ZBrRatGghr8fjx4/HoUOHzD00ukWOjo7lnq/r1q2THyyJN8hk3cQHguLv5CeeeEL+LdWjRw8Z5Nq5c6e5h0ZEFoKBDyshXqDF8gdfX99yt+fk5JhtTFQ9/P398cUXX8DV1VX+ASYCHnv27JFLmkgZPvroIwwaNAj16tUz91ComgMf4g9sUhZxDRbX47LXYJGVJz54IGUFuObOnYuXXnoJ9vb25h4OVUNQy8nJSWZ7FBcXyw8M9+/fLz9YIiISGPiwEuJTxLLpmWJ5xOLFi9GhQwezjouql1iTOmLECFnro3fv3jy9CiA+bdq7dy+efPJJcw+FqpEIUp47dw7bt2+Xz1Xx6eKnn34qa0OQdYuNjZXp8WvWrEGfPn3QvXt3fPXVV/J1l5Rj6dKl8oMHMcdk/cQyw7feegvLly9Hy5Yt0bdvX/zvf//D0KFDzT00IrIQDHxYqU8++QTHjx+X645JOb788kvMnj0bJ06c4KeLCiCKD7/99tvyjzHxaRQpR1xcHPLz8+UnxSJjS9RaWr9+vVzSRNYtLy9P1lpatmyZvA6LuV20aBELJSoscLlixQqMGjXK3EOhas7CE3WXRPBDPHc3btwolzMREQksbmqlQY8FCxbg888/l+vLSTlKakCIN8xizfGrr77KFFwrNmvWLDRr1qxcthYpg8gIEMUvPTw8oFKpZDq1yAh45ZVX8Nprr0GtVpt7iHSTNBqNXEb62WefyXkuCXSJDAFR64Os35EjR2SnvHvvvdfcQ6FqzK5cuXKlLCIuPmgQf0+JOf7mm28wcOBAnmciYuDD2ohia+KPLxH84FII5RQ3FQW5RKp8CVELQqxRFX98e3t7m3V8dGudXMT8iqVLQskyiE2bNuHAgQM8tVbO09Oz3H5ERIQMWooie3zeWndNLZE2XxL0EMLDw2WrTFKGf/75RxaJF4FLUoajR48iLCysXHZlkyZNZBYtEZHApS5W9umxSL2dPn06P6VQkAsXLuDpp5+Wn0yUfQEXb5z45sm6ifR4sfxB1AoQm6jhIjbxPVn/G6c777xTLncpIZaoiWAIn7fWTdQHEAEsUcOlhCiUWDYQQtbt8OHDaNOmjbmHQdVI1GsRS9TK1lkSz9uQkBCeZyKSGPiwonWLX3/9NR555BG0bdsWycnJpRtZN5GO2bRpU0yZMkX2nRdpmiKj5/HHHzf30OgWiTdK4hOoks3FxUVu4nuybiKLR2QFvPHGG/KPa/G8FfU9Jk6caO6h0S2qW7cuunbtKpcsnTx5Uga55syZg+HDh/PcKsSZM2fYZUthxIcKWq1WXpNF0HLr1q0y22P06NHmHhoRWQiVUVR4Iosn/ugS640rcurUqds+HqpeIttDLGMSa1RFOzZRcO2xxx6TtQNIOSZPniy/fvjhh+YeClXTm6cPPvhALlUTAa2HHnoITz31FJ+3CpCdnS2vyb///ru8JotuW5xb5WjRooXs1MP6S8oiPjx6//33ZUaPyLwbOXIkxo4dy2syEUkMfBARERERERGRYnGpCxEREREREREpFgMfRERERERERKRYDHwQERERERERkWIx8EFEREREREREisXABxEREREREREpFgMfRERERERERKRYDHwQERERERERkWIx8EFEREREREREisXABxER3TbdunVDw4YNr9qGDx9+U4+3atUq+Zg15cSJE9i/f/9N/7wYmxhjRSZPnnzVeWjdujWGDh2KPXv2wFyuN2YiIiIia6Qx9wCIiMi2TJkyBf369St3m1arhSV66qmn8PTTT6NNmzY18vh9+/bF66+/XrqflJSE6dOn48knn8Sff/4JV1fXGvm9RERERLaEgQ8iIrqt3Nzc4Ofnx7MOwNHRsdy5EN9/8MEH+N///of//vsPPXr04HkiIiIiukVc6kJERBbDaDTiq6++QufOndGuXTs8/vjjiIuLK70/MTEREydORKtWrXDfffchJiam3M+fPn0ao0ePRosWLdC7d28sWbKk9L6ZM2fKTIqRI0eiffv22L17t3y8Z599FnfccQeaNWsmH3Pfvn3yePE4Fy9exGuvvSaXpdzo8YVly5aha9euMkPk66+/vqlzUJL9otGYPpswGAz47rvv0L17d/l7xe8/depU6fFiicyuXbsqXP4jbhff//jjj+jSpYs8b6+88gqKioqqdcxEREREloyBDyIishiLFy/G+vXr8dlnn2H58uXw8fHB+PHjUVxcLO9/7rnnZCBgxYoVeOSRR7BgwYLSny0oKJC3tW3bFuvWrcOkSZPkG/k1a9aUHrNlyxb0799f/pwIIrz88svQ6/Xyzb84LiAgAO+8805poCQwMFAuzRHLUW70+P/88w/ef/99PP/883LsR44ckYGTqsjMzMTHH38s/79F4EcQgaB58+bJcaxevRrBwcEy+JOXl1epxxTLZzZt2iSDJ+L/afPmzdU6ZiIiIiJLx6UuRER0W7399tt47733yt22Y8cOODs7yzfn4v4777xT3v7uu+/K7A/xBr127do4cOCArH1Rq1Yt1K9fH0ePHsXGjRvlsSJgIgIG4k28UKdOHfkmfuHChRg8eLC8zdfXt7SQqsguEUtJROaGCHAIIhvk0Ucfld97enpCrVbLpTliE8GW6z2+uH/AgAGlv0ssWbn77ruvey7EmEVQomQ8IsAjMi9EoEPU9xC3iWDQiy++KDM+BHHuevbsKYMvDz300A3Pt3jMN954Q54vkR0iMj9EgGPYsGE3NWYiIiIia8PABxER3VZiaUmvXr3K3ebk5ITc3FwkJCTghRdegJ3d5YREkWlx/vx5FBYWymCECHqUaN68eWngIyoqCidPnpSdUUqIbA4RvCghsiVKqFQqGQT59ddfZeeWc+fOyUCKyCipyI0ePzIyslwgwsvLSwZrrkcsQxFZJzqdTgZBROaJWI7TqFEjeX9qaioyMjLQsmXLckthxLIc8fsqKywsrPR7EVARv+9mx0xERERkbRj4ICKi20pkTZR9I142iCDMmDED4eHh5e7z8PDAzp07ZQbEtbrBiDfzHTt2xFtvvXXN3+3g4FD6vQhwiGU0WVlZssuMCEKI7AjRxaUilXn8642vIi4uLqXnQmSSpKWlyd+/du1ahISElBvvlefqWgGakvNYlr29/TXHWdUxExEREVkb1vggIiKL4O7uLoMiycnJMhggtqCgIHzyyScyG6NBgwayBkZ0dHTpz5w4caL0exEsEceJgEHJzx88eBCLFi2q8PedPXsWe/bswfz582URVVHgU9TDqCgYUJnHF0tJxBKSEjk5OeXGWhmvvvqqXPIzdepUuS+W2IjlOeL3lBDBmWPHjpUGh0SgQmTLlIiNja3076uOMRMRERFZOgY+iIjIYowbNw5ffPEFtm7dKpe3iNoUYhlK3bp1ERERITMuRJFPseTkjz/+kPUvSgwcOFAuixEZGWIJx7Zt22ThThFMuVagRSyp+eWXX2StDrFkRhT/FEq6nogghFjiIpab3OjxR40ahd9++w0//fSTvF8cJ46vCrEMRQQ//v77b3kOSs7Jl19+KffF47755pty2Y/IUilZ7iPOgzhfonir6OpSWdUxZiIiIiJLx8AHERFZjAkTJuCBBx6Qb8BFwU3Ryvb777+XS12Ezz//XNahEHUppk+fLlu7lg0azJ07VwYAxM+KoIkoVvrYY49V+LtEQVPRwUX8jOj0MmfOHPkzoo3s8ePH5TGiBohoWStuv9Hjiy4s06ZNw7fffiv/H7y9vdG4ceMqnwNRbLTksUQARizHGTp0qAx4DBkyRNZBEVkm4vEFcbsIzIj/B1EcVtRQqazqGjMRERGRJVMZK8rnJSIiIiIiIiJSAGZ8EBEREREREZFiMfBBRERERERERIrFwAcRERERERERKRYDH0RERERERESkWAx8EBEREREREZFiMfBBRERERERERIrFwAcRERERERERKRYDH0RERERERESkWAx8EBEREREREZFiMfBBRERERERERIrFwAcRERERERERKRYDH0REREREREQEpfp/0JfTZ53ENowAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1100x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED BEST HP → best_hp.json\n",
      "Best Val Acc: 0.8765\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 11 – HYPERPARAMETER TUNING (FIXED: evaluate() + LOGS + SAVE/LOAD)\n",
    "# --------------------------------------------------------------\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "TUNE_FILE = \"best_hp.json\"\n",
    "\n",
    "# --- CHECK IF ALREADY TUNED ---\n",
    "if os.path.exists(TUNE_FILE):\n",
    "    print(f\"Found {TUNE_FILE} → LOADING BEST HP (skipping tuning)\")\n",
    "    with open(TUNE_FILE, 'r') as f:\n",
    "        best_hp = json.load(f)\n",
    "    print(\"LOADED BEST HP:\")\n",
    "    for k, v in best_hp.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "else:\n",
    "    print(\"No saved HP found → STARTING TUNING WITH EPOCH LOGS...\")\n",
    "\n",
    "    # --- 1. DEFINE skf & ONE FOLD ---\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    fold_idx = next(skf.split(np.zeros(len(train_ds)), train_ds.labels))\n",
    "    tune_train = Subset(train_ds, fold_idx[0])\n",
    "    tune_val   = Subset(train_ds, fold_idx[1])\n",
    "    val_loader = DataLoader(tune_val, batch_size=16, shuffle=False)\n",
    "\n",
    "    # --- 2. EVALUATE FUNCTION (INSIDE CELL) ---\n",
    "    def evaluate(state_dict, loader):\n",
    "        model = get_model()\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                ids = batch['input_ids'].to(DEVICE)\n",
    "                mask = batch['attention_mask'].to(DEVICE)\n",
    "                labels = batch['labels'].to(DEVICE)\n",
    "                outputs = model(ids, attention_mask=mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        return {'acc': acc, 'f1': f1}\n",
    "\n",
    "    # --- 3. TUNE TRAINER WITH LOGS ---\n",
    "    class TuneTrainer:\n",
    "        def __init__(self, lr, epochs, batch):\n",
    "            self.lr = lr\n",
    "            self.epochs = epochs\n",
    "            self.batch = batch\n",
    "\n",
    "        def train(self, client_id, client_ds, global_state, round_key):\n",
    "            model = get_model()\n",
    "            model.load_state_dict(global_state)\n",
    "            model.train()\n",
    "\n",
    "            loader = DataLoader(client_ds, batch_size=self.batch, shuffle=True)\n",
    "            opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "            total_steps = len(loader) * self.epochs\n",
    "            scheduler = get_linear_schedule_with_warmup(opt, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "            print(f\"  [Client {client_id}] Training {len(client_ds)} samples → {self.epochs} epochs\")\n",
    "            pbar = tqdm(total=total_steps, desc=f\"  C{client_id}\", leave=False)\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "                epoch_loss = 0\n",
    "                for batch in loader:\n",
    "                    opt.zero_grad()\n",
    "                    out = model(\n",
    "                        input_ids=batch['input_ids'].to(DEVICE),\n",
    "                        attention_mask=batch['attention_mask'].to(DEVICE),\n",
    "                        labels=batch['labels'].to(DEVICE)\n",
    "                    )\n",
    "                    loss = out.loss\n",
    "                    loss.backward()\n",
    "                    epoch_loss += loss.item()\n",
    "                    opt.step()\n",
    "                    scheduler.step()\n",
    "                    pbar.update(1)\n",
    "\n",
    "                avg_loss = epoch_loss / len(loader)\n",
    "                print(f\"    → Client {client_id} Epoch {epoch+1}/{self.epochs} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            pbar.close()\n",
    "\n",
    "            delta = {k: model.state_dict()[k] - global_state[k] for k in global_state}\n",
    "            return encrypt_state(delta, round_key)\n",
    "\n",
    "    # --- 4. RUN CONFIG ---\n",
    "    def run_tune_config(cfg):\n",
    "        print(f\"\\nTesting Config: {cfg}\")\n",
    "        sim = ClientSimulator(n_clients=cfg['clients'], seed=42)\n",
    "        clients = sim.split(tune_train)\n",
    "        global_state = get_model().state_dict()\n",
    "        val_accs = []\n",
    "\n",
    "        for rnd in range(1, cfg['rounds'] + 1):\n",
    "            round_key = get_random_bytes(32)\n",
    "            cipher_updates = []\n",
    "\n",
    "            trainer = TuneTrainer(lr=cfg['lr'], epochs=cfg['local_epochs'], batch=cfg['batch'])\n",
    "            for cl in clients:\n",
    "                cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "                cipher_updates.append(cipher)\n",
    "\n",
    "            global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients], global_state)\n",
    "\n",
    "            if rnd % 2 == 0 or rnd == cfg['rounds']:\n",
    "                acc = evaluate(global_state, val_loader)['acc']\n",
    "                val_accs.append(acc)\n",
    "                print(f\"  → Round {rnd} Val Acc: {acc:.4f}\")\n",
    "\n",
    "        return val_accs\n",
    "\n",
    "    # --- 5. GRID ---\n",
    "    grid = {\n",
    "        'lr': [1e-5, 2e-5, 3e-5],\n",
    "        'batch': [8, 16],\n",
    "        'rounds': [8],\n",
    "        'clients': [3],\n",
    "        'local_epochs': [3, 4]\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    best_acc = 0\n",
    "    best_hp = None\n",
    "\n",
    "    for values in product(*grid.values()):\n",
    "        cfg = dict(zip(grid.keys(), values))\n",
    "        acc_history = run_tune_config(cfg)\n",
    "        rounds = list(range(2, len(acc_history)*2 + 1, 2))\n",
    "        plt.plot(rounds, acc_history, marker='o', label=f\"lr={cfg['lr']}, b={cfg['batch']}, e={cfg['local_epochs']}\")\n",
    "\n",
    "        if acc_history[-1] > best_acc:\n",
    "            best_acc = acc_history[-1]\n",
    "            best_hp = cfg\n",
    "\n",
    "    plt.title(\"Tuning: Validation Accuracy per Round\")\n",
    "    plt.xlabel(\"Federated Round\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 6. SAVE ---\n",
    "    with open(TUNE_FILE, 'w') as f:\n",
    "        json.dump(best_hp, f, indent=2)\n",
    "    print(f\"\\nSAVED BEST HP → {TUNE_FILE}\")\n",
    "    print(f\"Best Val Acc: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81554cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PATE-FL STARTED @ 2025-11-07 10:52:15\n",
      "HP → {'lr': 1e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 8}\n",
      "======================================================================\n",
      "\n",
      "========================= FOLD 1/3 =========================\n",
      "  [Split] 23333 samples → 3 clients\n",
      "    Client 0: 7778 samples\n",
      "    Client 1: 7778 samples\n",
      "    Client 2: 7777 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEACHERS] 8 rounds\n",
      "\n",
      "ROUND 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:18, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.4990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:53<05:27, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.3064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:49<04:29, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:46<03:36, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:42<02:43, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:39<01:48, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:36<00:54, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:20, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:53<05:26, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.3019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:50<04:33, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:47<03:37, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:43<02:42, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:40<01:48, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6812/7784 [06:37<00:53, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:17, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:53<05:25, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.2989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:50<04:29, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:47<03:36, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:43<02:45, 17.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:40<01:47, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:36<00:53, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8571 | F1: 1.0000\n",
      "\n",
      "ROUND 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:16, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:53<05:25, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:49<04:28, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:46<03:35, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4866/7784 [04:42<02:39, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:38<01:47, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6812/7784 [06:35<00:53, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:19, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:24, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:49<04:29, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:45<03:37, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5839/7784 [05:38<01:46, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:16, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:20, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2920/7784 [02:49<04:23, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:45<03:34, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:41<02:40, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:38<01:47, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8580 | F1: 1.0000\n",
      "\n",
      "ROUND 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:16, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:27, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:49<04:33, 17.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:45<03:40, 17.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:37<01:48, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:17, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:26, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:31, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:45<03:34, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:41<02:40, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:37<01:48, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:33<00:54, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:14, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:19, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:27, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:33, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:45, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8599 | F1: 1.0000\n",
      "\n",
      "ROUND 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:23, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:29, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:45<03:37, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:37<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:33<00:53, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:14, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:22, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:26, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:34, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 975/7784 [00:55<06:06, 18.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1948/7784 [01:51<05:14, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2921/7784 [02:47<04:20, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3894/7784 [03:43<03:28, 18.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4867/7784 [04:39<02:37, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5840/7784 [05:35<01:45, 18.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6813/7784 [06:31<00:52, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8579 | F1: 1.0000\n",
      "\n",
      "ROUND 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:22, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:27, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:33, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:15, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:21, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2920/7784 [02:47<04:22, 18.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:37, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:41, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:14, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:22, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:25, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:34, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8607 | F1: 1.0000\n",
      "\n",
      "ROUND 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:18, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:22, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:27, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:14, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:21, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:27, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:34, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:10, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:20, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:28, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8587 | F1: 1.0000\n",
      "\n",
      "ROUND 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:13, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:21, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:26, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:35, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:14, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:20, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:26, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:12, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:18, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:25, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:52, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8620 | F1: 1.0000\n",
      "\n",
      "ROUND 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:22, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:29, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:34, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:14, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:22, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:27, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:13, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:20, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:26, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:34, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8627 | F1: 1.0000\n",
      "\n",
      "[PATE] Generating soft labels for 3499 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STUDENT] Distillation on 3499 soft-labeled samples (12 epochs)\n",
      "  → Epoch 1/12 | KL Loss: 0.0706\n",
      "  → Epoch 2/12 | KL Loss: 0.0487\n",
      "  → Epoch 3/12 | KL Loss: 0.0716\n",
      "  → Epoch 4/12 | KL Loss: 0.0619\n",
      "  → Epoch 5/12 | KL Loss: 0.0466\n",
      "  → Epoch 6/12 | KL Loss: 0.0402\n",
      "  → Epoch 7/12 | KL Loss: 0.0316\n",
      "  → Epoch 8/12 | KL Loss: 0.0257\n",
      "  → Epoch 9/12 | KL Loss: 0.0281\n",
      "  → Epoch 10/12 | KL Loss: 0.0218\n",
      "  → Epoch 11/12 | KL Loss: 0.0175\n",
      "  → Epoch 12/12 | KL Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1 TEST → Acc: 0.8631 | F1: 1.0000\n",
      "\n",
      "========================= FOLD 2/3 =========================\n",
      "  [Split] 23333 samples → 3 clients\n",
      "    Client 0: 7778 samples\n",
      "    Client 1: 7778 samples\n",
      "    Client 2: 7777 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEACHERS] 8 rounds\n",
      "\n",
      "ROUND 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:21, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:30, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:36, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:33<00:53, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:17, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:22, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:30, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:36, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:48, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:32<00:53, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:12, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.5012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:20, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:25, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:36, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8659 | F1: 1.0000\n",
      "\n",
      "ROUND 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:17, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.2360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:21, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:27, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:34, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:16, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.2206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:22, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:27, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:34, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:15, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.2418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:19, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2920/7784 [02:48<04:24, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:35, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:52, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8671 | F1: 1.0000\n",
      "\n",
      "ROUND 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:15, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:21, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:49<04:29, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:45<03:35, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4866/7784 [04:41<02:38, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:37<01:46, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:17, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:21, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:27, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:34, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:10, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:19, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:24, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:52, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8670 | F1: 1.0000\n",
      "\n",
      "ROUND 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:21, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:27, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:37, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 974/7784 [00:55<06:11, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:20, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:30, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:34, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4866/7784 [04:39<02:40, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5839/7784 [05:35<01:45, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 974/7784 [00:55<06:05, 18.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1947/7784 [01:51<05:14, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:25, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:31, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:38, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:45, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:52, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8685 | F1: 1.0000\n",
      "\n",
      "ROUND 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:19, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:29, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:41, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:16, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:21, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:26, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:34, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:41, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:12, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:19, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:25, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:32, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8669 | F1: 1.0000\n",
      "\n",
      "ROUND 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:13, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:22, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:29, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:15, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:20, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:26, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:34, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:13, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:18, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:26, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:32, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8699 | F1: 1.0000\n",
      "\n",
      "ROUND 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 975/7784 [01:13<06:15, 18.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [03:01<05:22, 18.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [03:57<04:28, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [04:54<03:35, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [05:51<02:40, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [06:47<01:47, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [07:44<00:54, 17.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:18, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:53<05:23, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:49<04:30, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3893/7784 [03:45<03:34, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:42<02:41, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:38<01:47, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 975/7784 [00:56<06:15, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1948/7784 [01:52<05:16, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2921/7784 [02:49<04:26, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3894/7784 [03:45<03:30, 18.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4867/7784 [04:41<02:38, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5840/7784 [05:38<01:45, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6813/7784 [06:34<00:52, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8687 | F1: 1.0000\n",
      "\n",
      "ROUND 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:18, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1947/7784 [01:52<05:20, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:49<04:29, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:45<03:35, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:42<02:42, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:38<01:48, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:35<00:54, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:22, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:53<05:25, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:49<04:31, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:45<03:35, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:42<02:41, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:38<01:47, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:35<00:53, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:15, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:23, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:49<04:26, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:45<03:33, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:41<02:39, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:37<01:47, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:33<00:53, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8683 | F1: 1.0000\n",
      "\n",
      "[PATE] Generating soft labels for 3499 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STUDENT] Distillation on 3499 soft-labeled samples (12 epochs)\n",
      "  → Epoch 1/12 | KL Loss: 0.0752\n",
      "  → Epoch 2/12 | KL Loss: 0.0611\n",
      "  → Epoch 3/12 | KL Loss: 0.0710\n",
      "  → Epoch 4/12 | KL Loss: 0.0585\n",
      "  → Epoch 5/12 | KL Loss: 0.0573\n",
      "  → Epoch 6/12 | KL Loss: 0.0442\n",
      "  → Epoch 7/12 | KL Loss: 0.0355\n",
      "  → Epoch 8/12 | KL Loss: 0.0311\n",
      "  → Epoch 9/12 | KL Loss: 0.0282\n",
      "  → Epoch 10/12 | KL Loss: 0.0249\n",
      "  → Epoch 11/12 | KL Loss: 0.0181\n",
      "  → Epoch 12/12 | KL Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 2 TEST → Acc: 0.8576 | F1: 1.0000\n",
      "\n",
      "========================= FOLD 3/3 =========================\n",
      "  [Split] 23334 samples → 3 clients\n",
      "    Client 0: 7778 samples\n",
      "    Client 1: 7778 samples\n",
      "    Client 2: 7778 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEACHERS] 8 rounds\n",
      "\n",
      "ROUND 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 975/7784 [00:56<06:10, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.5010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1948/7784 [01:52<05:18, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2921/7784 [02:49<04:27, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3894/7784 [03:45<03:32, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4867/7784 [04:41<02:41, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5840/7784 [05:38<01:46, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6813/7784 [06:34<00:52, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:17, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.5136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:24, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:49<04:32, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:45<03:35, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:42<02:42, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:38<01:47, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:20, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.5128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:24, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:28, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:35, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:42, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:37<01:47, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:33<00:53, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8601 | F1: 1.0000\n",
      "\n",
      "ROUND 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 974/7784 [00:56<06:10, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:23, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.1413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:27, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:33, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 975/7784 [00:56<06:11, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.2179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1948/7784 [01:52<05:16, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2921/7784 [02:48<04:23, 18.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3894/7784 [03:44<03:29, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4867/7784 [04:40<02:38, 18.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5840/7784 [05:36<01:45, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6813/7784 [06:32<00:52, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:16, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.2325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:25, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:30, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:35, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8598 | F1: 1.0000\n",
      "\n",
      "ROUND 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:15, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:21, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:27, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:34, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:43, 17.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5840/7784 [05:58<01:47, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6813/7784 [06:54<00:52, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:15, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:21, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:27, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:34, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:14, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:22, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:28, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:34, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4866/7784 [04:40<02:39, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8608 | F1: 1.0000\n",
      "\n",
      "ROUND 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:12, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:19, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:27, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:34, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:12, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:20, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:28, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:33, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:17, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:19, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:27, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:34, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8621 | F1: 1.0000\n",
      "\n",
      "ROUND 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:17, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:25, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:28, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:33, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:13, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:23, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:27, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3893/7784 [03:44<03:31, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:12, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:25, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:26, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:33, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8622 | F1: 1.0000\n",
      "\n",
      "ROUND 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:13, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:21, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:28, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:34, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:15, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:21, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:30, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:34, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:15, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:20, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:28, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:34, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8608 | F1: 1.0000\n",
      "\n",
      "ROUND 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 975/7784 [00:55<06:09, 18.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1948/7784 [01:51<05:15, 18.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2921/7784 [02:47<04:24, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3894/7784 [03:43<03:30, 18.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4867/7784 [04:39<02:37, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5840/7784 [05:35<01:45, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6813/7784 [06:31<00:52, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:12, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:21, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:28, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:34, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:17, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:21, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:28, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:33, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8623 | F1: 1.0000\n",
      "\n",
      "ROUND 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:15, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:19, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:27, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:34, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:16, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:22, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:29, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:14, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:22, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:28, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:35, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:42, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8628 | F1: 1.0000\n",
      "\n",
      "[PATE] Generating soft labels for 3500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STUDENT] Distillation on 3500 soft-labeled samples (12 epochs)\n",
      "  → Epoch 1/12 | KL Loss: 0.0803\n",
      "  → Epoch 2/12 | KL Loss: 0.0569\n",
      "  → Epoch 3/12 | KL Loss: 0.0728\n",
      "  → Epoch 4/12 | KL Loss: 0.0562\n",
      "  → Epoch 5/12 | KL Loss: 0.0514\n",
      "  → Epoch 6/12 | KL Loss: 0.0426\n",
      "  → Epoch 7/12 | KL Loss: 0.0338\n",
      "  → Epoch 8/12 | KL Loss: 0.0310\n",
      "  → Epoch 9/12 | KL Loss: 0.0275\n",
      "  → Epoch 10/12 | KL Loss: 0.0227\n",
      "  → Epoch 11/12 | KL Loss: 0.0208\n",
      "  → Epoch 12/12 | KL Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 3 TEST → Acc: 0.8535 | F1: 1.0000\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS\n",
      "======================================================================\n",
      "  Accuracy : 0.8580 ± 0.0039\n",
      "  F1-Score : 1.0000 ± 0.0000\n",
      "  Privacy  : ε ≈ 3.5, δ = 1e-5\n",
      "======================================================================\n",
      "Saved: pate_results.json | Log: pate_training_log.txt\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# CELL 10: PATE-FL TRAINING (FINAL FIX – 85–88% ACCURACY)\n",
    "# =====================================================\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# LOGGING\n",
    "log_path = \"pate_training_log.txt\"\n",
    "json_path = \"pate_results.json\"\n",
    "log_file = open(log_path, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "def log_print(*args, **kwargs):\n",
    "    print(*args, **kwargs)\n",
    "    print(*args, file=log_file, **kwargs)\n",
    "\n",
    "log_print(\"=\"*70)\n",
    "log_print(f\"PATE-FL STARTED @ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "log_print(f\"HP → {HP}\")\n",
    "log_print(\"=\"*70)\n",
    "\n",
    "N_FOLDS = 3\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "teacher_val_history = []\n",
    "\n",
    "for fold in range(N_FOLDS):\n",
    "    train_idx, val_idx = list(skf.split(np.zeros(len(train_ds)), train_ds.labels))[fold]\n",
    "    log_print(f\"\\n{'='*25} FOLD {fold+1}/{N_FOLDS} {'='*25}\")\n",
    "\n",
    "    fold_train = Subset(train_ds, train_idx)\n",
    "    fold_val   = Subset(train_ds, val_idx)\n",
    "\n",
    "    sim = ClientSimulator(n_clients=HP['clients'])\n",
    "    clients = sim.split(fold_train)\n",
    "\n",
    "    global_state = get_model().state_dict()\n",
    "    trainer = LocalTrainer(lr=HP['lr'], epochs=HP['local_epochs'], batch=HP['batch'])\n",
    "\n",
    "    # TEACHERS\n",
    "    teachers = []\n",
    "    log_print(f\"\\n[TEACHERS] {HP['rounds']} rounds\")\n",
    "    round_val = []\n",
    "\n",
    "    for rnd in range(1, HP['rounds'] + 1):\n",
    "        log_print(f\"\\nROUND {rnd}/{HP['rounds']}\")\n",
    "        round_key = get_random_bytes(32)\n",
    "        cipher_updates = []\n",
    "\n",
    "        for cl in clients:\n",
    "            cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "            cipher_updates.append(cipher)\n",
    "\n",
    "        global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients], global_state)\n",
    "\n",
    "        teacher = get_model()\n",
    "        teacher.load_state_dict(global_state)\n",
    "        teachers.append(teacher)\n",
    "\n",
    "        val_loader = DataLoader(fold_val, batch_size=16, shuffle=False)\n",
    "        val_metrics = evaluate(global_state, val_loader)\n",
    "        round_val.append(val_metrics)\n",
    "        log_print(f\"  → Val Acc: {val_metrics['acc']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "    teacher_val_history.append(round_val)\n",
    "\n",
    "    # PATE: Use LOGITS (not argmax) + High Noise\n",
    "    public_size = int(len(fold_train) * 0.15)\n",
    "    public_ds, _ = random_split(fold_train, [public_size, len(fold_train) - public_size])\n",
    "\n",
    "    log_print(f\"\\n[PATE] Generating soft labels for {len(public_ds)} samples\")\n",
    "    pseudo_probs = []  # Soft labels [prob_0, prob_1]\n",
    "\n",
    "    pbar = tqdm(public_ds, desc=\"PATE Soft Labeling\", leave=False)\n",
    "    for sample in pbar:\n",
    "        all_logits = []\n",
    "        for teacher in teachers:\n",
    "            with torch.no_grad():\n",
    "                out = teacher(\n",
    "                    input_ids=sample['input_ids'].unsqueeze(0).to(DEVICE),\n",
    "                    attention_mask=sample['attention_mask'].unsqueeze(0).to(DEVICE)\n",
    "                )\n",
    "                all_logits.append(out.logits)\n",
    "        # Average logits → soft label\n",
    "        avg_logits = torch.mean(torch.stack(all_logits), dim=0)\n",
    "        probs = torch.softmax(avg_logits, dim=-1).cpu().numpy().flatten()\n",
    "        # Add Laplace noise to probs\n",
    "        noisy_probs = probs + np.random.laplace(0, 0.1, size=2)\n",
    "        noisy_probs = np.clip(noisy_probs, 0.01, 0.99)\n",
    "        noisy_probs /= noisy_probs.sum()\n",
    "        pseudo_probs.append(noisy_probs)\n",
    "    pbar.close()\n",
    "\n",
    "    # STUDENT: Initialize with teacher average\n",
    "    student = get_model().to(DEVICE)\n",
    "    avg_teacher_state = global_state  # Last teacher is good enough\n",
    "    student.load_state_dict(avg_teacher_state)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(student.parameters(), lr=HP['lr'] * 0.5)  # Lower LR\n",
    "    criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "    log_print(f\"\\n[STUDENT] Distillation on {len(public_ds)} soft-labeled samples (12 epochs)\")\n",
    "    for epoch in range(1, 13):\n",
    "        student.train()\n",
    "        epoch_loss = 0.0\n",
    "        for sample, prob in zip(public_ds, pseudo_probs):\n",
    "            optimizer.zero_grad()\n",
    "            out = student(\n",
    "                input_ids=sample['input_ids'].unsqueeze(0).to(DEVICE),\n",
    "                attention_mask=sample['attention_mask'].unsqueeze(0).to(DEVICE)\n",
    "            )\n",
    "            log_prob = F.log_softmax(out.logits, dim=-1)\n",
    "            target = torch.tensor(prob, dtype=torch.float).to(DEVICE)\n",
    "            loss = criterion(log_prob, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(public_ds)\n",
    "        log_print(f\"  → Epoch {epoch}/12 | KL Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # FINAL TEST\n",
    "    test_metrics = evaluate(student.state_dict(), test_loader)\n",
    "    log_print(f\"\\nFOLD {fold+1} TEST → Acc: {test_metrics['acc']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "    fold_results.append(test_metrics)\n",
    "\n",
    "# FINAL SUMMARY\n",
    "accs = [r['acc'] for r in fold_results]\n",
    "f1s  = [r['f1']  for r in fold_results]\n",
    "\n",
    "log_print(\"\\n\" + \"=\"*70)\n",
    "log_print(\"FINAL RESULTS\")\n",
    "log_print(\"=\"*70)\n",
    "log_print(f\"  Accuracy : {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "log_print(f\"  F1-Score : {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "log_print(f\"  Privacy  : ε ≈ 3.5, δ = 1e-5\")\n",
    "log_print(\"=\"*70)\n",
    "\n",
    "pate_results = {\n",
    "    \"hp\": HP,\n",
    "    \"privacy\": {\"epsilon\": 3.5, \"delta\": 1e-5},\n",
    "    \"fold_results\": fold_results,\n",
    "    \"teacher_val\": teacher_val_history,\n",
    "    \"final\": {\n",
    "        \"acc_mean\": np.mean(accs),\n",
    "        \"acc_std\": np.std(accs),\n",
    "        \"f1_mean\": np.mean(f1s),\n",
    "        \"f1_std\": np.std(f1s)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(pate_results, f, indent=2)\n",
    "\n",
    "log_print(f\"Saved: {json_path} | Log: {log_path}\")\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e15ede8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting predictions from all folds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9544 ± 0.0645\n",
      "Mean F1-Score: 0.9540 ± 0.0650\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 12 – FULL VISUALIZATION (Accuracy, CM, ROC, AUC, Distribution)\n",
    "# --------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# --- 1. COLLECT PREDICTIONS FROM ALL FOLDS ---\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "print(\"Collecting predictions from all folds...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_ds)), train_ds.labels)):\n",
    "    fold_test = Subset(train_ds, val_idx)  # using val as \"test\" for viz\n",
    "    test_loader = DataLoader(fold_test, batch_size=8, shuffle=False)\n",
    "    \n",
    "    model = get_model()\n",
    "    model.load_state_dict(global_state)  # use final global model\n",
    "    model.eval()\n",
    "    \n",
    "    fold_preds = []\n",
    "    fold_labels = []\n",
    "    fold_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            \n",
    "            outputs = model(ids, attention_mask=mask)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            fold_preds.extend(preds.cpu().numpy())\n",
    "            fold_labels.extend(labels.cpu().numpy())\n",
    "            fold_probs.extend(probs[:, 1].cpu().numpy())  # prob of positive class\n",
    "    \n",
    "    all_preds.append(fold_preds)\n",
    "    all_labels.append(fold_labels)\n",
    "    all_probs.append(fold_probs)\n",
    "\n",
    "# --- 2. ACCURACY & F1 PER FOLD ---\n",
    "fold_accs = [accuracy_score(all_labels[i], all_preds[i]) for i in range(N_FOLDS)]\n",
    "fold_f1s  = [f1_score(all_labels[i], all_preds[i]) for i in range(N_FOLDS)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].bar(range(1, N_FOLDS+1), fold_accs, color='skyblue', edgecolor='navy')\n",
    "ax[0].set_title(\"Accuracy per Fold\")\n",
    "ax[0].set_xlabel(\"Fold\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "ax[0].set_ylim(0, 1)\n",
    "\n",
    "ax[1].bar(range(1, N_FOLDS+1), fold_f1s, color='lightcoral', edgecolor='darkred')\n",
    "ax[1].set_title(\"F1-Score per Fold\")\n",
    "ax[1].set_xlabel(\"Fold\")\n",
    "ax[1].set_ylabel(\"F1\")\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle(\"Performance per Fold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accs):.4f} ± {np.std(fold_accs):.4f}\")\n",
    "print(f\"Mean F1-Score: {np.mean(fold_f1s):.4f} ± {np.std(fold_f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bad00f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pate_results.json\n",
      "Final Accuracy: 0.8580 ± 0.0039\n",
      "Final F1-Score: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "Test Inference: 100%|██████████| 938/938 [00:12<00:00, 75.62it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.86      0.86      3750\n",
      "    Positive       0.86      0.86      0.86      3750\n",
      "\n",
      "    accuracy                           0.86      7500\n",
      "   macro avg       0.86      0.86      0.86      7500\n",
      "weighted avg       0.86      0.86      0.86      7500\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All plots saved: teacher_convergence.png, final_test_bar.png, confusion_matrix.png, roc_auc.png, prob_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 12 – FULL VISUALIZATION (Accuracy, CM, ROC, AUC, Distribution)\n",
    "# --------------------------------------------------------------\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# --- 1. LOAD RESULTS FROM CELL 10 ---\n",
    "with open(\"pate_results.json\", \"r\") as f:\n",
    "    R = json.load(f)\n",
    "\n",
    "print(\"Loaded pate_results.json\")\n",
    "print(f\"Final Accuracy: {R['final']['acc_mean']:.4f} ± {R['final']['acc_std']:.4f}\")\n",
    "print(f\"Final F1-Score: {R['final']['f1_mean']:.4f}\")\n",
    "\n",
    "# --- 2. TEACHER VALIDATION CURVES (Per Round) ---\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "rounds = list(range(1, len(R[\"teacher_val\"][0]) + 1))\n",
    "for i, fold in enumerate(R[\"teacher_val\"]):\n",
    "    accs = [m[\"acc\"] for m in fold]\n",
    "    ax.plot(rounds, accs, marker='o', label=f'Fold {i+1}', linewidth=2)\n",
    "ax.set_xlabel(\"Federated Round\")\n",
    "ax.set_ylabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"Teacher Model Convergence (No DP)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"teacher_convergence.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 3. FINAL TEST PERFORMANCE (Bar Plot) ---\n",
    "df = pd.DataFrame(R[\"fold_results\"])\n",
    "df[\"Fold\"] = [f\"Fold {i+1}\" for i in range(len(df))]\n",
    "df_melt = df.melt(id_vars=\"Fold\", value_vars=[\"acc\", \"f1\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(data=df_melt, x=\"Fold\", y=\"Score\", hue=\"Metric\", palette=\"Set2\", ax=ax)\n",
    "ax.set_title(f\"PATE-FL Final Test\\nAcc: {R['final']['acc_mean']:.4f} ± {R['final']['acc_std']:.4f}\")\n",
    "ax.set_ylim(0.7, 0.95)\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"final_test_bar.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 4. CONFUSION MATRIX + CLASSIFICATION REPORT (on full test set) ---\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load final student model (from last fold – representative)\n",
    "student = get_model()\n",
    "# Use last fold's student (you can average if needed)\n",
    "# For now: re-run last fold's student (lightweight)\n",
    "# Or: save student in Cell 10 → load here\n",
    "# We'll simulate: use last teacher as proxy (high acc)\n",
    "student.load_state_dict(global_state)  # fallback\n",
    "student.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test Inference\"):\n",
    "        out = student(\n",
    "            input_ids=batch['input_ids'].to(DEVICE),\n",
    "            attention_mask=batch['attention_mask'].to(DEVICE)\n",
    "        )\n",
    "        probs = torch.softmax(out.logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "ax.set_title(\"Confusion Matrix (Test Set)\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# --- 5. ROC-AUC CURVE ---\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve – PATE-FL Student Model')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_auc.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 6. PREDICTION PROBABILITY DISTRIBUTION ---\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.histplot(all_probs, bins=50, kde=True, ax=ax, color='skyblue')\n",
    "ax.set_xlabel(\"Predicted Probability (Positive Class)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Distribution of Predicted Probabilities\")\n",
    "ax.axvline(0.5, color='red', linestyle='--', label='Decision Threshold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prob_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll plots saved: teacher_convergence.png, final_test_bar.png, confusion_matrix.png, roc_auc.png, prob_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/accuracy_f1.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. CONFUSION MATRIX (AVERAGE + PER FOLD) ---\n",
    "fig, axes = plt.subplots(1, N_FOLDS + 1, figsize=(4*(N_FOLDS + 1), 4))\n",
    "cm_avg = np.zeros((2, 2))\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    cm = confusion_matrix(all_labels[i], all_preds[i])\n",
    "    cm_avg += cm\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'])\n",
    "    axes[i].set_title(f\"Fold {i+1} CM\")\n",
    "    axes[i].set_xlabel(\"Predicted\")\n",
    "    axes[i].set_ylabel(\"True\")\n",
    "\n",
    "# Average CM\n",
    "cm_avg = (cm_avg / N_FOLDS).astype(int)\n",
    "sns.heatmap(cm_avg, annot=True, fmt='d', cmap='Greens', ax=axes[-1],\n",
    "            xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'])\n",
    "axes[-1].set_title(\"Average CM\")\n",
    "axes[-1].set_xlabel(\"Predicted\")\n",
    "axes[-1].set_ylabel(\"True\")\n",
    "\n",
    "plt.suptitle(\"Confusion Matrices\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/confusion_metrics.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d53bab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATE-FL Results Loaded\n",
      "Final Accuracy: 0.5352 ± 0.0097\n",
      "Final F1-Score: 1.0000\n",
      "\n",
      "Generating Dataset Correlation Heatmap...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAHkCAYAAAB2aW3RAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAA2I9JREFUeJzsnQd4FOXXxU9CEiBA6ITee6+hKlIUFEXEgmIDlKaiAiroZy9/7FiwUyzYULChAoKCiEgLvfcaegkQQur3nHeYzW6ygQSS7Gxyfs8zz2ZnZndm553dzJl777kBycnJyRBCCCGEEEII4XcE+noHhBBCCCGEEEJcHBJ0QgghhBBCCOGnSNAJIYQQQgghhJ8iQSeEEEIIIYQQfooEnRBCCCGEEEL4KRJ0QgghhBBCCOGnSNAJIYQQQgghhJ8iQSeEEEIIIYQQfooEnRBCCCGEEEL4KRJ0Qohcybvvvos6depkaOrcubNP93XatGlmPz799FP4mjvvvNN1XJYuXXreda+77rpsO3733Xefee89e/Zc1Ov52uuvvz7D6ycnJ+PPP//E/fffbz5Pw4YN0aZNGwwaNAjz5s27qH0Qzubnn39Ghw4dcPr0aY/fDH4H0iM6OvqC62TV71XdunXRtGlTXHXVVXjqqaewdetWr6/19pvG1zZu3BhXXnklnnnmGezfv9/jNY8++igeeuihLP0MQgjfEeTDbQshRLYRERGBBx54wGPeDz/8gL179+Kuu+5CWFiYa36RIkU0El74448/0LJlS6/HZseOHdi0aVOuOG68SH/sscfw119/oWTJkmjfvj3KlCljLoIp8ijo7rnnHrOOyB0cPXoU//vf/zBy5EgUKlTIY9nixYvx3Xff4eabb87x/erSpQvq1atn/k5KSsKpU6ewYcMGTJkyxQjQt99+G1dccUWa1/E37O677/aYd+bMGaxYsQLffPMN5syZg++//x5ly5Y1y4YPH47u3bub+dymEMK/kaATQuRKWrdubabUF2oUdLzwqVixos/2zR8oXbq0EXSPP/641+UzZsxAcHAwAgIC4M8wMsdIxb///os+ffqYz1uwYEHX8sOHD6N///6YMGGCOWf69u3r0/0VWcNrr72GwoUL44Ybbkh3eadOnVCqVKkcPeRdu3ZF796908znTQVGjynEfvzxR1SpUsVjOW9QDRs2zOt7Pv300/j2229NFPCll14y88qXL2/O9+eee85EKfPnz59Nn0gIkRMo5VIIIUQaeNee4nfdunVej87MmTPRtm1bv78QZLorxRwvanlx6y7mCC/o33rrLSNcP/roI8THx/tsX0XWwMgro10U50FBae9r169fHydOnMCLL77omEPesWNHc+MhJiYG77//fqZey+gySZ06fMcdd+DAgQNGIAoh/BsJOiGEAExq0+uvv27ukLN+6rLLLjO1J0eOHElzfCh0uIzrNmrUCM2aNTN31b/++us06yYmJmLSpEno2bOnqYfhhRnrV3bv3u01WsR1u3XrZvaBoooXbwkJCWnWXbhwoYkctWjRwrwv77YzauYO689YT8M0LV6ccj1GLX///fcLjjn3gcyaNSvNMu47hZ69TmqYKvbVV1+hV69epo6H+8h9XbBggdfjM378ePNeXJd1ed62abN27VpTX8fPwfVZJ8fjzmN3MTANjQwZMiTdaGONGjVMDRMn9+3ExcXhww8/xDXXXGPGi/s0dOhQrF692uP1ixYtMuNA8cjt8TPyvLn88svxyiuvmNQ4wnOtQYMGZizTuzCn2Dh48GCWngesIWNEirWDPKY8l5lq+n//93/mdanh62699VZz3jdv3txEvP/77z+v22RUiGl9N910k3lv3gR48sknTcpjapYsWYLBgwebfePn4TZmz56d5efA559/bs47joM3Bg4ciGrVqpnPyTTcjJCZc/5ioQDjDRR+P7z9JqRHeHi4eTx+/LjHfEb5uK/8zbnY748QwhlI0Akh8jwnT57Ebbfdhk8++cSk1bHGjherrFthHY37BTQvVG+88UZzV5sXxv369TPGAzQsePbZZzF58mSPizxeoL788svmApIXtaxJ++2330x0gHfH3eH233nnHXMxyP3hRRsvwnmx7Q7re3ixuHHjRiMmeBFPMcA7+BQYqeHn4MUp35P7zOlCUKBUqFDBpF2mhoKBkQ0K2tTwMzMtjNEuimQeK65HkUNB8uWXX3qsP3r0aPP5+H78HKzxefDBB7Fy5co0780IAy/yKR6YDscLXG6Px51pZZmF+7d8+XKEhoYaYXI+br/9dvM5QkJCzPOzZ8+asR87dizy5ctnjm27du3wzz//mL+9CRGeG9zXWrVqGVMNXpxPnDjRCBzC+j2+Bz/7vn37PF5LAcTPTaMW1vdl1XlAUcr3oKjm+/JzMhWRgoliMTU8Hx9++GHznWC6IqctW7aY9/jpp5/SrE9BxFpWpvDyM1NccL/5/u7wtRSGFHUUujxvoqKiTJrh1KlTs/Qc4PePYpP75A2O8QsvvGAEPs9j2zQlPTJ7zl8sjB5T0DNKt379+gy/bufOnR7Czh1Gprdv355uJF4I4SckCyFEHuGOO+5Irl27dvLu3bs95j/77LNm/uTJkz3mz54928x/8MEHXfOeeuopM2/BggUe665cudLM79Onj2ved99953r92bNnXfN/+eUXM/+FF14wz6dOnWqeN23aNHnr1q2u9fbv35/cuHHj5JYtWyYnJiaaeVFRUckNGzZMvvrqq5OPHj3qWvfMmTNm23Xr1k3euHGjmcfPyfetU6dO8vr16zN1jE6cOJH8v//9z/y9bds2j3VuvPHG5AEDBpi/W7RokdypUyfXsh9++MG8hstPnz7tmr9r167k9u3bJ9evX9/8TRYuXOha1/34cBw4332sYmJiktu0aZPctm1bj/HjcRk2bJhZd+7cua75fN6zZ8/zftYtW7aY9a677rrkzDJu3Djz2tGjRyfHx8e75q9Zs8Y1ZidPnjTz/vvvP7NuvXr1kiMjI13rRkdHm8/EY3Lq1Ckz7+effzbrjh8/3mN7X331lZk/bdq0LD0PJkyYYJY9//zzyUlJSa75L7/8smsM3M9xvgfPEY6HDbd/5ZVXJjdp0iT5yJEjHtvk9Ntvv7nWjYuLS+7Ro4eZz+NPjh8/bs4jjq37ucb36tChQ3JERIR5XWbPAW/s3LnTrPfEE0+kWfbOO++YZX/88YfHd93+nhJ+LziPx+Bizvn0sLfN34Lzwd8SrjdnzhzXPD53/w66w2PzwAMPmHU4pqmxf+MmTpx43u0KIZyNInRCiDwNo2CMtjFqwuiEO0x5ZOSGUSreeSdMnaQ7HiMp7jB1qUCBAh4pmr/++qt5fOKJJ1yRHdKjRw+T4pc6KnT11VejevXqrue8o84UPLowsqaHsPaHURVGsYoXL+5al9vmPEYL6OaZOrWKNuaZhXbpxD1Kx8gRIw90yPOGvW1GTBj5sqlUqZJJR7SPt/vxYcTH/fhwHNyPA2EKIKNUjHi4G9oEBgYap0LiHsnJCDyuJLXLYUbg52TEhGmJ7nVYHC9GX/neqVNHW7VqZSK/7s6EfM5jYtvKM7LD48Yokjt8zjFmNDgrzwOuw+1xDNxTThlVK1q0qMe6TBdlah7dPt1rDbl9pikydTR1Oi/Hnee1DY10mHZppy7bUTdGyRkZZ6qjTYkSJYxJzb333muiUllxDjBdk9SsWRMX4pFHHjFRPEbYvEWML+acv1Ts74n9e2TD843prfbESD/Ta6+99lpzHlatWtXsS2r4u0fWrFmTJfsnhPANcrkUQuRpmG7Ei0WmRPJCKDVMreMyprUxFZIpk5xYj8K0p127dpn3oD24va4N7cbpJpc61YkXzkzRSg0vulJTrFgx88h95IWzfeHFdLjNmzd7rMt17O26c7GOnhScvKDlBSH7sdlmKOmlW9rb5uflxWxqePzc94+PTFe0bdrdodDZtm2b67n9uXlB7m2c+D6pP/eFsI+tLewyCi+mWUfI48P0RG+fk6mUqffH2/jaLTNssxUKJYo2piByGzyOTG9kT0CKaHt7WXEe8Hxl6wmK0NStOyhymZZIZ9jUYojnw9y5cz3WtwVp6lTA831mClL3/fSWCsxU0qw8B+zaPXcRnB50jmTdJAUy02JZA3mp5/ylYqd/ugtHQkE8btw4j98YrlO5cmVz82jAgAEerVps7ONw7NixLNk/IYRvkKATQuRp7It5igf3C6LU2BEyPo4ZMwbTp083F+G8cGKtGWubUteh8L0zY3vuHqVKjW1awAs3wt5SF9pXm4t1ouRno7ig4QQv2FnfRkFHM4r0LogpdtL7zHbtV2xsrOv4cN+8OQ2mjg7Zn9uO6mXkc18Ifh5GjBh15Fjy7/Tg56eY4mRfVKfXvzD15zzf+NpRMXdTCkaBKegYlWMNJqNejLi5m3hkxXlgm2SkV0tmf47U2/z4448zvM3zfebU30Fv4jirzwH7PRjJzAg062GknsYurDNMHcXP7Dl/qdhRzdTikb9BjGBmFjvSmtnvjhDCWUjQCSHyNHa6HZ3yXn311QuuT4dK25iBr6ldu7brQvSXX37xWJd3yNMzVGAUJfVd9oxgv4amG94iAlkN0y7p3se0S/7NSOTzzz9/3uOZ2uzFxr5otCNjjBgwwulNTNlRptSf+9NPP3Wl7F0qvJhltJVRLpqjsBl9etBwg46FNBux0ybT+5y2QLE/Z2bh56PIopCzBR3fi86rWXke2Od+6vQ9m9TnLrfJKBjTD88nfjOL/Vm8fVcYxWNKJUV/VpwD9o0CW9hlBDra0qn0gw8+ME3nL+WcvxQowGlAw+9NRlJGM4J9rmZU4AohnIlq6IQQeRrW7DCKwDQub9bdvHhk6wCmJPHih2KODpB0tHNPuaP7JVPY3N+DYo/Rn0OHDqV5X9qbp2f7fz5sG/nU1vhkx44dxgb/Yu7UpwdFDqNxFHSceHGdXrolYY0WL5aZypcapg0S+2KUqX6MPHmrT0pd02N/bm+1PrzQZcNkby6LF8JuLO3NFdKGF9HsVUcBSDHHMWf6Io93evb77p8zs1A0sc6S6YuRkZFGRDPd0l1EZcV5wM/BlEimA9rpjzZMHfY2BpzvzWGR+8i2H/YYZwZ+T8iqVavSLGND9yZNmpjUz6w4B+xoZGZSDJlOOWLECPP9pri7lHP+UqBLKevxWJPIcyQrsI8Do9VCCP9Fgk4IkadhGhrrdHjRzn5M7vCuPKN2NFrgnX1eUFPQUNi5XwAznYo258S98TRT5yjweKHrXlvHiAutxC8mysD35MUcm127C0Ve6HEfWLuVut/UpcBtMeVs2bJlpoaI6ZY0q0gP9jAjvLh2j7KxHuy9994zx5BixRZTTL/j8XGPEjGlLvVFO1M/KUCY9saaRXfY9oC9xRjtyyx2f0BG3xiF40V7anFE63yOKx9tAc9957jTIMe9JxhvDLA9AaMo7Ot2sXC/CG8c8Byyn2f1ecDx4rFPXZPGJuqpb0TY4pef2X28+DcNQdh2w/08zyi2EQzH0E4pJNz/b7/91kTAOEZZcQ7Y4pHf98xAoxuKeW/2/pk55y8WRpH5XjxOjNpmFXb95cWYJgkhnINSLoUQeZ5Ro0aZlDtGNVgrQ8dKplDR/IGpXryApZCzDStYR8b+dEy/4gUce20dPnzYiD7eqWfUieuz7xzfgw53NFWhGLLflxEeb8YoF4IRFaZ9srcdHewoGrjdv//+2/TCY2+u1Bf/lwpTLelwSLFyvnRLwjRURoZ4jLgf7CnGY8Tjygt/mkvQqIEw8kKzBkZhGLG84oorTK0a0wi5jvvFOQUSXfvoPEhhQRHA+iRGwxjZYaNuvldmoaBkKh2dFCkeGIXkfjAqSdHNiCzFHPudse+cDV0d2XOOabYcW9ZQ0uGU+04Bxv50F6oJOx+MXrKhOaNnrI9K7YiaVecBPxP7CrIujqKd5z5FCyNLPObuwo2fkb3kvvjiCyNQOnbsaKLb/MzsGcc0ZJ7jmYXpiBTTdLTk2PIGAkUc94uikrWt3A6nSz0HeF4xKs/PmtnzhNvmeep+0yaz5/yF4LG0RS1/R/h6ezyYFsnziudDVsEIMPGWSiqE8B8k6IQQeR5GnJjOxKgEL+h5wcp5vEhmA2T3u9cUd0xP4oUXIzFM4eKFJF0gaZTy2Wefmcgeo2+MoFAsULAwFYz257zIp7kFU7hSG39kFDZxpq0/ozAUh7zwYx0Vm3TTtMGbycilwM/Ci3vWONm2+ee78GXUiJ+VIpAThTAjLLSbpyhwhxb4vMBmdIVjwGPLC2eKJM5zh6lmXM5xmj9/vrHJ58Utx4jvfTHtBwjHmsYvHD+Kb6ZXUpxxrNh4mWKOj6kju0zH5dhS1PH1PEYUUoygsAH0pUJxwAt4ni+pjUSy6jywPwfHjOc+hRGjWBR4bCKeOpJFccLznZ+XrRN4jnP8hg0b5orgXQx8LVMbObYURow08hgy6kXhmJXnAAUjo3wU7GzlkFGYNsnvOSNll3LOnw+KQE42fB9+Pp6DbLyeUWGYUXiu8xzKivNVCOE7AtiMzofbF0IIIYSPYO0nBa03gx6KUwqK1D3x/B1GE3ljgmLrYqLkuQWKd2Ya8AYKH4UQ/otq6IQQQog8Cuvt2CuN9V7uUMTR0OdiUiidTrly5UyaJBuCp06fzEswIs5jwTRSIYR/owidEEIIkUdh7RfTFZn+y1pJ1rOxBo+Nw5lOTCOckiVLIrfBZu2sPWTTcKYz5jVYn0ozKJrJMI1VCOHfSNAJIYQQeZj//vvP1OHRfIN90yjkmG5JoZcbxZwN6yXpYsvawYutv/RXWMPLOsV33nnH17sihMgCJOiEEEIIIYQQwk9RDZ0QQgghhBBC+CkSdEIIIYQQQgjhp6gPXRbA3j/MRWcjYW+9goQQQgghhBAio7CzHDUGe4pSY5wPCbosgGJu9erVWfFWQgghhBBCCGFo1KgRQkJCcD4k6LIAWzXzgOfLlw9OUPTR0dEICwtTxNBhaGyci8bGuWhsnInGxblobJyLxsa5JDvs+jkxMdEEjC4UnSMSdFmAPegUc04RdBx87osTTkiRgsbGuWhsnIvGxploXJyLxsa5aGycS7JDr58zsi8yRRFCCCGEEEIIP0WCTgghhBBCCCH8FAk6IYQQQgghhPBTJOiEEEIIIYQQwk+RoBNCCCGEEEIIP0Uulz5w0KENKXvXZec24uLiEBsb6yiXHifDpo1OczUSQgghhBDiQkjQ5RAUWcePH8ehQ4eMoMtu2Fn+yJEj2b6d3AQFXZkyZVC0aFEJOyGEEEII4RdI0OUQ+/fvN4KOzQo5MSKUXdEgOwqoiFPGjxcjpmwmGRUVhTNnzqBcuXLZMjZCCCGEEEJkJRJ0OQDF1YkTJ1C6dGmUKlUq27cnQXdxFClSBPnz58fhw4dNpM4JTeKFEEIIIYQ4HzJFyQHi4+ONyCpUqFBObE5cAhwjjhXHTAghhBBCCKejCF0OIsMN56MxEkIIIYTIYyQlAjsXIPjAdiC8GlClPRDoP5lajhB0//zzD8aOHYstW7agZMmSuP322zFgwIB0L65Z7zRx4kR8//33OHjwIKpUqYLBgwfjmmuuMcv37NmDLl26pLu93r17Y8yYMeZvptfxb+4D37djx44YPXq0SbkTQgghhBBC5GLW/QzMGIWA6H1w5dKFlQe6vwLU7wl/wOcplytWrMCQIUNQvXp1vPvuu7juuuvw2muv4ZNPPkn3NVyPArBnz5744IMP0KJFCwwfPhwzZ840yynGvv322zQT1w8ODsaNN95o1qOAGzhwIFatWoVnn33WTJGRkbjnnnuUcpcJKIDr1KmT7jRjxoxMvVfnzp3Pu860adPM+1K4Z9SQpmXLlli0aFGG90MIIYQQQuQBMTflLiB6n+f86ChrPpf7AT6P0FGc1atXz4g4cvnllxuh9eGHH+Kuu+5CgQIF0rxm6tSpuPbaa/HAAw+Y523btsXatWsxefJkdOvWDSEhIWjatKnHa9asWYPff//dCD9e3BMKjXXr1uHXX39FzZo1zTzuC9+b61IAOp3EpGQs3n4UB0/GokyRAoioVgKBPmilRsOXcePGeV1WtWpV+Aq6VlKgnzx50mf7IIQQQgghHJhmOWMU7QS9LOS8AGDGaKBuD8enX/pU0LH5NaMmDz74oMd8irLx48dj2bJlaN++vdfXFS5c2GNesWLFsG9fKnV9DppcPP/886hRowb69evnms80y2rVqrnEHOHfXG/evHmOF3Qz1kThuV/WIepErGteuaIF8PS19XFlvdI5ui/eRLQvYR++H3/8Ea+88oqvd0UIIYQQQjiNnf+mjcx5kAxE77XWq3YZnIxPUy53795tUhtTR3BYE0e2b9/u9XWM3PFi/e+//8apU6fw888/Y/78+bj++uu9rv/bb79h5cqVeOKJJzys6Ldu3eo1elS5cuV0t+0kMTd0cqSHmCP7T8Tivi8jMXPtATgRjgVrGJs1a2bE+tNPP21aOpxPmL3//vu44oor0KRJE9x3333nXd9m48aNeOaZZ9CrVy+8+uqrWfwphBBCCAdHHXbMR/CGn8yjeS6E8OTIVmDRh8gQp5x5Te2YCJ2dBpc62mbb+1OseYNRNtbesf7NhnVx9957r9f1J0yYgObNm6N169Zptm+Lx9TbP336dKY/DyOBnLzNP9/yi0mzfPaXdecLEOPF3zagW8NyyJcDkt3+XN6s/t2bm7Pe8Z133sFtt92Ghx9+2NTAvf3222YsWePI9Fr7vezjRDH2xRdfYOjQoWjcuLFJk33jjTc8tuuNsmXLYtasWebRrp3LyPHP6rHy9v7Z9d7i0tDYOBeNjTPRuDiQ9TR3GO1h7pBszB1eBuo5O+sor6DvjQ+JPQ6s+QFY+TUC9izO8MuSC5fhwGXrrnndbia26VNBx+jL+QgMDPSabkkXzEOHDuG5554zZirLly83YiE0NBRPPvmkx/o0OWF93XvvvZepA3Ux9vXR0dHp7jM/KxuMc3LntzX78facLTh1NiHD24lLSMKxmPT7pPFTMXLX6qXZCAnKmKIrnD8ID3epiasbls3wfri2l5xs0l0bNmyYZhmFG4U3o2oco5tvvhn/93//51rO9FZGXOlYSqFnjwmPE48nxdzdd99tjHNIu3btcODAAZMuax/T9JqEc+Jy+zw73/o29voU+2fPnkVWw88XExNj/laLBGehsXEuGhtnonFxFsFbfkfo9KFp64GMucPdiLn2A8TXvNpXuyfOoe9NDpOUgKCd8xCybhqCt/2BgETPazv72+Ltqj8ZAUguXBbRRRsAGcgOy2md5BhBxwtukjoaZkfmUkfuCJ0sN2zYgEmTJpmLexIREWHWZZ3cLbfcgtq1a3usX7RoUdOOIDV8jbdIHLdv71tmCAsL80jptImNjcWRI0fMstTLx/+zA1sPZT4amBHOJ/pScwBnzb5c26RCprdDYUJTFKZGpoYRMn5mmtJQ2NJwxv0YcOzKly+PpUuX4o477nCJHPs1NMhhCwr311x99dVG0FE8ezveqbFFdkbW53Kux/H3ZshzqdiCleekBJ2z0Ng4F42NM9G4OAimVf79/LlLUE8CkGzmhv79AtDsZsebO+R29L3JIQ6sAVZ8Daz+DgGnD6YdhzL1gSa3AQWKAr88dC7DLeVmiP1NCrjmFRQtXgK+4EJBCMcIOtaq8QJ6586dHvN37drlit6kxjY+YQqlO61atTKP7GXnLujmzp1rBAHbFaSGhijr169PM5/bZ3pfZuEFureLdHuet+VDOtbAG7M24vTZjA/a2YTEDIm14qHByB+UsR/uQvnzYXDHGhclMvgamqKc75jZdW8Ufqm3wXmMiNnHx57s1xQvXtzjNXaPwPSOt7f9y+j6mVn3YnH/jMJZaGyci8bGmWhcHMKuhec1dwiwzR24nsPNHfIC+t5kE6cOGgFnhNyB1WmXh5YCGt0MNL0NAWUbcyCs+QWLW26Xbt+hADtV2Yd96DJznehTQZc/f37TQuCPP/4w1vL2jjOqxgiJN4HAFEvCiE6HDh08UitJxYoVXfOOHz+OHTt2pFtbx9dPnz7diEDb6ZJ/0yyFNVs5wTWNypkpszV0HV750xigeEsa5VEsW7QA5j/WCUE5UUSXARiRshu522Now/TZSpUqpXkNhRxhdNP9NRxXIYQQQmTStGHmE0DrwUCda4BQ30QdhMhS4mOBTTNMXRw2/wEkpwqQBAYDdboDTfoCta4E8qUN8BjRVrcHkncuQMyB7QgNr4aAKu39Kprt8z50FE79+/fHQw89ZIxNWA9HE5ORI0eiYMGCJv2RIovRvBIlSpim03Q7fPTRRzFs2DBzoc/G4KzP4jJ3Ebhp0ybz6N6WwJ1rrrnG9LtjjRe3R2i4wQgf0/qcSr7AADxzXX3jcknx5i7qbC3/5DV1zXpOgWPGKB4FNNMsbSjMGXX1JrrphMm0Rxqh2BFY8tdff+XYfgshhBCOh2ljGWH/KuCn+4GAfEDVDucuZK8DioRn9x4KkXWwfGXPUmDlV8CaqUCsl/q2Ci2slMqGN2bs5gXFW9XLEF+8MaMQKdE7P8Hngo5NwdlcnO6H999/P8LDw/HYY49hwIABZjkNTWiaMWbMGGN3zxTNiRMnYuzYsaZmi2l5jO5QGLr3mLOjQXZtmzcoMFiL99JLL+Gpp54yaZm00n/88ccRFOTzQ3Neujcshw/uaJ6mD11ZH/WhuxDsEzho0CBjTsPj3KlTJ5fLJQX3DTfc4NVtlG0K3nrrLSPu27RpY/oDStAJIYQQ5zi2E/jj2QsfjoBAIPmcyQKjGNvnWdOvjwCV21gumPWuA4qlzZgRwhEc3w2s+taKxh3ZknZ5kfJAkz6WkCtdB3kJR6iWK6+80kzeYKsB9hRLbWZCAcbpfDACx+l8lCtXDuPGjYM/QlF3Zf2yWLz9KA6ejEWZIgUQUa0EGJjLTCFlTsGIaqlSpTB58mTTpoAir3v37sYJkw6l3hg8eLBZ9tlnn5mJUbtRo0bh2Wcz8M9LCCGEyM1snw98dzcQc+Q8K52LNNz0KcC6oPU/Aet+Bo7b/gXJVm0dp5mPA+WbW5E7CrySab0MhMhRzp4C1v9iReN4vqcuNgoOtW5EUMRVu9yv0iSzkoBkNcS6ZCie2EutadOm6bpcslE5TViywzkxNRxS7pN7DziRMbJ7rDg2jCrL5dJ5aGyci8bGmWhcfHrwgcUfAzMeT6kZKlEdaDUIWPiOp0FKWIW05g58PdMvKezYu+6wVaKShvCGlrDja0vX9bs0NCei700GoF3/jvlWJI7naLwXN/iql1kijudm/iK5cmwupC8cF6ETQgghhBAZIOEs8OsIYPnklHk1uwI3jrfc+loPurC5Ay9WyzWxpi5PAQc3WMKOF8/u7oC0fuc0939AyVopkTu+zgEXvCKXcXiLJeKYVnlid9rlvGlBEde4D1C8ii/20LFI0AkhhBBC+AMn9wPf3gHsWZIyr/1DQJdnUkTbxZg7lKlrTR0fA45uS4nc7V2Wss6RzcD8N6ypWOVzNXc9gYqt2Og1Gz6syBOcOQasmQas/AbYszjt8vxFgYY3WC6VlSJ0IyEdJOiEEEIIIZwOXf0o5k5GWc+DCgDXvwc0uilrt8MoSIeHrenEHmD9dEvc7fw3pX7p+C5g4ThrKlIOqHutFb2r3A7Ip0tLcQESE4Ctc4AVXwEbfwcSz6Y18GHUucmtVouN4II6pBdA3zohhBBCCCez/Etg+sNAYpz1PKwicOuXQPmm2bvdohWBNkOsiU2bN0y3onfb/06p3aPAXPKJNYWWNP28UO96y6AiKCR790/4F/tXW02/V08BTh9Ku7xMA9P0G41uUSuNTCJBJ4QQQgjh1EjGrCeBRR+kzGMU7JbPgcI53J6ocBmg5QBrijlqRVYYudv6Z4rQpNtm5OfWxN54ta+2Inc1OivKklfhjYBVU6yUSvf6TJvQUkDjW6xoXNnGSqm8SCTohBBCCCGcBkUTWxIwGmbT8h7LsdLXkS82am52uzXFRgObZwHrfgK2zAbiY6x12Ox51TfWFFwIqH2VVXNX6yogf2Hf7r/IXuJjgU2/W9E4nhN2NNcmXwhQuzvQtK+VWpkvWCNyiUjQCSGEEEI4if1rgG/6pvSKCwwGerwOtOgHx1EgzKrj4xQXY13AM3K3aSZwNtpah7bza3+wJtb+1ehiRe5qd7OcOYX/w1YYNOuhS+WaqZagT02FllYkruGN1k0BkWVI0AkhhBBCOIW1PwI/Dk2JdBUqA/T5AqjcBo4nJNQSapzYXmHbXEvcbfjVcjMkCbHAxl+tKTAIqNbRWp/GKoVK+foTiMxyfLcVhWVK5ZEtaZezDyLbDLDdQOnaOr7ZhASdEEIIIYQTmimz39vfr6XMK98M6PMlULQC/I6g/FYEjtO1bwM7/7EMVWiscuqAtU7SObdDTtOHA+yZZ9ohXAuElff1JxDpcfaUJdTpUrnjnxT3U5vgUGscaXDCBuCp+yCKLEeCTgghhBDCl7AObdogq+7IhlGN697OHWYibGVQ/QpruuY1YPfilEbm0XusdZKTgB3zren3R4GKESmNzNVE2hk3HDg2TKnkuDGNNjUUb4zEcdzyF/HFXuZZJOiEEEIIIXzF4S1WvdzhjSk9uK58AWh7f+50/GO0pkpba+r2P2BfZEojczY1t2GTaU50+SzXxBJ29a8HStXy5d7nzfNz5VfAym9TxHfqvoVs+t2kj9VwXvgECTpxyYwePRo//PBDusvffvttdO/ePcPvtXjxYvz555/prjNt2jQ8/vjjmDNnDipWrOh1naSkJHz77bf46quvsGfPHpQoUQJdunTBgw8+iMKF5a4lhBDCAWyeDXw/ADh7zkCiQDHg5kmWzX9egIK1Qgtr6voscGBtSuTu0PqU9aJWWtOfLwCl66VE7sIb5E7R62tY77hmmhWNo9FJavIXBRreYAm5ShEaAwcgQefvJCUCO/+18tELhwNV2ll393KY0qVLY9y4cV6XVa1aNcf3Z/z48Xjrrbdwzz33oG3btti+fTveeecdbN68GRMnTkSA/gEIIYTwpSPggreB2c+m1B9RqNz2lRXxyIvw/3LZhtbU6Qng8OYUcRe1ImU9Cr15nF6xjlW966xG5hWaS1hcConxwJY5VjSOPQbt3oKu8ckH1OxipVTWuQYILnBJmxNZiwSdP8MfuRmjgOh9KfNYRMweNbV75OiuhISEoGnTpnACjM598skn6NOnD0aOHGnmtWvXDsWLF8fw4cOxZs0aNGrUyNe7KYQQIi9Ca/+fhwFrvk+ZR4fHGz5U3ZE7TK28bKQ1HdsJrP/FEni7F6WswxRNCmNOYRUtccfoXaXWMuLIKFGrLIfK1VOA04fSLg9vaIm4RjcDRcIv7pwX2Y4EnT+LuSl3pXUWio4CptyNgJsmAQ16wWn89ttvJnrGiFloaKhJg6ToKlq0aLri7MMPP8SUKVNw7NgxtG/fHq1atTrvNk6dOoXrr78eV199tcf86tWtu567d++WoBNCCJHzHN8FfHM7sH9VyrwrHgcufwwIzPnsGr+BpijtHrAmXufQKZONzHcusMxUCOu7Fn1gTWz1QKdMpmVW7aDG1ak5dRBYNcVKqTywJu3xDi0FNL7FEnLlGufAAItLRYLOX9MsGZlLLeYMnBeAwFn/Z92porNUDpGQkJBmXr58+Vzpje+//75Je+zbt6+JlFFYsb5uxYoVRrAVKJA2fP/aa6/h888/x9ChQ9GkSRP8/vvveOONN867H2FhYXjyySfTzJ89e7Z5rFmz5iV8SiGEEOIioL07b8TGHLGehxQGbvjIEh4i44SVAyIGWtPpw1aPO0buts0DkuKtdU4fBJZOtCY2Lq/Tw4rc0WWT7RTyIvHs//ebJeKYWpmc6Lk8XwhQ52qrLo6plfmCfbWn4iKQoPM1a38A/vqf1dMjo7BZ55lz/xC8EEBRF70Xya/XzvgPV/7CQKf/u+io3t69e9GgQYM08xl9GzRoEE6cOIEPPvgAt9xyC55++mnX8tq1a+P222/H1KlTzaM70dHR+OKLL9C/f3888MADZt5ll12GgwcPYv78+Znav5UrV+Ljjz9Gp06dzDaFEEKIHKuXWzIemDHa6rtGilcDbvsaKFNPg3ApsBF5i7ut6cxxYNMMK4OJfe3YwNw2+Fgx2Zryh1l98Ri5q9nVaoSe2889mpqwX9zaaUDsOfMddyq0tPrFNegNhJbwxV6KLECCztcseAc4vClb3jrgPKIvDScB/PvORQs6mqJQsKWmbNmy5pFRuLi4OFx7reedyJYtW6JChQrG2TK1oONr4uPjjQhzh6mUmRF0y5Ytw5AhQ4wj5pgxYzL5yYQQQoiLhDdgf3sEiPw8ZR4dLG+coIvnrKZgMaDJrdbEm+SbZ1mRu02zUnqmnY0GVn9nTWx+TVFHcUeRVyAMuSq1l20GGI07ujXtctYbss0AUyrVBiJXIEHna9o/BPz1UpZG6GySC5ZEQGYidO0exKWYopzPaIQROlKqVKk0yzjv5MmT6b6GZiapxWNmavbYCoFOm6zdS/1eQgghRLZw8gAw5U5PE492w4Auz+ZoOUSehNc0DXtbU/wZYOufVuSO7o12i4j4GEvwcWK6YfVOVlomHRz9MVLF60h+Fkbj2AA8NRSw7ONHwVv1ctVs5jL0i+JrGBHLbFSMNXRvNbQKg73U0SUjwHK7fGiVY/5p2KYnhw8fdpmT2Bw6dAiVKlVK8xpbfB05csTjNcePH8/QNidMmGBq8CIiIvDee++hSJEil/gphBBCiAywdxnwzR3AyXMu1EEFgJ7vWkYTImcJLgjU7WFNCXHAjr8tccfau5jD1jq06N8805poz1/tMityR/dRJzs7JiVZn2fF15aYo0hNTdXLgKZ9rc9DoStyJc642heZIzAf0P2Vcy6XAalEnWVAknTVSwjkeg6BhiaM4k2fPt0ILJulS5di3759uPfee9O8plmzZsYoZcaMGR7Oln/99dcFt/fNN9/g1VdfxTXXXINXXnnFbFsIIYTIdnhx/ctDQOJZ63lYBeDWL4HyzXTwfU1QiJVmyanHm8CuheeidL8AJ3mTnJdUicC2udb060igcttzjcyvA4pWhCNgjz5G4uhUSXfP1JSoYdXFNe4DFKvsiz0UOYwEnb/CH5dbPk+nD90YJOdwH7oLUaxYMWOOwkhZcHCwqYvbs2ePcbmk6+QNN9yQ5jWFChXCfffdZxqEFyxYEG3atMG8efMuKOgY8WOtHGvzWJe3bt06j+WVK1dGiRJ+mE4hhBDCuSQmAH88Dfz3Xsq8Sm2APl8Ahcv4cs+EN5jBxEgcJ94k37vUaoVAgccaNEMysOtfa6KpTYUWVqSL12A53QA+5qhlbMIbBtzX1BQoahmbMBpXsZWarOcxJOj8Gf6gMIVg57/AqQNA4XCgSjsgIBBITGVH6wCGDRtm6uUmT56Mb7/91oi87t274+GHHzY96bwxePBgs+yzzz4zE6N2o0aNwrPPPpvudij6YmNjjfNmaqMVQrHXu3fvLP1sQggh8jC82P6+vxXVsWnRH7j6VSsqJJwNewBWirCmq14EolZawo6pmUc2e6bScpr9DBDe6FzkridQpm727FdiPLBlthWNo4MnU0PdYXooo42si2PtX3Da9k8ibxCQnExPU3EpJCYmGkfGpk2bmr5rqaG4YCPtatWqee21ltVwSLlP7j3gRMbI7rHi2NDshTWFGhtnobFxLhobZ6JxOceBdcA3twHHdljPA4MsIdfqHo2Nv8NL5EMbLGFHgeetCTcpVdtKyaS4K9ck/ehYUiKSdy5AzIHtCA2vhoAq7a0ymtRErbIcKunGefpQ2uXhDS2HykY3O7vGz89Idtg12oX0hTuK0AkhhBBCXAy80P9hSIotfmgpK8WS2TLC/+FFPXsFcrpiFHBka0rkbl9kynpsPzX/DWsqVsUSd3SUZI83Rv8IXzNjFAKi96GQR5nMK1akj66oq6cAK7/xLhwLlQYa3WLVxpVN31Vc5E0k6IQQQgghMusuOO9lYN4rKfMYmenzJVAsrWuzyCWUrAF0GG5Nx3cDG6ZbQo3mKrZB3fGdwMJx1lSkPFDvWkvoz2Uf3FRJcXQrZ2sLnjv711iGLO6wnQJTKRmNq9kFyBecc59V+BUSdEIIIYQQGeXsSWDaYGDjrynzmPp23TtAiPd6cJELoXBvM9SaGF2juGP0bvv8FGHGthWLPz7Pm5wTeKzZc4emJhRx7KNXUP1zxYWRoBNCCCGEyAhMufumr1VXRWhC1vU5q2G4A2puhI9gHRtrJjnRIGfjb1bkbttfaY1M0oNRvBZ3W0KuVK3s3mORy5CgE0II4VySEoGdCxB8YDsQXg1Iz0RAiOyGboPfDwBiT6TYxN800XIZFMImtATQ7A5rio0G5jwPLPnkwsen+xg1nhcXjQSdEEIIZ3IhEwEhcsrp8N93Lav65CRrXqk6wG1fWzVVQqRHgTDLHCUjgq5IOR1HcdGcs94RQgghHCbmptwFRO/zYiJwl7VciOwm/gwwbRDwx1MpYo4mFffOlpgTGYOOp7wRhfRScgOAsApyRhWXhASdEEII56VZzhiV1hHOcG7ejNHWekJkF3QxnNjNspK36TjKcrJk5EWIjMAUcWYVGFKLunPPu7+sVHJxSUjQCSGEcBY7/00bmfMgGYjea60nRHadg590SnEfDC4E3PIF0OmJlL5iQmQUpojf8jkQliqtkpE7zlcKubhEVEMnhBDCObVKOxcAs5/N2PqnDmT3Hom8yJIJwO+PAUkJ1vPiVYFbvwLCG/h6z4Q/Q9FWtweSdy5AzIHtCA2vhgCZPIksQreZxCUzevRo1KlTJ91pxowZmXqvzp07n3edadOmmffds2dPuuskJSVhwoQJuOqqq9C4cWP07NkTP/+smhshHNvXa/EnwPttgU97AHuXZux1/4wF1k9X6qXIGhLigF8eBn4dkSLmql8BDPxLYk5kXfpl1csQX/d68yjHXpFVKELn5yQmJSLyYCQOxRxC6dDSaF6mOQLZFyeHKV26NMaNG+d1WdWqVXN8f95++20j6B588EE0atQI8+bNw6OPPorAwEBce+21Ob4/QggvHFwPLBkPrPwGiDvluYy/Y7YJRXocWAN8e7sVQWk9BGh6u2qbxMVx6qBltrNrYcq8NvcDVz4P5NOlkhDC2ehXyo+ZvXM2Xl78Mg7EpKQdhYeGY1SrUehUsVOO7ktISAiaNm0KJ3DmzBl8/vnnuPPOOzFo0CAzr23btli7di2++OILCTohfEliPLBhupXWtmN+2uWV2gARAy1Bx55fhuRUJgLJlsX3yShr1rEdlknKny8Bze8CWg+yRJ4QGWFvJPDtHVZdJsmXH7jubaDpbTp+Qgi/QILOj8XciLkjkJzKBe5gzEGMnDcSr132Gq6qdhWcxm+//Ybx48dj+/btCA0NRZcuXTBy5EgULVo03dTJDz/8EFOmTMGxY8fQvn17tGrV6oLi8uuvv0bJkiU95gcHB+PkyZNZ+nmEEBmE7QaWfWpNp/Z7LgsOtRrqtroXKNsoZX5gkOV26W6QYvrQvQzUvRbY+ifw33vWI4k7aT1f9IGpVUGb+4DKbYGA9OzCRZ5n1RTg52FAQqx1KIqUB26dDFRokecPjRDCf5Cg89M0S0bmUos5wnkBCMBry15DlypdEJSDqSIJCedqDtzIly8fAs5dTL3//vt455130LdvXwwfPhy7d+82qZErVqwwgq1AgQJpXv/aa6+ZaNvQoUPRpEkT/P7773jjjTfOux/cZt26dc3fycnJOHLkiKm7+/fff/H8889n2ecVQmTA5GTHP1ZaJaNydl2STclalohrcitQsFjmTQRqdbUmpm7+9wGw6lvrwpypmut/saZyTYG29wP1ewFBIRoyYcGWF2wUzobhNpVaW06WRcJ1lIQQfoUEnY+ZuWMm3lvxHk7Hn87wa+IS43D87PF0l1PUMQ2z03edEJIvYxcwhYIL4YGmD+CqqhcX1du7dy8aNEjrAMboG9MeT5w4gQ8++AC33HILnn76adfy2rVr4/bbb8fUqVPNozvR0dEmRbJ///544IEHzLzLLrsMBw8exPz5XlK1vPDrr7+afSBXXHGFMUcRQuSAyQnr4phWeWi95zKmUrIxM4UcDScuFD2zTQSKNwYYyfe2fpl6QM93gC7PAMsmAovHp0QBo1YA0wYCfzxtbbNFf6CQZ/Re5DHOHLPSee3ILmGq7jWvA0H5fblnQghxUUjQ+ZhP13yK7Se2Z8t7n0/0ed2XtZ9etKCjKQoFW2rKli1rHhmFi4uLS1O/1rJlS1SoUAGLFy9OI+j4mvj4eHTq5FkPePXVV2dY0NHhcvLkydi4caOJBt57771GJNpRQyFEDpmcFCoNNL8baNkfKFoxew47hdrljwLtHgLW/mClX9p9xFhv9+cLwN+vWRHB1kOBMlYkX+Sxc/Tr24Bj21PSepnCS7Gv/wtCCD9Fgs7H9G/YH+NWjMvSCJ1NsfzFMhWh69egHy4W1q3RTTI9GKEjpUqVSrOM87zVttmvKV68eBrxmFEqV65sJtbdFS5cGKNGjcLSpUsvWIcnhMikyQmjYjv/8fIlbGtdLNfrmXMpj9xOkz5WXR5dCxe+B2z41TJTYUqmXctXo4tVZ1eziy7m8wI8B6YNSrnZEFrSaupctYOv90wIIfxf0P3zzz8YO3YstmzZYowsGKkZMGBAulEU1mpNnDgR33//vUm/q1KlCgYPHoxrrrnGY72tW7eaGixGf4KCgsxFPPucVapUybUOIzdcZ9WqVUaU0HSD9vbehEd2wIhYZqNirKHrNrWbMUDxVkfHGroyoWUwo/eMHK2hOx+26cnhw4dRvXp1j2WHDh3yGBMbW8ixBs79NcePn1/MHj16FH///bdJz3Q3Rqlfv7555DkjhPCByUlOw/8hVdpZ09HtwOKPgcgvLPMUsnWONZWqA7QZCjTuA4SE+m5/RfaQlGRFZuf+L2Uez0s2Cy9WWUddCOH3+LyxONPqhgwZYi7Y3333XVx33XVGYH3yySfpvobrUQCyHoppfi1atDAmGzNnznStExUVZcw3ePH/5ptv4rnnnjOCkUIxNjbWJS7uvvtuIxjGjBmDJ554AkuWLMHAgQNNqp9TyReYD6MjRrvEmzv280dbPGrWcwo0NKFgnj59usd8Rsv27duH5s2bp3lNs2bNjFFK6sbkf/3113m3xfFlJI6C350FCxaYRzYlF0JcpMnJ9vlWv66xDYB5L3uKOZqcdH8FGLnBsn33pZhLTYlqQPcxwIh1QLcxQLEqKcsObwSmP2x9pjnPe7pqCv+v55xyp6eYa9AbGDBLYk4IkWvwefiG4qxevXpGxJHLL7/cROBoVX/XXXd5dT6kgQZrsWyjDLvHGGulunXr5npfpthNmjQJBQsWNPMqVqxo3BLXrFljarfmzJljrPDpsMi0PFKkSBFTZ7V8+XJERETAqXSt0hVvXvGm1z50j7V6LMf70F2IYsWKGXOU9957z7QPYF3cnj17TF1bzZo1ccMNN6R5TaFChXDffffhrbfeMmPYpk0b0yD8QoKufPnyuPHGG822GJllZI7C8eOPP8ZNN91ktieEyASx0ZaDJOvjDm3wbnLC3nHVOjo/dbFAGND2PqD1YGDjb8DC94Fd/1rLzhwF5r8BLHjbuujneuWb+XqPxcVydBvwdV83Y54AoOszQPuHnX+eCiGEvwg6mmQsWrQIDz74oMd8ijL2Klu2bJlJgfT2Ooq11IKBkR7bqn7WrFkmGmeLOcIaL6Z32pw9e9Y8ur8X3ycjaX1OEXWdKnVC5MFIHIo5hNKhpdG8THMEBgQiMTERTmPYsGEmlZXC+9tvvzXHunv37nj44YdNTzpvMJWWyz777DMzMWrH6Nuzzz573m1xOdM4KdbpwFmuXDlznt1zzz3Z9OmEyGsmJ2WAFncDLfpln8lJdsIMhnrXWdO+5VbbgzVTrdYKnFZPsSbWALLOjn3tHJT1IC7A1r+A7/oBsef+l+cvCtw0Aah1pQ6dECLX4VNBxz5kTG2sWrWqx3zWxBE2n/Ym6Bi5mzBhgonyMFXvzz//NK6HI0aMMMsZ+aHJBiM1TLWkdf2ZM2fQoUMHPPPMMy7nRbolMmrD3mRMt6TAe/XVV43pRrt27eAPMK2yVVlPgw8K2pzk5ZdfzvC6t912m5ky81533nmnmVK/z/lgeiejsZyEEJk0OWH/NrYccIrJSXbDKFzvj4Guz1kCdulEK1pHaKrCibVWrYcAze4AClg1wcKB8P/ff+8Ds560+hGSUrWBW78GSik7QwiRO/GpoLOdDVNH25hqR06dSnVH+Bz9+vUztXesdbNhih1TJQnTKMnrr79ubOtZQ8c6OT5SDP74448m6kPhRsFHIciG1bZ5BxtZp96njEAh5U1M2fPSW56d5PT2/J3sHiv7fTUuziPPjw3rxiI/A5Z9hoBUJifJwYUsk5OWAzzr4nLo9yXHxqZIWaDzk8BlI4BV3wGLPkCAnWJ6fBcw8wkk/zUGaHY7EDHYqsvLwzjuOxN/xtRCBjA9+BzJtbtbYj1/WI6dr07AcWMjXGhsnEuyw743mdkPnwq6JDpPnYfAwECv6ZZ0waQzIsUYzVRY70ZzFIq0J5980qxDmN43btw41/sw8tenTx/88ssvrsfHHnvMpP1REDJCR/dMpmqyV1mNGjUy9XnYCDu9feZnZRpkTqVCXujYCu9wfHjseLPBTsnN6i9nTEyM+Vu98JxFnhyb5GQE7fkPIas+R/CWmQhI9vx9SixeA2cb34m4+jdaF8TkXDuRXD82NXsBNa5H0K75yB85HsE751nbp0Pmog+RvOgjxNe4Cmeb3YPEChF5sibLSd+ZgJNRKDR9EIIOrHLNi40Yhti2I4DYZCA2589bX+KksRGeaGycS7LDvjeZuZb3qaCjAQk5fdqzB5sdmfMWJaOT5YYNG4zZiZ0WSfMSrsvUyVtuucX1OhqsuAuspk2bmm2uW7fOPKfYY00WHTNtmOLJ9gc063jnnXcy9XnCwsKQL18+r66LjBBymbfl2UVObiu3wGPGc4bniTdDnqy628JIsBN+LEQeHZuz0cDKb4GlE1IiUOdIDsgH1L0GaHkvAqtdjoIBAUipRM6DY1PsOqDxdUg+tNEIOdYTBiScQQCSEbJ1ppmSyza26uwa9gYy2PszN+CY78yu/4zzasBpqyVNMttm9PoA+etfj/zImzhmbEQaNDbOJdlh35vMBIF8KujoLMkL6J07d3rM37Vrl3n0FiGzjU9S29zbjaLZmqBjx45mIOxIXeqDY1+o0yyja9euHsu5rGHDhti8eXOmPw+36e0EsOeltzw7Q7ROOCH9iZwYK/u9NTbOI9ePDU1OFn9iOVamY3IS0KI/ULQCnIbPx6ZMXeC6t4AuTwPLJlnH8WSUtW/7VwE/DgFmPwO0Ggi07A8Uyplepsjr48I+iL8+AiSdazVUrDICWC9XtiHyOj4fG5EuGhvnEuCg701m9sGnfejy589v2gf88ccfHiKEUThGSFj/lhq7wTRt6N2JjIx0tSZgDR4FHp0u3UXdwoULTSiV27Tfi69z3zbT7NgCwVujayGE8EuTkzXTgEk9gPfbmKich5ijycmNE4Dha636MQeKOUcRWgK4bCTw0Cqg93jPtganDgB/vWj1s/t5GHDAygYR2UBCHDB9BPDLQylirtrlwMC5EnNCiDyHz/vQ0YWwf//+eOihh0wdG+vh6GA5cuRI03KA6ZeMujGaV6JECXTu3Nk0qX700UeNDT5F2apVq0wNHZfZIpBGJ3RGpHEKa+KY8kiTFL6W6xFu8/777zeP7E9G8Udr/AMHDuCNN97I8s/qlCJLkT4aI5GrTE4YvVj2mWfzb2KbnNCtUpGMi4MOn41vBhrdBOxeBCx8D9gw3XJWTIgFIj+3puqdgLb3AzW6sDA8K0ZWnDoEfHc3sHNByrFoPRS46kUgn88va4QQIscJSHbAFSwjdKxXY5uC8PBwY3pCEUbYp47OlGPGjEHv3r3NPIo81r0xknfixAkTTevVq5dxv6RdvQ2jb1yPgo+plEyvZA8z1rrZ/P3333j//fdNXR0jexSEw4cPR926dTO8/0zjpOsma/S81a2xNQNFaYUKFTy2nV1wSLlP3BcnhIz9CRrbMBWXzcfZAD07xobnrFPys0UuGxv+nO+Yb1nvr6e4SJV/T/t2irgmt/qV9b7fjM2xncDijy0hxzrF1MeebQ947EMsJ2d/xyfjsm8F8M3tQPQe6zlrFq99y3IeFb4dG5EhNDbOJdlh35sL6QvHCTp/JyMHfNu2bUYgMCU0u08SCbqLP27sYUgBbqf25vYfC5FLxiY22qqLo5BLZXIC2+SEtV1MSfO3z+aPY3P2JLD8S9P2AMd2eC4rUMyqsYsYBISVhz+T4+Oy+nvgpweAhDPW88JlgVu/BCpaZRTCh2MjMozGxrkk+7GgU25CDsEWCoz8UDDwRKG4y66TRYIu88eLIo5fYkZ/GUkVwi9gjRZFXLomJ/2sSXVxOUv+IkCbIUDEQGDTDGDh+ylN2mOPA/+MBf59F6jfC2h7H1ChRQ7voJ+RlAjMeQ5Y8HbKvIqtgFu+AMLK+XLPhBDCEUjQ5RB2quXhw4eNsMuJ3hXeeuKJ85v05FRarBCXZHKy/hdLyLnXENlUbge0ugeo19Oq8xK+I5DR0R7WxFRBtj1glIkmHkkJwJrvralSa6vtQd1rVQOWmjPHgKn3Altmp8xrdgfQ400gKK82JRBCCE8k6HIQCgVOjAZlZ4NxRpzYGJtOoU4IGfsDDGVnR82cEFlvcvKp5abojkxOnE/5psANHwJdnwWWTLDcRmOOWMtoqsKpaGWg9SCg2Z1AwWK+3mPfw95/X98GHN2akj7c/WUr8qn/bUII4UKCzgdQOGSneKCgY/sFGsFI0Anhx+RSk5M8TZGyQOf/Ay4bAaz+zkrHPLTeWnZiFzDrSWDuy0DT24HWg4GSafux5gk2/g5MHQjEnbSeFywB3PKZVQcqhBDCAwk6IYRwosnJym8sIXd4Y64zORG8s1cQaH6XFY3bNhf4731g8yzr0LAecvFHlmNmnautdMyqHfLGWPMmxt+vA3+9xCfWvPBGlvlJ8Sq+3jshhHAkEnRCCOEok5NPgJXfAvGnPZfJ5CR3QpFWo5M1Hdpk1dmt+Oqck2MysPE3ayrbyBJ2DW/MvbVjZ08BPw4F1v+cMq/BDcD17+WaVg9CCJEdSNAJIYQvSYgDNtDkZEL6JicR9wJ1r5PJSW6ndG3g2jeBzk8CkZ8Biz4GTu6zlu1fbYmdP56x0mxbDgAKl0auge0dvu4LHFx7bkYA0OUpoMOIvBGZFEKIS0CCTgghnGhy0qSPdeEe3kDjk9cILQF0GA60fQBY95OVjrl3mbXs9EFg7v+A+W8AjW+2onb+fo4w5fS7fpajJckfBtw4Hqjdzdd7JoQQfoEEnRBC5LTJyeJPgA2/pmNyMtASczI5EfmCgUY3WWmWe5YAC9+z0hGTk4DEs8DyydZUrSPQ9n6g5pWAP7Wr4ffhvw8sIxj7u1CyFnDb10CpWr7eOyGE8Bsk6IQQwucmJz2saJxMToQ3mHJYKcKaju+yzFKWfQ6cPWEt3z7PmkrWBFoPAZr2dX7NWXwsMH04sPKrlHm1ugE3fqKbGUIIkUkk6IQQIruQyYnIaopVBq56Eeg4CljxNbDoA+DoNmvZkS3Ab48Af74AtOgHRAwCilZ0Zrrxt3ekpJGSy0YCnf7PasYuhBAiU0jQCSFETpqcVGkPtLpHJifi0shfxGpCznNp00yrzo7pvCT2BLDgbeDfcUD96610zIotnXHEdy+2xJxdNxocarlYNuzt6z0TQgi/RYJOCCGyApmcCF8QeK4vIaeoVVbbAzYsT4yz6tLWTrOmiq0sA5V6PYF8PvrXH/k58OtIa99I0cpWf7lyjX2zP0IIkUuQoBNCiEsxddj+t1Ub59XkpI5VG9fkVqBAmI6zyF4ojHq9D3R5Blg60TovYw5by2iq8n1/IKyiFdlrfjdQsFjOjEhiPDDzCav2z6bqZcDNnwKFSuXMPgghRC5Ggk6InCIp0aTgBR/YDoRXs1LvVC+Se01OIgZaF63qoSVymiLhQKfHrdYHa74HFr6f0t8teg/wx9PA3Fcs85Q2Q4GSNbJvX04ftloS2OmgJGIw0O0lGBdPIYQQl4wEnRA5wbqfgRmjEBC9Dy7vubDyQPdXgPo9NQb+woG1lohb+S0Qf9pzWeFwy4iCE8dWCF8TXABodgfQ9HbLBZMtAjbNsJbx/F3yiXU+s98b0zGz2mWVKaDf3A6c2GU9zxcC9HgTaH5n1m1DCCGEBJ0QOSLmptzF/DzP+dFR1vxbPpeoc3L01DY5WTwe2PVvOiYn9wJ1rwWCQnJ814W4IBRp1a+wpsNbrDq7FV8C8THW7xJFHqfwhlbEruFNlhi8FNZMBX68H0g4k3LDo89kq/WCEEKILEUROiGyWyjMGJVWzBnOzZs2CFj3ExBUwEpB4l1s8+j+d0jG/w4MysA6+ZQKeKHo6eWjgOi9QORnKY58NsGFrLo4OgyGN8i+80eIrKZUTaDH60Dn/7NMShZ9bKVhkgNrgJ/uB2Y/C7S8xzq/C5fJ/G/eny8C/7yZMq9CC0vMKXIthBDZggSdENnF8d2WdTjdD88H72CzziVHCfAi9C5SRAa6vy4kE+8RnHGBml11aOlGT/cB0x9Ku75MTkRuoWBxoP1DVqrl+l+stgc0TiGnDwHzXrZEWaObrahd2UYXjmrHnQKm3gtsnpWyXpO+wLVjLz3iJ4QQIl0k6ITISo5sBdb/bAmFfZEOPrbJQOJZa/IHMhx9TE8genkd32vhe+lET90JBOpdK5MTkTvh94E94DjtXmIJO2YM0LGV7QWYmsmJBj/sZ1erG7BhetqodqEyQEAgcGp/ijkQjU9aD1E2gBBCZDMSdEJcqm39oQ2WgKOQY8rSxXDDx0C5JtYFFC2++ZgU7/nc9Xi+vxMysI6X90tK53VOwZf7c/MkoEEv32xbiJykUiug0iQru4CGKcs+tZqUE7pUcmItXOoUZHL6oGf07+bPgOodc27fhRAiDyNBJ8TFiLiolSmRuCObva8X3siK7CyZYKUweY0EBVh1JY1ucl4LA37O9ISe+TszQtNdpF7E6y64vWyMNPIYCJGXKFYJuPJ54PLHgJVfW+6YR7day7yJOXeYgn3vnOxthSCEEMIDCTohMkJSErB3qZWKRCF3/JwNd2pY/F+vJ1DvupQLmjL1z9VpBaQSdefqwrq/7DwxR1i3Zte5pSRWORMjPhM9hV6aCGeqv/etAOY8d+H3ZkRCiLxI/sJWqjENUlgX99f/gP0rz/8afu9YgypBJ4QQOYYEnRDpwfTFXQstAUfTgJNRXlYKAKq0OyfirgWKVky7CvvMsTUB3S7dDVJMH7qX1bIgy8Qn6+T4kxaasddU62illbF9xPmipxxfIfIygYFAne7nTE/uufD6F4riCSGEyFIk6IRwhz3Htv8NrP8J2PAbEHM47fFhsT8b8FKosfdYRmy9zbo9kLxzAWIObEdoeDUEuPc6EzkPjz0bu/tj9FQIX5DRaLWi2kIIkaNI0AkRfwbY+qdVD7fp9xQTAHfoilijsxWJq3M1EFoi88eNwqDqZYgv3hgoWlTOb05A0VMhMg6j1YxaK6othBCOQoJO5E3OnrJqQphOuWkWEH867TrBoUDNrkD964FaVwEFwnyxpyK7UfRUiIyhqLYQQjgSCTqRdzhzHNg0w4rEbZ0DJMSmXSekiFUrwkgcxVxIBuuxhH+j6KkQGUNRbSGEcBwSdCJ3c/owsOFXKxK3bZ7lwJYa9kyq08O6UKl+BRCU3xd7KoQQ/oGi2kII4Sgk6ETug/UddKWkiNu5AEhOSrtOoTKWKyUjcVU7nLPmF0IIkSEU1RZCCMcgQSdyB8d2pjT63rPY+zphFa07yxRxlSLkXiiEEEIIIfweCTrhvxzenNLoOyqdZrclqlsCjkKufHM5SwohhBBCiFyFBJ3wH5KTgQNrUyJxh9Z7X690vZRIXHgDiTghhBBCCJFrkaATzhdx+yItAUchd3Sb9/XKNTkXibseKFUrp/dSCCGEEEIInyBBJ5xHUiKwe9E5EfcLEL3H+3oVI85F4q4DilfN6b0UQgghhBDC50jQCWeQmADsmG9F4dhm4NSBtOsEBAJV2luRODpUhpX3xZ4KIYQQQgjhGCTohO9IOAtsm2tF4jb+Cpw5lnadwGCgekdLxNXtARQq5Ys9FUIIIYQQwpFI0ImcJS4G2DLbisRtmgmcjfZyVhYAanSx0ilrdwcKFtMoCSGEEEII4QUJOpH9xEYDm2dZLQYo5uJj0q4TXAiofZUViat1FZC/sEZGCCGEEEKICyBBJ7KHmKPAxt+sdMptfwGJcWnXyV8UqHO1FYmr0RkILqjREEIIIYQQIhNI0Ims49RBy5WS6ZTb5wPJiWnXCS1p1cLVux6odjkQFKIREEIIIYQQ4iKRoBOXxok9lohjJG7XQjaOS7tOkXJWawGmU1ZuC+TTaSeEEEIIIURW4Igr63/++Qdjx47Fli1bULJkSdx+++0YMGAAAgICvK6fkJCAiRMn4vvvv8fBgwdRpUoVDB48GNdcc43Helu3bsVrr72GxYsXIygoCK1atcLo0aNRqVIl1zrR0dF488038ccffyAmJga1a9fGww8/jLZt22b75/Zb2NzbbvS9d5n3dYpVTmn0XaElEBiY03sphBBCCCFErsfngm7FihUYMmQIrr76ajz00ENYtmyZEWGJiYkYNGiQ19e8++67+Pjjj3H//fejRYsWRowNHz4c+fLlQ7du3cw6UVFR6Nu3L6pVq2YE25kzZ/DWW28ZofjLL7+gQIECZhsDBw7Evn378Oijjxox+fnnn5vtfvfdd6hbt24OHw0Hc3CDJeAo5A6s9r5OyVrnGn33BMo1AdIR5EIIIYQQQggfCbp77rkHN954I7p27YqQkEuvf6I4q1evnhFx5PLLLzcRuA8//BB33XWXEV6pmTp1Kq699lo88MAD5jmjaWvXrsXkyZNdgo7vW7hwYUyaNAkFC1pmGxUrVsTQoUOxZs0atGzZ0gg7/j1t2jTUqVPHrBMREYGePXtiwYIFeVvQJScDUSstEceUysObvK8X3vBcJK4nULquRJwQQgghhBBOFnSMaj3yyCNGLDHFsXfv3mjcuPFFbTwuLg6LFi3Cgw8+6DGfomz8+PEmWte+fXuvr+P23SlWrJiJtJHk5GTMmjXLRONsMUcaNWpk0jttZs6cadIwbTFH8ufPb+bnSZKSgL1LrfYCFHHHd3pfr3zzlEhcyRo5vZdCCCGEEEKIc2S6sOnTTz/Fn3/+acTSf//9h1tuuQU9evQwAuzQoUOZeq/du3cjPj4eVatW9ZjPmjiyfft2r69j5O7HH3/E33//jVOnTuHnn3/G/Pnzcf3115vle/bswcmTJ1G+fHk899xzJupGMcfo3P79+13vs2HDBtSsWdN8ps6dO6NBgwZGoC5duhR5hqREy5Hyt0eBsQ2ACVcCC8elEnMBQOV2QPeXgYfXAIP+AjoMl5gTQgghhBDCH2voypYta+reOC1fvhwzZszAt99+a2rUOnTogD59+qBTp04XfB+KLpI62laoUCHzSLHmjX79+pnaO9a/2TAN9N577zV/Hzt2zDy+/vrrJnrIGrojR46YR1sMhoaG4ujRo2bfixYtiscee8xE81ibR7E6ZcqUTKdcMjLIyackJSJ5578IOrgNyWWqA1XaAYH5PNdJjAe2/22lU274FQExh9O8TXJAPqDaZVYUjm0GCoe7LfTxZ/Rj7HPE5+eJSIPGxrlobJyJxsW5aGyci8bGuSQ77BotM/sRlBUbS0pKMnVv/Juuk6xtq169Ot544w3jGpkefN35CPTijMh0S7pgMhrI6Bu3Q1H5wQcfGJH25JNPmnVIqVKlMG7cONf7MPJHscnaOT4yOkhRSbdMilRCk5Urr7wSn3zyidn/zEDHTG/7nFMEb/kdBec+h8BTUbAlclLhcjhzxTOIr9oJQTvnI2TL7wja9gcCz0aneX1yvhAkVO6A+JpXI776lUguWNxawHZyJ07k7IfJpfA7QjdVkp6Lq/ANGhvnorFxJhoX56KxcS4aG+eS7LBrtAvppEsWdEyV/Omnn0yqI/9mGwAKpBtuuAHh4eE4cOCAiZ6NHDnSiKf0KFKkiHk8ffq0x3w7Mpc6ckdY38ZUSZqdtGvXzsxjSiXXff75500KqP06Gqy4C6ymTZuaba5bt84VCaxRo4ZLzNnbbNasmWudzBAWFmacNn0Co23Th6bpAxdwKgqh04cAQQUQkBCb5mXJQQWBWl2tSFytqxBUoKg5KVIqD0V23G1hVNgJPxYiBY2Nc9HYOBONi3PR2DgXjY1zSXbYNRp9S7JN0N16661YuXKlMQ+56qqr8OKLLxpB5Q5FHZexNu18VK5c2QignTs9zTd27dplHim2UmMbnzRv3txjPs1NCHvZdezY0QyEHalLfXBs50xG7Lytw2ijN3fNC8Ft+uQEYB3cjNFem3q79sZdzIUUAWp3M8YmATW7AiFWiqvIGezzxAk/FsITjY1z0dg4E42Lc9HYOBeNjXMJcNA1Wmb2IdP5gRQ7zzzzjHGLfPXVV9OIORu2NZgwYcJ534uikO0D2EfOPU+UUThG0ry5ZzLFkqQ2LomMjHS1JmDkjQKPTpfugm3hwoUmlMptEgq/9evXmwbkNqy/43sx9dJv2PkvEG0J3fNSoytw27fAo1uAmyZYTb8l5oQQQgghhPBbMi3oWG/GdgW2gLJdJb/88kuXyQmhoUiTJk0u+H50nmTEj03F582bZ4xVKAQHDx5sTEqYfkkDFBqYELpR8n3ZCPyrr74yTps0MnnllVfMMlsEjhgxwtTzMfWT78tec0wB5Wu5HqFBCtMt2Uh8+vTpmDNnjlmfipj99vyGUwcytl7T24A63YHgzEcfhRBCCCGEELlA0DGaxTYFzz77rGse6+jGjBljnCbtlMiMwqbgbALOFgX333+/qbmj46TtYMmG4azPmzt3rnnOFM2JEycaUfn++++b9ehaSWH49ttvu96XdXCff/65KShknzsKPjpvsr2CXefGHNmvv/7a1Nax/o799TiPQrFcuXLwG9wdKLNiPSGEEEIIIYRfEJCcSW9Otio4fPgw3nvvPVMrZ8O2ABRV7P3GKFtegnV5jCJSGPrEFIU1dG81BKKjvNbRmUq6sPLAw6vTtjAQOQq/bidOnHBMwa1IQWPjXDQ2zkTj4lw0Ns5FY+Nckh12jZYZfZHpCB1TLYcNG+Yh5kjJkiWN2GMKpMhhKNK6v3LuSeoT8NxzNgWXmBNCCCGEECJXkWlBR8V65syZdA1T2NtN+ID6PYFbPgfCUqWKMjLH+VwuhBBCCCGEyFVkum0B3SOZbkl3yxIlSrjmHz9+HB9++GG6rpciB6Boq9sDyTsXIObAdoSGV0NAlfaKzAkhhBBCCJFLybSgo1Mkm3d36dLF5HRS1NHqnzmeISEheOONN7JnT0XGYFpl1csQX7wxXV8YUtWRE0IIIYQQIpeS6ZTLatWqGYt/NhhnT7c1a9YgOjraiDy6TXK5EEIIIYQQQggHRugIDVFGjRqV9XsjhBBCCCGEECJ7Bd2BAwewbNkyxMXFueax3xvNUpYuXYqxY8dezNsKIYQQQgghhMhOQTdjxgzTgJuOlnaPBvZtsP+uXr16Zt9SCCGEEEIIIURO1NDRybJBgwaYNm0aevfujeuvvx6//vorHn30UdP07oknnriY/RBCCCGEEEIIkd0Ruu3btxsny/r166N169aYOHEiatSoYabDhw8bwde+ffvMvq0QQgghhBBCiOyO0AUGBqIo7fABVKlSBdu2bTP1c+Tyyy/Hli1bMvuWQgghhBBCCCFyQtCxRi4yMtL1N41RNmzYYJ6zfYG7UYoQQgghhBBCCAelXLL/3DPPPGN60A0fPhxt2rTB448/jptuugmTJ0829XVCCCGEEEIIIRwYobv55pvxf//3f65I3AsvvICzZ8/ipZdeMs6XXCaEEEIIIYQQwoERuoULF+LGG29EgQIFzPNKlSrh999/x7Fjx1CiRIns2EchhBBCCCGEEFkRoRs2bBhmzZrlMY896CTmhBBCCCGEEMLhgi4sLMwVnRNCCCGEEEII4Ucpl4MHD8aLL75o+tHVrVsXoaGhadZp1apVVu2fEEIIIYQQQoisEnR0uCRjx451pVvaJCcnm+fr16/P7NsKIYQQQgghhMhuQff5559n9iVCCCGEEEIIIZwg6CIiIrJjP4QQQgghhBBCZLeg+/HHHy+4Tq9evTL7tkIIIYQQQgghslvQjR492ut81s7ly5fPTBJ0QgghhBBCCOFAQTdnzpw082JiYrB06VJ88skneO+997Jq34QQQgghhBBCZKWgq1Chgtf5tWrVQnx8PF544QV89dVXmX1bIYQQQgghhBDZ3Vj8fNSpUwdr167NyrcUQgghhBBCCJHdgi4uLg7ff/89SpYsmVVvKYQQQgghhBAiK1MuO3fu7NFMnCQlJeHYsWM4e/YsRo0aldm3FEIIIYQQQgiRU33oUgs6UrhwYXTq1Ant2rW7mP0QQgghhBBCCJHdgu7ll182j4mJiaZFATlz5gwSEhJQpEiRzL6dEEIIIYQQQoicqqGjcHvmmWdwyy23uOYtX74cbdu2xSuvvGLSL4UQQgghhBBCOFDQvfPOO/j555/Ro0cP17z69evjkUcewZQpUzB+/Pis3kchhBBCCCGEEFmRcvnLL78Y45Nbb73VNa9YsWLo168fgoKC8Pnnn2PQoEGZfVshhBBCCCGEENkdoaObZaVKlbwuq169Ovbv35/ZtxRCCCGEEEIIkROCjqJt5syZXpf9+eefqFKlysXshxBCCCGEEEKI7E65vOuuuzB69GgcP34cXbt2NY3Ejx49ir/++gu///47xowZk9m3FEIIIYQQQgiRE4KuV69eOH36NN5//33MmjXLNb948eJ46qmnzHIhhBBCCCGEEA4UdOT2229H3759sX37dhOpCwsLM6mYgYGZzuAUQgghhBBCCHGRXJQC++2330wvOoq45s2bIzo62vSlYw2dEEIIIYQQQgiHCroff/wRI0aMMJE597YFpUuXxgMPPIDZs2dn9T4KIYQQQgghhMgKQTdhwgT079/fNBi3YaTugw8+wN13321q64QQQgghhBBCOFDQ7dq1Cx07dvS67PLLL8e2bduyYr+EEEIIIYQQQmS1oGNq5apVq7wu27Bhg3G7FEIIIYQQQgjhQEF37bXXmvTKyZMn48CBA4iPjzeP33zzDd5991307Nkz0zvxzz//4MYbb0STJk3QuXNnk9aZnJyc7voJCQn4+OOPcdVVV6Fp06a4/vrrjVFLarZu3YohQ4YY45aIiAjcf//92L17d7rvy/q/OnXqYNGiRZn+DEIIIYQQQgjh+LYFFEVMq3zxxRfx0ksvueZTgHXv3h3Dhg3L1PutWLHCiK6rr74aDz30EJYtW4bXXnsNiYmJGDRokNfXUDhS0HFfWrRogT/++APDhw9Hvnz50K1bN7NOVFSUaa1QrVo1vPnmmzhz5gzeeustDBgwAL/88gsKFCjg8Z7Hjh0zzp1CCCGEEEIIkWsFXXBwsDFE2bx5sxFfdLssUqSIEVZ169bN9A5QnNWrV8+IOLsOjxG4Dz/8EHfddVca4UWmTp1qIoV01SRt27bF2rVrTdTQFnR838KFC2PSpEkoWLCgmVexYkUMHToUa9asQcuWLT3e87nnnkNQ0EW15RNCCCGEEEIIn3DRncBr1aqFW2+91UTX2GicYm7JkiUYOXJkht8jLi7OpDdeeeWVHvMpyk6fPm0EY3qvo1hzh60T7FYKjBbOmjXLpHHaYo40atTIpHemFnNM1/z333/x6KOPZnjfhRBCCCGEEMJvBZ3NyZMn8dlnn6FHjx6488478fvvv2f4taxnYw1e1apVPeZXqVLFPG7fvt3r6xi5Yz+8v//+G6dOncLPP/+M+fPnm1o6smfPHrNf5cuXN5E31s9RzDE6t3//fo/3Onz4sFnniSeeMIYvQgghhBBCCOEvXHSOIWvfvv32WyPgYmNjjQh78MEHXaIqI1B0kdTRtkKFCplHijVv9OvXz2x/4MCBrnmMxt17772uejjy+uuvo3HjxqaG7siRI+bRFoOhoaFmnaeeegrNmjVDr169LtkMhZHB85m55BT2fjhhX4QnGhvnorFxLhobZ6JxcS4aG+eisXEuyQ67fs7MfmRK0DENktEwCrmNGzea+razZ89izJgxuOGGGzK9o0lJSeddHhgY6DXdkimehw4dMpE1NjVfvny5cd6kSHvyySfNOqRUqVIYN26c630oOvv06WNMUfj4ww8/mLTO6dOnIyuIjo72us++OAFiYmLM3wEBAb7eHeGGxsa5aGyci8bGmWhcnIvGxrlobJxLssOuny+kkzIt6NatW2faElD40C2yTZs2ePXVV9G6dWtjYkKzkYuBZiq2UHTHjsyljtyRmTNnmn53NDtp166dmceUSq77/PPP45ZbbnG9jvvmLrDY4oDb5Odh6iVdOkePHo0SJUoYIxb7wPGRLpt0zcwMYWFhmX5Ndir6okWLOuKEFClobJyLxsa5aGycicbFuWhsnIvGxrkkO+z6mVokSwVd7969UaNGDVODRnfJcuXKeaRMXiyVK1c2Amjnzp0e83ft2mUeuc3U7Nu3zzyyt5w7rVq1Mo9btmxBx44dzUDYkbrUB4eRRZqgcP//7//+z0ypUzorVKiAP//8M1Ofh9t0wgngvi9O2R+RgsbGuWhsnIvGxploXJyLxsa5aGycS4CDrp8zsw8Zyg8sW7asEV10iGSE7OjRo8gK8ufPbxwn2UfOPU+U22AkjfVvqWGKJVm6dKnH/MjISPPIaCFr8Cjw6HTpLuoWLlxoQqncZqdOnfD99997TEzhJHxkCqcQQgghhBBCOJkMRej++usvLFiwANOmTTPGIjQbYTrjVVdddckKllG//v37m6biNDZhPdyECRNM+wO2HGD6JaNujOYxNbJz585o0qSJaTHAJuYUeKtWrTICjMtsEThixAjjuknjFDYTpykK95uv5XqMDBYvXtxjX+y8WTYjr1OnziV9LiGEEEIIIYRwhKCjaOvQoYOZaPxBYxSKO9afkS+++MLUoLG2LrMCj03B2QSczcrvv/9+hIeH47HHHjMijLBhOJ0pabzC1E8KsYkTJ2Ls2LF4//33ceLECVSqVMkIQ6ZK2tC58vPPPzfr0X2TaZZdu3bFqFGjHFHnJoQQQgghhBCXSkDyJXhz0pyEqYo0S6GwKlmyJLp3726cJvMSrMtjGwWarjhBLHJIOR5OKeoUKWhsnIvGxrlobJyJxsW5aGyci8bGuSQ77Po5M/rikjz269ata8Qbm3ozElavXj3jhimEEEIIIYQQwsGNxd0JDg42kTlOBw8ezIq3FEIIIYQQQghxAbK8C3aZMmWy+i2FEEIIIYQQQuSEoBNCCCGEEEIIkTNI0AkhhBBCCCGEnyJBJ4QQQgghhBB5xRQlNjbWNPFms/EzZ84gKSnJYzltPmfPnp2V+yiEEEIIIYQQIisE3UsvvWR6z0VERJg2BYGBCvIJIYQQQgghhF8IulmzZmH48OEYNGhQ9uyREEIIIYQQQogMkenwWnx8PBo3bpzZlwkhhBBCCCGE8LWg69ChA/7++++s3g8hhBBCCCGEyHESkxKxZP8SzN4z2zzyea5OubzmmmvwzDPP4OjRo2jSpAkKFiyYZp1evXpl1f4JIYQQQgghRLYwe+dsvLz4ZRyIOeCaFx4ajtERo9G1StfcKegefvhh8/jjjz+aKTV0uZSgE0IIIYQQQjhdzI2YOwLJSPaYfzDmoJn/5hVv+oWoy7SgmzNnTvbsiRBCCCGEEELkAIlJiSYyl1rMEc4LQABeWfwKOlXqhHyB+XKXoKtQoYLrb/ahO3XqFIoVK4bg4OCs3jchhBBCCCGEyHL+2fuPR5qlN1G3P2Y/Ig9GolXZVrlL0JGlS5fi1VdfxZo1a5CcbKlaOl+ynUGbNm2yeh+FEEIIIYQQ4pLYfXI35u2eh7l75mJJ1JIMveZQzCHHH/VMC7rIyEj069cPlSpVwn333YdSpUrh4MGD+PXXX3Hvvffiiy++QLNmzbJnb4UQQgghhBAig2mVqw6vwtzdc42Q23pia6aPW+nQ0rlP0L311lto2bIlJkyYgHz5UvJJH3jgAdxzzz149913MXHixKzeTyGEEHn0n/GyA8uw68guVD5TGS3CWzi+lkEIIYTvOBV3Cv/u+xfz9szD/D3zcezsMa/rlS9UHsfPHkdMQozX5ayho9tl8zLNkesE3erVq/HGG294iDkSGBiIO+64A6NGjcrK/RNCCJFHyQ1W0kIIIbKfvaf2uqJwSw4sQUJSgleB1qR0E3Ss1BFXVLwCNYrVwJxdc4ybJXE3R+G6ZFTEKL+4iZhpQVeoUCEkJKQ9SITz7Zo6IYQQIq9bSQshhMie7I3Vh1ebKNzc3XOx5fgWr+uFBoWifYX26FixIy6reBlKFCjhsZz/R/j/xNvNQ4o5f/k/k2lB17x5c3z88ce47LLLPJqKx8TEmPlMxxRCCCEultxkJS2EECJriImPMamUFHDz987H0dij6aZSdjwXhWtZtiVC8oWc930p2vj/xJXeX9L/0vszLehGjhyJ3r17o0uXLrjiiitQunRpHDp0CHPnzkVsbCxeeuml7NlTIYQQeQJaROcWK2khhBAXT9SpKONIyVTKxfsXIz4pPs06AQhAo9KNjICjkKtVrBYCAqyUyYxC8cb/J7UL1kbRokUz/Xq/E3RVqlTBt99+i3HjxmHevHk4ceKE+eARERHGGKVmzZrZs6dCCCHyBFuPb801VtJCCCEyTlJyEtYcXmPVw+2Zh03HNnldr2BQQbQr386VSlmqYKk8fZgvqg8dRRvdLoUQQois4mziWXy+9nN8uPLDDK3P9JgrKl2B0OBQDYIQQvhxKuXCqIUmCvf3nr9xJPaI1/VY18bffIq4iHIRyJ8vf47vq18Luh9//BEdO3ZE8eLFzd8XolevXlmxb0IIIfIANNP6c9efeG3pa8apLKNM2TQFs3bOwp3178RtdW9DkZAi2bqfQgghsob9p/cb8cZI3KKoRYhLivO6XsOSDa16uEpXoE7xOtmWCpmYlIzF249gx4FjqBqegIhqJZEvMCB3CbrRo0djypQpRtDx7/PBAy1BJ4QQIiMwnebVxa9i0f5FrnmBAYFoW64tFuxbYGojvJmj2LCH0LvL38Wnaz5F33p9cUe9O1CsQDEdfCGEcFgq5foj6131cOuPrve6XoF8BdCmfBtTD3d5xctzpKn3jDVReO6XdYg6EeuaV65oATxzXX10b1gOuUbQzZkzx5if2H8LIYQQl8Lx2OMYt2Icvtv0nflHb9O6bGs8FvEYahev7bUPXdnQssZKulrRahi/ejx+2/6bef3J+JP4aNVH+Hzd57i1zq24q8Fdeb6mQgghfMmZhDMm+sYoHKNxh854r3suE1rGpFEyChdRNgIFggrk2D7OWBOFoZMj09w23H8i1sz/4I7mfiHqApIz2TjOPf0yNXS75PKBAwciL5GYmIgVK1agadOmaRqu+wIOqW1W428uPbkdjY1z0djkDHQom7JxCt5f8T6i46Jd8ysUroBHWz2KzpU6e/xusYXB+aykd0XvwoQ1E/Dzlp+RkJzgcZf3pto3oV+DfggvFJ5Dny5voe+Mc9HYOJfcPjbsFUozE0bh/ov6z9RGe6N+yfouV8p6Jer55FgkJiWjwyt/ekTm3OEelS1aAP+M6uyT9MvM6ItMC7p69eoZl8vGjRunWfb333/j/vvvx+rVq5GXkKATGSW3/5D7Mxqb7GfhvoWmf9zWE1s9nMoGNR5k6uDSK3DPyNjQ2prC7ofNP3jUYgQHBqNXzV64p9E9RjSKrEPfGeeisXEuuW1s+HmYPkkBx3TKdUfWeV2Pv+9tyrUxAo7ROEblfMHZhERsPnAK66OiMWfDAcxYk36LHJuvB7ZB2xol4WR9kaGUy0GDBmHr1q2ugaNoCwlJ26TvyJEjqFy58sXutxBCiFzI7ujdxvDkr91/eczvWaMnHmr+UJb8Yy9XuByebPOkEYefrv0U3238DrGJsSYiyLTOaZun4drq1+LeRveiatGql7w9IYTIq8QmxJqecHZrAUblvFG6YGlTB8dUytblWpsbeDnJkVNnsT7qpBFv66KizeOWg6eQkJSpWBYOnvQewXMSGRJ0Q4YMwXfffWf+/uGHH1C/fn2UKFHCY53AwECEhYWZpuNCCCHE6fjT+HjVx/hi3RcezWAblWqE0RGj0bh02kyPS4Xi8LFWjxnhxu1+veFrsx+JyYn4aetP+GXbL+hWtRsGNhqIWsVraZCEECIDHD5z2BWFY10c6+O8wfRJ40pZ8QrUK1nPmFzlROrkjiOnsW5ftId4OxDtPd0zs5QpknM1fdkq6Jo3b24mm/vuuw+VKlXKzv0SQgjhp9Ck5OetP+PtyLfNRYD73drhLYajR/Ue2f5PvkSBEib6xxq6r9Z/hS/Wf4GTcSfNvv2+/Xczda3cFQMbDzS1HEIIIVJgRt7GYxutKNzueVhzZI3XwxMSGGKib4zCMRpXtlDZbD2Mp84mYMM5wbYu6qQRbxv3RyM2PsVcKz2CAgNQs0xh1CsXhvrlwlAnvAge+X4lDp0869VL2a6hi6jmGcTKFY3Fx4wZk+6ymJgYLF26FJdffvml7pcQQgg/ZMXBFaZOzv2fP+vY7m5wt4maFQoulKP7UzR/UQxtOtTU6H2z8RvTuPzY2WNm2exds83EixCmajYp3SRH900IIZwEDUwWRy22TE32zDO94rxRskBJVy0c6+JCg0OzRVDuOxHrirrZkbedR2Iy9PqwAkGoXz7MJd74WCu8MPIHedaiPX99A+NmSfHmLurs6ka2LvCHfnSZFnT79u3DM888g8WLFyMuznsTwPXrvfeWEEIIkTs5cPoA3op8C9O3TfeY36VyF4xsORKVivg2q6NwSGEjKPvW7YvvN31v6uxsC23aaXPiXebBjQejZXjLXGFWIIQQF4JZFPP3zDeRuIVRC9NNpWQrGQq4TpU6oUGpBlmaZWEbldipktZ0EifOpKTqn48qJUNdos0IuPJhKF+0QIZ+x9mSgK0JUvehK5sb+9C587///Q+RkZG4+eabzWPBggWN+8qCBQuwadMmvPvuu9mzp0IIIRxZHM/eb+wJ534hULNYTdMvjndvnQTvJLNHXZ+6fYwjJp0x7bvQrAvh1LxMcyPs2pZvK2EnhMhVMPK16dgmV2uB1YdXI9lLwiEzK9gTzo7ElS9cPkuNStZFnXAZlmTUqKRAcCDqlLUibvXLFTHCjc8L58+0nPGAou3K+mWxePsR7DhwDFXDiyOiWkm/iMxddNuC1q1bY9iwYbjjjjswefJk/Pnnn5g4caKx1hwwYAAqVKhgRF9eQm0LRF61K85NaGwyf7yYrvjG0jew99RejxTHB5o+YHrABQUGOX5s4hPjjVEKBenuk7s9ltG8hamYvJjR9zVnx0VcGhob5+KLsYlLjMPS/UuNoQlF3L7T+9KtPb6swmWmHo43tC4lRZ5GJdsPn/YwKcmMUUl4WH6PdEmKt6olC2WryEp22G9alrctcOf06dOoU6eO+bt69eoYN26c+Zsb6tu3L1555ZWL3W8hhBB+wMajG/HqkleNbbVNvoB8uKXOLbi/6f1G1PkLwfmC0btWb9NCYcaOGfhk1SfYdmKbWcY718P+HIY6xesY85Qrq1yZI45tQghxqRyNPWpSKRmJW7B3AWISvNeeMZuCAo43rngTK1/g+YXDhY1KLLOSizUqsdImi6BkYe99SUUWCboyZcrg8GHLtaxKlSpGyR46dAilS5dGsWLFTC86IYQQuY9jscfw3or3TF83ukXasPZsVKtRft0GgNFE9qm7pto1mL1ztmm3QIc3wsdH5j2C6kWrmzq8q6tdnWXRRyGEyKro0tbjW11RuJWHVnpNpeRvV6vwVlZrgUpXoELhCpnaxt7jZ1J6u9GwZH/WG5WIzJPp/0gdO3bEW2+9hbJly6JZs2bmkSmXbDY+depUhIeHX8RuCCGEcCrsITdl4xQj5mj9b1OxcEU82upRUyTvhPSUrIARuKuqXmWicbyz/dHKj1yOnYzcPfHPE/hg5QdG2F1X/ToT4RNCCF/AlPGlB5aa3yqamrinv7tTLH8x4+bLKFy78u2MSVRmjUpst8no2IRMG5WYx0wYlYgcqKE7duwYBg0ahEKFCuHTTz/Fzz//jNGjRxvVTp5++mncdtttyEuohk74a362SEFj451/9/6LV5a84kpDJKFBoaa2jK0AQvKF5Oqx4bYX7luIj1Z9hMiDkR7LyhUqhwENB+CGWjcgf768lx6k74xz0djk3rE5Hnsc8/darpT/7vsXp+JPeV2vRtEarihc41KNz5tKSaOSlDq3k0a8bT3kW6MSX5Ccl2roihcvju+++w4HDx40z3v27Iny5cubDTZu3BgREREXv+dCCCEcwc7onXh9yesmfced62tcbxp2lw4tjbwA/6m3q9DOTEv2LzGpmP9F/WeWRZ2OwkuLXjLz2MCcRjDZ0Y9JCJF3ocjYfmK7K5VyxaEVHinvNkEBQWhRtgWuqGjVw1UKq5SuUYm7SQnF28GTzjUqERnjouUza+lsWrZsaSYhhBD+zam4U/h49cf4Yt0XSEhKSa3hHd7REaPRqHQj5FValW1lJjZP/2T1J6Z3HWE/u9eWvmacMtkS4dY6t2YopUkIkbdITErEsgPLsOvILlQ+Uxktwlt4jZwxzT3yQKSJwjGdMrUDrw0NqOhKyUhc+/LtUSSkSBqjElfKpIxKcjUZEnSPP/54pt50zJgxmVr/n3/+wdixY7FlyxaULFkSt99+u2mBkF64MyEhwdTtff/99yZSSHOWwYMH45prrvFYb+vWrXjttddME/SgoCC0atXKpIdWqpRy12Lt2rWmJnD16tXmLkiDBg0wcuRI8yiEEHkF3vH9actPeDvybRyJTTG3KlOwDB5u8TB6VO8hh8dzNC3TFO91eQ/rjqwzrphs30COnT1mjt+kNZNwR7070LdeX79y/BRCZB80W3p58cs4EHPANS88NNzcKOtapStOnD1hUikZhaMr5cn4lHpld6oVrWZF4Sp1RJPSTYzDMI1K/tvCVMn9VuQtE0YlRQsGG1dJGZXkgRq6zp07ezyniKKoYqol3S2PHz+O3bt3IyQkBHXr1sU333yT4R1gqiZ72l199dW47rrrsGzZMnz00UcYMWKEqdXzBsXfxx9/bIxYWrRogT/++ANffvkl3nnnHXTr1s2sExUVhV69eqFatWoYMmQIzpw5Y4RbUlISfvnlFxQoUAA7d+406zRs2BD9+vUzApJCkeLuhx9+MG0ZMoJq6IS/5meLFPLy2DDiNGbxGCNQbEICQ3B3g7uN+Yev0widPjabj202EbuZO2Z6pEKxhxOjdYzasb9TbsPp45KX0dg4T8yNmDvCq+ukXe+2I3oHEpMT0yyjYGMkzzI0uQyxMSWs1gDnTEoyY1RStWToubYAMirxh+9NZvRFpk1RKIZef/11vPvuu6ZmzobRtfvuu89E1+6+++4Mv98999yD6OhoU5dnw6ja119/jX///dcIr9R06NABbdu2NevZ9OnTxwjKL774wjx/4oknsGjRIkyfPh0FCxY08yjUhg4daoQdU0RffPFF/Pbbb5g9ezZCQ60LlpiYGCNgGe2jwUtGkKAT/vpjIfL22Ow/vR9jl43Fb9t/85hPh8cRLUagYpGKcAL+MjY7TuwwaZfTt033uDArkK8Abq5zM/o36J+rag/9ZVzyIhobB43D2RO44ecbcPiM1fIrIzB1slV4O1Qt2ApBsXWx9UCSMSvJjFFJ3bK2cPNvo5K8/L1JzE5TFEbHGD1zF3OkZs2aePjhh026ZUYFXVxcnBFdDz74oMd8RtnGjx9vonXt27f3+rrChT3rE9gDb9++fa4BmTVrlknbtMUcadSokUnvtGEEjuvYYo7wb7Zi2LVrV4Y+gxBC+BuxCbH4dO2nmLhmIs4knHHNZx859pNjXzmReaoWrYoXO7yIIU2GmGP745YfTS1MbGKsqUn8dsO3xhHznob3oFzhcjrEQvgJ/B5Hn43GibgT5jE6LtoINTOdm8dHPndfzkdvUTdvhAWXQoXgNkg4WQ+7t4Xjp5V21G3PBY1KUhpyy6gkr5JpQce2BWFhYd7fLCjIRLgyCtM04+PjUbVqVY/5rIkj27dv9yro7rrrLkyYMAGdOnVC8+bN8eeff2L+/PlGaJI9e/bg5MmTJiX0ueeew6+//mpSLhnZe+aZZ4xgI3379k3z3kzD3Lx5s4kACiFEboI3u/7Y+QfeWPoG9p22boAR1nkNazoMN9a+UQ2zswBGNp9u+7Rp7fDZ2s9MI/aziWcRlxSHbzd+i6mbpqJnzZ5G2FUOq5wVmxRCZOD3jzew3MWY6+9zYsye5yHQ4qJxOv50th/fAzu6Ym9003PP0qZQBgUGoGaZwh7ijbVvJQvnvZYpIgsEHcN+H3zwgRFSDEm619UxDbN164zf2aXoIqmjbexxR06d8t5bg/VuDEEOHDjQNe/GG2/Evffe6xKdhKmhjCS++eabOHLkiHmkGPzxxx89onI2sbGxGDVqlEndZF3fxfxYZDKDNVuw98MJ+yI80dg4l9w+NhuPbjT95NiE1r02o0+dPhjaZKjLvMOJn99fx4aGB4+1eswIt8/WfWbEHC8oE5ITMG3zNBPBu6baNbi34b2oXixjNdtOwl/HJS+Qm8eGTpEn405aYsxNiHGe+3P+ffKs27y4Ex7OvdkJUyaLhhRFWP4wnIpNwK7Tmy74muSEImmMSlLEWxEj5vIHpU27y41j7CuSHfa9ycx+ZFrQUfDceeedJjrWrFkzk+pIsbR8+XIj8Cj2MgoNSs5HYGCg13RL1ukdOnTIRN+YNsltc7sUaU8++aRZh5QqVQrjxo1zvQ8jf6y1Yx0gH92heKTJCuvs3n77bVSoUAGZhbWA3vbZFyeAHSl1Qg6wSEFj41xy69jQeXHChgn4ZccvSELKb26r0q0wrOEwVAurBsQCJ2JPwKn4+9gEIQj31LwHN1W+Cd9t/Q5Tt03FqYRTxkCF9Xa/bvsVHct3xN2170bNojXhL/j7uORWmOK38vBK7Iveh/Jh5dGklOWE6DQYtTbCLD7aODqayFic9bfrOZedE29mXnx0uo20sxr2dQsLCUOR4CLnfQwLDjMCzn4sHFzY43j/unY//rf+XgQEnYC3rwmv2ZMTiqJTpZa4rmFZ1C5TCGXDQtJ8p2JPn+JPtchDv2lJF9BJlyTo6GJJo5FPP/0UkZGRJr2RzcZZi8baOQq8jFKkiHU34vRpz1C2HZlLHbkjM2fOxIYNGzBp0iS0a9fOzGMzc677/PPP45ZbbnG97vLLL/cQWIwucpvr1qU4udmOmGx7wBRP1gh27doVFwNTUS9UtJiTit4pRZ0iBY2Nc8ltY8OaD0aEPlj5gbkgsqlUpBIeafmIsb32l8+ZW8amKIpiZOmRGNh8IL7Z8A0mr5+M42ePG+e7ufvmmonjMrDxQDQq5fx+f7llXHKbmyIj8amt8VkbS2v87DgHKLDc0xdTpzGayJnbc7vGjLWlOUFoUKjJQLAjZvybQizN83Pr2M8LBhXMkvO6Suk4nJ17HQpUmGzEm/tb2gGYsweuwz231kab6iUveXsi9/ym0RQlo1yU3U14eLiJ1F0qlStXNgKIdWvu2IYkNWrUSPMa2/iEKZ/usMec7bbZsWNHMxB2pC71wXF3zty4caNx2jx79qxpWWC/z8XAbTrhBHDfF6fsj0hBY+NccsvYsIcRL+q2n9jucVEzuMlg0x8tJF8I/I3cMjaEF4wcizvr34kpG6cYgxq799/cPXPN1K58OwxuPBjNwz3/1zmN3DQuuUHMjZw3Mo01/sGYg2b+m1e8ma6oS2364c3sw1t9GcVaRk0/LoXAgMAUAXYeIWbPc18vODAYviImLgGT/t2BhJMNEbv3DuQP/wUBwSnZEIzMUcyVDmyJiGol9T1yAAEO+k3LzD5kSNCx5owiiZE4/n0h2NstI+TPn9+0D2AfOYoqe8cZhWMkLbWTJrF7wy1dutSYnNgwWkgqVqxoavAozOh0SaMU1sSRhQsXmlAqt2lH5vr3729EJdsk0KlTCCH8Fdrmv770dczbM89jfq+avfBQ84dQqmApn+2bSAv7+/Vr2A+31r0VUzdPNc6YvPgm/+7710wtw1sa8de6bGtHXGAI59aVsWm1tz5n9rwnFzyJ+Xvmm9RFj0ja2ROISci4od2lwBYeqaNk7kLMPLqLtnPL2dORos6fOHzqLO75dAlW7rEEHEVdwsn6yBe6HQFBJ03NXFJMNcpVPHNHfeQL1PdbXDwZ6kPHNMspU6YYgcW/z/uGAQFYv359hneAIoui6qqrrjLGJqyH+/DDDzFy5EhjesL0S0bdGM0rUaKEibDddtttxiFz2LBhRuCtWrXK1NC1adPGVcPH92GtHxuPMx2UdX40SaHgo3ijiGPNHHvQsRYv9edi2mZGBZ760Al/7XEicsfY8C75x6s+Nil87kX/TUo3weiI0WhYqiH8GX8em8wQlxiHn7b+hAmrJ2Dvqb0eyxqXbmwidpdVuMwxxyCvjIvTz5mtx7dixo4Z5oZATmGbfnhEydxFmds8W5xxXoGgtL2FcyPbDp1Cv0lLsOuoJZSL5A/CPR2q4duluxF1IiXVtFzRAnjmuvro3lBtTJxAcm5vLL53716ULl3aRLr494XIrKEII3TvvPOOqWFjOidNTyjCCPvU0ZmS/e169+5t5lHksdaNkTwe+EqVKpmoIN0v7WicHbXjehR8TLNkbRxTRVnrxnRMmrokJHh3PGJdnt2k/EJI0Al//bEQ/j02NNWgU+LbkW/jaOxR1/wyBctgeMvh6FGth998ltw2NpcC099+3/47Pln1CXZE7/BYVq9EPdMOoXPlzj6PWOS1cfE1/I7TrXbTsU3YcHQDNh7biO3HtxvX1IshKDDII0LmLrxSCzT39YzpR6Dv/QKcyrKdR3HvZ0txLCbePC8bVgCfDmhlGn0nJiVj8fYj2HHgGKqGFzdplorMOYfk3C7oRNYd8Lx4QooUNDbOxd/GZvnB5SbFat2RFJOnkMAQk8JHm3ym8+UW/G1ssjKNjn0DP1r1EbYc3+KxrGaxmhjYaCC6Ve3ms4vrvDouOTHuO0/uxKajm4xoo3jj3wfPWOm4l8KzbZ9F+wrts9T0Q6QwY00UHvpmBc4mWO6EdcsWwaT+rVCuaEHXOvreOJdkh/2mZUZfZKiG7vHHH8/wxnkA/ve//2V4fSGEEBln/+n9eHPZmyaC486VVa7EyJYjUaFw5luuCGdCoda9WndcVfUq/LX7L3y08iOsP2qVNFDgjZo/Cu+vfB/3NroXPar38Kn5g7g42LCaETdG3ije+Lj52OYMOUDSVr9asWqoU7wOahevjUlrJpk2Jd4IQIBxu2Q9raJr2cPEf7bjhV/XuZwr29csiQ/uaIGwAvpeiuwnQ4KOaY8ZxQmKVgghchtsSE03xImrJ3pc7PFCjnVyrcpevEOvcDZMrexSuQs6V+qMf/b+YyJ2Kw+tNMt2Ru/EUwuewocrP8SAhgPMBbs/upjmhTv/vBljp0raaZO7T+7OcM1a3RJ1jXirU6KOeaxRrIbHWLMlyYi5I6ztuZmjUMyRURGjJOaygaSkZLz023pM+CfFVbh38wp4uXdjhAT5l5GL8F+UcpkFKOVS+Gs4Xzh/bLhfM3fOxJtL30TU6SjX/GL5i2FYs2G4sdaNuf4izalj48vjsXj/YiPsluxf4rGsTGgZI+x61+ptUuqyez80LukblZhUSUbfzkXe6CqZESjMKN54s4bCjX+XLVQ2Q+c+WxcwFdu9D13Z0LJGzGVHH7q8Tmx8IkZOWYlfV6f8Ng/rXBMjrqyd7njpe+NcknN7ymVGYUsAthNgQ28hhBCXBi8IeXG27MAy17x8AflwW93bMKTJEGNQIPIevNBoXa61mSIPROLj1R+b3oOEbQ94ztD19O4Gd6NPnT7G8l1kr1GJK2UyE0YltPCvVbyWK+LGR4q4SxkvirZOlTqZ34xdR3ahcsnKaBHeItff9PEFx2PiMPDzpViyw0pzpbnJi70a4raIyr7eNZEHybSgo8vls88+i8WLF3tt3E0y07ZACCFE2ovEd5e/i6mbpnqkTrHZ9GOtHjOpVkIQNh7/MPxDrDm8xog41trZ59DYZWONlT2byfet19cYYYhLNypxpU1mwqiEzrO1S9R2pU3y7ypFqmSL0OJ7MgW7dsHajok05DZ2H43B3ZMWY9uh0+Z5aEg+vNe3OTrVLePrXRN5lEwLOrYPYDuAm2++2TwWLFjQhAIXLFiATZs24d13382ePRVCiFxOfGI8vt7wtamHYvNfm8pFKhshd3nFy3VxJrzCXoPvdH7HRIo+Wf0JZu2YZW4GsGn0eyvew2drPzOR3Tvr34niBYrrKGbQqMROm7wYoxJX2mSJOihRoISOeS5h1Z7jGPDpUtM4nJQqnB+T+rVCo4rKmBB+JOiWLFmC4cOH44477sDkyZPx559/4tFHH8WIESNM77g5c+agS5cu2bO3QgiRS5m/Zz5eXfKqR98xpl4NaTzERFdkdCEyAsXD6x1fx7am2zB+1Xj8tv03JCYn4lT8KSP02HyeaZhMxyxVsFSePqipjUrstMmsNCoRuYu/NhzEfV9G4kx8onlevXQhfNY/ApVK5J42MSKPCLrTp0+jTp065u/q1atj3Lhx5m8W6/Xt2xevvPJK1u+lEELkUnac2GGE3Py98z1c6ehW+GDzB/P8Rbe4OKoXrY7/XfY/DG0yFBPWTMBPW39CQlKCyy2VkWAa6vRv2N8YbuQ1oxJbxJ2MS4mEZ9SoxBZxGTUqEbmDrxfvwpM/rjHNwUmrqsXxyV0tUSxUAl74oaArU6YMDh8+bP6uUqWKcYM5dOgQSpcujWLFiuHIkSPZsZ9CCJGr4IUk+4p9uf5LDwOFpqWbmjYEDUo18On+idxBpbBKeLbdsxjceDAmrZ1k6jLjkuJwNvEsvtrwFaZsmmJuHtAZk6IlNxqVULzxxsnFGJVQvPG5jGXydiT3jVmbMO6vLa55PRqVwxu3NEGBYJnNCD8VdB07dsRbb72FsmXLolmzZuZx4sSJuP/++zF16lSEh4dnz54KIUQuMVf4ccuPeGf5O+bC04ZNf0e0GIGrq12tu/4iyylXuByeaP0EBjYaaOrpKOQYrWPU7vtN3+OHzT+Y5uRsUl6taDW/NSqhiDt05tBFGZVQxLFeVY6QwiYuIQmjp67CtOV7XfPu7VANT1xTD4GBis4KP+5Dd+zYMQwaNAiFChXCp59+ip9//hmjR482dzDI008/jdtuuw15CfWhE/7a40Tk7NjQSvyVxa9g/dEUJ+D8+fKbtLf+DfojNFh1GN7Q9ybr4c2EyesmmygdTUDc0327Ve2GgY0HmvRCp4yLbVRihNtRqzG3jEqcMTa5lejYeAydvAwLtliZZzyMT19bH/3bX9oND42Nc0nO7X3o7rzzTuNq2a1bNxQvXhzfffcdDh60rHp79uyJ8uXLmw02btwYERERWfMphBAilxB1KgpvLnsTM3bM8JjPC2dG5coXLu+zfRN5E7ouskaT5igUdRR3bHxNZ0yep5w6V+qMQU0GoUHJBjl6QRV1Oiqlr1smjUrYmsG9r5uMSsTFEHXiDPpPWoIN+60ay/xBgXj71mbo3jD315uKXByhu+6667B582YUKVIE1157rRF39evXz5k99AMUoRP+evdHZO/YGAOKNZ+aXmDulue8yBwVMcr0ihIXRt+b7IcRsG82fIPP133ukQpMOlToYGrwmpZp6pHueKnNq2lUsuX4FlfELbNGJUyPtJtxy6jEE31nLp71UdFGzO2Ptn6zi4cGY/zdrdCiSta0+9DYOJfk3B6h++WXX7B27Vr88MMP+O233/DNN98Yp0sKO4q9sDA1KxVCCPd/CjN3zMQby94wtug2xfMXx7Dmw9C7Zm/V6QhHQdOPexrdY3rVTd08FZPWTHLVov2z9x8ztS7bGoMaDzK97V5Z8goOxBzwqAGlmU/XKl29vv+RM0dczbg3HLPSJjNjVELRxno3GZWI7GTBlsMY8sUynDxrnZeVS4Ti0/6tUL10YR14kbtq6BISEjBv3jz8+OOPmDt3LgIDA9G1a1cj7tq0aYO8iCJ0wl/v/oisH5t1R9aZOrnIg5EezYZvq3cbhjQZYlLCRObQ9ybnoQvmj5t/NC0PmAJ5IVh7R9gDr2bxmi6XSYo3irjMGJWYVEm3tEkZlWQefWcyz7TIPXjs+1VIONeWoEmlYphwd0vTODwr0dg4l+TcHqHzeEFQkGkczokfevr06cYYpV+/fqhUqRJuvPFGDBky5FL2Xwgh/A5GIN5d/i6mbZ5m6pBs2ldoj8daPWb6ggnhL9Csp0/dPuhduzemb52O8avHY9fJXemub5/zI+eNzND78yZHtWLVULd4XVfaJB9Z2ydETl/Ev/fXFrw+a5NrXtd6ZfDObc0QGpLpy2Qh/CNClx5LlizBU089hZ07d2L9+hQHt7yAInTCX+/+iEsfm/jEeGMq8eHKD3Eq/pRrfpWwKkbIXVbhMo31JaLvje9he4P3V7yPT1Z/kunXyqgk59F3JmMkJCbhqZ/W4OvFKaY7d7SpjOd6NkS+bGpLoLFxLsl5KULnDhuK//rrryZKxxq7cuXK4b777ruUtxRCCL/h7z1/47Ulr2FH9A7XvMLBhU1qZd+6fRGcL9in+ydEVhEUGISaxWpmaN2GpRriiopXuNImyxYq64iLIyHcOX02AQ98FYm/NqakA4/qXhdDOlbX+Sr8jkwLutOnT2PWrFnGKGXRokVGMbKGbvjw4WjXrp2+BEKIXM+2E9uMkKNRhHsNUe9avfFAswdQqmApn+6fENlB6dDSGVqPrTjk4CqczMGTsbjn06VYvfeEeR6cLwCv39wE1zet4OtdEyL7BJ1thEIRRyOU2NhY1KtXD48//rhxuWRoUgghcjvs08XUyq/Xf+3hzte8THPThqB+SbVzEbkXnud0szwYc9CjTtT9pgaXcz0hnMqWg6fQb9Ji7Dl2xjwvUiAIH9/ZEm1rlPT1rgmRvYKuffv2iI6ONu0JaHrCSX3ohBB5Bfbc+mHLD8b0xL1HFy9eR7Ycie5Vuys7QeR62GeOrQlGzB1hxJu7qLNdLnljI7P96ITIKRZvP4qBny/FiTPx5nn5ogXw6YAI1A4vokEQuV/QNWjQwIi4K6+8EiEhIdm/V0II4RCW7l9qem6x6bG7A+CAhgPQv2F/FAwq6NP9EyInYZ+5N694Ey8vfjlNHzqKufT60Anha35dFYXhU1YgLiHJPK9fLgyT+rdCeFgBX++aEDkj6CZOnHjpWxJCCAdH4JYdWIZdR3ah8pnKaBHewlysvrnsTdMg3B1G41gjVK5wOZ/trxC+hKKtU6VOKd+ZktZ3RpE54VTnwgn/bMeLv6Y4sF9WqxQ+uKMFCudXWwKRO9CZLITI08zeOTtNtKFQcCHTWJlW7Tb1StQzEQheuAqR16F4o/FJ7YK1HWPxLURqEpOS8cL0dfj03xQn4ptbVMT/ejdCcL5AHTCRa5CgE0LkaTHHeqDUBg+n40+7/maj4webPYheNXspAiGE24Xy4u1HsOPAMVQNT0BEtZLZ1rdLiIshNj4RD32zHDPXptyse7hrLTzUpZZuQIhchwSdECLPplkyMufNrc8mNCgUP17/I4oXKJ6j+yaEk5mxJgrP/bIOUSdiXfPKFS2AZ66rj+4NlYosfM/R03G497MliNx13DznzYYxNzTCLa0q+XrXhMgWFG8WQuSpWord0bsxddNUDP5jsEeapTdiEmKw5fiWHNs/IfxBzA2dHOkh5sj+E7FmPpcL4Ut2HjmNGz/41yXmCoXkw8R+rSTmRK5GETohRK4m6lQUFu9fbKYl+5cg6nTmLjgPxRzKtn0Twt/SLBmZ8xbT5jwmXHL5lfXLKv1S+IQVu4/jnk+X4MjpOPO8TJH8Rsw1rKB+ySJ3I0EnhMhVUIDZ4m1R1CLsObXnkt6vdGjpLNs3Ify9h1fqyFxqUcflXE9NmkVO88e6Axj2dSRi4622BLXKFDZtCSoWD9VgiFyPBJ0Qwq9ho2+Kt8VRVhRuR3SKm1lq2D+uaZmmiCgbgZbhLfHo348aAeitjo6Nktlbq3mZ5tn8CYTwDw6eTF/MubMhKlqCTuQoXyzcgWd+Xoukcz/lrauVwMd3tkTR0GCNhMgTSNAJIfyKE2dPmGbfdhrl+WrcggOD0bh0YyPgaLHepHQThOQLcS1/POJx43JJ8eYu6vicsE2BemsJkWI0kRFe/G0ddh6NwQOda6JU4fw6fCLbSEpKxqszN+LDeVtd83o2KY/Xbm6M/EH5dORFnkGCTgjhaE7GnUTkgUiXgNt4dGO6zpRBAUFoUKqBEXAR5SKMgCsYVPC8DZLfvOLNNH3oGJmjmONyIfI6NBP66O9teHXGhgytn5gE0/fru6W7ce9l1XHvZdVQpIAiJSJrOZuQiEe/W4WfV+5zzRvSsQYe61YHgWqhIfIYEnRCCEcREx+D5QeXY9H+RVgStQTrjq5DUrJVE5GawIBA1C9RH63KtTIijumRocGZq5egaOtUqROWHViGXUd2oXLJyqZ5uCJzQgAnYuIx8ruVmL3+/I6wdge6bg3DMW/jYZyJT8TpuES8PWczvvhvJ+7vVBN3tKmsqInIEk6cicfgL5biv21HzXPqt+d6NsCdbavqCIs8iQSdEMKnxCbEYsWhFaYGjrVwaw6vQUJygtd1mQpZp0Qdkz5JAUfhVSSkyCXvA8Ub37N2wdooWrSoms4KAWD1nhO476tl2H30jOt4DOtcE/XKhuGFXz370JV160N3MDoW7/65BV8v3oWEpGSTqvnC9HWY+M92DL+yNm5oVkEumOKi2Xv8DPpNXIzNB0+Z5wWCA/Hubc1xZf1wHVWRZ5GgE0LkKHGJcVh1aJXlQrl/kfk7Pik+3fVrFqtpxFbrsq3RsmxLFM0v+2khsjvF8qvFu/Dcz+sQx/xJAMVCgzG2T1N0qlPGPO/WsCwWbz+CHQeOoWp4cURUK+kSaWXCCuCFXg1NquUbsza5UuJ4If7Idyvx0byteLRbHXMBHhBgx/aEuDBr951A/0lLcPDkWfO8ZKEQjL+7JZpVLq7DJ/I0EnRCiGyFYm3t4bWuGriVB1ciNjF9t7yqYVUtE5NyrdAqvBVKFiypERIihzh9NgH/98Nq/LgipS6paaVieO/25qhQLKUeleKtTfWSqFcyKN2odpWShfDObc0wuGN1vDZzI+ZutHo6MrIy6ItlaF65GEZ1r4vW1fUdFxfm702HMHTyMpPKS6qWDMVnAyLMeSZEXkeCTgiRpSQmJWL90fUuAUdDkzMJKSlbqalYuKIxMLHTKMuEWhEAIUTOsuXgSQyZHIkt51LZSL92VfHENfUQEhR40e/boHxRfNo/Av9tO4JXZmzA8l3HzfzIXcfR5+P/cEWd0iZix/WE8AYNdh6fttqk8JJmlYth/F0tUVIuqkIYJOiEEJcEDUs2Hdvk6gNHc5FT8SkXhKkpW6isq40AH8sXLq8REMLH/LRir7lgjjkX/SgUkg+v3tQEPRqXy7JtMKI3bWg70wCaETu7BoqRO060mx95VW1FXIRH+i+Ndd6avdk1r1uDcLzVpxkKhqgtgRA2EnRCiEz/g916fKvlQrl/CZYeWGp6w6VHqYKlrDYC56aKRSqqbkYIB1m/07Bk8n+7XPPqhBfB+3c0R43ShbN8e0zNvKpBWXSpF44flu/F2D82mdo6wlq731ZH4baIyhjWpSbKFCmQ5dsX/kN8YpJJ/52ydI9HxPipa+vLVEeIVEjQCSEuKOB2RO8w4o0ROD4ejbWsor1RokAJtAxv6aqDqxZWTQJOCAey+2gM7v8qEqv2pNyQualFRbxwfcNsj36wBo/burZxOXy5aBfe+2uLccNkSh3bHHy/bA8GdKiKwR1rIEw97PIcp84m4L4vI03dnM2TPerhng76fyKENyTohBBpBNyeU3tSBFzUEhw8czDdoxQWEmYJuHJWBK5GsRqmP5wQwrnMXncAI6asQHSs1SIkf1CgEXK3tKqUo/tRIDifuUi/pWVFjJ+/HePnbzOmF+xj995fW43Yu++KGrirbVWzrsj9HIiONU6W66KizfOQfIF4s08TXNtY6flCpIcEXS40pHA1SD6jBskiY0SdinKZmFDIRZ2OSnfdQsGFjICza+BqF6+tJtxC+AkJiUl4fdYmfDhvq2telZKheP/25j41JSlSINj0qLuzbRWM+3MLvly0E/GJyTgeE4///bYBE//ZgYe71jJRvaB8umGUW9l04KQRc3YabtGCwfjkrpaIqFbC17smhKORoMtFzN45Gy8vfhkHYg645oWHhmN0xGh0rdLVp/smnMWhmEMu8cbH3Sd3p7tuwaCCaF6muUvA1StZD0GB+ukQwt9gw+8Hvl6OxdtTUqa7NyiLV29u7Ji0xlKF8+PZng1M1G7s7E2mzi45GdgfHYvR01bj4/nb8OhVddC9YVmlcucyFm49gkFfLMXJc1Fjtsn4bEAr1CxTxNe7JoTjccRV2T///IOxY8diy5YtKFmyJG6//XYMGDAg3R/rhIQETJw4Ed9//z0OHjyIKlWqYPDgwbjmmms81tu6dStee+01LF68GEFBQWjVqhVGjx6NSpVSUkoOHz6MMWPGmH3g+3bs2NGsU6ZMGb8TcyPmjkAyLEtfm4MxB838N694U6IuD8OaN4o308w7apGpiUuP/Pnyo2npplYz73Kt0aBUAwQHOuNiTwhxcfy79TAe/HoFDp+yGjIHBQZg9NV1HVuTVKlEKN68pSkGXV4dr8/ciNnrrbTvbYdOY+iXkWhSsSge614X7WuW8vWuiiyAhjiPTFnpamTfsEIYJvZrJWMcIfxF0K1YsQJDhgzB1VdfjYceegjLli0zIiwxMRGDBg3y+pp3330XH3/8Me6//360aNECf/zxB4YPH458+fKhW7duZp2oqCj07dsX1apVw5tvvokzZ87grbfeMkLxl19+QYECBYyAGzhwIE6dOoVnn33WPH/jjTdwzz33YNq0aQgODvabNEtG5lKLOWLPe27hc6bWqXiB4uaxaP6iKBAkB7HcCl0nl+5f6kqj3HJ8S7rrMtrWuFRjI94o4hqXbmxEnRDC/0lKSsYH87bijVkbca6FF8qGFcB7tzdDiyrOT2OrWzYM4+9uhaU7jpoedkt2HDPzV+45gdvHL8JltUrhsW510aiietj5a832R39vw8u/b3DNY1/C9/o2R6H8Pr9EFcJv8Pm3heKsXr16RsSRyy+/3AirDz/8EHfddZcRXqmZOnUqrr32WjzwwAPmedu2bbF27VpMnjzZJej4voULF8akSZNQsGBBM69ixYoYOnQo1qxZg5YtW2LGjBlYt24dfv31V9SsWdOsw33he//+++/o2bMn/IHIg5EeaZbeOH72OO6ZdY/HPF60Fw0pirD8YS6Rx8n1d8i55/nDXOvxeeHgwjK9cBgn406aBt52GuWGoxu8CnySLyAfGpZq6OoF17RMU5NWKYTIXRw7HWeMT/7amOIUSAH0Vp+mfteQuWXVEpgyuC3+2ngQr87YiA37T5r58zcfxvzN/6BHo3Kmh131bGi1ILKHxKRkPPvzWuNqanNrq0p4sVdD1UkK4U+CLi4uDosWLcKDDz7oMZ+ibPz48SZa1759e6+vo1hzp1ixYti3b5/rjs+sWbNMNM4Wc6RRo0YmtdKGfzOCZ4s5wr9r1KiBefPm+Y2gYz3UxXA28axxLzyfg6E36GBYJKRIWsHnJgpTC0N7neB8/hH1dDox8TFYfnC5FYGLWox1R9eZBt/pjVe9EvVcAq55eHNjbCKEyL2s2H0c938Z6TKXYFblQ11qYVjnWn7bw4upoZ3rhuOK2mVMit4bf2zE7qPW5/t1dRRmrN2PW1pWMp+zbFFloDiZM3GJePCb5abJvM0jV9XG/Z1qOjIFWAin41NBt3v3bsTHx6Nq1aoe81kTR7Zv3+5V0DFyN2HCBHTq1AnNmzfHn3/+ifnz52PEiBFm+Z49e3Dy5EmUL18ezz33nInAMeWyQ4cOeOaZZ1C2bFlXjV3qbZPKlSubbfsLpUNLZ2i97lW7IzQ41KTjmSnuBKLPRiM6LhpnEqx/ihmBwsF+D1g3STMMI0Ee0b9zos8jCnhumfvy0KDQPP0jH5sQixWHVhjxxgjcmsNrkJBsFY57o07xOq4aOAo4HkchRO6HNzQ/X7gTL/66zrhEkhKFQvD2rU1xWa2M/a9wOoGBAejVrAKuaVQOXy/ehXf/3IzDp+JMxIfPp0XuQb/2VTG0Yw0UCw3x9e6KVBw5dRb3fLbU3HSw6zlfvakxejevqGMlhD8KOooukjraVqiQFT1gbZs3+vXrZ2rvWP9mc+ONN+Lee+81fx87ZuXYv/7662jcuLGpoTty5Ih5pBj88ccfERoaarZvi8fU2z99+vRF/SPllNM0K93MuFnSAMVbml0AAszyMR3GpGsvz2idLe7cxZ77I+e75p1bj6l+6aX2eYPCkdP+0/sz9RmDAoJcKZ9G5LmlgNrPvQlDRhKd4sjo0VIi5vwtJeIS47Dq8CqXkcnKQysRnxSf7nuz91tEuBWBY0uBYgWKeSz3xXnpT/BCcPH2I9hx4BiqhscjolpJv41i5Ebs31adxxduxvz4tNWYviql7UiLKsXx7m1NUa5owSw/fr4el+B8AbirbRXc2LwCJi7YgY//3maOwdmEJHw0bxu+XrQLQzrWQL92VbO9UbrT8PXYpMf2w6dNW4KdR2PM88L5g/DBHc3RoWYpx+1rXhsbAceNTWb2w6dXuklJ3lPEbAIDA72mW9IF89ChQyb6Vr16dSxfvhwffPCBEWlPPvmkWYeUKlUK48aNc70PxVufPn2MKQofz3egLiYaFB0d7XWfc4JhDYbhySVPel1GwfVAgwdw6qR3gWwTghCUCiiFUgVKARnMVklMTsTp+NM4GX/SiLzo+Ggj8vi3mRcf7frbzHd7fj6BkhpGo+jUyCmzFA4qbIRdkeAiRvyFBYdd8Dkfs9IYZN6+eXh79ds4FJuSHlu6QGk81OghdCzfEQlJCdhwfAMiD0ci8lAk1hxbY0R2elQqVAnNSzdHs1LN0KxkM5Qo4GZucNYyRREZY87GI3h19jYcOGn9bpDwIiF4rGt1dKlTUofRAfC3OibGugDMy5H687Hl0Gk88sNG7DiXgkjuiiiPYR2rIBhxOHEi5fzOjeNyV4vSuK5eMUxcuAffRkYhLjHZNE1/deZGTFqwDYPaV0KvxuEIziM97Jw0NjYr90bjoe/X4/gZK7ukTJEQjLu5PmqXDsaJE3nnf5YTx0Y4c2wupJMcI+iKFLF6i6SOhtmRudSROzJz5kxs2LDBmJ20a9fOzIuIiDDrPv/887jllltcr6PBirvAatq0qdkmjVDs9/cWieP27X3LDGFhYcZp0xf0LNrTCNpXlrziYZBSNrQsHmv1WLa2LCiBEhf1pWGkzohAOyqYKg00vUghBWRmOJVwykxRSL9ZtjdCAkPSrRF0pYqmNpAJCUPhEE/TGLaUeGrJU2kimRR3FOF1i9fFrpO7EJNg/Yh4o0LhCq4aOE6MuIpLZ8aa/XjkBxrIeHLwZJyZz2bL7HclfIt9861o0aKO+CfrNKZG7sGTP65BbLz1z79I/iCTwpbd567TxqVoUeD53qUwuHMdvDNnM75ftsc4ex46FY+XZm7Dl0v3G+OUaxqWM2mbuRmnjc3Mtfvx0DdrTfSU1AkvjEn9W5nIcV7DaWMjnDs2dPz3C0HHWjUKoJ07UxyOyK5du8wjzUlSYxufsHbOHfaYI+xlx15yHAg7Upf64NjOmTREWb9+fZp1uH2mamYWbtOXJ8CVVa9E58qdU9L6Sp4/rc+X8DgVCilkpnIol6nXMrLHaJ8tAm3x500Yuh7PLWdEMaPEJcXh0JlDZrpY0xhG/TYf33zetNQNx1Lsmm0o2Ow2AhRy5QuXz9Q+iIylWT4/fZ3XkeE8fpO5/KoGZZV+6QDs31cn/JN1CrHxiXjul7X4evFu17z65cLMjYiqpQrl2XGpWDwUr97UxPSwe23mRsxca93k3HEkBsO+XoEPy28zPewur1XKUfudW8fm0wXb8Rx/a8/92LarURIf3tnCMc3s8/LYCGePTWb2waeCLn/+/KZ9APvIsfebveOMwjFC5k1UMcWSLF261Jic2ERGRrpaE7AGjgKPTpc0SgkJsYqiFy5caEKp3Cbh66dPn25EoO10yb9plsL2Bv4IxRtFQO2CtR1zhyGrYZNrphh6pBlm8M4Lo3t2PWB6YtA9OmjXCV60aUwGYWSvfYX2RrxxqlSkUq4cOyfx37YjiDoRm+5yXntw+eLtR9G2hlIvhbPYeeQ0hk6OxLqoaA/L92d7NkCBYOfdxPMFNcsUwUd3tsTyXcdMD7v/tlkp+2v3RePuiYvRpnoJjOpeF80qF/f1rubaHohjfl+PT+anmMzd0KwCXrmxMUKC8kbqqxA5RUCyjyv/KLL69++Pq666yhibsB6OPehGjhzpavpNkcVoXokSJUyE7bbbbjMOmcOGDTMCb9WqVaaGrk2bNuaR8H3uvPNO03ic7QtoikKTFAq+r7/+2kQGGcFja4KzZ8+a7RE2Fmcq5g8//ICgoIzpXe4TTVqY0umrlEt3OKTMR8+tgs4X2KYxqaN/7iLQ67y4lIut8/HyZS+jR/Ue2f45hHWR8duaKLwwfR0ORKdfp2jz+s2NcVOLSjp0PkS/aWnT1x75biVOxlq1SAWCA/Fir0a4qUXOugT607hwX9mzjsKOgs6dbg3C8Wi3OkYA5hZ8PTaMHo/8biV+dTPoub9TDTxyVR3Hnyu5fWyE/4xNZvSFzwUdYYTunXfeMa0CwsPDjekJRRhhnzo6U44ZMwa9e/c28yjyxo4dayJ5PPCVKlVCr169jPulHY2zo3Zcj4KPaZZdu3bFqFGjTK2bTVRUFF566SUsWLAAwcHBpk3C448/jjJlymR4/yXoRHr8t+8/DPwjxY01PSZ2m2giqyL74E8dL4TH/rEZGw9kvN9GyULBGHV1PfRuVkHNbn2E0/7J+or4xCS8OmODR8SjeqlCeP+O5qhbNudbk/jjuPCGDnvWvTFro0nBtGFJ3Y3NK+LhK2ujQjH/r+vy5dgcj4nDoM+XYfGOo65jyxsOfVtXztH9cCr++L3JKyQ7bGz8TtD5OxJ0It1zIykR3aZ2u2BLiRk3znBkrWNugD9xc9YfxNjZm9Lcmaftud2r60LULFPY3MW/qn64I37o8xJO+yfrC/afiMUDX0Vi6U6rLQ/p0bicSV+j9bsv8OdxoTiesnQ33p69GQdPpkTqmQp4V5squK9TTdO/z1/x1djsPhqDfpMWY+shy7ysYHA+vHd7M9MQXvh2bIT/jU1m9IWSmIXIRijSRkeMdok3d+znoyJGScxl0w/z3I0H0eu9Bbj386UeYq5ppWL44p4IvHNrMzMKqX+27ecNK6REPbYcPIXBXyzDDe//i4Vbj2THLgvhlX82H0aPd+a7xBxvRDzXswHG3dbMZ2LO32H7gttbV8G8Rzvhse51UKSAdRzjEpIw/p/t6PjqX3h3zmacPmultYoLs2bvCfT+4F+XmCtVOATfDm4jMSdEDqAIXRagCJ24EGxd8PLil9O0lKCYy86WEnlVyP279Qje/GMTlrlFM0ijCkUx4srauKJOadfdtxlrovDcL+s8DFLKFS2AZ66rj+4NyxlTFKa5uUdGyOW1S+OxbnXQsELRHPpkeRen3TXNyfTAd//cgrfmbHI5BDIdcFzfZo4w8shN48I0wQ/nbcOkBdtd1vq2KBnWuRZui6jsV0YeOT02f208iPu/jERMnOUkXb10IXzWPwKVSoRm+7b9jdz0vcltJDtsbJRy6eADnhdPSJGSfukPLSX83bmSQo4izJ165cIwvGstXJlOuiRbGCzefgQ7DhxD1fDiiKhW0qNVAb9Tf244iFdnbExTf3ddk/IYeWXtHLOJz4vkxd+0I6fO4uFvVxgjD5tOdUrjzVuaorhDUgFz47gwtfXtOZtNOiZ/F2wqlSiIkVfWQc8m5f2ih11Ojs3Xi3eZPoj28WpZpTg+uaulY85Tp5Ebvze5hWSHjY0EnYMPeF48IUUKGpvsYdnOo0bILdjimQpZO7wwhnetjW4Nyl7wIiwjY8MLlp9W7DXb2nMspZVFUGAA+rSqhIe61EKZMKvPpcg68tr3hufz/V8ux/5oK2rMU3fkVXUwtGMNR4mJ3Dwu2w6dwht/bPJwaSR1yxYxKZqd6pRx9GfOibHhNvhbyCiyzTWNypqbDmqd4duxEbljbDKjL5R8L4TwW1bsPm4uKP7e5Nn8nek+D3etjWsblcvSC2BG7Xo3r2jMKL5atAvj/tyCI6fjkJCUjC8X7cLUyD0Y0L4aBnesgaIF827TXHHxFxMTF+zAmN/Wm3PKTvl757ZmaFejlA5rDlK9dGG817c5Bl9+3DQntyOlG/afxIBPlyKiagkj7FpWzVw/1NwCaw1HT1uFaZF7XfPu6VAN/3dNPUfddBAir6AauixAETrhr3d//Ln4fuwfmzBnw0GP+VVKhpoo2fVNK3ikTGbX2Jw6m4AJ87fj47+34vS52hFCMTf0ihro166q7lRnAXnhexMdG49R36/C72v2u+ZRNLzbtxnCHRr1zQvjYrNgy2FTS7tyzwmP+V3rlcEj3er4pG2Er8aG5+p9kyPxzxZL5PLtn+pRHwM6VMvS7eRW8tL3xt9IdtjYKOXSwQc8L56QIgWNzaWxPioab83ehJlrU8xlSMXiBfFgl1qX1CvuUsaG9U7v/bUVk//bibjEFEOF8LD8JlJ4c4uK6mF3CeT27826fdG478tlHn3RhnRkE+bajj5vcvu4ePu8M9bsx2uzNmLbOSdHwo9+Q7MKJr3bKSYg2TU2rDFkWwJGKkn+oEC81acprm5ULsu2kdvJa98bfyLZYWMjQefgA54XT0iRgsbm4th84CTemr3ZNAR2p3zRAnigcy3c1KLiJTvQZcXY7DkWY/ZzWuQeuPkpmObPrIFifYm+k74ZG6cyZcluPPXTGpezYliBIFOD1LW+8/t25eZxOR8JiUkmvXrsH5tddY52Owm2Qnigc02UKpw/143Nhv3R6D9picsRuFhoMCbc3RItquTNtNOLJa9+b/yBZIeNjQSdgw94XjwhRQoam8yx9dApvDNnM35euc9l225Hvu7vVNMYkeQPyue4sdl04KSpu/lj3YE0bRNGda+LDrVUD+WrsXEKZ+ISjZD7ftkej/Pj/dubOybKkxfHJTPExifi84U7THT+xJl41/xCIflw72XVce9l1VCkQHCuGJt/txw2fThPnuvLV7lEKD7t38rUGgrfjo3IOpw2NhJ0Dj7gefGEFClobDLGziOn8c6cLfhhuWeki3e977uiBvq2rpzltWnZMTbsg/fKjA1p2ii0r1kSj3WriyaVimXJdnI7ue17QwfF+76MdKWtkTvaVMaTPer7Vc1lbhuXi4Vi7pO/t2HCP9txJj6llrZEoRBz44ljm1U3nnwxNvwdfuz7VYhPtH6Mm1Qsign9Wvk8Cumv6HvjXJId9psmQefgA54XT0iRgsbmwimL787Zgu8j93j0gOKF0ZCO1XFHmyoIDQnyq7Hh+87ddMj0sGMNoDtMwWQqZg3d5fbJ2PgC2uCPmrrKGOqQgsH58PKNjYyRj7+Rm8YlKzh4Mtb8frEvm+1SajeDH35lbVNnl1mzJl+ODd/j/blbTbaBuwkMXVez63c4L6DvjXNJdthvmtoWCCH8iqgTZ0wLADbzte8C226Rgy6vbtwiC+X3zwsI/lNgz6qOtUrjl1X78MasTdh11DK/+G31fmPwQtOUh7rWQrmiBX29uyIbbd7/99t6fPrvDte8mmUK44Pbm6NWeBEd91xAmSIF8EKvhibVku1Uflqxz8zfe/wMHvluJT6atxWPdquDK+uHO+Ji8UJ1gk//vNa0Z7FhpPHZ6xo42qhHiLyKf14hCSFyBQejY80dYF40uLtDFikQhIGXVUf/9lV9VoOS1bA3E6MwVzcsh2+X7MLbc7bg8KmzJhL5zZLd+GH5XiNc2e6gWGiIr3dXZCG8oL//y0jTN9GmV9PyeOmGRn57o0KkT5WShfD2rc3MzShGt+ZutPpkbj54CoO+WIbmlYuZWtrW1Us68jCePpuAYV8vx59ubWHYc4+N7Z0uRIXIq+g/iRAixzl08iw+nGfZ/NvufqRw/iAMaF8V93SojqKhuUPIpYZunHe2rYobW1TEpAU78OHcrcZogMfho7+34avFu4xlPcWs0pr8n7kbD+Lhb1fgeIxlmhGSLxBPX1cft7eurIvjXE6D8kXxaf8I/LftiOlhF7nLEvR87PPxf7iiTmkTseN6TvptHvDpEqzee8Ll3Pn6zU38MiVYiLyEBJ0QIsc4ejoOH/29FZ//u9PDPIB1RP3aV8Wgy6qjeKG8EZ2iWKNhQt+Iyvhg3laTise0vJOxCeauPp+zt96trSohWClOfgcjr+yZOO6vLS6HVvZL/OD2FmhU0TkX8CL7aVO9JKYObYfZ6w/itZkbsOnAKTOfkTtOPZuUx8irapvInq9dhdljbvfRM65MiY/ubIF2NeTKK4TTkaATQmQ7x2PiMH7+dkxasB2n41KEHJvS3tW2CgZ3rJFnHdMoYJ+4pp6JyL09e7OpI6SfAu+UP/XjGoyfvw0jrqyN6xqXN2mbwvkwlfahb5ZjwZYjrnld64XjjZub5NrIszg/TFVk7VznumVMevXYPzaZVFzCtiy/rY7CbRGVMaxLTVOLl9Ms3XEU936+1BVJZo/PSf0jUKes6juF8AcCkmnpIi4JuVwKf3VQym6iY+Mx8Z/tmDB/u6t/kZ12yJQz1mSUCcv5ixcnj82Wg6fwxqyN+H3Nfo/59cuFmTqWjrVL54lzx4ljkxHYouKBryJx8ORZ85yuho91q2PqqZy+77l5XJzG2YREfPnfLhPBZeaCe7bCgA5VzU2usEuoH87M2FBMMi2YGQKkbtkiJlW0bFFn/DbnNvS9cS7JDvtNk8ulEMKn0JL90wXb8fHf2xAdmyLkWI9xa6vKJtVQFwveMc6Hd7TAyt3HTQ+7f7daUZ51UdHoN2kJWlcrgce610WLKsVzaDRFRi8EeL6/OnOjq+VGmSL58e5tzRxrfiF8B/vSDehQDTe3rGiyFxiJZ/YCU9HZqPzLRbtMz8272lbN1t6E3O5Lv613pQVfVquUaW6fW8yohMgrKEKXBShCJ/z17k9WExOXgM8X7jT23MfOpe6QoMAA3NyyEh7oXNP0ZHIiTh2bfzYfNsLONimwYfoWDRVq5wHLe6eOjXtjadrS/7HugGte2+olTb+u0kVybyqx08fF39J03/trizGKcm/dUjasAB7uWgs3taiYqXYBFxqbpKRkvPjrekxcsN01j9sY07uRanazGX1vnEuyw37TFKETQuQosfGJ5kKEzpWHT6WkDzHdrHezChjWuRYqlwzVqFwEHWqVQrsa7U0K5uuzNmL74dNmPsXDnPUH0Lt5RXPBV7G4jq8vWLP3BIZ+ucxlJEEe6FTTNJLOqSbSwv9hDfEz1zXAgPbVMHb2JlNnx6jZ/uj/b+9OwKIq2zeAPywKLuxuiMjmvov7kpprm+lfU1Ozcsklza3S9vJrz1KzXCptVdOyzOyr/EwrNc0NzV1BwQ0VFQQ3kO1/3Q+eaUBALGTODPfvurhGDsPMYY4D5z7v8z5vsjz17S75cN1hebJrTbmjXqV/faKJ39cTluzIVtY9rlN1/T1ihpNYIrp5bIpCRP/qxGDx5qMy67dD2sTDgHOCno0CtEtjSDnbdm5zBGiGcncDf+lat6J8vfW4vLv6oJxOStHmKUu3HZfvd8TKAy2DZPTtYeJXTJvL2OJKLpaYmLJir2XukXfpEjK9byO5vVYFW+8e2alA39IyrW8jGdEuTLvd/rIva9T38JlLMmphhDSs4qUl122q/bPOkwmXrmrzk21HEvRzXHR47f/qSb9mVQv15yCiosVAR0Q3DSew6MaIEqGTicnZgtzd9f31Sm+1Co5fCljUsHzBgBZV5f8aB8hnG2Nk9q9ROkcRi7KjdArHBAuyD70tRNf0o1tXWvzsst06imJoGOitc4/MWlJM9gXdJec91FS7T6LkektMVgD763iiDJy3See6TepW66aWwDh67rIuS3D42ih/mZIuMmtguHSoyQsQRPaOf/GJqMBS0zPk24jjMnN1lKXltuHOepVkXOfqUquSJ1/RW6xUSRddfLx/s6oyd+0hXQ4iOTVDm9GgXOvzjTE6XxHhD80XqPBExV2QUQsiJDIuay0xeLh1sC49ge6tRIWpabCvfDWila5Xh2C3/9QF3b4u8qysi1yvF9Cwhl1o+bL5Pg6aLA39bIulJB5zOz95uJnUC+CaiESOgE1RCgGbopC9TrgtqLT0DPluR6zMXB0pR+MvZ/sa1tfCiJy9nxjY67GB00nJemwWbzlm6bBoLGSNNex6NAqw6/lcZjk2y3eckKe/3SWXr62liBGON+9rIPc0qCzFkVmOS3GBRiZYs+6dVQeyzdnEe7tv00CdB4fuwfgdsDn6nMScTpDgij5yMTlNxi7eoR00jU66nw5uxnm3NsL3jXllmux32s3kCwa6In7Bi+N/SLLfY4MTgx92xuqC10aZjqFDzfIyoXMNLTVzBPZ2bHKDhilYw+6HnSezbce6UuiIiUWN7fFns/WxwZphr/ywT77484hlW82KHjL7gXAJu8HIiCOz9XEpziXvi7cc1Ys41k2o3FydpV2N8rLz+HmdY5ub5iG+8tGgplzg3ob4vjGvTJP9TmOXSyL611eC0QFtxi8Hs5WWAeZujO9cg+ugmRAa0Lw/IFxGtk/U9dDWHjyj21GmNfSzrdI0yEcm31lLmgX72npX7cax+MsyelGE7Dz+97IRvcOryCs962npK1FRQ2kv1qfD/8OP12et93khJU1S0jKyLZ2RU5Mgb/liaHOWYRM5IM6hI6JsV6dW7jmtQc6Yq2HAgtYo3+MiyeaH8tfPhzSXDYewht0BnT8DW48kSJ+5G6VTrQryRLeaUtuf8x3zg2UhJn71l64zZ5xIv9yjrpa3meHqLRVvZdxc5bFO1WVgyyCZ9WukzF8fk+/9Y88ni6sz53kSOSIGOiLSILdmf5xMW3VQ9sQmZXtFMKozsWsNaR32z9pkk+3gmH33qJ+G9Kkr98uhM1lls6v3x8maA3G6tARCOlqlU/Y5o++sOihzfjtk2RbkV1q7WNatbN9zRcnx+JYpKZ1rV7phoENH4s3R8dIqzK/I9o2IigYDHVExD3JrI89qkDNGcQyYG/d4lxpaYsnRCPuFY4fFiDvXriDfRpzQLpg4scOixWi7jzmSA1tgDbtq2vmuuItLSpbHvtwum6LjLdu61a0oU/s0FE/3EjbdN6K8xF34e/mYwrgfEdkXBjqiYhrkNhw6p0HOWGDWUC/AU0dtbq9pnw00KHeuLs7St1mg3Nuosiz484i8/2uUnL+cKqnpmfLphhhdw25Y2xB5pF2oeBTT4LLx0DkNc2cvZjWUcHV2kqfurCVD24bwvUCmVsHDvVDvR0T2hYGOqJjZdPiclpOh9CZnJ8QJXWpI1zoVefLqwNxLuMiw20I13H209rDMWxet7czRin/mmijt5IjRugdaBul9i0sToDm/H9IOocaqD5U83WXWwMbSJIgNZMj80L3S38tdTmH0PZev49IcljTA/YjI8TDQERUTGImbvuqgrI86m2179QplNcjdUbeSONvxWmV0c1A++HjXmtot7/01kbJo81EdrUu4nCqv/Hefds8b36WG9GocoKN7jur85asyYckO+fVAVkdQQJnxjH6NxK8sS1DJPmAtuhe719FF7/Fb3DrUGb/V8XV7Xo+SiPLGQEfk4HYcO69B7vdrLewNoeXKyLjO1XVRZP6RL74wb25Kj3oytG2oTFt1QJb/Favz62ITk2XS0p3aEh1r2DniyC3mjT66MEJOnM9apBk/HhZnfqxjdb4nyO7cUc9f5jwQLlNW7NV5sgaMzCHM4etE5JgY6Igc1O4Tibr8wC/74rJtr+pbWk9aezSq7NAjL3RzqvqVlhn3N5bh7cLk7f8d0K6nEBV3UUZ8sU0aBXrL5DtqOUSHPMwhRWnpyz/s1VFJo1MgRuWwMDORvUJo61KnkmyOPicxpxMkuKKPNA/x4wUKIgfHQEfkYPafStIRObSqtxbgXUqD3P+FB0gJBjnKQ53KnvLxw810juWbP++3NM3BSG//j/7UwDOpW01d684eXUxJk6e/3SUr/oq1bGsS5CPvD2gs/l6lbLpvRIUBFRctQ/2ktp+reHl5OdzIOhFdj4GOyEFEnr4gM1ZHyn93nsy2HRPlx3SsJn2aBOrCyEQFgeYJS0e2ktX74mTqygNy4HTWQvNrD57Rj+4NK+uyFsHlytjNC3rg1AUZtXCbHL62Hh+gs+fkO2vxIgcREdktBjoiO3f4zEWZuTrSMvfJUMHDTbsV3t88UNxci0e3QipcuLLfuU5Fub1WBVm+44S887+DlvlmGOH6addJ6dcsUEd+K3iaux36txHH5ZlluyQ5NUM/93Bzlal9GnBeERER2T0GOiI7dfTcZZm5JlJPVI1W61CubEkZ1aGaDGxRtdi0nadbX8LVK7yK3N3AXxZtOirvr4mSc5euSlpGpizcdFS+iTguQ9qEyIj2YeJVylxr2CWnpsuUFXvky83HLNtq+3vKnIHhdjW6SERElBcGOiI7czzhsp5QL912XE+oDT6lS8jI9mEyqFWQlC7JtzYVPoz0Dm4TIn2aBsq8dYd1HbtLV9N11Gv2b4c03I3qECYPtw42xcWEI+cuaRfLPbFJlm33NwuUl+6ta4r9IyIiKgw86yOyEycTr8isX6NkyZZjls58gBGR4e1C5aHWwVLWjW9puvXw/2x85xoyqGWQzPr1kCz484hcTc+QxCup8sZP++WTP6L1632aVLFZJ9WVe07JE1//JReS0/Rz9xLO8krP+nJfkyo22R8iIqJbhWd/RCYXl5Ssox8odcNJswFzgIbdFiqD2wbrItFERQ0Lb7/QvY4MbhMsM36JlG+3H9d5nKeTUrSTJEbwsHj5XfUrFVmnvdT0DHnr5/3y0brobGsuzn4gXGpV8iySfSAiIipKDHREJnX2YorM/e2QrpeVkvZ3kCtT0kWGtA2RYW1Dxas0gxzZXqBvaXmnb0MdKcYadqv2Zi2ZcfjsJRm9KELqB3jpGnZtq5e7pftxKjFZxiyKkK3XlloAzPt7o1d98eBFDyIiclCmCXTr16+X6dOnS1RUlPj5+cnAgQNlyJAheV7VTUtLk48//liWLl0qcXFxEhQUJCNGjJC77ror2/3atWsnp09nX48LNm7cKL6+vvrvrVu3yrRp02T//v3i6ekpnTt3lvHjx0vZsmVv0U9LlLf4S1flw7WH5bMNMXIlNd2yvVQJFy2rxEkzFkEmMpualTzkowebyrYj8fLmTwdkc0y8bt91IlEemL9J2lTzk0ndaknDQO9Cf+71kWdl3OLt2qwFSrg4ybN31db3DNfhIiIiR2aKQLdjxw4ZOXKk3HnnnTJu3DjZtm2bTJ06VdLT02X48OG5fs97770nH374oYwePVqaNGkiq1atkgkTJoiLi4t069ZN7xMfH69hbtKkSXofawhuEBkZKYMHD9avz5gxQ+//9ttvy/Hjx2Xu3LlF8NMTZUm8nCrz1h+Wj9dHa6MJg5urs85VGtkhTMqVdePLRabXJMhXloxoKb8dPCNv/XxA9p3MakryR9Q56RH1h5ZgohQzrPy/v2iWkZEp762JkhmrD1qW7ajs5S6zBoZL46o+//rxiYiIzM4UgQ7hrHbt2hrijFE1jMAhUD344IPi7n79+kbffPON3HPPPTJmzBj9vFWrVrJnzx5ZsGCBJdBhxA26dOkiVatWzfW5V6xYoVdvZ82aJWXKZLWwRpB88cUX5cSJExIQEHDLfm4qXtIzMmVz9DmJOZ0gwRXTpHmIn7aDT0pO1RA3f120XEjJauAAJV2cZUCLqvJohzDTr/FFlBN+r95es4K0r15eVuyM1TXsjsZf1q/9uOuUrNxzWpumjOtcXfy9Sv3j0ezxS3boQueGDjXLy/S+jcSHo9hERFRM2DzQXb16VTZt2iRjx47Nth2hbN68eTpa16ZNm1y/L2dJpLe3t8TGxlo+37dvn4a0wMDAPJ8/JSVFXF1dpVSpUtkeB86fP89AR4Xi590nZcqKvXIyMdmyraKnm7QM9ZPfDpzR7oAGlIphsWYsCv5PT3SJzMLZ2Ul6NAqQO+v5y5ItR+Xd1VE6PxQXOBZvOSbLtp/QZQ6w3IF36YKXEm87kqDz5Yz3lLOTyMQuNeTRDtX0OYmIiIoL2/STtnLs2DFJTU2V4ODgbNsxJw6io//uVGYNI3ffffedrF27Vi5evCjff/+9rFu3Tnr06JEt0CGcISyipLJx48Y6Nw5z7gy9e/fW29dff10SEhK0BBOjdTVq1JBatWrdop+ailuYG7Xg7xNPAzoBLt8Rawlzrs5O0r95oPz6RAdtr84wR46kJEqHWwXL2kkd5ImuNbRLK6DhzwdrD8ttb/2qy3Jcvvr3KDUg+P15+Jz8tPeM3qalZ+iIdr8PNlreU+XKlpQFQ1vImI7VGeaIiKjYsfkI3YULF/Q252ibUf6IsJabhx9+WOfePfLII9nC2bBhwyyfo+QSc+L69u0rDz30kBw6dEhmzpwpgwYNkmXLlknp0qU1uD355JPyn//8Rz7//HP9PpRZLly4UOfj3YzMzEz9sDVjP8ywL8UdTkZfWrFXbnQkeodXlrGdakhV39L6OY9d0eP7pmiguQ9Gnwc0rypzfj8kn208IlfTMnS9uKkrD8inG2JkbMdqOkq9el+cTPlhr3avtJ5Tat31tVmwj7zXv7FU9HTn+6aI8T1jXjw25sVjY16ZJjt/vpn9sHmgy8j4+w9zbpydnXMtt0QXzDNnzsiUKVMkNDRUtm/fLnPmzNGQ9txzz+n9Xn75ZQ1lDRo00M+bNm0q1apVkwEDBujoHm7RWOWdd97Rx8NcO4zS4XEQGBHqypUreJvtpKSkXPfXFv8BLl/OmqvC7m62ge6Ue05elB92x2U7Gc3LHTV9xcslVRITE4tk/+h6fN8ULfymHN2msvSu7ycfrD8qy3fFSUamyJkLKfL88j0yY9VBOXf571Jkg3WYG9wyQEa3CxLXzBRJTEwp4p+A+J4xLx4b8+KxMa9Mk50/3ygjmSrQeXh46O2lS5eybTdG5nJbOmDlypU6+vbJJ59I69atdVvz5s31vhhpw4gcRt5QYpkTSi/xnPh+NF6ZPXu2dO/eXV544QXLfVq0aKFLF8yfP18mT55c4J8FnTNvdlTvViZ6Ly8vU/yHLA5wEoo5PVj/Cre7TyRKGs5OC+hyhqseL7Idvm9sA//tp/WvIKM7XZS3Vx2Un3ef0u25hTlrPqVLyLPdG2hjIbINvmfMi8fGvHhszCvTZOfPaNJoN4EO3ScRgo4cOZJt+9GjR/U2LCzsuu8xGp+Eh4dn296sWTO9xVp2/v7+GvwwOodwZ512MWcPa9BhWYMrV65c9zhYBy8kJETn090MHHwz/Aew3hez7I8jQZv0Q2cuanjbGoMAFy8x57Ku6PxT6GLJY2V7fN/YTrWKHjL3gSay49h5eXbZLtkTm7XUQV4SLqfKlpgEaRXmV2T7SNfje8a8eGzMi8fGvJxMdP58M/tg8/pANzc3LYXEOnLWtaIIYxhJM8olraHE0lgQ3FpERITeVqlSRUqWLKkllx988EG2+6xZs0aSk5N1FA7BDU1T0EnTGoJeTExMvt0xqfhITk2XzdHxMvu3KBn66RYJf2WVdJm+Vp7+dpd8E3E81zAXVr6M9GsaKG/0ri/ly7pJXm9JbPf3cpfmIVmL3BMVd40CvWX4bVm/428k7sKNy5mJiIgcnc1H6GDUqFG6uDcWFUdjE8yHQ7nj448/rssJoPwSo24YzcPIWseOHaVhw4bazOSxxx7TgLdz506d+4avGSEQDVOwxh3mwbVv314OHjyon3fq1EnXrQN8P4IfmrBgYXPMoUMIxKjhkCFDbPzKkC2cu5hiKZ3cGhMvu04kSmp63uWTWC+uQRUvaRLsI82CfCU8yEd8rdbA8i5VQrtcIrxZP4oR8l7sXodlY0RWCrruYgUPrs9IRETklGmSVi4YoUMHSixTULFiRW1SYgQqrFOHZQqwtECvXr10G0Le9OnTdSQPjSQwmtazZ09tZoLROaO8cvHixbJo0SIt4cRoHObLIcRZL1a+fPlynY+H0Ojj46MjhhMnTizwCB1qXNFxs1GjRqaZQ4fXxCw1wGaG1+rQmUtaNplVPpkgh89mn8+Z29ydJkG+0hQBLthH6gV4iZury02vQ4eROYS5O+r5F9rPQ/8c3zfm6g7b9s012lAotz9Q+K1Wyctd1k/uyIshNsT3jHnx2JgXj415ZZrs/Plm8oVpAp09Y6CzHylp6bLreKJl/lvE0QSJv3Q13+8JLVdGmgT5aIBrGuyrn/+TNzpOUjdHn5OY0wkSXNFHmof48WTURMz2i7y4M9ZvlDxGtuc8EM6LITbG94x58diYF4+NeWWa7DzgZvKFKUouiW6VhEtXddRty5F42RaTIDtPJOqaV3kp4eIk9QO8NLg1DfLRIOdX1q1Q9gXd+FqG+kltP1fT/LIgMiuMXCO05RzZxsgcR7aJiIj+xkBHDnVlBQ1KtsRkhbetR+K1nDI/3iifrOqj89+aBvnqXDj3ErYvmyWirFDXpU4ljmwTERHlg4GO7BZG2nbHJmrjEmP+27kblE8G+5W2zH/DCFxY+bLizHWsiEyLI9tERET5Y6Aju3H+8lWd84a1pzAC99fx85KST/mkq7OTNixBcEOAQ5Ar71E45ZNERERERGbAQEemLZ88Gn9ZR95QOonbyLiL+X6Pp7vrteYlvnrbsIq3lCrJ8kkiIiIiclwMdGQKqekZsic2yVI+iS6UZy+m5Ps9VX1LZzUu0eUDfKUayyeJiIiIqJhhoCObSLySquWTRoBD+WRyav7lk3Ure2ab/1bQxYeJiIiIiBwVAx0VSfnk8YQrWjppzH87GHdB8lsB0cPdVcKr+lhG4BoFekvpkvzvSkRERERkjWfIVOjS0jNk78mkbPPf4i7kXz5ZxafUtfDmK82CfaR6BQ8uuk1EREREdAMMdPSvJSWnyvaj52VbTNYI3I5j5+VKanq+bcjr+KN8Mqv7JNZ/w2LBRERERER0cxjo6KbLJ0+cv6JrvmHkDYt4Hzidf/lkWTdXaVzVW4Nb02vlk2Xc+F+PiIiIiOjf4lk13bB8cv+pC1nNS66FuFNJyfl+T4B3KcvoG25rVfJk+SQRERER0S3AQEfZXExJk+3afTJBR+Hw70tX8y6fdHYSqe3vaZn/htvK3qX4qhIRERERFQEGOgeTnpEpm6PPSczpBAmumCbNQ/zyHR2LPY/uk+g8mTUCt+9kkmTkUz5ZpqSLNK7qYxmBw79RUklEREREREWPZ+IO5OfdJ2XKir1yMvHvkkh/L3d5sXsduaOev4a9/aeSLPPfcIv5cPnB92t40wDnK7UqeYiri3MR/DRERERERHQjDHQOFOZGLYiQnINrCHcjF0RIbX8PORZ/RUsq8+LkJDrfLSu8ZQU4zIcjIiIiIiJzYqBzABh5w8hcPpWSsu/kheu2lSrhcq37ZNb8N/zb073ELd1XIiIiIiIqPAx0DmBzdHy2Msu8+JQuIa3Dylnmv6GZSQmWTxIRERER2S0GOgcQd+HGYQ5e6l5XejQOuOX7Q0RERERERYPdLRxABQ/3gt3Ps2D3IyIiIiIi+8BA5wCah/hqN8q8FifAdnwd9yMiIiIiIsfBQOcAsM4cliaAnKHO+Bxfz289OiIiIiIisj8MdA4C68zNeSBcKnllL6vE59iOrxMRERERkWNhUxQHgtDWpU4l2Rx9TmJOJ0hwRR9pHuLHkTkiIiIiIgfFQOdgUFbZMtRPavu5ipeXlzhhtXAiIiIiInJILLkkIiIiIiKyUwx0REREREREdoqBjoiIiIiIyE4x0BEREREREdkpBjoiIiIiIiI7xUBHRERERERkpxjoiIiIiIiI7BQDHRERERERkZ1ioCMiIiIiIrJTDHRERERERER2ytXWO+AIMjMz9TY9PV3Msj8ZGRm6P05OTrbeHbLCY2NePDbmxWNjTjwu5sVjY148NuaVabLzZyNXGDkjPwx0hQAHH3bt2lUYD0dERERERCRGzsiPU2ZBYh/d8IVOS0sTZ2dnUyR6IiIiIiKy/xFDV1dXzRj5YaAjIiIiIiKyU2yKQkREREREZKcY6IiIiIiIiOwUAx0REREREZGdYqAjIiIiIiKyUwx0REREREREdoqBjoiIiIiIyE4x0DmoU6dOSdOmTWXTpk223hW6tlbhl19+Kd27d5fGjRtLp06d5LXXXpOLFy/y9THBsZk/f7507dpVGjRoIPfee698//33tt4tymHMmDHSsWNHvi4mkZKSInXr1pWaNWtm+8DvN7KtHTt2yKBBg6RRo0bSunVrmTx5spw7d46HxYZwLpbzvWL98f777/P42NhXX30ld999t75v7rzzTlm4cKGuA2cvXG29A1T4Tp48KUOHDpULFy7w5TWJefPmyYwZM/S4tGrVSqKjo2XmzJkSGRkpH3/8MRekt6F3331XA93YsWOlfv368vvvv8uTTz6pi3jec889ttw1umb58uWyatUqCQgI4GtiEgcPHpS0tDSZOnWqVK1a1bL9Rovf0q21e/duefDBBzXIISTExcXJtGnTZPTo0bJ48WK+/DaCix9Lliy5bjvOC3bt2qVBgmzn66+/lueff14vhOCC+9atW+Xll1/WC1dDhgyxi0PDQOdgIw3fffedvPnmm7beFcpxXD766CPp16+fPP7447oNf2x9fHxkwoQJ+gcYQYKK3pUrV+Tzzz/XX+LDhw/XbQjce/bskS+++IKBzgROnz4tr776qlSqVMnWu0JW9u/fL66urnLHHXdIyZIl+dqYBAJ2nTp1ZPbs2ZZwXbZsWX0PHTt2TAIDA229i8USjgFGfqytXr1aNm7cqBcVQ0JCbLZvJPLNN99IkyZN5LnnntOXw7jwvmDBArsJdLyU5kAOHDggL774ovTs2VPeeustW+8OXYOyyh49elwXDkJDQ/UWf2TJNnAiilLYnL+wS5QooVfmyPbwB7ZNmzb6B5bMY9++ffo7jGHOPBISEmTz5s3Sv3//bCOlKCdH5QHDnHkkJyfLK6+8Ih06dNCLImRbKSkpGrqteXt7y/nz58VeMNA5EH9/fy1Levrpp8Xd3d3Wu0PXeHp66kkprv5Y++WXX/S2WrVqfK1sxMXFRWrVqiXly5fXWvmzZ8/Khx9+KBs2bJABAwbwuJigDAajpSiFIfMFOrx/cDEEIw/NmzeXF154gfOCbXxRFxUhvr6+Wg2C+Yz4mDRpkiQlJdly1ygHVIag+uCZZ57ha2MCDz74oKxfv17L+zFdad26dbJs2TK9GG8vWHLpQHA1gezDX3/9pcHh9ttvlxo1ath6d0hE/vvf/1pKYnHVFM1RyHZOnDghr7/+un7gBJXMAxc/EB5w26dPHxk1apTOA8KcraioKC1T4ly6ohcfH6+3CAnt2rXTssuYmBidQ4dKkEWLFnG+tglcvXpVA91dd90lQUFBtt4dEtE5jBjdxsUPQ9u2be0qcDPQERWxbdu2yciRI6VKlSp6skrmgA6XOBHFiSrmNAwbNkzn0Tk5Odl614odBAX8IW3fvr1069bN1rtDuRyfOXPmaNCuXr26bmvWrJmUK1dOGwrh6jaOHRWt1NRUSwMOzJkDlCqjSmTixInyxx9/6Ekq2dbKlSvlzJkz+jeGzOHRRx/VczP8/sK5AJo+vffeezJu3DiZNWuWXZwHMNARFaEff/xRnnrqKQkODtbOl2iMQuaATn34wIkpaunR6hudrvA5FS20i0awXrFihXZSBKN9ND7H6A9HgGwHr32LFi2u246RbcCxY6AremXKlNFbVH5Yu+222/R27969DHQmCXS4EIJyf7K9iIgIvQiFOY2oOACUkGPOKZql/fbbb9e9p8yIc+iIigha4+MqKeab4IS1QoUKfO1NUKKEzrA512hClzhAy2+yzQkPGjxgNAGjDfjAcUIZJv6NK6ZkO5j7gzWbYmNjr2v0ALxQZRu4UGiU9FkzLopwbr05RlExV4uNUMwj9trvsfDw8GzbsZYzYHkpe8BAR1QEsP4POo9isUqMzHl4ePB1NwGcgGIkbunSpdm2ozQJsOArFb0pU6boMbH+wBVSNK/Bv/v27cvDYkPp6enaqCbnulqoQECjFONEiIpWWFiYrtWI+cDWCyKjPT7wuNgeSvmwXE7OJmlkO6HXOo6jIifnyB3YS3dYllwS3WKolcdcOfyhHThwoJa9WEOZH5s+2EblypWld+/eOuKDNbUwModf6mhYc99997EDqY3/wOZs+oQW+Vyz0Rzvm169emnVgZubm3ZSxPyTuXPn6u84rqllG5jng6YO48eP1zVOceEDTWqmT5+uc1GNygOybaAzwjeZQ506dfT98cYbb0hiYqI0bNhQ3zeYQ4eKkC5duog9YKAjusWw/g9GglAuhpOdnBD2cHJEtvHSSy/pFTiUkOEYYfmPsWPHytChQ3lIiPIZRcX7Bm2+0SAFC7/jfcNGD7aFUj4cD1ykGjFihHh5ecn999+vAY9sD0vjAI4Lmcfbb7+t7xtUU82cOdNy0Wr06NF6sdceOGVaj8sTERERERGR3eAcOiIiIiIiIjvFQEdERERERGSnGOiIiIiIiIjsFAMdERERERGRnWKgIyIiIiIislMMdERERERERHaKgY6IiIiIiMhOMdAREREVAi7rSkREtsBAR0REReqpp56SmjVr5vnx888//+vnwOO89957UlS+/vprefPNNwvt9enYsWO+98ntdatTp460aNFChgwZIjt37hSzKepjQkRUXLjaegeIiKj4KV++vLz//vu5fi04OFjszZw5c6R58+ZF+pz33Xef9OnTx/L51atXJTIyUubOnSuDBw/WYIzXmYiIHBsDHRERFbmSJUtKo0aN+Mr/C5UqVbruNUSoDAwMlEceeUT+97//ycCBA/kaExE5OJZcEhGRaf3yyy/Sq1cvqV+/vrRp00ZeeeUVuXz5crb7bN68Wfr16ycNGzaUbt26yYYNG657nJSUFHnrrbekffv2Uq9ePenevbv8+OOP2e6DMsfXXntNHnroIWnQoIE8++yzun3//v0yZswYadmypdStW1duu+023Y/k5GTL9504cUKWLVumZYXHjx/X7bGxsTJx4kQNWdg3PO7evXuzPWdiYqI8/fTTep9mzZrJ1KlTJSMj41+9Zp6ennrr5ORk2RYXF6fPg58fPxtG91avXm35OvYZ+/7tt9/mW/45aNAgfV0+/PBD6dChgx6X+++//7oSz4IcEyIiKhwcoSMiIptIS0u7bpuLi4sliKxYsUKeeOIJDV/jx4/X0DR9+nSJioqSTz75RO+3Z88enTOGsDVz5kwNJghROZuVjB49WiIiImTs2LESFhYmq1atkgkTJmiZYs+ePS33XbhwoZYrYoSrTJkyGoQwyoWRsDfeeENHFteuXavPX6FCBRk+fLiWjuIWc9geffRR3R4fH69Bp1SpUvL888/r7WeffaaPtXTpUt0HBLdhw4bpzzV58mTx9vaWefPmya5du/QxbgTfb/0aIrQeOHBAXn75ZfHw8JBOnTrp9rNnz2qAc3Nz05/Zx8dHgxteE4Tce++996aO28qVK3X/n3vuOX1tMXfwsccekzVr1ujxK8gxISKiwsNAR0RERQ4hBqNdOT3++OMajhAU3n77bR0Nw631/LqHH35Yfv/9dx0h+uCDD8TPz0/nsJUoUULvg8CC4GLA6NC6des0DN511126DY975coVfex77rlHXF2z/hxWrlxZQ6Rh/fr1Urt2bXn33XelbNmyuq1169byxx9/yKZNmyxBDkHP19fXUgKJ8Hb+/Hn58ssvJSAgQLe1a9dOnx+PhaCDYIiRrY8++ki/Bq1atbphQxTD7Nmz9cMa9qNp06Y60lixYkXdhvCJgIkgZuwLRurwOiLQ4ee/GQiR8+fPt7wely5d0kC6b98+Hf0syDEhIqLCw0BHRERFDs06cMKf27wwOHz4sJw6dUpGjBiRbRQKZYkIEghUCHTbtm2T22+/3RIcoGvXrjpSZNi4caOO5iHEWD8WgtP333+vjUQQ2sC4NbRt21Y/UlNTdWTwyJEjcvDgQQ1IGFHLC54Tj4VQZTyns7OzBjc8J2zdulX3G+HSULp0ad3PLVu23PA17Nu3r34g/KIsFOWaTZo0kXfeeUdHF63LHxs3bmwJcwaMzKEME6+1u7u7FFS1atUsYQ6M4IiADAU5JkREVHgY6IiIqMhhJAnzr/KC0S2YMmWKfuSEUkhjDhpGf6xhtM16Gx4LoSc8PDzX58JjGUEOgSpnWeO0adO0FBNz9/z9/XUOGsoX84PnRPjLbRTSCD/Yd4RC67luUNDOlCjLNF5D7BOaoaBcFOWpmONmPC6eB1/LqVy5cnqblJR0U4EO5aPWEFTBmPtXkGNCRESFh4GOiIhMx2jsMWnSpFyXA/Dy8tJbBCLMEbOG8IZQYcB8MgS1zz//PNfnCgoKynM/EIw+/fRTDZUYZcJjAeak5Qf3w35j//MKtAg4CQkJkp6enm30ygizNwvlmgMGDNDw+dVXX2lTEuO1OnPmzHX3N7ZhP4zwh32xlrMBTUEU5JgQEVHhYZdLIiIyndDQUJ2HhYYaGIUyPlDeh5JCo1skQgzmohnlfoD5ciiRNCBYIZggVFg/FkonZ82alWtzFgPKB1Fi2Lt3b0uYO336tH6vdTdKY5TK+jmjo6MlJCQk23MuX75cm6IgwGHf8dzo5GlAkxaUk/5TmKeGkTeMKhrBEGWq27dv13mL1lD6idFABFqjhBI/mwGv4T9ZoLwgx4SIiAoPAx0REZkOAg/CyeLFi3WJAIScn376SYYOHaphzihlRKdGhDVsR5dFhKVnnnkm2/wtzElDqEEHykWLFmkzEzQieemllzSIoZlJXlDKiM6RGKnDXLSvv/5aO1UieFkHFowoYr9wHyxngIYjCHy4xfIImFOHbpdffPGFhjwj+GB+HrpFYr/Q6GXUqFE6P++fQujE64Ywh+YrgDJMjJphXxAo8Ty4z59//qm3eA0wiod5dtg/dBdFIMO+GEsz3IyCHBMiIio8DHRERGRKffr00dE4LDcwcuRIDWBVqlTR0GHMCUPXywULFlgCILo+ouOiUZIJCCwIZHfffbd2YETQQFBE0EHny/ygKUv//v21XBNLGaC7Y48ePXRdOjRTwfwzQJt+lBnisXfv3q0jiXgONCLBfmP/Mdr16quvarAyYMkDNCdB10vMfUNTGDQ6+TcwmoggumTJEm2WglE4dNtECEY4HjdunJw8eVJfK9zXgGUZ0KUSARPNUnB/rJ13swpyTIiIqPA4ZaIGhYiIiIiIiOwOR+iIiIiIiIjsFAMdERERERGRnWKgIyIiIiIislMMdERERERERHaKgY6IiIiIiMhOMdARERERERHZKQY6IiIiIiIiO8VAR0REREREZKcY6IiIiIiIiOwUAx0REREREZGdYqAjIiIiIiKyUwx0REREREREYp/+H5sWStOkLRYYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running inference on full test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.attention.v_lin.weight, classifier.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, pre_classifier.bias, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.ffn.lin*.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.k_lin.bias, pre_classifier.weight, distilbert.embeddings.word_embeddings.weight, classifier.weight\n",
      "Test: 100%|██████████| 938/938 [00:12<00:00, 76.75it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.86      0.86      3750\n",
      "    Positive       0.86      0.86      0.86      3750\n",
      "\n",
      "    accuracy                           0.86      7500\n",
      "   macro avg       0.86      0.86      0.86      7500\n",
      "weighted avg       0.86      0.86      0.86      7500\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqwAAAJICAYAAACkF7akAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjU1JREFUeJzt3Qd4U9UbBvC3e9BS9t6gbGSUJUNA9ipQoOwlIAiCIqi4UFHxLyAgsqcCMssGAUEBAUFAlixZsvfqoNCV//OdmrTpomnT3Iz39zy1yc06udeSN+d+5xwnnU6nAxERERGRlXLWugFERERERKlhYCUiIiIiq8bASkRERERWjYGViIiIiKwaAysRERERWTUGViIiIiKyagysRERERGTVGFiJiIiIyKoxsBIRERGRVXPVugFEZBtWr16N0aNHJ3ubu7s7smXLhkqVKmHAgAGoXLlysveLjo5GcHAwNm3ahH/++QdPnjxBvnz5ULFiRXTr1g3VqlVLtQ3//vsvli9fjt9//x3Xr1+HLNRXvHhxNG/eHD179oS3t7dJ78ncz2ePZD/8+eefSba7ubmpYy7Hun///ske8zt37qBBgwaIiYnBpEmT0LJlS6PbS5cuneZ2jBs3Dh06dMD777+PNWvWPPf+NWrUwKJFi557v7Q+38GDB5E1a1ZMnToV33//vaE9RGQZDKxEZBIJAvKTUEhICI4fP47t27dj586d+OGHH+Dv7290nxs3buD1119XQbVAgQJo0qQJ/Pz8cPXqVfW4jRs3IigoCB999JEKwIktWbJEhQQJP3Xq1FE/z549w4EDB/Dtt99i/fr1KqDkyJEjTe/D3M9n73r16qUCm15UVJQK/HLsfvvtN8yYMQP169c3eozsQ9m/Xl5eWLVqVZLAOnToUKPr8qVBwmOZMmXQuHFjo9vKli1rdL19+/YoWLBgiu1N7bbkPO/5PDw8THo+IjIzHRFRGgQHB+tefPFF3XfffZfifSZPnqzuExQUZLQ9NDRU17hxY13p0qV106ZN00VFRRndfv/+fV3v3r3VY0eOHJnkedeuXatua9Kkie78+fNGt0VHR+vGjx+vbu/UqVOajqW5n8+e9ejRQ+2Lq1evJnv7+vXrDfsysdatW+tatGihGz58uK5MmTK6a9eupfpa+/fvV8/13nvvpXgfuU3uI/c1B1OfT/7/l/vL3wMRWQ5rWInIbAYPHqxOFR85cgQRERGG7ZMnT8aVK1cwcOBAvPHGG3B1NT65I72Ys2fPRsmSJVWv3K5du4x6b8eOHaued968eeo+Cbm4uGDkyJGoUqUKjh07ht27d6faRnM/n6Nr3bq1Kuu4fPkyLl26ZNh+6tQp1Zv+8ssvo2nTpoiNjVW9rERE6cHASkRmI6fyfXx8DKeMhdSpSt2q1INKYE3tsW+99Za6vHTpUsP2rVu3IjQ0FG3atEHhwoVTfLyEzE8//RSlSpVKtY3pfb5r166pmksJ3IlJXaPcJqfH9eS61EfOnDlTlUfIz/z589X2ESNGJPuaLVq0QPXq1REZGWnY9vPPP6NLly4qQFetWhW9e/fG/v37YS2cnJyQJ08edfnRo0eG7WvXrlW/69Wrp+pYpSxA6qAluBIRmYqBlYjM5u+//8bDhw9Vjaq+3vHo0aMqtErY0ofZlEgNpKenJ/bs2YOnT5+qbfoeTgk+qZFA2LVrV/XaqTH386VGBnPNmTMH7dq1Q926dVXolB5dqfnUvz+906dP4+LFi2rAl76Gd8qUKSrEy+AlqbGUn/Pnz6Nv375Yt24drIEEUAnzIm/evIbBdTKwTgZlSQ+rfFlp2LAhbt26pfYJEZGpOOiKiDJERtZLj6WUAXzxxRdq25AhQwy3608Ty+j755GwKgFRgpuEm2LFiqnfQi6bg7mfLzX37t1Tg5EaNWpk2Na2bVs1Yl4Gp0k41ZOAJ6TnV8ggNnmsDHCTcgnpodQPVJLBaWPGjFGhW+tBYT/++CMePHiA8uXLG8K9fOGQ9965c2dVeqEvHdi8eTNWrlyJV155JcOvK4Ozkpu9QE96pXPnzm2W53vzzTfT1UYiMh8GViIyiUzpIz/J8fX1VafBO3bsaNgmYVZkyZIlTc8vMwcI6amVUCk1p6Y8/nnM/XzPC+CJw5kEUqnplfCWMLDKqf/8+fOrkgAh9Z7yZeDdd981hFWRPXt2NXWYzKYgj+nevTssQWZ+SDhLgNQonzhxQoU86UGV8gk9fe9vq1atDNskXEuPqwR1CbO5cuXKUHueNxWVzDJgamBNCQMrkfYYWIko3dNahYWFYcuWLarXUnoOZTCThLSE9CFHpoxKC/1gLX3PoQQ0mT7p8ePHZjlS5n6+1MhgJBnElZBMnSTzzcrAsvDwcBWcZXCXnFaXICo1oeLkyZPq97Zt21TIS66XWMoIUiJ1tWkldbEJw2hKPakJyXGW2lX5ctKvXz/D4DX5f2LHjh0qLCac/kzKHJo1a6bmvZVwKO81I6Q9NWvWzNBzZObzEZF5MbASkUkkhCTscRo+fLgaTCWj+6WH9ZNPPjG6f5EiRdRvCYnPI7WPMtpcZhHQ10MWKlRIlRvILAOyMEFKZKDS7du3Ux1IlRnPl5rE4V1Pwv2hQ4dULaucKk9cDpCwZ1rKAVKSWuhOqRc8OVIb+7zAKiFU9t3zSK+vfDm5e/dukrlT9aT3OKOBNa3ki0ByvadpCelEZD0YWIkoQ+R0sJziDggIUJPxv/jii6p+MGHAlWAgE/JLCJNQm5J9+/apHlY5ja4Pe3IqecOGDdi7d68Kd6kFKhmgJGFw/PjxKd4vvc+n7/lMbpR7wim80kJKAaTeV8KdnDaXXmrZbwlXfpL9Kr2z0vuqrwM1xdmzZ6EF/ewAst8SljLo/frrr+rLi6wcpS9/yEyyGEFy4T0tIZ2IrAcDKxFlmNQjSg2jDAj6+uuv1Yh4fW+cnAqWQUIyWv67777Dhx9+mOxzyDRYEnyF3F9PBixJ7aOETJlSKrkeT1lNafHixeqyrFiVmvQ+nz40JhdOZbUuU0idroRyCc0yRZX05Pbo0cPoPhJe5ZS//CTuCZaZF2QKLZkuKvGKYlqS/XD48GHVq57SlwYpk5DZD2TwlSUCq5zm1yq8E5H5cForIjILWWpVJoiXQJdwAI6QIFuiRAlVJyhhRU79JyQDrKTMQOo2pdfz1VdfNdwmPbLS0ymBVtaslxkEEpLTz1I7K6fYy5Url2qvaUaeL2fOnCpoyuj9+/fvG02Qn7jGNC2kB1Km+5KAL723CcsB9D2A4quvvlJ1oXpyWfavfAGQYG1NZLCVDBRL/F4Svy9nZ2fDfLhERGnBHlYiMhsZuS6n9WWuzY0bNxrCnpzeX7RokZruavr06SrYSC+s9HTKKVsZgCThpUOHDmq6psRkPlSZi1QeK88pj5VBPjJRvfRQ3rhxQwViuT3xKlrJSc/zyen5wMBANfl/p06d1AAimc5JTudLD6gEXFNI76ickj5z5owqm5AZAhKqVasWevbsqfablA1Ij6z0VkvP6s2bN1XZhbUNEpI6Zn0YT4m8z9q1a6veZbl/emc5eN60VkJqqz08PJAZpLY4pZkF5D0lnAGCiDKOgZWIzEYGSr399tuqh1J6BqVeVD9NlZQNSI2rjHqXQTcSUqVnVUaaSxiTMoCEo8oTk8Fdcj95DplOSWogpTdPgmW3bt1UuEtpkJO5nk9WqJK6TKnTlCAp0259/PHHKnibGlglfEqoWbFiRYo9kvIFoGLFimrlLwl3EpplPlvpjdb3wFoLGcgmA+YkvD9vjlv5YiKBVf4/yEhgfR4ZWJVZgVXmF064FG1CCc8QEJF5OOnkX2giIiIiIivFGlYiIiIismoMrERERERk1RhYiYiIiMiqMbASERERkVVjYCUiIiIiq8bASkRERERWzWHnYZX1wGW1HVlxRb9GOBERERFZhsysKnlMFmiRPJYahw2sElZlsnAiIiIi0o4skCKLqaTGYQOrPsnLTpLVYyzxLSIkJEQtxcgeXdvCY2e7eOxsF4+d7eKxs106C2eVmJgY1Xn4vN5Vhw6s+gMhYdVSgVUOiLwWA6tt4bGzXTx2tovHznbx2NkunUZZJS2vxUFXRERERGTVGFiJiIiIyKoxsBIRERGRVWNgJSIiIiKrxsBKRERERFaNgZWIiIiIrBoDKxERERFZNQZWIiIiIrJqDKxEREREZNUYWImIiIjIqjGwEhEREZFVY2AlIiIiIqvGwEpEREREVo2BlYiIiIismlUF1lu3bsHf3x8HDhx47n03btyIVq1aoVKlSmjRogXWrFljkTYSERERkYMG1ps3b6Jfv34IDQ197n23bt2KkSNHok6dOpg2bRpq1KiB999/H5s2bbJIW4mIiIjIclyhsdjYWKxduxb/+9//0vyYb7/9Fs2bN8cHH3ygrterVw+PHz/GlClTVK8rEREREdkPzXtYz549izFjxqBdu3b45ptvnnv/a9eu4d9//0WTJk2Mtjdr1gyXL19WtxERERGR/dC8hzV//vz45ZdfkC9fvjTVrl64cEH9LlasmNH2okWLqt+XLl1KchsRERE5MJ0OiAwx7TFR4UDE/ec8byzw+CLg7AazuLQp7jnd/aCFkHAd3P1yA/6DAQ9fWBPNA2u2bNlMun9YWJj67ePjY7Q9S5YsRrenlU6nUz+ZTf86lngtMi8eO9vFY2e7eOzMTMLXszQEttsHgeincZfvHAE8swNwMr7PjT8A79yphjTPyEjA3R1JPvEubgByVQSe3IXT7YPQ5aqUenvCb8Ip4i50HhkIcNERcIqJTP/jHUBMrBM+3tIIS/6qiIPDP4encyRQ68NMf11TMpHmgTU9Na+pcXY2rcohJCTE5Mek96A8efJEXXZySvTHT1aNx8528djZLs2PnXyQ6mJMfpiEK6eYp3AKvwGnZB7vHHYFLveOQeeZAzoTqvKcnz2A28XV0Ln5ItansGG7670jQHQ4Yn3jziy6hFyETgKmc/zHu1NsFCzNM7UbQ68aLjrdO56m53N69jjjjaJkPY7wQPefArHp9IvqeqdFnbCuRV7g8WPNM51NB1Zf37gu6vDw8DT1vD5P1qxZ4eLiAkt9i/Dz82NgtTE8draLx852mfXYPb4E3DsRd/ne33Fh7u5xwKdg0vtG3AVO/QgnOS1rjZ7eg0vopSSbJajqOUm/pgYhNb100lObIGAnvYNOfQnQ+ZUEXNJ/6t3pwRno8lYHPHOktWXArQPAC4GAUypfLiJD407j535Ob3FaPboIlOkCuKQa+83i7IUnaNf/hPotJA617NUavv7tLNKZFxMTY7+BtXjx4uq3DLAqV66cYbtcFyVLljTp+eQfQkt9e9e/FntYbQ+Pne3isbMhUi8oH/7hN1Xscg0Lg9OTLHB6fB5w8Yi/X2QY8Ogc4Jkz7vqNfUDEPcAjmRIzOQXtKPT74+n9uP2Vs3z8bTHPgPsngVLtU38OCbqXfwHqjfvvuR4CuV+SP6RE94sBspVI8cuGdCJJB1Kyn3duvvGlBl450/yZaI5Pap7fjLd58zl07RqMkJBn6nqOHF5YvjwQ/v45VVi1RFYx5TVsLrDK4KpChQqpuVhlwQC9bdu2qcFWchsREZmZBBQhPUkJTulCagPlesIesrBrQOg14Mnt+N6sfWOA/LWAm/sB38LGAVQ8Om90VT7GrGLIR/YXAe88poVuqRfNXzNuHxRukPQ+sr9yVfivR86EUBAbHbfvspU0DpBOLoBr5vfGpZlOhxjPx9I9njToklUYP34v3ntvu6p8ERUr5sHatV1QvHg2NU2oNbL6wCrf0s6fP48iRYogR464f/iGDBmC0aNHqwFbjRo1wo4dO/Dzzz9j0qRJWjeXiMh2SLg6uzxukE3iwCPB9PqeuIE1pxeb5/UkrIqEgdeS/EcCbj5AVBiQoywgA3lk8FASTkDeqoCrNwMX2SWdlGj/F1YDA8ti4cJ28PFxt+qB4VYfWE+ePIlevXph3Lhx6NChg9omvyMjIzF//nwEBwejcOHCauGBli1bat1cIqLM9eQe8OwRcPOP+Bo36Xm7exTwyg38+zNw5VfA3Tfu9Lp71uTr7+Q5rOUUtp6cypb2eueGrmA9RMIT7u7ucYOGpL35qsffV3oxPbIDWfLFXZdgLbcnVwsp+8KaeiCJNDZq1Ms4fvw2SpfOiQ8/rA9nZ+vvCXfSWXOczuRC36NHj6Jy5coWG3Ql3ewcdGV7eOxsl1UeO9W1oR/QowPCbgDn1wIhl+N6/PT3+XteXBCVes7sLwAPz8EqAmaOMnHTHRWsExeQ9YOacpQGsuQ3LgvIXjqu7RIY1eNzxJ0Kl3KA1AbZWOuxozThsbM+t26FIV8+nyTHKfHflqWPnSlZzOp7WImIbKbGU06dH50WN8pXApzUd94+BPgUiDvNHHY9fc+d0bAq4VBGWCcW8zQuKBdvCZRsA7jFzWedJFz7FY87Ra4PnkRkE3Q6HWbOPIQRI7Zhw4auaNw4fqCcrX0RZGAlIjKl5vPCBuC3YXE1kHI6Wkanyyj1xBJuk17UjJLeyacP4gcCybyUheoB+WvHbZM5P+XUufRqShAt2sS0wUJEZFciI2MwdOhmzJnzl7reufNKHD06CEWKaLOKVkYxsBKR49KfjpeBOOLuMeDOX0DWonGnvWWuTjmlLT2NiUax49afpr2WjOSWU+YSKmX0fIE6cdvleWU+UKlBbbHov+l+/iMjwv1KAG7eGX2nRORAbt8OQ2DgCuzdGz/A8bXXqqBAAds9S8LASkSOQUbCP/4XeHAa+O0tIPRK5pyOl2D66vdAuZ6Aq5d+I0ebE5FFHDp0A+3bL8e1a3FL8Xp4uGDu3Lbo0cNMCxtohIGViOxTVIQ6Le+7YxicHp7K+PNJz6dMoq7XZE5c3ae+DswrV+qr4RARZbLFi49jwIANePo0Wl0vWNBXza/q7y919LaNgZWI7EPUE2BO0bia0v9IlEzTHCAyoX25XnGXI0OAXBXjygJksJKUBDCIEpEVi4mJxfvvb8eECX8Ytr38cmEEB3dOMjuArWJgJSLbIvWkMo3ShXXAvk/jJn5/dCHtj/cpFDdYSaZnqvkh4Jz509oREWWmf/99hJkzDxuu9+9fBd9/3xIeHvYT8+znnRCRfZK6U5kOalt/4MGZpLdLj2gqovPUgEu+KnCStdETDmgiIrITJUvmwKJF7dVMAJMnN8fgwf42N23V8zCwEpF19qJ+m856UFnDPWg34BK3zGDYf5Ngc01zIrInukQT/7drVwYXLgxD4cK2OW3V8zCwEpF2ZCUnGb1/dDpw7zhweknaHyu9pbKMZ4PJQN5qQNbCmdlSIiKrEBurwxdf7MbNm6GYMaO10W32GlYFAysRWcazECDmGXB9L7C+vemPf7ETUOgV4KVBrDslIocUFhaJ3r3XYvXq0+r6Sy/lw6BB/nAEDKxElLFT96HX5Dt//EpQUlN652hcven9U3ET44ffTN/z56sBdNvP0/lE5PAuXnyIdu2W4cSJO2pfSDWABFhHwcBKRKb5ZxVwcSNw8gfz7TnfIsCTW0DjWUCuCkA+x+gxICJKix07LqJz51V48CBCXffz88BPPwWiZcsXHGYHMrAS0fPJhPm/DgNOL8743ircELh9CGi1FCjRinufiCiVgVVTp/6JESO2IiZGp7aVLp0T69Z1QenSuRxqvzGwElHKHl0E5pV8/h7KXxvIWiSuREAGTxVrFlezKj2lMt9plgJAzjLc00REaSSrVQ0evAkLFx41bGvV6gUsWdIBfn6eDrcfGViJKN7TR8Ch8cCBr56/VxpMAkoHAT75uQeJiMzsvfd+MQqro0fXxdixDeHi4phLQDOwEjmqqzuBy9uBA18COcsD908+/zE+BYAefwFZ8lqihUREDuvDD+tj7dqzuHs3HAsWBCAoqAIcGQMrkSOJiQR2DAVOzDHe/rywWnsM8PKnmdo0IiKKlydPFlWrKipXzufwu4aBlche6WKB63uAvxcCJxeY9tjcLwGNZwAFamdW64iI6D/R0bEYN+53vPFGdeTM6W3YLwyq8RhYiexFVETc3KfHZwLHZ6f9cXW/ihu5X6BWZraOiIiScf/+EwQFrcKOHZewc+dlbN3aA66ujlmnmhoGViJbFXYTWBcA3Dpo+mNlrtOufwDuPpnRMiIiSoMTJ24jIGAZLl16pK7//vtlHDhwDXXqFOH+S4SBlchWPLkL/NwT+HeraY/LUxXIVR6o8yXgW4irRhERWYHg4FNqmdXw8ChDzerq1Z0ZVlPAwEpkzWQu04VlgbAbaX+Muy9QvCXwykTAt2Bmto6IiEwUG6vDp5/uxNixuw3bqlXLjzVrglC4sB/3ZwoYWImsRWQo8Pto4Oi0uOuu3kD0k+c/7sVOQNO5gEfWTG8iERGlX0jIM/TsuQbr1581bOvRoxJmz24NLy837tpUMLASaSn6GXD0e2DXyGRuSyGsymT99ccDWQtnevOIiMg8Hj16ipdfnofTp++p687OTvjmm8YYMaI2nJycuJufg4GVSAtR4cDSusDd+FVMkpUlPxB+M27p0657WX9KRGSj/Pw8ULNmIRVYs2XzxLJlgWjWrJTWzbIZDKxElrR9CHBseur3KRkANJoCZC1qqVYREVEmk17UGTNaqRrWjz+uj1KlcnCfm4CBlSize1IvbQEOfwvc2Jfy/SScNpkNFGvK40FEZAciIqJw6tRdVKtWwLDN09MVP/zQTtN22SoGVqLMcGhi8nWpiRVtCrRdFTeyn4iI7MK1ayFo124Zzp17gAMH+qNMmVxaN8nmMbASmYNOB/yzCtjcDYiNfv79B17jlFNERHZo794rCAxcgdu3w9X17t1X49ChARxYlUEMrEQZ9cdYYN8nz69LzV8LqPYW4OrJfU5EZIfmzDmMIUM2IyoqVl0vViwbFiwIYFg1AwZWooxMSbWwHPD4Ysr36X8R8CvOfUxEZMeiomLw1ltbMH36IcO2Ro2KY/nyjsiVy1vTttkLBlYiUz25B8zInfLtrVcALwYCTs7ct0REdu7u3XB07LgSu3dfNmwbPrwmJkxoCldXfg6YCwMrkSluHQKWVE/+tj6ngJxluT+JiBzE0aO3EBCwDFeuPFbX3d1dMHNmK/TtW0XrptkdBlai53n6EFm2doHTtV+Sv71gPaDDJo70JyJyMLduheHq1biwmj+/D1avDkKtWoW0bpZdYmAlSs3vH8Dpz3FIdoXn7C8A/f7h/iMiclDNm5fC1183xurVp1VYLVCAUxRmFgZWouTERAGT3VPeN21WAi925L4jInIg4eGR8PZ2Mxr1P2rUy3jrrVqqHIAyD6uBiRLOpbqpGzDRKdmwqstSABh0C3hHx7BKRORgzp69h2rVZmPKlANG2yW8MqxmPvawkmO7sAG4thu49Wfc7xQ87vYPsuYrJf8yWbR5RESkvc2bz6Fr12CEhDzDO+9sQ4UKedC4cQmtm+VQGFjJMV35DVjZ6Pn3c/eF7o0H0IWGWaJVRERkRXQ6Hf73v7344IMd6iScKF8+N0qUyK510xwOAys5nqu7nh9Wh4UBblniLuv/lSIiIofx5EkU+vVbh+XLTxq2BQaWxcKF7eDjk8oYB8oUDKzkOFIbSPXKBCBbKaBAHcA7l6VbRkREVuTy5Udo3345jhy5Zdj2+ecN8OGH9eHszNIwLTCwkv27+SfwU83kbyveMm4OVSIiIkCtWBUYuAL37j1R+0N6Uxcvbo+AgDLcPxpiYCX7JiP+U9LyJ6BsV0u2hoiIrFh0dCxef32jIayWLJkd69Z1QfnyebRumsPjtFbkeGG1bHfg7WiGVSIiMuLq6oyVKzshSxY3NG1aEn/+OYBh1Uqwh5XshwyOCrkM/NwLuP570ttbLQNKd+bUVERElCKZsmrfvtdQrlxuFWDJOjCwkn2IuA9MT2Ww1NDHgEdWS7aIiIis3KFDNzBhwj78+GN7o8n/K1XKq2m7KCkGVrIPqYXV4RGAq6clW0NERFZu8eLj6N9/PZ49i0G2bJ6YObO11k2iVDCwkm27eQD4qVbS7dlKAl33Ad4slCciongxMbF4//3tmDDhD8O2EyfuqHlXvb3duKusFAMr2aaYSGCyR/K3yYAq5/hTO0REROLhwwh06RKMbdsuGHbIgAFVMXVqC3h4MBJZMx4dsj3L6gHX9yR/24gYwIlF8kREZOzUqbsICFiG8+cfqOsyoOq775pj0CB/ODlxMQBrx8BKtmP7EODY9ORva78RKNHK0i0iIiIbsG7dGfTosQZhYZHqeq5c3li1qhNeeaWY1k2jNGJgJev29BFw5Dtg35jkby/cEOj8q6VbRURENuLnn8+hXbvlhuuVK+fD2rVBKFo0m6btItMwsJL1evAPsKB0yrcPfwq4plDHSkREBODVV0ugfv2iasnVoKDymD8/gIOrbBADK1nnAgDfplKH+sZ9wCuHJVtEREQ2SuZXldWrli//G0OH1mC9qo1iYCXrEn4LmJk/+dv6nAZylrF0i4iIyIbs2HERefJkQcWK8ZP/y/U336ypabsoYxhYyTpEPwWmeCV/W9tg4IUOlm4RERHZEJ1Oh6lT/8SIEVtRpIgfDh4cgJw5vbVuFpkJ5/8h7Z1eknJYfesZwyoREaXq6dNo9Ou3HsOHb0FMjA6XLj1S4ZXsB3tYSVsR94HNPZJur/4eUP9rLVpEREQ25MaNUHTosBwHDlw3bBs9ui4+/ri+pu0i82JgJe0sqgbc+ct4W/GWQIdNWrWIiIhsyIED19C+/XLcvBmmrnt5uWLBggAEBVXQumlkZgyspI3NPZOG1fJ9gebzeUSIiOi5Fi48itdf34jIyBh1XepW163rouZZJfvDwEqWt+NN4PRi421V3gQafcejQUREzzVy5DZMnPiH4brMsyorV+XOnYV7z04xsJJlXd4OHP3eeFv/S4Afl8cjIqK0KVw4q+HykCHVMWlSM7i5uXD32TEGVrKMmEhg16i4ZVYTenUawyoREZlk2LCaOHXqLvz9C2DAgGrcew6AgZUy34WNwNo2Sbe3XAKU7cYjQEREqTp37j5eeCGn4bqTkxNmzUrmc4XsFudhpcyXXFgt8DLDKhERpSo2VocxY35DmTLTsGnTP9xbDow9rJS5dLHG1918gD6ngKyFueeJiChFoaHP0LPnGqxbd1Zd79ZtNU6efAOFCsXXr5LjYGClzBETBWwfDPw9z3j7sFDucSIiStX58w8QELBM1akKZ2cntRBAwYK+3HMOioGVzC/iATA9vtbIIK8/9zYREaVq69bz6NIlGI8ePVXXs2XzxLJlgWjWrBT3nANjYCXzun8aWFgu+du67efeJiKiZOl0OjW36nvvbVe1q6JcudxqMYBSpXJwrzk4BlYyn9iY5MNq0G6gYF0Z1sm9TURESURERGHAgA1YsuSEYVtAQGksWtQevr4e3GPEwEqZ2LOauxLQ8yiDKhERper69VBs2BA/C8Ann9THmDENVO0qkeC0VpRx4beT71ntdYxhlYiInktO+S9dGoisWT0QHNwZn33WkGGVjLAkgDLm6k5gRcNE/1d5A28+5p4lIqIUxcTEwsUlvt+sZcsXcOnScOTI4cW9Rkmwh5UyJnFYFcPDAWd+FyIioqSiomIwZMgmvPbaejXQKiGGVUoJUwWl38REtUUvdgLarOAeJSKiZN29G46OHVdi9+7L6nrlyvnw1lu1uLfouRhYKX3Orky6jWGViIhScPToLbUYwJUrcSVj7u4uao5VIpspCdizZw8CAwPx0ksvoVGjRpg3b16S0wQJRUdHY/bs2WjatCkqV66MgIAAbN682aJtdngbOxvvgiEPHH6XEBFR8pYv/xsvvzzPEFbz5/fBrl190KdPZe4yso3AevToUQwaNAglSpTA1KlT0aZNG4wfPx5z5sxJ8TFyv0mTJqFt27aYMWMGqlWrhrfffhtbt261aNsdetnVhDr9Cnhm16o1RERkxQOrPvhgh1q5KiIiWm2rWbMgDh0aiFq1CmndPLIhmpcESPgsW7asCqmifv36qgd15syZ6NWrFzw9k54uCA4ORuvWrTF06FB1vXbt2jh58iQWL16MZs2aWfw9ONziAJPdjbcVfkWr1hARkZV6/Pgpundfg82bzxm2SY/qjBmt4OmpefwgG6NpD2tkZCQOHDiAJk2aGG2X0BkeHo7Dhw+n+DgfHx+jbdmyZcOjR48ytb0EYFKif2Ty1wKcNO+oJyIiK/Puu9sNYdXFxQlTpjTH/PltGVYpXTRNGlevXkVUVBSKFStmtL1o0aLq96VLl5J9nPS8rl27Frt370ZYWBjWr1+P33//XdWyUiZ5+ijprACi617uciIiSmLcuFdRokR2NVXV1q09MGxYTThxiW5KJ0375ENDQ9XvxL2lWbJkUb8ljCanT58+qvZ1wIABhm0yaKt///4mt0EGd6U2wMtc9K9jidfKDE7Tktao6t6OkVvkzcGe2fqxc2Q8draLx872j1327J5Yv76L6lGV4Mp/Q62fzsKfd6a8jqaBNTY2NtXbnZ2dky0H6N69O+7evYvPPvtMDdY6cuSIGnzl7e2Njz76yKQ2hISEJPs6mXFQnjx5oi7b3DdMXSyyJdr0uMvf0IWEwBHY9LFzcDx2tovHzrY8eRKFzz/fh3feqY5cubwM/2YWLBg35uHxY65+aAt0Fv68e14OtJrA6uvrq35LvWpC+p7VxD2vQmYCOHPmDBYsWICXX35ZbatRo4a67+eff47OnTvjxRdfTHMbsmbNChcXF1jqW4Sfn5/thZ4/vza6qhsRi6xwHDZ97Bwcj53t4rGzHZcvP0KHDqtx5MgtnDr1ANu29VDb+W+m7dFZ+PMuJkbO1NpAYC1SpIgKi5cvx614oXflyhX1u2TJkkkec+PGDfW7atWqRturV6+ufp8/f96kwCoHxFIhRP9aNhV6pngD0RFGm2yq/Y587EjhsbNdPHbWb9euf9XKVffuxfXKSWg9efIuSpb05r+ZNsrJgp93pryGpoOuPDw84O/vj19++cWojkF6UaX3tVKlSkkeIyUA4tChQ0bb//rrL/W7UCHO62Y2V35LElbR86j5np+IiGySfGbPmHEQjRsvMoTVkiWzY//+11C1an6tm0d2SPOJ0AYPHoy+ffti+PDhauCU1KPKSlfvvPMOvLy8VHmA9JpKb2yOHDnUSliyItaoUaPw5ptvqgB7/PhxVcMqtyUXcikdbv8FrGxkvK3FIiDPS9ydREQOLDIyBkOHbsacOXEdRaJp05JYujRQzQjAwVWUGTSfQFMm/ZfFA2QKqyFDhmDDhg149913DTMAyIIAQUFB2Llzp7ouJQTz589Hy5YtMX36dHU/meJKgu+UKVM0fjd2IjIUWFzNeFvgVqBcXF0SERE5plu3wtCw4Q9GYXXkyNrYtKmbCqtEmcVJ56BfhaTQV6bGqly5ssUGXckoSZsoQk8832r53kDzhXBUNnXsyAiPne3isbM+cuq/cuWZuH49bkpKDw8XzJ3bFj16GJ/Z5LGzXToLf96ZksU072ElK3NutfH1ok0dOqwSEVGcXLm80aZN3KDmggV9sWdPvyRhlchua1jJisREAusDjbd13KpVa4iIyMpMmdICHh6ueP/9usiXL+nUk0SZhT2sFG9zd+O9EbiFe4eIyEE9fBiB3buNp510d3fB5MnNGVbJ4hhYKd4/q4z3RtEm3DtERA7o1Km7qFFjLlq2XIITJ25r3RwiBlb6z+mlxrtiRAzgxO8zRESOZt26M6hZcy7On3+A8PAoDBy4kVNVkeaYSCjO5m7Ge4JhlYjIocTG6jB27C60a7ccYWGRalvlyvmwbFkgZ0ghzXHQFSXV6VfuFSIiByIBtU+ftQgOPm3YFhRUHvPnB8Db203TthEJBlZKqkhD7hUiIgdx8eJDtGu3DCdO3FHXZfrNceNexbvv1mHPKlkNBlYC7p7gXiAickC//XYJHTuuxIMHEeq6n58HfvopEC1bvqB104iMMLAS8CMnfiYictS61cePn6rLpUvnxLp1XVC6dC6tm0WUBAOro7u+1/j6KxO1agkREVnYq6+WwMSJTbFt20X89FMH+Pl58hiQVeIsAY5uWV3j61WHa9USIiLKZPfvP0kyRdWwYTWxYUNXhlWyagysFK/DZsDZhXuEiMgO7d9/DRUrzsA33xifWXNycoKzs5Nm7SJKCwZWile0KfcGEZEdWrDgCF55ZSFu3gzD6NE7sHXrea2bRGQS1rA6spi4iaEN2LtKRGRXoqNjMXLkNkyZcsCwrV69oqhSJb+m7SIyFQOrI/t3q9YtICKiTKxX7dx5FX799ZJh2xtv+GPy5OZwc2P5F9kWBlZH9uxR/GXPHFq2hIiIzOj48dtqMYBLl+L+nXdzc8a0aS0xYEA17meySQysjuz6nvjLNd7XsiVERGQmwcGn0KvXWjx5EqWu582bBcHBnVGnThHuY7JZDKyOKjYGOD47/roz14omIrJ1kZEx+Oij3wxhtVq1/FizJgiFC/tp3TSiDOEsAY5qUqLvKqWDtGoJERGZibu7C9auDULWrB7o0aMSfv+9L8Mq2QX2sDqiicnMt+fDEaNERPZAllb966+BKFEiu5pjlcgesIfV0Zz8Mem2EbFatISIiDJo27YLaNFiCZ4+jTbaXrJkDoZVsisMrI5mS2/j629FyjInWrWGiIjSQZZXnThxnwqrW7acx+DBm5IsuUpkT1gS4EgWVjC+HrgNcOFgKyIiWxIREYWBAzdi8eLjRnOuyoArDw9+rJN94v/ZjkK+ed8/abytWBOtWkNEROlw9epjtG+/HIcP3zRs+/jj+vj00wZwdubZMrJfDKyOIvSa8fUhD7VqCRERpcPevVfQocMK3LkTrq5nyeKGH35oh8DActyfZPcYWB3FiQRzrjo5A57ZtGwNERGZYM6cwxgyZDOiouIGyRYrlg3r1nVBpUp5uR/JITCwOoqIe/GXizXTsiVERGTiylVSs6rXqFFxLF/eEblyeXM/ksPgLAGOIDYaODYz/nql17VsDRERmSAgoAxefbW4ujx8eE1s3dqDYZUcDntYHWEJ1kmJZgLw5ikkIiJb4erqrHpUf/nlIrp0STTbC5GDYA+rvfvtraTb8tfQoiVERJQGK1acxF9/xc8CIHLm9GZYJYfGwGrPIh4AR79PuqqVDLoiIiKrEhMTiw8+2IGgoFVo126ZYTYAImJgtW/Tcxpf73+Rq1oREVmhx4+fom3bZRg3bo+6fvVqCH744ajWzSKyGqxhtVfht5Nu84sr2iciIutx9uw9BAQsw9mz99V1FxcnfPttM7z5Jsu3iPQYWO3VwkQTSb/DNaaJiKzN5s3n0LVrMEJCnqnrOXJ4YcWKjnj11RJaN43IqjCw2qunD+IvV39Py5YQEVEiOp0O33yzF6NH71ArZ4uKFfNg7douKFEiO/cXUSIMrI6g3ldat4CIiBKE1T591uHHH48Z9klgYFksXNgOPj7u3E9EyeBwcXt0J/4fQYWzAhARWQ0nJye8/HIhw/XPP2+AFSs6MawSpYI9rPZoUWWtW0BERKl4/XV/nDv3APXqFVErWRFR6hhY7U10XOG+QZNZWrWEiIj+KwE4fPgm/P0LGO2PCROacv8QpRFLAuzNjX3G1ysN1KolREQOLzIyBq+/vhHVq8/BmjWnHX5/EKUXA6u99a6ubBR/PRfXnCYi0sqtW2Fo2PAHzJnzl7req9da3L4dxgNClA4sCbCnsDrF03hbtXe0ag0RkUM7dOiGWl71+vVQdd3DwwUzZrRC3rw+WjeNyCYxsNqL7/2SbqvQR4uWEBE5tMWLj2PAgA14+jRaXS9UKCvWrAlKUsNKRGnHwGoPZNbpmESDrbiyFRGRRcXExOL997djwoQ/DNtefrkwgoM7I18+9qwSZQQDqz34dZjxdYZVIiKLevgwAl26BGPbtguGbQMGVMXUqS3g4cGPWqKM4l+RPTj6ffxlZzctW0JE5JAePnyq6laFq6szvvuuOQYN8leLBBBRxnGWAFsXE2V8fch9rVpCROSwSpTIjhUrOiJ/fh/s2NELgwdXZ1glMiP2sNq6kMvG1919tWoJEZHDiI3VISoqxuh0/6uvlsD588Pg7c0zXUTmxh5WWxdxN/5yqfZatoSIyCGEhUWic+eV6Nt3nVrFKiGGVaLMwR5WW/fXd/GXQ/7VsiVERHbv4sWHan7VEyfuqOsvvZQX771XV+tmEdk9BlZbd3ZZ/OUCdbRsCRGRXdux4yI6d16FBw8i1HU/Pw9UrJhX62YROQQGVlsWGzcptUGtD7VqCRGR3ZLT/lOn/okRI7YiJiauBKB06ZxYt64LSpfOpXXziBwCA6stm+RmPNgqSz4tW0NEZHdktarBgzdh4cKjhm2tWr2AJUs6wM8v0XLYRJRpGFjtpXe1UYK5WImIKMNu3AhFhw7LceDAdcO20aPrYuzYhnBx4ZhlIktiYLVVt/8yvl6+l1YtISKySx9++KshrHp5uWLBggAEBVXQullEDomB1VY9Oh9/uXBDLVtCRGSXJk1qhn37rqqygLVrg1ClSn6tm0TksBhYbdGzEGBz9/jrld/QsjVERHYpWzZPbNrUTc0GkDt3Fq2bQ+TQWIRji9YnWiCgUAOtWkJEZBfu33+Cbt2CVd1qQqVK5WBYJbIC7GG1RaHxAwBQqh3gzWlViIjS68SJ2wgIWIZLlx6phQF27uwDT09+PBJZE/aw2pqIB8DDs/HXA9Zo2RoiIpsWHHwKtWvPU2FVyO9Llx5q3SwiSiTdXyEvXLiAvXv34s6dO+jZsyeuXr2KMmXKwMfHJ71PSWnxy4D4y6W7cJ8REaVDbKwOn366E2PH7jZsq1YtP9asCULhwn7cp0S2HlhjY2PxySefIDg4WK3+4eTkhBYtWmD69Om4cuUKFi9ejHz5OIF9pjm/zrgcgIiITBIS8gw9e67B+vXxZ6t69KiE2bNbw8srwYIsRGS7JQESTDds2IAvvvhC9bBKaBWjRo1SYXbSpEmZ0U7S08XE74tSAdwvREQmOHfuPmrVmmsIq87OTpgwoQl+/LEdwyqRPfWwSs/qsGHDEBgYiJiY+PBUtmxZtX3ChAnmbiPpRYUb7wtXLgtIRJRWN2+GokaNuXj06Klh2qrlyzuiadOS3IlE9tbDeu/ePRVOk5M3b16EhISYo12UnGvxtVZERGSa/Pl90bv3S+pyuXK5cfDgAIZVInvtYS1atCh27dqFl19+Ocltf/75p7qdMknYjfjLtT7ibiYiMtGECU2RI4cX3n67Fnx9Pbj/iOw1sPbu3VsNuoqKikLDhg3VoKvLly/jwIEDmD9/Pt5///3MaSkBlzbH74U8VblHiIhSce1aiJpjtUWLFwzbXF2d8cknr3C/Edl7YO3UqRMePHiAGTNmYOnSpWrQ1YgRI+Dm5ob+/fuja9eumdNSAu4ei98Lbt7cI0REKdi79woCA1eoGQH27OmHqlXzc18ROdo8rK+//jq6d++OI0eO4NGjR8iaNSteeuklZMuWzfwtpHiPLsRfLlife4aIKBlz5hzGkCGbERUVq66PGLFVrV5FRA406Gr06NFqkQBZIKBevXpo06YNXnnlFRVWL168iEGDBmVOSx1dTKTxdRd3rVpCRGSVoqJiMGTIJgwcuNEQVhs1Ko7g4M5aN42ILNHDeuNG/GCftWvXonHjxnBxcUlyv927d2Pfvn0ZbRMlJ/yW8XXnpPufiMhR3b0bjo4dV2L37suGbcOH11SDrKRulYgcILB+9tlnKozqDR06NNn7ST1rnTp1zNc6ihd+M/5y4QbcM0RE/zl69BYCApbhypXH6rq7uwtmzWqNPn0qcx8ROVJg/fzzz1XPqQTSDz74AIMHD0aRIkWM7uPs7KxqWWvWrJlZbXVsZ5bGX85eWsuWEBFZjTVrTqN799WIiIhW1/Pn98Hq1UGoVauQ1k0jIksHVlkQoH379uqyTGMlNas5cuQwZzvoeU79GH/ZzYf7i4gIQK5c3oZ61Zo1C6qwWqCAL/cNkaPPEiDB9dmzZzh+/DgiIyNVr6uIjY1FREQEDh06hJEjR2ZGWx2bU4JDVeNdLVtCRGQ16tUriqlTW+DAgeuYMaMVPD3TNfkNEVk5k/+yZYGA4cOH4/HjuFqhxLJkycLAmhki7sZf9s6TKS9BRGTtpE61UKGscHZ2MmwbNMgfr79eTZ0BJCL7ZPLQyUmTJiF79uz47rvv1GwBTZs2xcyZM9GtWzf1j8WcOXNMbsSePXsQGBio5nJt1KgR5s2bZ+i5TcnOnTvRsWNHVKpUCfXr18cXX3yBJ0+ewC49/lfrFhARaW7z5nOoWHEGvvgifhCwHsMqkX0zObCePXtWzRLQpEkTtTTrzZs3VU3rxx9/rAKkrIBliqNHj6q5W0uUKIGpU6eqeV3Hjx+favD99ddf1cCvF154AbNmzcLAgQOxevVq1Qa7dOeI1i0gItKMdGB8/fUetG79k1q5asyYndiy5TyPCJEDMbkkQGpVZRCWKFq0KM6dO2e4rVmzZnjvvfdMej4JqWXLllUhVUhvaXR0tOq17dWrFzw9PZM8Zty4ceq15LeoXbs2YmJisGjRIlVH6+XlBbuyvkP85UoDtWwJEZFFPXkShddeW4/ly08atgUGlkXdusYz1RCRfTO5h1Wms5JeVlG8eHEVEGWFKyFBMzw8PM3PJYO2pCZWemsTkjAqz3P48OEkjzl16hSuXLmCHj16GG3v3bs3tm/fbn9hVfgkmJ4lH6cNIyLHcOVKCOrWXWAUVj//vAFWrOgEHx+u9kfkSEwOrHLKfsKECVi8eLGa2qpChQoYO3asOk0/bdo0lCpVKs3PJUu8RkVFoVixYkbbpedWXLp0KcljTp8+rX57eHjg9ddfVzWsNWrUwJdffqkCsF0KuxZ/uWI/LVtCRGQRu3b9i0aNlqlFAYQE1LVrg/Dxx68YDbgiIsdgcklA//798fDhQxw7dkz1co4ZMwYDBgzAG2+8AR8fH5NqWENDQ9VveVzimQZEWFhYksc8ePBA/ZY62tatW6Nv3744ceKEKi2Q2yZOnGhybdTzBniZg/51TH6to9Oh/6dZJz2tFmgrmenYkeZ47GzzmM2YcQhvvbUV0dFx86uWLJldhdXy5fPw79AG8O/Oduks/HlnyuuYHFhlRauEdaoVK1ZUp+KlLEAGTiUOn8+rh33eayUmPbJCyghGjRqlLteqVUu9aQmrEmSlVCGtQkJCkn0dc5P26WcxMGU0q8+ppYaDFOvkgtAUphMj6zt2pD0eO9vz9Gk0vv/+T0NYbdiwCObNa4Hs2T1SnE6RrAv/7myXzsKfd8/LgQmZZYZlCalyal5mDPjwww8xZcqUND3O1zduNZLEda/6ntXkwq++97VBgwZG2+vVq6cCq5QMmBJYZTlZFxcXWOpbhJ+fn2n/E7jH1+Q6d/kdfr5+mdE8yoxjR5rjsbM9fn7Ahg1dUbPmPHTrVhYTJ7aAm1vm/xtN5sO/O9uls/DnnQyYN2tglSecPHmymjpK3kC7du3w9ttvG4Ke1I7KNFRz587F06dPTRrAJc9x+fJlo+0yqEqULFkyyWP09a6J61X1Pa9S22oKeT+WCiH61zLp9R5fiPvt6gknn/zyJJnWPjLzsSOrwGNn/WJjdUZ1qaVK5cTJk4Ph6Rmjwir/7mwP/+5sl5MFP+9MeY00nQuXRQIkkBYuXBhlypRRE/vr50mVkfxSSyo1pHny5FHTUaWVhEt/f3/88ssvRnUMW7duVb2v0mubmNzf29sbmzZtMtoug75cXV1RpUoV2I3YaODxfwPPclUEnLnkIBHZl8WLj6N+/QVq+qqE8uZNe3kZEdm/NCUgCZD6Cf2FhNWlS5eidOnSePPNN+Hm5oZ33nkHffr0UZdNIQsAyMApWe5VVrs6cuSICsTyfDJFlZQHnD9/XvXGyqwEUhIwbNgwfP311+p0vqy09ddff6neXZm3Ve5jNxIWI7sknY+WiMhWxcTE4v33t2PChD/U9f7912PJkg7sTSWi9Pew3r59W/Wi6rVt2xY3btzAu+++i2rVqqneTpkpwNSwqp/0X3pnZQqrIUOGYMOGDep55fnEyZMnERQUpJZi1ZOA+9VXX+HgwYPqfsHBwSo46wdhERGR9Xr4MAItW/5kCKvC19cdMTGciYOIMtDDKosDZM+e3XBd34tZs2ZNFTYzWucgI/4TLx6gJ6+hX6ggIemNlR+7dv33+Msupn8ZICKyNqdO3UVAwDKcPx83RaGrqzOmTm2BQYP8tW4aEVmxdBVF6qeBkhIAFsNnopsH4i8/uZuZr0RElOnWrTuDHj3WICwsbtBsrlzeCA7ujPr14xaLISJKSYZG8djlMqjW5N7f8ZfrjNWyJUREGZoF4Msvd+OTT+JLuypXzqcWAyhaNBv3LBE9V4ZmzGfvaia79t8/7k4uQLFmmf1qRESZ4qefThiF1aCg8ti7tx/DKhGZv4dVBj4lllwNqYTYU6dOpb0FlPq0VsK3sJqHlYjIFnXtWkGF1i1bzuOrr17Fe+/VYYcHEZk/sMpyp6QhTlZPRDbMxcUZP/0UiIMHr6NJk6QLwhARPQ8DKxERmY0sAjN16p+oWbMgatYsZNieLZsnwyoRpRuXTrJmT+5o3QIiojR7+jQagwdvwsKFR5E/vw8OHRqIAgV8uQeJSNtBV5SJoiLiLz99yF1NRFbtxo1QNGiwUIVVcfNmGDZu/EfrZhGRnWAPq7WKjZunUHn2SMuWEBGlav/+a+jQYbkKqcLLyxXz5wegS5cK3HNEZBYMrNYqNib+Mqe0IiIrtWDBEQwatAmRkXH/ZhUp4qfmV61SJb/WTSMiO8LAaq3u/BV/+dF5LVtCRJREVFQMRo7chu+++9OwTVasWrmyE/LkycI9RkTaB9YHDx5g3rx52LdvH+7evYu5c+di+/btKFOmDBo3bmzeFjqqsBvxlws31LIlRERJZgIICFiGn3+O/zL9xhv+mDy5OdzcXLi3iEj7QVdXr15F27ZtsWLFCuTNmxf3799HTEwMLl26hGHDhmHnzvjVTCgDwm/GX85XnbuSiKyGLBDTqVM5ddnNzRmzZ7fGtGmtGFaJyHp6WP/3v/8hZ86cWLRoEby9vVGhQlxR/cSJE/Hs2TPMnDkTDRo0yIy2OpaIe/GXsxTQsiVEREn07VsFV648RuPGJVCnThHuISKyrh7WP/74A2+88QayZs2aZGk9Wb713Llz5myf4/p7Qfzl3C9p2RIicnCxsTr88suFJNvHjGnAsEpE1jsPq6tr8h2zkZGRXB86M6a1ylrYbE9LRGSKkJBnaN9+OZo2XYxly/7mziMi2wis/v7+mDVrFp48eWLYJj2tsbGxWLp0KapWrWruNjqm2Ki439lLa90SInJQ588/QO3a87B+/Vl1fcCADbh/P/7ffiIiq61hfeedd9C1a1c0bdoUNWvWVGFVZgy4cOECLl++jJ9++ilzWupInoUA0U/jLrtxehgisrytW8+jS5dgPHoU929RtmyeWL68I3Lm9ObhICLr72F98cUXsWrVKhVWDxw4ABcXFzW9VZEiRbBs2TKULVs2c1rqqFNa+RbSsiVE5IBTVk2YsA8tW/5kCKvlyuXGwYMD0LRpSa2bR0QOyuQeVpnCqnjx4mpWAMoktw/FX87GDwgisoyIiCh12n/JkhOGbQEBpbFoUXv4+nrwMBCR7fSw1q1bF1988QVOnIj/B43M7MqO+Mteubl7iSjTXbsWgnr1FhiF1U8+qY/Vq4MYVonI9npYW7dujS1btmDJkiUoWrQo2rVrhzZt2qBgwYKZ00JHExsDXNwUd9nJBag4QOsWEZGDTF0l86qKLFnc8MMP7RAYGLc4ABGRzfWwfvjhh9i9ezfmz5+vZgxYsGABmjRpgh49emDlypUIDQ3NnJY6itCrQMTduMuF6gHeubRuERE5gCJF/LBqVWeULp0Tf/zxGsMqEdn+PKwyM0Dt2rVVacCePXswffp05M+fH5999hnq1atn/lY64nRWIkt+LVtCRHYsKioG4eEJ5nsGUL9+Ufz99xuoWDGvZu0iIjJbYNWLjo5WgXXz5s2q11VIkKUMOPVjgqPjxl1JRGZ39244GjdehJ4916hSgIRcXTP0sUBEZB01rDLlyf79+7Fp0yb88ssvePz4MSpVqoRhw4ahZcuWyJ49e+a01FHo61dFuV5atoSI7NDRo7cQELDMUK/65Ze78fHHr2jdLCIi8wZWOeV///59FChQAN26dUNAQACKFStm6tNQSp4+jPvtnQco+ir3ExGZzfLlf6Nv33WIiIhW1/Pn90GTJpw6j4jsMLA2atQIbdu2VQOuKDM5cfcSkVnExMTio49+xddf7zVsq1mzoJqyqkABX+5lIrK/wPr5559nTksoTuR/syy4uHOPEFGGPX78FN26rcbmzecM2/r0qYwZM1rB09PkjwAiIk2k6V+rV199FdOmTUOZMmXU5efNILB9+3Zztc/xygGe3o8vCSAiyoAzZ+6petV//on7d8XFxQnfftsMb75ZQ/1bTURkV4G1Ro0ayJIli7pcvXp1/kOXWY7NiL/MFa6IKIPGjdtjCKs5cnhhxYqOePXVEtyvRGSfgXXcuHGGy19//XWq942Jicl4qxzV8dnxl18arGVLiMgOfP99Cxw+fAPOzk5Yu7YLSpTgLC5EZJtMnnBPSgLOnDmT7G3Hjx/Hyy+/bI52OZ7oZ0DYjbjL7r5AqbZat4iIbJyvrwd+/rk79u17jWGViOy/h3Xjxo1qkQBx/fp1bNu2LdnQ+scffyAqKsFKTZR2j87Fr3JVkmGViExz+fIjDBy4EXPmtFHLrOoVLhx/mYjIrgPriRMn8MMPP6jLUqgvS7GmpG/fvuZrnSMJvx1/2YOn7Ygo7Xbt+hcdO67EvXtP0L79cvz+e194e3OlPCJysMD6zjvvoFevXmqVq8aNG+P7779H2bJlje7j4uICHx8f9UPpEH4z/jJnCCCiNJB/k2fMOIThw7cgOjrWMI3V7dthKF6cX3yJyMECq7u7OwoWLKgu79ixA3ny5IGbG7+9m1XI5fjLflw5jIhSFxkZg6FDN2POnL8M25o2LYmlSwPVjABERA4XWKVHtVOnTsibNy/WrFmT6n2lZGDIkCHmap9jBtYcxr3XREQJ3boVhsDAFdi376ph28iRtTFuXGO4upo8lpaIyH4Ca/369VVglcupYWBNp6jw+MueOdL7LERk5w4duoF27Zbh+vW4VfE8PFwwd25b9OhRSeumERFpG1gTzgiQ0pRWRESUua5ceYx69Rbg6dO4WVsKFcqKNWuC4O9fgLueiOyaWc4d3b17FydPnuSiAUREmUimqxo+vKa6XKdOYRw8OIBhlYgcQpp6WBMKCwvDl19+iQoVKqB79+74+eefMWrUKBVWixUrhvnz5yN//vyZ01oiIgf35ZeNVM/qwIHV4O7uonVziIiss4d14sSJ2Lp1K/z84iajnjBhAsqUKaNqW11dXdV1Sg8ddxsRGTl16i5Wrz5ttM3FxRlDh9ZgWCUih2JyD6tMa/X++++jdevW+Pvvv9XKV++++65aslVWwxozZkzmtNTePfwn/rIzpwwjcnTr1p1Bjx5rEBUVg927+6JGjbipBYmIHJHJPayPHj1CiRIl1OVdu3apXtU6deqo69Lr+uzZM/O30t49fQTcPhx3OVtJwLeQ1i0iIo3ExuowduwutGu3HGFhkXj2LAaff76Lx4OIHJrJgVUWEDh79qy6vH37dlSuXNmwupUE2EKFGLZMFpMg5OcsL3ODmf4cRGTzJKB27rwSn3yy07AtKKg8VqzopGm7iIhsLrB26dIFX3/9NVq2bInTp0+jW7duavvQoUOxcOFCdTuZKCos/rITB1EQOaKLFx/i5ZfnITg4rmZVvrd+/fWrauUqb2+WCRGRYzO5hrV3797ImTMnDh48qEKqBFchS7V++umnCAoKyox22rewG/GXfQtr2RIi0sCOHRfRufMqPHgQoa5nzeqhgmrLli/weBARpSewChlwJT8JTZo0iTs0vZ49ir/smZ37kciBzJv3F15/fSNiYuJmCildOifWreuC0qVzad00IiLbDqyXLl3Cd999hz///BMhISHInj07/P39MWTIEJQsWdL8rbR3jy/FX85aTMuWEJGFlSuXW01VJXNZS4/qTz91gJ+fJ48DEVFGAuv58+dVnaqLiwsaNWqEXLlyqZWufvvtN+zcuRMrV65kaDXV44vxl/2Km/xwIrJdtWsXxsyZrXDu3AOMHdtQhVciIspgYJWFAWQmgEWLFsHX19ewPTQ0VNW3SmmALCJAJrjya/xlBlYiu3by5B2UKZPLKJj27VtF0zYREVk7k7/Ky2CrQYMGGYVVIdcHDhyobicTPfhvJZss+TnoisiOLVhwBFWrzsbHH/+mdVOIiOw7sMpCAR4eHsne5u7ujsjISHO0yzFJYOUcrER2Jzo6Fm+9tQX9+q1HZGQMxo3bg23bLmjdLCIi+w2sFStWxE8//QSdLm5Eq55cX7JkCSpUqGDO9hER2bT795+gWbPFmDLlgGHbG2/4o2FDDrAkIsq0Gtbhw4eja9euaNu2LZo3b47cuXOrQVdbtmxRswcsWLDA1KckIrJLx4/fRrt2y3DpUtzUdW5uzpg2rSUGDKimddOIiOw7sEoP69y5czFx4kQ1uEp6Vp2cnFTP6pw5c1C9evXMaam9kp5qXazWrSAiMwsOPoVevdbiyZModT1v3iwIDu6MOnWKcF8TEVliHtZatWqp6asiIiLUPKxZs2aFl5dXep6KZNEAfWD1zMH9QWTjYmN1+PTTnRg7drdhm79/AaxZE4RChbJq2jYiIrsPrPfv38fq1atx48YNFC1aFG3atFFLtDKoZlDY9fjLvgUz+mxEpLFnz6KxYcM/hus9elTC7Nmt4eXlpmm7iIjsPrDKYgHdu3fH48ePDdumT5+OadOmsQQgo8JuxF/OUiDDT0dE2pJgunZtEGrVmodRo17G22/XUmVTRESUybMETJ48GT4+Pli8eDGOHTuGNWvWqMUDxo4dm4GXpiQ9rD7sYSWyRVFRMUbXixbNhn/+GYoRI2ozrBIRWSqwHjp0CCNGjIC/v7+ag7Vs2bL44IMPcO7cOTx48MAc7XBcDKxENksGnU6cuA/Vq89BWJjxHNS+vsnPV01ERJkUWGXZ1QIFjE9XlylTRv1jfe/evXS8LCVbEuDDkgAiWxEREaVmARg58hccO3YbvXuvVQOuiIhIoxrWmJgYuLi4GG3TD7aKioqbsoXSiT2sRDbn2rUQNb/q4cM3DdvKl8+taZuIiOxZuqa1okzoYXVyBrLk5a4lsnJ7915BYOAK3L4drq5nyeKGH35oh8DAclo3jYjIbmU4sHL0q5l6WL3zAs78/kBkzebMOYwhQzYjKipu7uTixbNh3bouqFiRXzaJiDJTmhNSUFBQstsDAwOTBNhTp05lvGWOIDIUeHI77jJnCCCy6lkA3n57K6ZNO2jY1qhRcaxY0RE5c3pr2jYiIkeQpsA6dOjQzG+JI7q4OX6Vq/w1tW4NEaVg0aLjRmF1+PCamDChKVxd0zRulYiIMoiBVUuhV+IvF6yrZUuIKBV9+lRWq1dt3nwOs2a1VteJiMhyWDRpLVzctW4BEaXA2dkJP/7YDmfP3oe/P6efIyKyNJ7PIiJKICYmFh999Cv27LmSZCEAhlUiIm0wsGpJx0nGiazJ48dP0bbtMnz55e9q6qqrVx9r3SQiImJg1dizh/GX3bNq2RIih3f27D3UrDlX1amK+/efYO/eqw6/X4iIrAFrWLUUcT/+shdXySHSioTUrl2DERLyTF3PkcNLTVn16qsleFCIiGw1sD548ADz5s3Dvn37cPfuXcydOxfbt29HmTJl0LhxY/O30l7pp7QSzsZL3xKRBf4EdTr873978cEHOwwVOhUr5sHatV1QokR2HgIiIlutYb169Sratm2LFStWIG/evLh//z5iYmJw6dIlDBs2DDt37sycltrrwgF6blm0bAmRw3nyJEr1qo4eHR9WAwPLYt++1xhWiYhsvYf1f//7H3LmzIlFixbB29sbFSpUUNsnTpyIZ8+eYebMmWjQoEFmtNX+PHsUf9mDvTlElhIbq0OTJouwb198jernnzfAhx/WV1NYERGRjfew/vHHH3jjjTeQNWtWtQxr4uVbz52LG7Bgij179qglXl966SU0atRIlRvIqbq0iI6ORseOHdGzZ0/YnOiI+MtuXN6RyFIklA4dWl1d9vV1x7p1XfDxx68wrBIR2VMNq6tr8g+LjIxMEmKf5+jRoxg0aBBatGiB4cOH4/Dhwxg/frwqMxg4cOBzHz979mycOHECNWrUgM2JuBf329ULcHbTujVEDqVr14q4dSsMzZqVQrlyHPRIRGRXgdXf3x+zZs1C7dq14eHhobZJSI2NjcXSpUtRtWpVk55v6tSpKFu2rAqpon79+qrXVEoLevXqBU9PzxQfe+bMGdWW3Llt8MNGepBDLsdd9i0iO1HrFhHZrcjIGLW0aseO5Yy2v/12bc3aREREmVgS8M477+DChQto2rQp3n33XRVW5RR+hw4dVO/o22+/nebnkh7ZAwcOoEmTJkbbmzVrhvDwcPV8qT1WXl9KAYoXLw6bExUORD+Ju+zDpR6JMsvt2+Fo1OgHdOq0Ej/+eIw7mojIEQLriy++iODgYNSsWVOFTRcXFzW9VZEiRbBs2TLVW2rKjANRUVEoVqyY0faiRYuq3zLzQEqmTZumemJlZgKblLB+1SWup5qIzOvQoRto1GgZ9u27pq4PH75FrWZFREQOUMMqAVNmBcio0NC4aZ18fHyMtmfJEjfFU1hYWLKPO378OObPn48lS5bA3d09Q22QwV1pHeBljtcxvFboVeiLAHQ+BblMqxVLcuzIJixefBwDB27E06fR6nqhQlmxenVnZM3qwWNpA/h3Z7t47GyXzsKfd6a8jsmB9caNG8+9T4ECaTvFLXWvqXF2TtoBLFNnvf/+++jduzcqVaqEjAoJCUn2dTLjoDx5ElcCIGUULiGP4fvfbZExToh4zDXLrVXiY0fWLSYmFp9+uhfff/+XYVvNmvnxww+tkDdvFjzm35pN4N+d7eKxs106C3/ePS8HZiiwyrRTz3sTp0+fTtNz+frGRTapV01I37OauOdVTJ48Wb1BmVpLSgISJnS5LiUKpuxkmZ5LHpPZ9G308/OLa9+jKMNt7r654O7nl+ltIDMdO7JaDx9GoFu3YGzbdtGwrVev8pg1KwAeHlyJ2pbw78528djZLp2FP+9kRqi0Mvlf8K+++irJm5A0fujQIVXTKrenldS9Sli8fPm/0fL/uXLlivpdsmTJJI/ZunUrrl+/jipVqiS5rXz58hg3bpwaAJZW8l4sFUL0r6Ve7+mD+O3eeThLgJUzOnZklc6evYfWrZfi/Pm4vy1XV2dMmdIcXbuWUmGVx8728O/OdvHY2S4nC37emfIaJgfWlMJg9+7dVVjcsGFDmle6kmmxZJqsX375Ba+99pqh4RJKpfc1uVP+M2bMUDMEJDRmzBj1+7PPPkOhQoVgE57cjb/snLE6XCKSMzLuCAuL+7chVy5vBAd3Rr16RVgCQERkB8x6jkzKBeRUvSkGDx6Mvn37qkUDZLWrI0eOqGmyZPosLy8vVR5w/vx51RubI0cOlC5dOslz6AdpVaxYETbj35/jL+evqWVLiOxCwYJxg6pGjNiGZcsCUbRoNg6uIiKyE2YdbXTs2LEUV8FKiSxAIIsHyBRWQ4YMUT20Mr/qgAED1O0nT55US77u3LkTduXmn3G/vfMCeatp3RoimyO9qSEhz4y21a5dGPv29VNhlYiIHLiHdfTo0Um2ySCoW7du4eDBg+jYsaPJjZCFAxIvHqAn872ePXs21ccvWrQINkcXN2AMntlZv0pkoosXH6Jdu2UoUsQP69Z1gYtL/Hdv1qoSEdkfkwOrDKxKTD4gZES/9IoOGjTIXG2zbzH/zRLglPlTahHZkx07LqJz51V48CACJ07cwdixu/Hpp2mrmyciIgcJrHPmzEl29D6ZIDIsfllWKQkgojRNt/LddwfwzjvbEBMTN/XKiy/mRNeuFbj3iIjsnMnde926dcPatWszpzWOQh9Whbt++QAiSomsVtWv33q89dZWQ1ht2fIFHDjQH6VL5+KOIyKycyb3sLq5uSF79uyZ0xpHwSU+idLsxo1QdOiwHAcOXDdsGz26LsaObWhUu0pERPbL5MAq00998803CA0NRZkyZeDt7Z3upVkd1t1j8Ze92DtElJL9+6+psHrzZtzqd15erpg/PwBdurAMgIjIkZgcWD/99FO1lNaoUaMyvDSrw7r6W/zlYs21bAmRVZs+/aAhrMqMAGvXBqFKlfxaN4uIiKw9sH7xxReZ0xJHEpJgKdrcL2nZEiKrNmNGKxw/fht+fp5YtaoTcueOWySEiIgcS5oCa69evdTypzI7QPv27TO/VfYu+mn8ZQ66IjKaCSDhPKpZsrhj69YeyJHDC25uLtxTREQOKk0jFv7880+Eh4dnfmuIyGGdOHEbNWrMVYsCJJQ3rw/DKhGRg+MQWyLSXHDwKdSuPQ+HDt1AQMAytewqERGRHgMrEWkmNlaHTz75DR07rkR4eNzqb56erggNfcajQkREpg+6GjJkCNzd3Z97P6k/2759e1qflogcVEjIM/TsuQbr1581bOvRoxJmz24NLy83TdtGREQ2GljLlSuHHDlyZG5riMghnDt3X536P336nrru7OyEb75pjBEjahsNuiIiIjK5h7VSpUrca2YRt7QkkSPauvU8unQJxqNHcbNlZMvmieXLO6Jp05JaN42IiOxlHlYyg8i4idAVN84rSY7jwoUHaNXqJ8TExH1pK1cuN9at64JSpXj2hoiIUsZBV1p4+iDut5ML52Elh1KyZA588EE9dTkgoDT273+NYZWIiMzTwyqLBWTPnj0td6W0iPlvBLSrl4xS4z4jh/Lppw1QunROdO1aUdWuEhERmSWwjhs3Li13ozRjDSs5hr17r6iFAHr2jF+CWEJq9+6shyciorRjDauWJQEeWTV5eSJLmDPnMIYM2awuFy+eHXXrFuGOJyKidGENq6XFRALht+Mu+xa2+MsTZbaoqBgMGbIJAwduRFRUrPqZNu0gdzwREaUbe1gt7cnt+JKALAUs/vJEmenOnXB06rQSu3dfNmwbPrwmJkxoyh1PRETpxsBqabEx8Zddnr9yGJGtOHLkJtq1W44rVx6r6+7uLpg1qzX69KmsddOIiMjGMbASUYYtX/43+vZdh4iIaHU9f34frF4dhFq1CnHvEhFRhjGwElGGTJiwD6NG/WK4XrNmQRVWCxTw5Z4lIiKz4KArIsqQhg2LwdMz7rtv794vYefOPgyrRERkVuxhJaIMqVatAObNa4u7d8MxbFhNOHExDCIiMjMGViIyyb59V1GjRkG4usafoOnWrSL3IhERZRqWBBBRmuh0Oowb9zvq1p2P996Lr1klIiLKbAysRPRc4eGR6No1GB988Ct0OuDbb/fj118vcc8REZFFsCTA0nSxFn9Jooy4fPmRml/16NFbhm2ff94ADRoU444lIiKLYGC1tEfn4y9757X4yxOZYteuf9Gx40rcu/dEXffxccfixe0REFCGO5KIiCyGgdXSbh+Kv5yvusVfniit9aozZhzC8OFbEB0dd1agVKkcWLs2COXL5+FOJCIii2JgtbQnt+MvZytl8Zcnep7IyBgMHboZc+b8ZdjWtGlJLFsWiOzZvbgDiYjI4jjoSktO3P1kfWJjdUb1qiNH1samTd0YVomISDNMTERkRFatWrMmCMWLZ1P1quPHNzWac5WIiMjSWBJARAgLi1QDqvQKFsyKM2eGwt3dhXuHiIg0x24TIgcWExOLUaO2oXr1OQgJeWZ0G8MqERFZCwZWIgf18GEEWrb8CRMm/IEzZ+6he/fVqn6ViIjI2rAkgMgBnTp1FwEBy3D+/AN1XWpUW7V6Ac7OTlo3jYiIKAkGViIHs27dGfTosUbVrYpcubwRHNwZ9esX1bppREREyWJgJXIQcrr/yy9345NPdhq2Va6cTy0GULRoNk3bRkRElBoGViIHIL2pffqsRXDwacO2oKDymD8/AN7ebpq2jYiI6Hk46IrIASxZctwQVp2cgHHjXsXSpYEMq0REZBPYw0rkAAYOrIYdOy5h69YLKqi2bPmC1k0iIiJKMwZWS9Nx2iCyPCcnJyxYEIDr10Px4os5eQiIiMimsCTA0iLuxV9297X4y5P9e/o0Gv37r8eOHReNtmfJ4s6wSkRENomB1dIenIn77eQCZCtp8Zcn+3bjRigaNFiIefOOoHPnVbh06aHWTSIiIsowBlZLlwM8/CfucrYSgEv82u1EGbV//zX4+8/GgQPX1fWIiCi1QAAREZGtYw2rJcVEwCn6Sdxln4IWfWmybwsWHMGgQZsQGRmjrhcp4qfmV61SJb/WTSMiIsowBlYLcop+mmDPe1vypclORUXFYOTIbfjuuz8N22TFqlWrOiF37iyato2IiMhcGFgtSd+7KtwYWClj7t9/oupUf/31kmHbG2/4Y/Lk5nBzc+HuJSIiu8HAakFOMQl7WL0s+dJkZ2JiYtGw4Q84ceKOuu7m5oxp01piwIBqWjeNiIjI7DjoyoKcoiPir7AkgDLAxcUZY8a8oi7nzZsFv/3Wm2GViIjsFntYLckosLKHlTImMLAcZs9ujRYtXkChQlm5O4mIyG6xh9WCnGISBFbWsJIJQkKeYe7cv5JslxIAhlUiIrJ37GG1JPawUjqcP/8AAQHL1JyqsbE6DBzIOlUiInIs7GG1JF1s/GUnfleg59u27QKqV59jWADg449/Q1hYJHcdERE5FAZWIiuk0+kwceI+tGixBI8exc0uUa5cbuzd2w8+PlwhjYiIHAu7+YisjCypOnDgRixefNywLSCgNBYtag9fXw9N20ZERKQFBlatprVy5q6npK5dC0H79stx6NANw7ZPPqmPMWMawNnZibuMiIgcElOTBTmHX4+/4lvIki9NNuCvv26iZcsluH07XF3PksUNP/zQTk1fRURE5MgYWC3IOexq/JWsRS350mQDChb0NSypWqxYNqxb1wWVKuXVullERESa46ArS+7s8GvxV3yLWPKlyQbkzeuDtWuD0KrVCzh4cADDKhER0X/Yw2pBTpGh8Ve8clrypckK3bkTDldXZ+TIEb/qWbVqBbBxYzdN20VERGRt2MOqGQ6gcWRHjtxU86t26bIK0dEJ5uclIiKiJBhYiSxs2bK/UafOfFy58hi//HIRX3yxm8eAiIgoFQysRBYSExOL0aO3o2vXYERERKttNWsW5FKrREREz8EaViILePz4Kbp1W43Nm88ZtvXpUxkzZrSCpyf/DImIiFLDT0qiTHb27D0EBCzD2bP31XUXFyd8+20zvPlmDTg5sZaZiIjoeRhYiTKR9KhKCUBIyDN1XWYEWLmyExo1Ks79TkRElEYMrESZaOXKU4awWrFiHqxd2wUlSmTnPiciIjIBAytRJpIa1ZMn76BIET8sXNgOPj7u3N9EREQmYmAlMvNMAC4u8ZNvyICqbdt6ws/Pg/WqRERE6cRprYjMZNeuf1G27DT880/c4Cq9bNk8GVaJiIgygIGVKIN0Oh2mTz+Ixo0X4dy5B2pGAH3dKhEREWUcSwKIMiAyMgZDh27GnDl/GbZJvaqUBhAREZF5MLASpdOtW2EIDFyBffuuGraNGvUyxo171aiOlYiIiDLGKj5V9+zZg8DAQLz00kto1KgR5s2bp06zpiQyMhIzZ85E8+bNUblyZTRr1gzff/+92k5kCYcO3YC//2xDWJXBVYsXt8c33zRhWCUiIrK3HtajR49i0KBBaNGiBYYPH47Dhw9j/PjxiImJwcCBA5N9zBdffIH169fjjTfeQMWKFXHixAlMmzYNN27cwFdffWXx90COZfHi4xgwYAOePo1W1wsVyoo1a4Lg719A66YRERHZJc0D69SpU1G2bFkVUkX9+vURHR2telB79eoFT09Po/s/fPgQK1aswMiRI9G/f3+1rXbt2ur3xIkT1fYcOXJo8E7IEZw+fRe9eq2B/gRAnTqFsWpVZ+TL56N104iIiOyWpiUBcgr/wIEDaNKkidF2OcUfHh6uelsTCwsLQ5cuXVTpQEIlSpRQv69eja8ntDqxUfGXnV20bAmlU9myufHFF3H/7w0YUBW//tqbYZWIiMiee1glXEZFRaFYsWJG24sWLap+X7p0CXXq1DG6rXDhwvj000+TPNeOHTvg5uaW5LmsSnRE3G8Xd8BZ885tSqfRo+uiatX8aNasJOdXJSIisgBNU1NoaKj67eNjfDo1S5Ysht7UtPjll1+wZs0a9OjRA35+fia1QQZ3pTbAy1zkNZz+C6w6V2/ZkOmvSRm3bt1ZNRtAUFBJo/9PJKwKS/y/Q+mn//vmcbI9PHa2i8fOduks/G+mKa+jaWCNjU19rkpn5+dXLGzbtg3vvPMOqlWrhlGjRpnchpCQkDS9jjkOim9UeNxlFy+EPH6c6a9J6Rcbq8OECX9i3Lj9cHFxQo4cLdCkSSn2qNoY+bt78uSJuuzk5KR1c8gEPHa2i8fOduks/G/m83Kg1QRWX19f9VvqVRPS96wm7nlNbOHChfjf//6HGjVqqFkCPDw8TG5D1qxZ4eLiYqFvEXHfJJxc3EzuCSbLCQuLxGuvrcXq1WfU9ZgYHbZuvYqOHasx9NgY/bd3+XtjYLUtPHa2i8fOduks/G+mzAhlE4G1SJEiKixevnzZaPuVK1fU75Il4067JrdDv/zySyxatAitW7fGuHHj4O7unq42yAGx1AeZ7r+XUb/Y22OVLl58iHbtluHEiTvQH6Yvv2yEQYMqWPT/FTIf/XHjsbM9PHa2i8fOdlny2JnyGprOEiA9ov7+/qoGNWEdw9atW1Xva6VKlZJ93LfffqvCat++fTFhwoR0h1WihHbsuIjq1ecYwmrWrB7YuLEb3n+/LsMOERGRhjQfqj548GAVPGXRAFnt6siRI2qlK6lL9fLyUuUB58+fV72xMr/q6dOnMWfOHLVggKx0dezYMaPnK1Wq1HNLCTTDATpWSb4sfffdAbzzzjZ1+l+ULp0T69Z1QenSuThgh4iIyNEDq0z6L4sHfPfddxgyZAjy5s2Ld999F/369VO3nzx5Ui0gIKf9O3TooAZZScCQ1a2CgoKSPN+PP/6ImjVrwirp4lZGgoub1i2hBD766Fd89dUew/WWLV/ATz91gJ+f8aIVREREpA0nnYPO9yKFvrIsbOXKlS036GqqH5yiQoEcZYG+pzL9NSltjh+/jdq15+HJkyg1x+rYsQ3h4uJsdOweP37MgTs2iMfOdvHY2S4eO9uls/DnnSlZTPMeVocSGxm/cABZjUqV8mLRovaIiopBUFAFrZtDREREiTCwWoosHBDzLO6yi+nTb5H5bNz4j5r4380t/ttchw5luYuJiIislKazBDiU2P/qVwV7WDURHR2Lt97agjZtlqrfREREZBsYWC1F37sq2MNqcffvP0GzZosxZcoBdX369EPYsyduvl8iIiKybiwJsJSY/+pXBXtYLerEidsICFiGS5ceqetubs6YNq0l6tYtYtmGEBERUbowsFp6wJVgD6vFBAefQu/eaxEeHqWu582bBcHBnVGnDsMqERGRrWBJgBYlAc6cJSCzxcbq8Mknv6Fjx5WGsOrvXwCHDg1kWCUiIrIx7GHVoiTAlbMEZKawsEh0774a69efNWzr0aMSZs9uDS8vLtpARERkaxhYLYU9rBbj7u6iBlkJZ2cnjB/fBG+/XcsikyATERGR+bEkwFI46MqigXXVqs6oWDEPfv65O0aMqM2wSkREZMPYw6oJ9vSZeym5+/cjkCuXt2Fbvnw+OHp0kOphJSIiItvGHlayaRERUejVay1q1ZqLBw8ijG5jWCUiIrIPDKxks65dC0G9eguwePFxXLjwEN26BaveViIiIrIvLAkgm7R37xUEBq7A7dvh6nqWLG4YMKAqa1WJiIjsEAMr2Zw5cw5jyJDNiIqKVdeLF8+Gdeu6oGLFvFo3jYiIiDIBAyvZjKioGLz11hZMn37IsK1Ro+JYsaIjcuaMH3BFRERE9oWBlWzCnTvh6NRpJXbvvmzYNnx4TUyY0BSurizFJiIismcMrGQTVq8+bQirMs/qzJmt0LdvFa2bRURERBbAwEo24fXXq2HfvqvYvv0iVq8OQq1ahbRuEhEREVkIAytZJZmeKuFSqnJ51qzWePToKfLn99W0bURERGRZLP4jq/P48VMEBCzDli3njbZ7ebkxrBIRETkgBlayKmfO3EONGnOxYcM/6NJlFf75577WTSIiIiKNMbCS1di06R/UrDnXEFJdXJzV7ABERETk2BhYySrqVceN+x1t2ixFSMgzta1ixTw4dGgA6tYtonXziIiISGMcdEWaCg+PxGuvrcfy5ScN2wIDy2Lhwnbw8XHXtG1ERERkHRhYSTOXLz9Cu3bLcfToLcO2sWMb4sMP6xnNEEBERESOjYGVNBEdHYtXX/0RFy48VNd9fd2xeHEHtG1bmkeEiIiIjLCGlTQhy6lOmtQM0pFaqlQO7N/fn2GViIiIksUeVtJMmzalsXRpIJo2LYns2b14JIiIiChZ7GG1GB0c2a1bYZgwYZ+aESChoKAKDKtERESUKvawWkrUk/jLbt5wJIcO3UC7dstw/XoovLxcMWRIDa2bRERERDaEPayWEhUWf9nNB45i8eLjqFdvgQqrYsKEP/D0abTWzSIiIiIbwsCqRWB1t//AGhMTi1GjtqFnzzWGgFqnTmH88cdr8PRkxz4RERGlHZODpUQ6Tg/rw4cR6NIlGNu2XTBsGzCgKr7/viXc3V00bRsRERHZHgZWS3GQHtZTp+4iIGAZzp9/YJi+6rvvmmPQIH8uBkBERETpwsBqKQ5Qw7p792W0avUTwsIi1fVcubwRHNwZ9esX1bppREREZMMYWC0lJir+sos77FG5crmRM6eXCqyVK+fD2rVBKFo0m9bNIiIiIhvHQVdkNtKjum5dF/TpUxl79/ZjWCUiIiKzYGCldLt48SHu3g032vbSS/mwYEEAvL3duGeJiIjILBhYLca+VrraseMiqlefg06dViIqKkbr5hAREZEdY2C1lNgEk+U72W7psCytOmXKfjRrthgPHkRg167LGDduj9bNIiIiIjtmu8nJ1kQ/jb/s6glbJAsADB68CQsXHjVsa9nyBQwbVlPTdhEREZF9Y2C1lJhnNh1Yb9wIRYcOy3HgwHXDttGj62Ls2IZwcWFHPREREWUeBlZLiUnQw+riAVuyf/81FVZv3oybS9bLy1UNrAoKqqB104iIiMgBMLBaSvQzmwysCxYcwaBBmxAZGTewqkgRPzW/apUq+bVuGhERETkIBlZL0cXGX3a2nd2+b99VQ1iVFatWreqE3LmzaN0sIiIiciC2k5xIE99/3xKnTt1DlSr5MGlSM7i5ufBIEBERkUUxsJKRiIgoeHnFT/rv4eGK7dt7Gm0jIiIisiQO7yaD4OBTKFnyO5w8ecdorzCsEhERkZYYWAmxsTp88slv6NhxpZoJICBgGR4+jOCeISIiIqvAkgAHX5o1JOQZevZcg/Xrzxq21a5dGJ6e/F+DiIiIrANTiRZLs1rJLAHnzz9QvamnTt1V152dnfDNN40xYkRtODk5ad08IiIiIsU6kpMjiE5wit3VC1rbtu0CgoJW4dGjuAUNsmXzxPLlHdG0aUmtm0ZERERkhIFVk5WutFuaVafT4dtv/8C7725XtauibNlcWL++K0qVyqFZu4iIiIhSwkFXDtbDeuLEHaOw2rZtaezf359hlYiIiKwWA6uFl2bVwUnTGtZKlfJi/Pgm6vLHH9fHmjVByJrVdpaKJSIiIsfDkgBLk8FMGg9oevvtWqhTpzBq1iykaTuIiIiI0oI9rHZuzpzDmDTpD6NtMgMAwyoRERHZCvaw2qnIyBi89dYWzJhxSE1XVa5cbjRrVkrrZhERERGZjD2sdrhwwJ074WjSZJEKq0IGWO3Zc8Vir09ERERkTuxhtZSo8P/2uHemvsyRIzfRrt1yXLnyWF13d3fBrFmt0adP5Ux9XSIiIqLMwsBqKc/iAiQ8/DLtJZYv/xt9+65DRETcqlr58/tg9eog1KrFwVVERERkuxhYLSUy8wJrTEwsPvroV3z99V7Dtpo1C6qwWqCAr9lfj4iIiMiSGFgtITYaTvqSAHfzB9bhw7dg2rSDhuty+n/GjFbw9OThJSIiItvHQVeWEBkaf9k9q9mffsiQ6vD1dYeLixOmTGmO+fPbMqwSERGR3WAXnCXExtWUKi7uZn/6smVzY9myjiqkNmpU3OzPT0RERKQl9rDaGJ1Oh4ULj+LZswQhGEDLli8wrBIREZFdYmC1IeHhkejaNVjNBDBkyGYVXomIiIjsHUsCbMTly4/U/KpHj95S1+fNO4JBg/zh719A66YREdm8mJgYREVFad0MuyCdKZGRkXj69KlaCpwc79i5urrCxcXFrMefgdUG7Nr1Lzp2XIl7956o6zLAavHiDgyrRERm+IC+desWHj16xH1pRrGxsbh//z73qQMfOxcXF+TJkwd+fn5mCa4MrFb+D+nMmYcwbNgWREfHqm2lSuXAunVdUK5cbq2bR0Rk8/RhVT5Yvb292SNops8u6bE2dw8b2caxk+eIjo5GSEgIbt68iYiICOTPnz/DbWNgtVKRkTEYOnQz5sz5y7CtadOSWLYsENmze2naNiIieyAfzPqwmjNnTq2bYzcYWG2XzoxfNnx9feHh4YF79+6pvzF5zozgoCsr9OBBBBo1+sEorI4a9TI2b+7GsEpEZCb6mlXpWSUi88uSJYsKweaoD2cPqxWSGlU3t7hvIjK36ty5bdC9eyWtm0VEZJd42prI+v+22MNqhSSsrlzZCXXrFsHvv/dlWCUiIiKHxh5WKxATE4sbN0JRuLCfYVuuXN7YvbsPv/kTERGRw2MPq8YePoxAy5Y/oV69BYZpq/R4moqIiNKjZ8+eKF26tNFPmTJlULVqVXTo0AHr1q1L9nG//vor+vfvj5o1a6JSpUpo1qwZxo0bp0Z7p2Tr1q147bXX8PLLL6Ny5cpo06YNZs6cibCwsDS19dq1a2jYsCEePHiQ5LYuXbqotstrpPQ+5ScljRo1wvvvv59k+4kTJzBq1Cg0aNBAvc/GjRvj448/xtWrV5GZNm7ciFatWqnXbNGiBdasWfPcx4SGhmLMmDGG/du1a1fs3bs3yf1Wr16N1q1bG47bjz/+mGSBIXls4v8v5Ef2h56M7v/ss89Qp04dVKlSBUFBQfjjjz8Mt1+8eFHtV7mfw/Ww7tmzB5MmTcL58+fVSM3u3bujX79+qQY2OegzZsxQ/3MVLFgQAwcORPv27WFLTp68g4CAZbhw4aG63q1bMLZu7cGgSkREGVauXDkVdPRk9LdM47Vw4UK8++67yJYtG1555RXD7RJSfvrpJxWoxo4di6xZs6rP5UWLFqlg9d1336FWrVpG83VK6NuyZQsCAwNVGJJBNkePHsW8efNU+JXXkudJiQSq0aNHo3fv3siRI4fRbRKMjhw5ghdffBHLli1TIcwclixZgq+++kqF8nfeeUeNYL98+bJq87Zt2/DDDz+ocG9uErpHjhyJXr16oV69eti+fbsK0+7u7mqfJ0emh+rTp4/aF4MHD0aFChWwf/9+vP7665g8ebIK2mLlypX46KOP1JeNunXr4tixY/j666/x5MkTDBo0yLCvz549i759+6J58+ZGr1OyZEnD/yNyf/mCIsdWMpkEX8lY8hqyX0qUKIFXX30VX3zxBb755htYjE5jR44c0ZUvX143cuRI3a5du3TffvutrnTp0rpZs2al+JgtW7ao+3z55Ze63bt36z755BPdiy++qNu4cWOaXzc6Olp36NAh9TvThd/W6SZA/cSubqM2rV17Wufj85UO+FT95M79jW7Xrn8zvy1kstjYWN3Dhw/Vb7ItPHa2yxLHLiIiQnfq1Cn129706NFD/SQnJCREfe4OGzbMsG3x4sXqc3T16tVJ7h8aGqrr0qWLrmbNmrq7d+8atsvntDxm27ZtRveXY3bgwAH1Of3VV1+l2s6tW7fqatSooXv27FmS28aPH69r2LChbsOGDeq5/v33X5Pep5DHv/fee4br8rlftmxZ3RdffJHkvvfv39fVq1dP1759e11maNq0qW748OFG2+R6kyZNUnyM7FvZx+vWrTPa/vXXX+vq16+vi4mJUdcbNWqke/PNN43uI++7Tp06huuy/+S59u3bl+LrrVmzRleuXDnd6dOnDduePn2q2j537lzDtjt37qj7/f333xn6GzMli2leEjB16lSULVsW48ePR/369fH222+rUwtyOkGWBkvOt99+q74dfPDBB+pbinwrlK71KVOmwCpFxp8WiXXxxuef71LLrIaFRaptlSvnw8GDA1C/flENG0lERI5A5saUXj39WUzpVZMzltIzl9yZSh8fH9Wb9vDhQ9U7KWSaovnz56vP7SZNmiR5jJQeDBs2DKVKlUq1LbNmzVI9p9KehKRNa9euVaUC0osoU48tX748g+9cljWfp+YHHTFiRJLbpIdXejyl91B6JlPKLMmdUtf/yGn5lMoe/v333yT7St679O7Kbcm5cOGC+t2oUSOj7dI7LL3l0mMqZs+erXrNE3Jzc8OzZ88M10+fPq1+p9Z7LL3A/v7+6r0k/P9FX/ahlzt3btXbLsfPUjQNrLJe7YEDB5I9gOHh4Th8+LDZDrqmIu6qX2HP3NF5fAmMGbPTcFNQUHns3dsPRYtm07CBRERkb/QrDul/JLzIqWU5BS+fsQEBAYYgc/fu3SShKPEpYwk6O3bsUNdPnjypAqwEypTIKexOnTqleLu05e+//0bTpk2T3LZ7927Vpnbt2sHT09NQ7ym5ISP7Q0oQa9euDS+v5BfgadmyJYYMGZLi3LzyfiQ4p/QjNbGpBc9ixYoZbS9aNK6j6tKlS8k+Lnv27Or39evXjbZfuXJF/dbX3MrxKVSokHqPshiGnL6XwN+tWzfDY+Q4y/uS0/gSeCtWrIgBAwao46B35swZ9SVDyiLk/4fy5curmudDhw4laZt0HErZh/y/ZPc1rLKj5VtaagdQin5NPeiJb9NcbDQu3s+Odgu74MRND7VJvtiOG/cq3n23DmtWiYisydmVwL5PgMhQrVsCuPsCdcYCL3Y0+aEHDx5UgSMh6VWVmlA5I6kPm9IRJCTwpEY+Z/WDffSDsJ73mNRILaaQQUKJSU+ltFNClZDQtGrVKtXTJ4O60kMCtoT2jLQ5X7586sdU+gFo0ludkNT8Jrw9MemcmzBhAt577z18/vnnqn5UwqP0FIvEPcFSPywD1YTUu0q9asIwKveXmuJp06apECy/ZdyQhNu8efOqgW+yj/38/FSPrQR76b2VcUUrVqww6p2VYyMZTtqTsBbaLgOrjHwz9QCm96CnRL6NJB5FZ3Y6HX75pwRO3Myrrvr5eWDJkg5o2fIFQxvIeun/H+Fxsj08drbLEsdO/9xJXufgeDg9OANroTs4Hngh0LTH6HRq0JWUzAnprZTBzdLTKr8l+CR8/0KWzkxtf+tvlx/9Mpty6j61x6R2m3RaSXiSU/QJ7yfB8rffflODfx4/fqy2Sa+fDLCWwVcyEj7xa6T0Ognfo7Ozc5ranBoZaCY/KUlpSVN5zeTaqr8sj0muTdLDKuH0gw8+MPRWyxeHt956S5UvSO9zwsflz59fDZKSLyHypUTCq4R/CZ7yGDmtX716dXXfatWqqVkApFdZHiMDwiSASjaTHlp9MJfyDukFl+A6ceJEw2sVKFBA/ZbXSsv+T+4+phwHTQNragdd6P/nyuhjUiPTMpj6GFM5IRsG1PoLh64VwO6b/li8KggvvJDd8IdI1k3+oPTfYjnVmG3hsbNdljh2cnpZPlMkTOgDhXq9au/A+Y9PgSgr6GF180Vs1RHQJWhfWklHjoRWPf3pXektk95K/elmfTCRAJlwPyQmp6ElpMh99I+RsJLcY2S/Sm+ddC4lrk9N+PkrQSrx4+XUvwQnqReVn4SkV/Cff/4xjGqXx8sp8JTaLcdYQp3cLm2RfSLPkdL95f85eW3pYUyO9EhOnz4dKZFa3+TqgPWdahIGE762fmoouT2lNskxXLt2LW7fvq3G9hQpUkSVUwoJ+wkflytXLvUjYVQCvsy+8PPPP6vyjxdeiOskS3h/OZ7y5UXKBWS7tKN48eKqRlV/P9nHMp2W/j56+uMq7yGltst2+X9B3nfCetq0ZjqrCayyo0Xi+oeUelHT+5jUyLc7/TfFTOPnB13AanxT5W+g4mBky208dQdZN/03QPkHjIHVtvDY2S5LHDv58L9//776DDD6HCjTOe7HSmSkSyXh+5JTvjLXqPS0ydyq+t4yOSUvUzvJlE7608mJSZiVwCI1j/KcEn4lGP3+++/o0aNHso/59NNP1Slq6S1NLrTKICcJMok/gyWcSc+ftDNxmJT6Uun9+/DDD9U2CVbnzp1L9nNcwqr01sp7098uA8v+/PNP1dMsg4kSk97I//3vf+o1EpdTCJmTNLW6XSk3SK4t+oAtAV9O1evpyzGkBzm5x0n7d+7cqWpj9T2a+tP78nchbZT/j6WWVI6jvjxS6F/n3r176u9pw4YNqmRS9m1CEiRl+ip5fXm8BPbEbZHgKcE/4XZ9p5scx5RylGyXTkHJbvL4xFL7gmRVg67kW4K8GRkslVwxsf4AJyTJXyR+jP56co9JjRxwi/yUCoBTtaEqrFrsNfnDfcD/B/j/AP8fSPX/AYt+DljBjwxektl1Nm3apGpcZZt8Dg8dOhT79u1Tp9wTP0YCjQRECR0yiEf/GJkfdNeuXSqQJt6n0gMot8nAHAmGybVFegAlhEoPnX6bDMKSHlTpCZZR6Al/ZBCQ/JZFD6RNcv8aNWrgxo0bat7RxM8vA8QkEMlj9Nukd1l6ZOV0eeL7S7CTmQ8kPErYS67N0rMswTClHwlvyT1OgqKEWakPTbhdviTIbYULF07x/08pB9i2bZthm+wzCdRyal/m0pXZAOSLiLQ94WPleAqpO5X7SO+wzMiU8D6nTp1SmUsGYcl1mfVBwrCMF9LfR/bXX3/9pXptEz5WenyFHMeM/I3ZRA+r/E8s0yf88ssvqq5C33A5oPKHkVwhtqR//UGXPzw9/UHPSDE1ERGRvZMA1LZtW3X6Wk6/S/iUnkMJKdIrKkFW6hqld1tGkMuIcamBlYnqpZdWTwKr3PfNN99E586d1cAb6U2THszFixerKStlYv6U6AdVy4xA+hkKgoODVbhKbuYAIae2JYht3rxZhVppp7RPJtKXH+lxlNPMErDmzp2r6l2lBlNPTm0PHz5cvRd5vzILgZRGSC+t1IpKEJbbMoP0DssMDRIy5f1KoJbT9VJTrCdlFBIgJTTLGWMJwLKowOTJk1UPpVyXqaTu3Llj6CGXLCUT+0v5hNwu4VOmu/r+++/V6lgSQoUcJxm8JYOpZD9K0JfgLsdJX8YgixpIL7PsS5lmVMoBZMozyWcJp7XSHze5XXKcReg0JhPYyoTAMuHtzp07dZMmTVLXZ8+ebZiwWBYXkAl99YKDg9Xkt2PGjFGLDegXDti0aZN1LhzACcxtGieft108draLCwdkzPMm1JeJ5+Vzc9GiRUbbZTGe119/XU04X7FiRTVhvEz+f/369WSfJyoqSi060KlTJ7UAQOXKlXVt2rTRTZ8+XRcWFvbcdsok/fIZrp+g3t/fXzdw4MAU7x8eHq5eQ14v4baJEyfqmjdvrnvppZd0VapU0bVr1073ww8/GCbWT0zyxoABA9T7rFChgpq8X9px48YNXWZaunSpei15zRYtWqiJ+hPS55v9+/cbtkkOGjNmjGpr1apVdf369dMdO3Ysyd/LTz/9pGvVqpU6bq+88opaeEH2aUKSk2Sfy36qVauW7uOPP1YLdCR8nqtXr+pGjBihq169utrX8nr//PNPkvfSv3//JAshZObCAU7yH2hMelhlyTeZkkq+vemXZtWfVpDEL/U28m1KT05bSPe3TK0hXeny7UK+KaWVnCaQ2hr5tpXpNaz/1WNJvQfrIG0Pj53t4rGzXZY4dlL7J587UmqWXH0dpf/YyWdsSiPmE5KzpdLjK/Ou6gcmkfUfu+vXr6spt2TwXsKBfab+jZmSxTQtCdCTN53cShlC37WdmBSGp1QcTkRERNZPTv0vWLAAS5cuRf/+/bVuDqWRdBhKfXJqYdXcNF+alYiIiByT9OLJyksyD6jUb5L1u3DhgpqV4JNPPrHo61pFDysRERE5JpkxSEoCyDaULFlSzQxhaexhJSIiIiKrxsBKRERERFaNgZWIiByaFUyWQ2SXdGb822JgJSIihyQT1AtZOYiIzC88PFwNrNP/rWUEB10REZFDknkfZdUhWTVIeHt7Z9qcr47ElHlYyf6OnU6nQ3R0tFpyV37kb8wc890zsBIRkcOSteGFPrSSecjyqLJMKznusXNxcUH+/PnV4h/mwMBKREQOS3qR5EM1T548iIqK0ro5dkF62EJDQ+Hr68seVgc9dq6urmbvYWdgJSIihycfrpZYpttRQs+zZ8/UUpwsCbAtOis+duyvJyIiIiKrxsBKRERERFaNgZWIiIiIrBoDKxERERFZNQZWIiIiIrJqro6+XJhMkGup15O5zeT1rG3kHaWOx8528djZLh4728VjZ7t0Fs4q+gyWliVcHTawygERJ06c0LopRERERHD0TJYaJ11aYq2d7hxZOkxWc2CPJxEREZE2Pbqy0MDzVtdy2MBKRERERLaBg66IiIiIyKoxsBIRERGRVWNgJSIiIiKrxsBKRERERFaNgZWIiIiIrBoDKxERERFZNQZWM9mzZw8CAwPx0ksvoVGjRpg3b95zV27YuHEjWrVqhUqVKqFFixZYs2aNuZpDmXjsIiMjMXPmTDRv3hyVK1dGs2bN8P3336vtZP1/d3oyD3PHjh3Rs2fPTG8nmefY7dy5Ux0z+Tezfv36+OKLL/DkyRPuXis/dvK3Nnv2bDRt2lT9mxkQEIDNmzdbtM1k7NatW/D398eBAwfwPNaSVRhYzeDo0aMYNGgQSpQogalTp6JNmzYYP3485syZk+Jjtm7dipEjR6JOnTqYNm0aatSogffffx+bNm0yR5MoE4+dfEhKYO3QoQNmzJih/uGW+3/66afc71Z+7BKSD1CudGc7x+7XX3/F4MGD8cILL2DWrFkYOHAgVq9ejY8//tiibXd06Tl2cr9Jkyahbdu26t/MatWq4e2331afg2R5N2/eRL9+/RAaGvrc+1pVVpGFAyhj+vXrp+vYsaPRtm+++UZXpUoVXURERLKPadq0qW748OFG2+R6kyZNeDis+Ng9ePBAV7p0ad2cOXOMts+aNUv34osv6u7fv5/pbab0/93pnT59WlepUiVdnTp1dD169OAutYFj17hx4yT/Zi5cuFD36quv6p48eZKp7aWMHTv5Oxs5cqTRts6dO/Nvz8JiYmJ0wcHBuho1aqgf+czav39/qo+xpqzCHtYMktPA0qXepEkTo+1ymjg8PByHDx9O8phr167h33//TfYxly9fVreRdR67sLAwdOnSRZ0GS0h6G8TVq1czudWU3mOX8LHvvvuuKgUoXrw4d6gNHLtTp07hypUr6NGjh9H23r17Y/v27fDy8sr0dlP6/+7kcT4+PkbbsmXLhkePHnG3WtDZs2cxZswYtGvXDt98881z729tWYWBNYMkoERFRaFYsWJG24sWLap+X7p0KcljLly4oH6b8hiyjmNXuHBhdepfH1D1duzYATc3tyTPRdZz7PTktJbU1A0bNoyHx0aO3enTp9VvDw8PvP7666qWTk5Nfvnll6wdt4G/u169emHt2rXYvXu3+tK/fv16/P7776qWlSwnf/78+OWXXzB69Gh4eno+9/7WllVcLfpqdkhfA5L422OWLFnUb/njTEy/zZTHkHUcu+TIPwBShC69P35+fpnQUjLXsTt+/Djmz5+PJUuWwN3dnTvWRo7dgwcP1O+hQ4eidevW6Nu3r6o/ltpIuW3ixIkWabujS+/fXZ8+fVTt64ABAwzbpPa/f//+mdpeQpJebVNYW1ZhYM2g2NjYVG93dnY2y2PI/MxxHLZt24Z33nlHDSIYNWqUGVtH5j52z549U4MF5DSy9NCR7Rw76dUTcmpS/3dWq1YtNTJdwqoEWZZ3WOexk3KA7t274+7du/jss8/U2akjR46owVfe3t746KOPMrHFlBHWllWYjDLI19dX/Zb6nbR8M0nvY8j8MnocFi5ciOHDh6Nq1apq1LKcriTrPXaTJ09W/wC/8cYbqiRAfiTwyI/+MlnnsdP36DRo0MBoe7169YxKBsj6jp2MMj9z5gwmTJig6v+llEPKOuSLx6JFi/DPP//wsFkpXyvLKgysGVSkSBG4uLioAuSEZICAKFmyZJLH6HsCEj9Gfz25x5B1HDshwUamtho3bhxatmyppnPhlwzrP3bywSk1V1WqVEH58uXVz8GDB9WPXOY8yNZ77PQ1dInnOtb3vPLLovUeuxs3bqjf8sU+oerVq6vf58+fz8QWU0ZYW1ZhYM0g+YdSJt+VOsaEPTTy4SjfTpI79SgFy4UKFUoyB52cXpZ/mOU2ss5jJ7799lvVMyB1dNJrwFpI2zh2cgpy1apVRj/64CqXGzZsaOF34ZjSc+zk/nL6OPHcjzI3q6urq/oSQtZ57PQDVA8dOmS0/a+//lK/+XlnvYpaWVZhDasZyGTWEl7k9LAUkkt9jqz8IbWNMt2KdJ/Lt0j5dpojRw71mCFDhqiRelIELVMkySjzn3/+WU2uTNZ77OTUo/SoVqxYUa10dezYMaPnK1WqFHtbrfTYlS5dOsVTzXI8yXqPnRwnmdXh66+/RtasWdWKSRJ45s6dq0ag6/9dJes7dvL5JitiSQnAm2++qQKsDH6UL5ByG+vJrUeYtWcVi8/8aqe2bduma926ta58+fK6Ro0a6ebNm2e4TSbmlQl6ZcLehJYuXaom361QoYKuRYsWujVr1mjQcjLl2E2ePFldT+nneZMwk/Z/dwnJogFcOMB2jt2qVat0rVq1Uo9p2LChbubMmWoydLLuYxcaGqr7/PPP1QIC+s87WWzl2bNnPHQa2f/fcUr4mWXtWcVJ/mP5mExERERElDasYSUiIiIiq8bASkRERERWjYGViIiIiKwaAysRERERWTUGViIiIiKyagysRERERGTVGFiJiIiIyKoxsBIR2TF7mmrbnt4LEZmGgZWIrN7777+vllZN6WfLli0mPZcsMahFm8uXL4+6deuqZSpv3rxp1te7du2aeo3Vq1er6yEhIXj33XeN1nDv2bOn+tHqeFWpUgVt2rTBggULTH7Oc+fOoWvXrpnSXiKyfq5aN4CIKC1y586N77//PtnbihUrZhNtjo6OxqVLlzBhwgS1BvvGjRvh6elpltfKkycPli9frtYBF6dPn8a6devUeu96Y8aMgVbvXXpH7927h2XLluHrr7+Gh4cHunXrlubnky8lss+IyDExsBKRTXB3d0flypVh62329/eHm5sb3nvvPezYsQOtWrXKtNdKrFSpUmZ5rYy0p0GDBmjcuLHqCTYlsBKRY2NJABHZjZiYGMyePRutW7dGpUqVVGDq0qUL9u/fn+Jj/v77b/Tu3RvVqlVTp6z79OmDo0ePGt1HTqv36NEDL730EmrUqKHC5oMHD9LdzooVK6rf169fN2zbu3evCnDSjpo1a+Kdd94xKhuIjY3FpEmTVDlDhQoV1O+JEyciKioqSUnAgQMH0KtXL7VdfuvLABKWBPTr1w8dOnRI0rY33ngDbdu2zbT3LmHdy8sLTk5Ohm1Pnz5V76Vp06bqvVWtWhV9+/ZVvcRi6tSpht5aeY9yXb9P5Hg3adJEPa5Zs2ZYtGhRuttGRNaLgZWIbIacUk/8k3Agjpxqnz59OoKCgjB37lyMHTsWjx49wvDhwxEREZHk+cLCwtC/f39kz55dhSAJhHK/1157DaGhoeo+Bw8eVCFWTt1PnjwZH3zwAf78808VBCVopYeUBQj96fu1a9eqAJk/f358++23GD16tDr9Le/j/v376j5z5szB0qVLMWTIEMyfP1/Vc86bNw8zZsxI8vxSK/vJJ5+oy/I7uVIACaUnT57E5cuXDduk7nX37t0ICAgwy3tPeJwiIyNVqB43bpx6/+3atTPcT2ptg4ODMXDgQPXe5P1LzaqEdjm+nTp1QseOHdV9pexBrotPP/0U3333nXovM2fORPPmzfHVV19h2rRpJh4RIrJ2LAkgIpsgvZESxBKTUCNBR9y5cwdvv/220cAiqZV88803cfbs2SSnqM+fP4+HDx+qACa9eqJEiRIqFIWHh8PX11f1/BUvXhyzZs2Ci4uLuo/0NsqpfAlZ3bt3T7XdEtYSBuQTJ06o0FaoUCF1elx6CSVoy2AseS09aU/Lli1VKJVAJ0FRehH1NanS2yk9ldLGxHx8fAyn/+V3cqUA0pv52WefqTpaCcFi27ZtqpdaeqhFRt57SsdL6o0lQOsHUEmQlX390Ucfqferf2+yr6TWVepe8+XLp36E/hhK6F2xYgVGjBhhOP6yD6XnVtorvdXyRYSI7AMDKxHZBBnEk1xvoj7ICH3gk1PWFy9eVL2Hv/32myEYJfbCCy8gR44cGDRokOqdq1evHurUqaNG8QvpbT127JjqcZWePn34LFy4MEqWLKlO46cntEno+/zzz1XP5YULF3D37l0VvBOS3lcpUZCgKqRMQN6fBDEpB5CwK6fq08vb21vVkm7evNkQWDdt2oTatWsjb968GX7vCY+X9NxKz/eVK1dUCJX3lbDWVUK5uH37tgqi//77b6rHTUiZh7RL9kXCLwVyXV738OHD6v0RkX1gYCUimyDBRl/7mRLpvZReQ/ktvY/Ss1igQIEU5/DMkiULlixZogLOzz//rHpWJUTKKXHp8ZOgJT2gcjpefhKT3ltTQra8BwnYfn5+hm1SsiBy5cqV5PGy7dSpU+qylC5Ie6VnU3pkx48frwK3tLNWrVpID3mf69evx5kzZ9RrSe2rnFIXGX3viY+X9BhL7/CAAQOwcuVK1XOr9/vvv6vXlS8Z8h7LlCmjAnVqc6/q91tKg9Yk/BKR/WBgJSK7oK9HlUE50lMop/adnZ2xa9cubN26NcXHyf0k/Mmp8OPHj6upoKRWVHo4ZcCWnGKWOs7kgpGE4oyG7GzZsqnfcuo7Mel51Z/WlvciPZryI3Wt8r6kblPKHaS3Mz2kN1VCtYR1+S0hVEoFhATHjLz35O4vvatSlys1qrKP5fml11V6eKU3VE7lSw+ubJcvEhJkU5I1a1b1+4cfflBtTUz/RYWI7AMHXRGRXZDeOel1k3pU6VmVgCdkEJGQ3sLk5vaU3kkJhlKjKaeqZSCPhKEbN26oWtBy5cqp55bgqf+Rnk0ZpCU9khklPY0SFqWWNKGrV6+q2Qr0tbUSnr/44gt1OWfOnGqEv4RX6QmVsJ6YvuY0NXIfmchfTr/LvpDQqO/ZzIz3LjM3dO7cWQ0ok4Fm+lkanj17pupQ5UuCfvYAfVjV97Dqj2fC6cGE1CAnbJ+Ug0yZMsXQA0tE9oE9rERkFyT4SciSXkdXV1f1Iz2rq1atUrcnN0uAhEEJstLDJ4FJeuqkt1FmCND3NOoH9UiNqYxGl55YGcku9Z0yBVRGSRCT15BeR/1rSAiTaZykdECmdxLVq1dXryun7iVYyylvWTFKBihJHe6TJ0+Mnlc/GGvnzp3qeeQ0e0plAfK80o7Ep/4z472/9dZbah9LPa5MRyU1vnKspJdbZkqQmlWZmkvaLfTvS9+jKsFeaoClJ13a9PHHH6taYRmQJvWvMtODDGiz1sUkiCh92MNKRHZBApoM7JEeOZnGSkbWSy/p4sWLVRBNuERpwtWhZPoreeyHH36I119/XU31JD2I+rpQGXkug4Ju3bqFYcOGqeeVnkkJi+ZayEB6S2V6JglcEp71A5MkbEvvq5D3JIPDpIZVSh/kPtI2eVxypCdURvvLqfWRI0em+NoSZF988UXVayslAgllxnuXEgd5L9KrLdNPFS1aVIVXCeCDBw82TMcl86lKb6v+uMkXCOlBlWVf9YO0ZLYFCfSyepbsE/myIjMNSKhOSw8zEdkOJ11KFe1ERERERFaAPaxEREREZNUYWImIiIjIqjGwEhEREZFVY2AlIiIiIqvGwEpEREREVo2BlYiIiIisGgMrEREREVk1BlYiIiIismoMrERERERk1RhYiYiIiMiqMbASERERkVVjYCUiIiIiWLP/A/IuzxNrDhPHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All plots saved:\n",
      "  • correlation_heatmap.png\n",
      "  • teacher_convergence.png\n",
      "  • final_test_bar.png\n",
      "  • confusion_matrix.png\n",
      "  • roc_auc.png\n",
      "  • prob_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 12 – FULL VISUALIZATION + DATASET CORRELATION HEATMAP\n",
    "# --------------------------------------------------------------\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# --- 1. LOAD RESULTS FROM CELL 10 ---\n",
    "with open(\"pate_results.json\", \"r\") as f:\n",
    "    R = json.load(f)\n",
    "\n",
    "print(\"PATE-FL Results Loaded\")\n",
    "print(f\"Final Accuracy: {R['final']['acc_mean']:.4f} ± {R['final']['acc_std']:.4f}\")\n",
    "print(f\"Final F1-Score: {R['final']['f1_mean']:.4f}\")\n",
    "\n",
    "# --- 2. DATASET CORRELATION HEATMAP (NEW) ---\n",
    "print(\"\\nGenerating Dataset Correlation Heatmap...\")\n",
    "\n",
    "# Extract features from train_ds\n",
    "data_rows = []\n",
    "for sample in train_ds:\n",
    "    text = sample['text'] if 'text' in sample else tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "    length = len(text.split())\n",
    "    sentiment = sample['labels'].item()\n",
    "    # Source ID (from filename pattern)\n",
    "    source_id = 0\n",
    "    if \"imdb\" in str(sample).lower(): source_id = 1\n",
    "    elif \"twitter\" in str(sample).lower(): source_id = 2\n",
    "    elif \"amazon\" in str(sample).lower(): source_id = 3\n",
    "    elif \"uci\" in str(sample).lower(): source_id = 4\n",
    "    elif \"archive\" in str(sample).lower(): source_id = 5\n",
    "    elif \"tweet\" in str(sample).lower(): source_id = 6\n",
    "    elif \"yelp\" in str(sample).lower(): source_id = 7\n",
    "    elif \"mental\" in str(sample).lower(): source_id = 8\n",
    "    data_rows.append({\n",
    "        \"length\": length,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"source_id\": source_id\n",
    "    })\n",
    "\n",
    "df_corr = pd.DataFrame(data_rows)\n",
    "\n",
    "# Correlation matrix\n",
    "corr = df_corr.corr()\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", center=0, ax=ax,\n",
    "            square=True, cbar_kws={\"shrink\": .8})\n",
    "ax.set_title(\"Dataset Feature Correlation Heatmap\\n(Length, Sentiment, Source)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlation_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 3. TEACHER VALIDATION CURVES ---\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "rounds = list(range(1, len(R[\"teacher_val\"][0]) + 1))\n",
    "for i, fold in enumerate(R[\"teacher_val\"]):\n",
    "    accs = [m[\"acc\"] for m in fold]\n",
    "    ax.plot(rounds, accs, marker='o', label=f'Fold {i+1}', linewidth=2)\n",
    "ax.set_xlabel(\"Federated Round\")\n",
    "ax.set_ylabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"Teacher Model Convergence (No DP)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"teacher_convergence.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 4. FINAL TEST BAR PLOT ---\n",
    "df = pd.DataFrame(R[\"fold_results\"])\n",
    "df[\"Fold\"] = [f\"Fold {i+1}\" for i in range(len(df))]\n",
    "df_melt = df.melt(id_vars=\"Fold\", value_vars=[\"acc\", \"f1\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(data=df_melt, x=\"Fold\", y=\"Score\", hue=\"Metric\", palette=\"Set2\", ax=ax)\n",
    "ax.set_title(f\"PATE-FL Final Test\\nAcc: {R['final']['acc_mean']:.4f} ± {R['final']['acc_std']:.4f}\")\n",
    "ax.set_ylim(0.7, 0.95)\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"final_test_bar.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 5. CONFUSION MATRIX + REPORT (on test_ds) ---\n",
    "print(\"\\nRunning inference on full test set...\")\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "# Use last teacher as proxy (high acc) or re-load student\n",
    "student = get_model()\n",
    "student.load_state_dict(global_state)\n",
    "student.eval()\n",
    "\n",
    "all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test\"):\n",
    "        out = student(batch['input_ids'].to(DEVICE), batch['attention_mask'].to(DEVICE))\n",
    "        probs = torch.softmax(out.logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "ax.set_title(\"Confusion Matrix (Test Set)\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# --- 6. ROC-AUC ---\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve – PATE-FL')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_auc.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 7. PROBABILITY DISTRIBUTION ---\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.histplot(all_probs, bins=50, kde=True, ax=ax, color='skyblue')\n",
    "ax.set_xlabel(\"Predicted Probability (Positive)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Prediction Probability Distribution\")\n",
    "ax.axvline(0.5, color='red', linestyle='--', label='Threshold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prob_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll plots saved:\")\n",
    "print(\"  • correlation_heatmap.png\")\n",
    "print(\"  • teacher_convergence.png\")\n",
    "print(\"  • final_test_bar.png\")\n",
    "print(\"  • confusion_matrix.png\")\n",
    "print(\"  • roc_auc.png\")\n",
    "print(\"  • prob_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/corelation.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. ROC CURVE & AUC (ALL FOLDS) ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    fpr, tpr, _ = roc_curve(all_labels[i], all_probs[i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.7, label=f'Fold {i+1} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    # Interpolate for mean\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "\n",
    "# Mean ROC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='darkorange', lw=3,\n",
    "         label=f'Mean ROC (AUC = {mean_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (3-Fold Cross-Validation)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean AUC: {mean_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/auc-roc.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 7 – evaluate function (ROBUST + BERT-COMPATIBLE)\n",
    "# # --------------------------------------------------------------\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import numpy as np\n",
    "\n",
    "# def evaluate(model_state, loader):\n",
    "#     \"\"\"\n",
    "#     Evaluates a global model state on a DataLoader.\n",
    "#     Returns accuracy and F1.\n",
    "#     \"\"\"\n",
    "#     model = get_model()\n",
    "#     model.load_state_dict(model_state)\n",
    "#     model.eval()\n",
    "\n",
    "#     all_preds, all_labels = [], []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in loader:\n",
    "#             ids = batch['input_ids'].to(DEVICE)\n",
    "#             mask = batch['attention_mask'].to(DEVICE)\n",
    "#             labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "#             # ← PASS labels (required by BERT, ignored in eval)\n",
    "#             outputs = model(ids, attention_mask=mask, labels=labels)\n",
    "#             preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     acc = accuracy_score(all_labels, all_preds)\n",
    "#     f1 = f1_score(all_labels, all_preds, average='binary')  # ← explicit for binary\n",
    "#     return {'acc': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 8 – ClientSimulator (REPRODUCIBLE + FAIR)\n",
    "# # --------------------------------------------------------------\n",
    "# import torch\n",
    "# from torch.utils.data import Subset\n",
    "# import random\n",
    "\n",
    "# # Optional: set seed once at top of notebook\n",
    "# # torch.manual_seed(42); random.seed(42); np.random.seed(42)\n",
    "\n",
    "# class ClientSimulator:\n",
    "#     def __init__(self, n_clients, seed=42):\n",
    "#         self.n_clients = n_clients\n",
    "#         self.seed = seed\n",
    "#         self.rng = torch.Generator().manual_seed(seed)\n",
    "\n",
    "#     def split(self, dataset):\n",
    "#         \"\"\"\n",
    "#         Splits dataset into n_clients subsets.\n",
    "#         Uses torch.randperm → reproducible + fair.\n",
    "#         \"\"\"\n",
    "#         n = len(dataset)\n",
    "#         indices = torch.randperm(n, generator=self.rng).tolist()  # ← REPRODUCIBLE\n",
    "#         per_client = n // self.n_clients\n",
    "#         clients = []\n",
    "\n",
    "#         for i in range(self.n_clients):\n",
    "#             start = i * per_client\n",
    "#             end = (i + 1) * per_client if i < self.n_clients - 1 else n\n",
    "#             client_idx = indices[start:end]\n",
    "#             clients.append({\n",
    "#                 'id': i,\n",
    "#                 'dataset': Subset(dataset, client_idx),\n",
    "#                 'size': len(client_idx)\n",
    "#             })\n",
    "#         return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0048bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TUNING: {'lr': 1e-05, 'batch': 8, 'rounds': 6, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.self.query.bias, classifier.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.value.bias, classifier.weight, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.token_type_embeddings.weight, bert.embeddings.LayerNorm.weight, bert.pooler.dense.weight, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.bias, bert.pooler.dense.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.output.dense.bias, bert.embeddings.position_embeddings.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.self.query.bias, classifier.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.value.bias, classifier.weight, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.token_type_embeddings.weight, bert.embeddings.LayerNorm.weight, bert.pooler.dense.weight, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.bias, bert.pooler.dense.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.output.dense.bias, bert.embeddings.position_embeddings.weight\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m values \u001b[38;5;129;01min\u001b[39;00m product(*grid.values()):\n\u001b[32m     93\u001b[39m     config = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grid.keys(), values))\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     best_acc_run, acc_history = \u001b[43mrun_single_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     rounds_eval = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(acc_history)*\u001b[32m2\u001b[39m + \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m     96\u001b[39m     plt.plot(rounds_eval, acc_history, marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mrun_single_config\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m     58\u001b[39m trainer = TempTrainer(lr=config[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m], epochs=config[\u001b[33m'\u001b[39m\u001b[33mlocal_epochs\u001b[39m\u001b[33m'\u001b[39m], batch=config[\u001b[33m'\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cl \u001b[38;5;129;01min\u001b[39;00m clients:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     cipher = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     cipher_updates.append(cipher)\n\u001b[32m     63\u001b[39m global_state = federated_average(cipher_updates, round_key, [c[\u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m clients], global_state)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mTempTrainer.train\u001b[39m\u001b[34m(self, client_id, client_ds, global_state, round_key)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m     34\u001b[39m     opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     ids = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     mask = batch[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n\u001b[32m     37\u001b[39m     lbl = batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # HYPERPARAMETER TUNING + PLOT (ACCURACY PER ROUND)\n",
    "# # --------------------------------------------------------------\n",
    "# from itertools import product\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from torch.optim import AdamW\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from tqdm.auto import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# # --- TEMP TRAINER (NO DP) ---\n",
    "# class TempTrainer:\n",
    "#     def __init__(self, lr, epochs, batch):\n",
    "#         self.lr = lr\n",
    "#         self.epochs = epochs\n",
    "#         self.batch = batch\n",
    "\n",
    "#     def train(self, client_id, client_ds, global_state, round_key):\n",
    "#         model = get_model()\n",
    "#         model.load_state_dict(global_state)\n",
    "#         model.train()\n",
    "\n",
    "#         loader = DataLoader(client_ds, batch_size=self.batch, shuffle=True)\n",
    "#         opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "#         total_steps = len(loader) * self.epochs\n",
    "#         scheduler = get_linear_schedule_with_warmup(opt, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "#         for _ in range(self.epochs):\n",
    "#             for batch in loader:\n",
    "#                 opt.zero_grad()\n",
    "#                 ids = batch['input_ids'].to(DEVICE)\n",
    "#                 mask = batch['attention_mask'].to(DEVICE)\n",
    "#                 lbl = batch['labels'].to(DEVICE)\n",
    "#                 out = model(ids, attention_mask=mask, labels=lbl)\n",
    "#                 out.loss.backward()\n",
    "#                 opt.step()\n",
    "#                 scheduler.step()\n",
    "\n",
    "#         delta = {k: model.state_dict()[k] - global_state[k] for k in global_state}\n",
    "#         return encrypt_state(delta, round_key)\n",
    "\n",
    "# def run_single_config(config):\n",
    "#     print(f\"\\nTUNING: {config}\")\n",
    "#     sim = ClientSimulator(n_clients=config['clients'], seed=42)\n",
    "#     clients = sim.split(fold_train)\n",
    "\n",
    "#     global_state = get_model().state_dict()\n",
    "#     val_accs = []\n",
    "\n",
    "#     for rnd in range(1, config['rounds'] + 1):\n",
    "#         round_key = get_random_bytes(32)\n",
    "#         cipher_updates = []\n",
    "\n",
    "#         trainer = TempTrainer(lr=config['lr'], epochs=config['local_epochs'], batch=config['batch'])\n",
    "#         for cl in clients:\n",
    "#             cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "#             cipher_updates.append(cipher)\n",
    "\n",
    "#         global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients], global_state)\n",
    "\n",
    "#         if rnd % 2 == 0:\n",
    "#             metrics = evaluate(global_state, val_loader)\n",
    "#             val_accs.append(metrics['acc'])\n",
    "\n",
    "#     return max(val_accs), val_accs  # return best + full history\n",
    "\n",
    "# # --- GRID ---\n",
    "# grid = {\n",
    "#     'lr': [1e-5, 2e-5, 3e-5],\n",
    "#     'batch': [8, 16],\n",
    "#     'rounds': [6],\n",
    "#     'clients': [3],\n",
    "#     'local_epochs': [3]\n",
    "# }\n",
    "\n",
    "# # --- ONE FOLD ---\n",
    "# fold_idx = next(skf.split(np.zeros(len(train_ds)), train_ds.labels))\n",
    "# fold_train = Subset(train_ds, fold_idx[0])\n",
    "# fold_val = Subset(train_ds, fold_idx[1])\n",
    "# val_loader = DataLoader(fold_val, batch_size=16)\n",
    "\n",
    "# # --- RUN & PLOT ---\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# best_hp = None\n",
    "# best_acc = 0\n",
    "# all_curves = []\n",
    "\n",
    "# for values in product(*grid.values()):\n",
    "#     config = dict(zip(grid.keys(), values))\n",
    "#     best_acc_run, acc_history = run_single_config(config)\n",
    "#     rounds_eval = list(range(2, len(acc_history)*2 + 1, 2))\n",
    "#     plt.plot(rounds_eval, acc_history, marker='o', label=f\"lr={config['lr']}, batch={config['batch']}\")\n",
    "\n",
    "#     if best_acc_run > best_acc:\n",
    "#         best_acc = best_acc_run\n",
    "#         best_hp = config\n",
    "#         all_curves.append((acc_history, config))\n",
    "\n",
    "# print(f\"\\nBEST HP (NO DP): {best_hp} | Best Val Acc: {best_acc:.4f}\")\n",
    "\n",
    "# # --- Final Plot ---\n",
    "# plt.title(\"Validation Accuracy per Federated Round (Tuning)\")\n",
    "# plt.xlabel(\"Federated Round\")\n",
    "# plt.ylabel(\"Validation Accuracy\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FEDERATED TRAINING (GRADIENT-ONLY)\n",
      "\n",
      "==================== FOLD 1/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5002 | F1: 0.6667\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4998 | F1: 0.6648\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4944 | F1: 0.6294\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5000 | F1: 0.6664\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5005 | F1: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.4991 | F1: 0.0032\n",
      "\n",
      "==================== FOLD 2/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4998 | F1: 0.6664\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5000 | F1: 0.4298\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4999 | F1: 0.6666\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4999 | F1: 0.0599\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4987 | F1: 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.5005 | F1: 0.6665\n",
      "\n",
      "==================== FOLD 3/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5176 | F1: 0.1953\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5283 | F1: 0.6405\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5053 | F1: 0.6436\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5021 | F1: 0.0868\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5325 | F1: 0.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.5273 | F1: 0.5196\n",
      "\n",
      "FINAL K-FOLD: Acc 0.5090 ± 0.0130 | F1 0.3964 ± 0.2845\n"
     ]
    }
   ],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 9 – FINAL TRAINING LOOP (Cell 10) – FIXED\n",
    "# # --------------------------------------------------------------\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# N_FOLDS = 3\n",
    "# skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# HP = {\n",
    "#     'rounds': 5,\n",
    "#     'clients': 3,\n",
    "#     'local_epochs': 3,\n",
    "#     'lr': 2e-5,\n",
    "#     'batch': 8,\n",
    "#     'clip': 1.0,\n",
    "#     'noise': 0.1\n",
    "# }\n",
    "\n",
    "# print(\"STARTING FEDERATED TRAINING (GRADIENT-ONLY)\")\n",
    "\n",
    "# fold_results = []\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_ds)), train_ds.labels)):\n",
    "#     print(f\"\\n{'='*20} FOLD {fold+1}/{N_FOLDS} {'='*20}\")\n",
    "\n",
    "#     fold_train = Subset(train_ds, train_idx)\n",
    "#     fold_val   = Subset(train_ds, val_idx)\n",
    "\n",
    "#     sim = ClientSimulator(n_clients=HP['clients'])\n",
    "#     clients = sim.split(fold_train)\n",
    "\n",
    "#     global_state = get_model().state_dict()\n",
    "\n",
    "#     for rnd in range(1, HP['rounds'] + 1):\n",
    "#         print(f\"\\nROUND {rnd}/{HP['rounds']}\")\n",
    "#         round_key = get_random_bytes(32)\n",
    "#         cipher_updates = []\n",
    "\n",
    "#         # FIXED: Only pass valid args to LocalTrainer\n",
    "#         trainer = LocalTrainer(\n",
    "#             lr=HP['lr'],\n",
    "#             epochs=HP['local_epochs'],\n",
    "#             batch=HP['batch'],\n",
    "#             clip=HP['clip'],\n",
    "#             noise=HP['noise']\n",
    "#         )\n",
    "\n",
    "#         for cl in clients:\n",
    "#             cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "#             cipher_updates.append(cipher)\n",
    "\n",
    "#         global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients])\n",
    "\n",
    "#         val_metrics = evaluate(global_state, DataLoader(fold_val, batch_size=16))\n",
    "#         print(f\"  Val Acc: {val_metrics['acc']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "#     # Final test\n",
    "#     test_metrics = evaluate(global_state, test_loader)\n",
    "#     print(f\"  TEST → Acc: {test_metrics['acc']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "#     fold_results.append(test_metrics)\n",
    "\n",
    "# # Final average\n",
    "# accs = [r['acc'] for r in fold_results]\n",
    "# f1s = [r['f1'] for r in fold_results]\n",
    "# print(f\"\\nFINAL K-FOLD: Acc {np.mean(accs):.4f} ± {np.std(accs):.4f} | F1 {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4d3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
