{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9a77a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upgrading pip...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install --upgrade pip --quiet --no-cache-dir\n",
      "Installing core packages...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install numpy pandas scikit-learn matplotlib seaborn tqdm --quiet --no-cache-dir\n",
      "Installing PyTorch with CUDA...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio --quiet --no-cache-dir\n",
      "Installing HuggingFace...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install transformers datasets accelerate --quiet --no-cache-dir\n",
      "Installing privacy & text...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install opacus nltk --quiet --no-cache-dir\n",
      "Installing XAI...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install captum lime shap --quiet --no-cache-dir\n",
      "Installing encryption & PDF...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install pycryptodome reportlab --quiet --no-cache-dir\n",
      "\n",
      "ALL DONE! NOW:\n",
      "1. RESTART KERNEL\n",
      "2. Run Cell 2+\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 1 – Install ALL dependencies (SPACE-SAFE + RESTART)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import shlex\n",
    "\n",
    "def pip_install(package_cmd):\n",
    "    full_cmd = f'\"{sys.executable}\" -m pip install {package_cmd} --quiet --no-cache-dir'\n",
    "    print(f\"> {full_cmd}\")\n",
    "    get_ipython().system(full_cmd)\n",
    "\n",
    "print(\"Upgrading pip...\")\n",
    "pip_install(\"--upgrade pip\")\n",
    "\n",
    "print(\"Installing core packages...\")\n",
    "pip_install(\"numpy pandas scikit-learn matplotlib seaborn tqdm\")\n",
    "\n",
    "print(\"Installing PyTorch with CUDA...\")\n",
    "pip_install(\"--index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio\")\n",
    "\n",
    "print(\"Installing HuggingFace...\")\n",
    "pip_install(\"transformers datasets accelerate\")\n",
    "\n",
    "print(\"Installing privacy & text...\")\n",
    "pip_install(\"opacus nltk\")\n",
    "\n",
    "print(\"Installing XAI...\")\n",
    "pip_install(\"captum lime shap\")\n",
    "\n",
    "print(\"Installing encryption & PDF...\")\n",
    "pip_install(\"pycryptodome reportlab\")\n",
    "\n",
    "print(\"\\nALL DONE! NOW:\")\n",
    "print(\"1. RESTART KERNEL\")\n",
    "print(\"2. Run Cell 2+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba62a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Bubt task\\Ml-Project(new)\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f677cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "GPU name: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 1 – Imports & GPU check\n",
    "# --------------------------------------------------------------\n",
    "import os, json, random, time, warnings, string, re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, f1_score,\n",
    "                             confusion_matrix, classification_report,\n",
    "                             roc_auc_score, roc_curve, auc,\n",
    "                             precision_recall_curve)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import (BertTokenizer, BertForSequenceClassification,\n",
    "                          get_linear_schedule_with_warmup)\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# XAI\n",
    "from captum.attr import IntegratedGradients\n",
    "import lime.lime_text\n",
    "import shap\n",
    "\n",
    "# Encryption\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def seed_all(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "seed_all()\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {DEVICE}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d144d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# Cell 2.0 – Imports & GPU Check\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e57aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 2 – Text cleaning\n",
    "# --------------------------------------------------------------\n",
    "def clean_text(t):\n",
    "    if pd.isna(t): return \"\"\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r'http\\S+|www\\S+|https\\S+', '', t, flags=re.MULTILINE)\n",
    "    t = re.sub(r'<.*?>', '', t)\n",
    "    t = re.sub(r'[^a-zA-Z\\s]', '', t)\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e9682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder: data\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell: Create 'data' folder\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "print(\"Created folder: data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1c0a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data/my_reviews.csv with 500 rows\n",
      "First 5 rows:\n",
      "              review  sentiment\n",
      "0    Waste of money!          0\n",
      "1  Highly recommend!          1\n",
      "2       Never again!          0\n",
      "3         Excellent!          1\n",
      "4           Perfect!          1\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell: Create my_reviews.csv with 500 rows\n",
    "# --------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 250 positive + 250 negative = 500 rows\n",
    "pos_phrases = [\n",
    "    \"I love this!\", \"Amazing!\", \"Best ever!\", \"Highly recommend!\", \"Perfect!\",\n",
    "    \"Excellent!\", \"So happy!\", \"Great!\", \"Fantastic!\", \"Worth it!\"\n",
    "]\n",
    "neg_phrases = [\n",
    "    \"Terrible!\", \"Waste of money!\", \"Disappointing!\", \"Poor quality!\", \"Never again!\",\n",
    "    \"Bad service!\", \"Hated it!\", \"Not worth it!\", \"Broken!\", \"Misleading!\"\n",
    "]\n",
    "\n",
    "# Repeat to reach 250 each\n",
    "texts = (pos_phrases * 25) + (neg_phrases * 25)\n",
    "labels = [1] * 250 + [0] * 250\n",
    "\n",
    "# Shuffle\n",
    "combined = list(zip(texts, labels))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(combined)\n",
    "texts, labels = zip(*combined)\n",
    "\n",
    "# Save\n",
    "df = pd.DataFrame({'review': texts, 'sentiment': labels})\n",
    "df.to_csv('data/my_reviews.csv', index=False)\n",
    "print(f\"Created data/my_reviews.csv with {len(df)} rows\")\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cb8b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading IMDB...\n",
      "Downloading Yelp...\n",
      "Downloading Twitter...\n",
      "Twitter: 7093 Neg, 17849 Pos available\n",
      "Added 500 custom rows (250+250)\n",
      "Raw merged: 55593 rows\n",
      "After cleaning: 55593 rows\n",
      "Before final: Neg=27343, Pos=28250\n",
      "\n",
      "BALANCED DATASET SAVED: data/merged_dataset_balanced.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL: 50000 rows → 25,000 Negative + 25,000 Positive\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user oh let me know if you hear about whats on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after receiving a ridiculously rude private me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>getting lost in space frozen for years thats u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this was shown as part of the th edinburgh int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one of my collegue have been raving about oreg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>theo robertson has commented that waw didnt ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i saw this in a sneak two days before the offi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this is a place for really good middle eastern...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>birkenstocks with socks straw hats cargo short...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>just realized i hadnt written a review about t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  user oh let me know if you hear about whats on...          1\n",
       "1  after receiving a ridiculously rude private me...          0\n",
       "2  getting lost in space frozen for years thats u...          0\n",
       "3  this was shown as part of the th edinburgh int...          0\n",
       "4  one of my collegue have been raving about oreg...          1\n",
       "5  theo robertson has commented that waw didnt ad...          1\n",
       "6  i saw this in a sneak two days before the offi...          0\n",
       "7  this is a place for really good middle eastern...          1\n",
       "8  birkenstocks with socks straw hats cargo short...          0\n",
       "9  just realized i hadnt written a review about t...          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 3 – ROBUST 50/50 BALANCED DATASET (25k + 25k = 50k)\n",
    "# --------------------------------------------------------------\n",
    "def load_and_merge_datasets(my_csv_path='data/my_reviews.csv',\n",
    "                            target_total=50_000,\n",
    "                            custom_ratio=0.01):  # 500 rows\n",
    "    dfs = []\n",
    "\n",
    "    # ---- 1. Load public datasets ----\n",
    "    print(\"Downloading IMDB...\")\n",
    "    imdb = load_dataset('imdb', split='train')\n",
    "\n",
    "    print(\"Downloading Yelp...\")\n",
    "    yelp = load_dataset('yelp_review_full', split='train')\n",
    "\n",
    "    print(\"Downloading Twitter...\")\n",
    "    twitter_raw = load_dataset(\"cardiffnlp/tweet_eval\", name=\"sentiment\", split=\"train\")\n",
    "    twitter = twitter_raw.filter(lambda x: x['label'] != 1)\n",
    "    twitter = twitter.map(lambda x: {'text': x['text'], 'label': 0 if x['label'] == 0 else 1})\n",
    "\n",
    "    # ---- 2. Final target per class ----\n",
    "    final_per_class = target_total // 2  # 25,000\n",
    "    custom_per_class = 250  # 250 neg + 250 pos = 500\n",
    "\n",
    "    # ---- 3. IMDB: 50/50 (large enough) ----\n",
    "    df_imdb = pd.DataFrame({'review': imdb['text'], 'sentiment': imdb['label']})\n",
    "    imdb_neg = df_imdb[df_imdb['sentiment'] == 0].sample(min(10000, len(df_imdb[df_imdb['sentiment'] == 0])), random_state=42)\n",
    "    imdb_pos = df_imdb[df_imdb['sentiment'] == 1].sample(min(10000, len(df_imdb[df_imdb['sentiment'] == 1])), random_state=42)\n",
    "    dfs.append(pd.concat([imdb_neg, imdb_pos]))\n",
    "\n",
    "    # ---- 4. Yelp: 50/50 (map 0,1→0; 2,3,4→1) ----\n",
    "    df_yelp = pd.DataFrame({'review': yelp['text'], 'sentiment': yelp['label']})\n",
    "    df_yelp['sentiment'] = df_yelp['sentiment'].map(lambda x: 0 if x in [0,1] else 1)\n",
    "    yelp_neg = df_yelp[df_yelp['sentiment'] == 0].sample(min(10000, len(df_yelp[df_yelp['sentiment'] == 0])), random_state=42)\n",
    "    yelp_pos = df_yelp[df_yelp['sentiment'] == 1].sample(min(10000, len(df_yelp[df_yelp['sentiment'] == 1])), random_state=42)\n",
    "    dfs.append(pd.concat([yelp_neg, yelp_pos]))\n",
    "\n",
    "    # ---- 5. Twitter: Take ALL available (safe) ----\n",
    "    df_tw = pd.DataFrame({'review': twitter['text'], 'sentiment': twitter['label']})\n",
    "    tw_neg_count = len(df_tw[df_tw['sentiment'] == 0])\n",
    "    tw_pos_count = len(df_tw[df_tw['sentiment'] == 1])\n",
    "    print(f\"Twitter: {tw_neg_count} Neg, {tw_pos_count} Pos available\")\n",
    "    tw_neg = df_tw[df_tw['sentiment'] == 0].sample(min(tw_neg_count, 8000), random_state=42)\n",
    "    tw_pos = df_tw[df_tw['sentiment'] == 1].sample(min(tw_pos_count, 8000), random_state=42)\n",
    "    dfs.append(pd.concat([tw_neg, tw_pos]))\n",
    "\n",
    "    # ---- 6. Custom: 250 + 250 ----\n",
    "    if not os.path.exists(my_csv_path):\n",
    "        raise FileNotFoundError(f\"{my_csv_path} not found!\")\n",
    "    my = pd.read_csv(my_csv_path, usecols=['review','sentiment'])\n",
    "    my_neg = my[my['sentiment'] == 0].sample(250, random_state=42)\n",
    "    my_pos = my[my['sentiment'] == 1].sample(250, random_state=42)\n",
    "    dfs.append(pd.concat([my_neg, my_pos]))\n",
    "    print(f\"Added 500 custom rows (250+250)\")\n",
    "\n",
    "    # ---- 7. Merge & clean ----\n",
    "    full = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Raw merged: {len(full)} rows\")\n",
    "\n",
    "    full['review'] = full['review'].apply(clean_text)\n",
    "    full = full[full['review'].str.len() > 0].reset_index(drop=True)\n",
    "    print(f\"After cleaning: {len(full)} rows\")\n",
    "\n",
    "    # ---- 8. FINAL 50/50: 25k + 25k ----\n",
    "    neg = full[full['sentiment'] == 0]\n",
    "    pos = full[full['sentiment'] == 1]\n",
    "\n",
    "    print(f\"Before final: Neg={len(neg)}, Pos={len(pos)}\")\n",
    "\n",
    "    final_neg = neg.sample(final_per_class, replace=True, random_state=42) if len(neg) < final_per_class else neg.sample(final_per_class, random_state=42)\n",
    "    final_pos = pos.sample(final_per_class, replace=True, random_state=42) if len(pos) < final_per_class else pos.sample(final_per_class, random_state=42)\n",
    "\n",
    "    df_final = pd.concat([final_neg, final_pos]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# RUN + SAVE + PLOT\n",
    "# ----------------------------------------------------------------\n",
    "df_all = load_and_merge_datasets()\n",
    "\n",
    "# ---- SAVE ----\n",
    "save_path = 'data/merged_dataset_balanced.csv'\n",
    "df_all[['review', 'sentiment']].to_csv(save_path, index=False)\n",
    "print(f\"\\nBALANCED DATASET SAVED: {save_path}\")\n",
    "\n",
    "# ---- PLOT ----\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "counts = df_all['sentiment'].value_counts().sort_index()\n",
    "labels = ['Negative', 'Positive']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=labels, y=counts.values, palette='coolwarm')\n",
    "plt.title('PERFECT 50/50 BALANCE')\n",
    "plt.ylabel('Count')\n",
    "for i, v in enumerate(counts.values):\n",
    "    plt.text(i, v + 200, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(counts.values, labels=labels, autopct='%1.1f%%', colors=['#ff6666', '#66b3ff'], startangle=90)\n",
    "plt.title('50.0% | 50.0%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFINAL: {len(df_all)} rows → 25,000 Negative + 25,000 Positive\")\n",
    "print(\"First 10 rows:\")\n",
    "display(df_all[['review', 'sentiment']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995cc602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 35000 | Val: 7500 | Test: 7500\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – Train / Val / Test split\n",
    "y = df_all['sentiment'].values\n",
    "X_idx = np.arange(len(df_all))\n",
    "\n",
    "train_idx, temp_idx = train_test_split(X_idx, test_size=0.30, stratify=y, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.50, stratify=y[temp_idx], random_state=42)\n",
    "\n",
    "train_df = df_all.iloc[train_idx].reset_index(drop=True)\n",
    "val_df   = df_all.iloc[val_idx].reset_index(drop=True)\n",
    "test_df  = df_all.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5008f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Ready → Train:35000 Val:7500 Test:7500\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 5 – Tokenization + Safe Dataset\n",
    "# --------------------------------------------------------------\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "print(\"Tokenizing...\")\n",
    "tokenized_train = tokenize_batch(train_df['review'].tolist())\n",
    "tokenized_val   = tokenize_batch(val_df['review'].tolist())\n",
    "tokenized_test  = tokenize_batch(test_df['review'].tolist())\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = list(labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx].clone().detach() for k,v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "    def __len__(self): return len(self.labels)\n",
    "\n",
    "train_ds = ReviewDataset(tokenized_train, train_df['sentiment'].values)\n",
    "val_ds   = ReviewDataset(tokenized_val,   val_df['sentiment'].values)\n",
    "test_ds  = ReviewDataset(tokenized_test,  test_df['sentiment'].values)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "print(f\"Ready → Train:{len(train_ds)} Val:{len(val_ds)} Test:{len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132277af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 6 – Model Definition (with Warning Suppression)\n",
    "# --------------------------------------------------------------\n",
    "import logging\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "def get_model():\n",
    "    return BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=2,\n",
    "        problem_type=\"single_label_classification\",\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d49883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 7 – Encryption / Decryption (Weight Delta Only)\n",
    "# --------------------------------------------------------------\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "import io\n",
    "import torch\n",
    "\n",
    "def encrypt_state(delta_dict, key):\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(delta_dict, buffer)\n",
    "    data = buffer.getvalue()\n",
    "    buffer.close()\n",
    "\n",
    "    cipher = AES.new(key, AES.MODE_GCM)\n",
    "    ciphertext, tag = cipher.encrypt_and_digest(pad(data, AES.block_size))\n",
    "    \n",
    "    return {\n",
    "        'ciphertext': ciphertext,\n",
    "        'nonce': cipher.nonce,\n",
    "        'tag': tag\n",
    "    }\n",
    "\n",
    "def decrypt_state(enc, key):\n",
    "    cipher = AES.new(key, AES.MODE_GCM, nonce=enc['nonce'])\n",
    "    plaintext = cipher.decrypt(enc['ciphertext'])\n",
    "    cipher.verify(enc['tag'])\n",
    "    plaintext = unpad(plaintext, AES.block_size)\n",
    "    \n",
    "    buffer = io.BytesIO(plaintext)\n",
    "    delta_dict = torch.load(buffer, map_location='cpu')\n",
    "    buffer.close()\n",
    "    return delta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1632b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting functorch\n",
      "  Using cached functorch-2.0.0-py2.py3-none-any.whl.metadata (346 bytes)\n",
      "INFO: pip is looking at multiple versions of functorch to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached functorch-1.13.1-py2.py3-none-any.whl.metadata (353 bytes)\n",
      "  Using cached functorch-1.13.0-py2.py3-none-any.whl.metadata (353 bytes)\n",
      "\n",
      "The conflict is caused by:\n",
      "    functorch 2.0.0 depends on torch<2.1 and >=2.0\n",
      "    functorch 1.13.1 depends on torch<1.13.2 and >=1.13.1\n",
      "    functorch 1.13.0 depends on torch<1.13.1 and >=1.13.0\n",
      "\n",
      "Additionally, some packages in these conflicts have no matching distributions available for your environment:\n",
      "    torch\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install functorch==1.13.0, functorch==1.13.1 and functorch==2.0.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install functorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987e2623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opacus==1.0.2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.8 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (2.5.1+cu121)\n",
      "Requirement already satisfied: scipy>=1.2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (1.16.2)\n",
      "Requirement already satisfied: filelock in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (4.15.0)\n",
      "Requirement already satisfied: networkx in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8->opacus==1.0.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from jinja2->torch>=1.8->opacus==1.0.2) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opacus==1.0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43523c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 8 – ClientSimulator + LocalTrainer (DP-SGD: batch_size=1)\n",
    "# --------------------------------------------------------------\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from opacus import PrivacyEngine\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "# ==============================================================\n",
    "# 1. CLIENT SIMULATOR (unchanged)\n",
    "# ==============================================================\n",
    "class ClientSimulator:\n",
    "    def __init__(self, n_clients, seed=42):\n",
    "        self.n_clients = n_clients\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    def split(self, dataset):\n",
    "        n = len(dataset)\n",
    "        indices = torch.randperm(n).tolist()\n",
    "        base = n // self.n_clients\n",
    "        rem = n % self.n_clients\n",
    "        clients = []\n",
    "        start = 0\n",
    "        for i in range(self.n_clients):\n",
    "            extra = 1 if i < rem else 0\n",
    "            size = base + extra\n",
    "            end = start + size\n",
    "            clients.append({\n",
    "                'id': i,\n",
    "                'dataset': Subset(dataset, indices[start:end]),\n",
    "                'size': size\n",
    "            })\n",
    "            start = end\n",
    "        print(f\"  [Split] {n} samples → {self.n_clients} clients\")\n",
    "        for c in clients:\n",
    "            print(f\"    Client {c['id']}: {c['size']} samples\")\n",
    "        return clients\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 2. LOCAL TRAINER (DP-SGD REQUIRES batch_size=1)\n",
    "# ==============================================================\n",
    "class LocalTrainer:\n",
    "    def __init__(self, lr, epochs, clip, noise):\n",
    "        \"\"\"\n",
    "        DP-SGD with Opacus (hooks mode) requires batch_size=1.\n",
    "        We ignore 'batch' from HP to avoid errors.\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.clip = clip\n",
    "        self.noise = noise\n",
    "        self.privacy_engine = PrivacyEngine()\n",
    "\n",
    "    def train(self, client_id, client_ds, global_state, round_key):\n",
    "        model = get_model()\n",
    "        model.load_state_dict(global_state)\n",
    "        model.train()\n",
    "        model.to(DEVICE)\n",
    "\n",
    "        # DP-SGD + hooks → MUST use batch_size=1\n",
    "        loader = DataLoader(client_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "        opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "\n",
    "        if self.noise > 0:\n",
    "            print(f\"  [DP] Client {client_id} | batch_size=1 | noise={self.noise} | clip={self.clip}\")\n",
    "            model, opt, loader = self.privacy_engine.make_private(\n",
    "                module=model,\n",
    "                optimizer=opt,\n",
    "                data_loader=loader,\n",
    "                noise_multiplier=self.noise,\n",
    "                max_grad_norm=self.clip,\n",
    "                poisson_sampling=False,\n",
    "                loss_reduction=\"mean\",\n",
    "            )\n",
    "\n",
    "        total_steps = len(loader) * self.epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            opt,\n",
    "            num_warmup_steps=int(0.1 * total_steps),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        print(f\"  [Client {client_id}] Training {len(client_ds)} samples → {self.epochs} epochs\")\n",
    "        pbar = tqdm(total=total_steps, desc=f\"  C{client_id}\", leave=False)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in loader:\n",
    "                opt.zero_grad()\n",
    "\n",
    "                out = model(\n",
    "                    input_ids=batch['input_ids'].to(DEVICE),\n",
    "                    attention_mask=batch['attention_mask'].to(DEVICE),\n",
    "                    labels=batch['labels'].to(DEVICE)\n",
    "                )\n",
    "\n",
    "                loss = out.loss\n",
    "                loss.backward()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                opt.step()\n",
    "                scheduler.step()\n",
    "                pbar.update(1)\n",
    "\n",
    "            print(f\"    → Client {client_id} Epoch {epoch+1}/{self.epochs} Loss: {epoch_loss/len(loader):.4f}\")\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        # Extract clean state dict\n",
    "        base_model = model._module if self.noise > 0 else model\n",
    "        state_dict = base_model.state_dict()\n",
    "\n",
    "        # Compute delta\n",
    "        delta = {k: state_dict[k] - global_state[k] for k in global_state}\n",
    "\n",
    "        return encrypt_state(delta, round_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21686485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 9 – Federated Average (Apply Delta)\n",
    "# --------------------------------------------------------------\n",
    "def federated_average(cipher_updates, round_key, client_sizes, global_state):\n",
    "    total_size = sum(client_sizes)\n",
    "    agg_delta = None\n",
    "\n",
    "    for enc, size in zip(cipher_updates, client_sizes):\n",
    "        delta = decrypt_state(enc, round_key)\n",
    "        weight = size / total_size\n",
    "        if agg_delta is None:\n",
    "            agg_delta = {k: v * weight for k, v in delta.items()}\n",
    "        else:\n",
    "            for k in agg_delta:\n",
    "                agg_delta[k] += delta[k] * weight\n",
    "\n",
    "    model = get_model()\n",
    "    model.load_state_dict(global_state)\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in agg_delta:\n",
    "            param.data += agg_delta[name].to(DEVICE)\n",
    "\n",
    "    return model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d34bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST HYPERPARAMETERS LOADED:\n",
      "  lr: 1e-05\n",
      "  batch: 8\n",
      "  rounds: 8\n",
      "  clients: 3\n",
      "  local_epochs: 4\n"
     ]
    }
   ],
   "source": [
    "# === LOAD BEST HYPERPARAMETERS (NO TUNING) ===\n",
    "import json\n",
    "import os\n",
    "\n",
    "HP_FILE = \"best_hp.json\"\n",
    "if not os.path.exists(HP_FILE):\n",
    "    raise FileNotFoundError(f\"ERROR: {HP_FILE} not found! Place it in the same folder as the notebook.\")\n",
    "\n",
    "with open(HP_FILE) as f:\n",
    "    HP = json.load(f)\n",
    "\n",
    "print(\"BEST HYPERPARAMETERS LOADED:\")\n",
    "for k, v in HP.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Optional: Reduce for quick test\n",
    "# HP['rounds'] = 1\n",
    "# HP['clients'] = 2\n",
    "# HP['local_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f55e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved HP found → STARTING TUNING WITH EPOCH LOGS...\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:06, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:13, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:36, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:36, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8716\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:32, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:32, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:48, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:38, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:46, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:36, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8765\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:15,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:29,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:05,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:30,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 9a38d35d-d5f8-4396-bb7d-7f090bd2c112)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "11/01/2025 08:29:47:WARNING:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 9a38d35d-d5f8-4396-bb7d-7f090bd2c112)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "11/01/2025 08:29:47:WARNING:Retrying in 1s [Retry 1/5].\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 488/1461 [01:31<02:30,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:02<01:15,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:05,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8742\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:36,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:29,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:04,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:36,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:34<01:17,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 488/1948 [01:31<03:54,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:46,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:32,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:38,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:44,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:35,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:42,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:43,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:03,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:34<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:43,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:32,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:37,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:31,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:45,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:09,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:45,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:29,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8722\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:04, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:09, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:30, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:36, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:02, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:06, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:31<01:32, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:31<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8755\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:37, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:43, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:46, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:30, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:37, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:44, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:13<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:48, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:08, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8762\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:00,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 975/1461 [03:02<01:16,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:15,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:31,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:01<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:01<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8734\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 975/1948 [03:02<02:33,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:42,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:40,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:03,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:14,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:34<01:18,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:47,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:33<01:16,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:35,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:39,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 975/1948 [03:02<02:34,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:35,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:43,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:01<03:01,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:29,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:37,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:10,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:35,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:48,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:34<01:16,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:34<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8749\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:07, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:09, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:08, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:09, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:33, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:09, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:36, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:06, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8746\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:45<04:38, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:30<03:04, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:15<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:45<04:37, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:30<03:06, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:15<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:49, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:30<03:10, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:15<01:35, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:45<04:42, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:30<03:05, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:15<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:38, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:37, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:38, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:30, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:38,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:07, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:46, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:42, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:45<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:30<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:15<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:46, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:30<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:15<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8743\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:03<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:06,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:03<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:03<01:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:03<01:33,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 488/1461 [01:31<02:33,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:04,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:07,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 975/1461 [03:02<01:17,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:34,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:01<01:30,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 488/1461 [01:31<02:35,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:01<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:14,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:02<01:14,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:01<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8733\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:01<02:30,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:32<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:36,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:37,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:39,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:45,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:29,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:30,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:29,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:29,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:43,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:30,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:46,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:01<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:32<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:46,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<02:59,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8723\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED BEST HP → best_hp.json\n",
      "Best Val Acc: 0.8765\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 11 – HYPERPARAMETER TUNING (FIXED: evaluate() + LOGS + SAVE/LOAD)\n",
    "# --------------------------------------------------------------\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "TUNE_FILE = \"best_hp.json\"\n",
    "\n",
    "# --- CHECK IF ALREADY TUNED ---\n",
    "if os.path.exists(TUNE_FILE):\n",
    "    print(f\"Found {TUNE_FILE} → LOADING BEST HP (skipping tuning)\")\n",
    "    with open(TUNE_FILE, 'r') as f:\n",
    "        best_hp = json.load(f)\n",
    "    print(\"LOADED BEST HP:\")\n",
    "    for k, v in best_hp.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "else:\n",
    "    print(\"No saved HP found → STARTING TUNING WITH EPOCH LOGS...\")\n",
    "\n",
    "    # --- 1. DEFINE skf & ONE FOLD ---\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    fold_idx = next(skf.split(np.zeros(len(train_ds)), train_ds.labels))\n",
    "    tune_train = Subset(train_ds, fold_idx[0])\n",
    "    tune_val   = Subset(train_ds, fold_idx[1])\n",
    "    val_loader = DataLoader(tune_val, batch_size=16, shuffle=False)\n",
    "\n",
    "    # --- 2. EVALUATE FUNCTION (INSIDE CELL) ---\n",
    "    def evaluate(state_dict, loader):\n",
    "        model = get_model()\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                ids = batch['input_ids'].to(DEVICE)\n",
    "                mask = batch['attention_mask'].to(DEVICE)\n",
    "                labels = batch['labels'].to(DEVICE)\n",
    "                outputs = model(ids, attention_mask=mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        return {'acc': acc, 'f1': f1}\n",
    "\n",
    "    # --- 3. TUNE TRAINER WITH LOGS ---\n",
    "    class TuneTrainer:\n",
    "        def __init__(self, lr, epochs, batch):\n",
    "            self.lr = lr\n",
    "            self.epochs = epochs\n",
    "            self.batch = batch\n",
    "\n",
    "        def train(self, client_id, client_ds, global_state, round_key):\n",
    "            model = get_model()\n",
    "            model.load_state_dict(global_state)\n",
    "            model.train()\n",
    "\n",
    "            loader = DataLoader(client_ds, batch_size=self.batch, shuffle=True)\n",
    "            opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "            total_steps = len(loader) * self.epochs\n",
    "            scheduler = get_linear_schedule_with_warmup(opt, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "            print(f\"  [Client {client_id}] Training {len(client_ds)} samples → {self.epochs} epochs\")\n",
    "            pbar = tqdm(total=total_steps, desc=f\"  C{client_id}\", leave=False)\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "                epoch_loss = 0\n",
    "                for batch in loader:\n",
    "                    opt.zero_grad()\n",
    "                    out = model(\n",
    "                        input_ids=batch['input_ids'].to(DEVICE),\n",
    "                        attention_mask=batch['attention_mask'].to(DEVICE),\n",
    "                        labels=batch['labels'].to(DEVICE)\n",
    "                    )\n",
    "                    loss = out.loss\n",
    "                    loss.backward()\n",
    "                    epoch_loss += loss.item()\n",
    "                    opt.step()\n",
    "                    scheduler.step()\n",
    "                    pbar.update(1)\n",
    "\n",
    "                avg_loss = epoch_loss / len(loader)\n",
    "                print(f\"    → Client {client_id} Epoch {epoch+1}/{self.epochs} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            pbar.close()\n",
    "\n",
    "            delta = {k: model.state_dict()[k] - global_state[k] for k in global_state}\n",
    "            return encrypt_state(delta, round_key)\n",
    "\n",
    "    # --- 4. RUN CONFIG ---\n",
    "    def run_tune_config(cfg):\n",
    "        print(f\"\\nTesting Config: {cfg}\")\n",
    "        sim = ClientSimulator(n_clients=cfg['clients'], seed=42)\n",
    "        clients = sim.split(tune_train)\n",
    "        global_state = get_model().state_dict()\n",
    "        val_accs = []\n",
    "\n",
    "        for rnd in range(1, cfg['rounds'] + 1):\n",
    "            round_key = get_random_bytes(32)\n",
    "            cipher_updates = []\n",
    "\n",
    "            trainer = TuneTrainer(lr=cfg['lr'], epochs=cfg['local_epochs'], batch=cfg['batch'])\n",
    "            for cl in clients:\n",
    "                cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "                cipher_updates.append(cipher)\n",
    "\n",
    "            global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients], global_state)\n",
    "\n",
    "            if rnd % 2 == 0 or rnd == cfg['rounds']:\n",
    "                acc = evaluate(global_state, val_loader)['acc']\n",
    "                val_accs.append(acc)\n",
    "                print(f\"  → Round {rnd} Val Acc: {acc:.4f}\")\n",
    "\n",
    "        return val_accs\n",
    "\n",
    "    # --- 5. GRID ---\n",
    "    grid = {\n",
    "        'lr': [1e-5, 2e-5, 3e-5],\n",
    "        'batch': [8, 16],\n",
    "        'rounds': [8],\n",
    "        'clients': [3],\n",
    "        'local_epochs': [3, 4]\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    best_acc = 0\n",
    "    best_hp = None\n",
    "\n",
    "    for values in product(*grid.values()):\n",
    "        cfg = dict(zip(grid.keys(), values))\n",
    "        acc_history = run_tune_config(cfg)\n",
    "        rounds = list(range(2, len(acc_history)*2 + 1, 2))\n",
    "        plt.plot(rounds, acc_history, marker='o', label=f\"lr={cfg['lr']}, b={cfg['batch']}, e={cfg['local_epochs']}\")\n",
    "\n",
    "        if acc_history[-1] > best_acc:\n",
    "            best_acc = acc_history[-1]\n",
    "            best_hp = cfg\n",
    "\n",
    "    plt.title(\"Tuning: Validation Accuracy per Round\")\n",
    "    plt.xlabel(\"Federated Round\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 6. SAVE ---\n",
    "    with open(TUNE_FILE, 'w') as f:\n",
    "        json.dump(best_hp, f, indent=2)\n",
    "    print(f\"\\nSAVED BEST HP → {TUNE_FILE}\")\n",
    "    print(f\"Best Val Acc: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81554cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FEDERATED TRAINING (DP-SGD + ENCRYPTION)\n",
      "\n",
      "========================= FOLD 1/3 =========================\n",
      "  [Split] 23333 samples → 3 clients\n",
      "    Client 0: 7778 samples\n",
      "    Client 1: 7778 samples\n",
      "    Client 2: 7777 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: classifier.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.value.weight, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.attention.output.dense.weight, bert.pooler.dense.bias, classifier.bias, bert.encoder.layer.*.output.dense.weight, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.output.dense.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.self.query.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Round 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: classifier.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.value.weight, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.attention.output.dense.weight, bert.pooler.dense.bias, classifier.bias, bert.encoder.layer.*.output.dense.weight, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.output.dense.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.self.query.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [DP] Client 0 | batch_size=1 | noise=0.1 | clip=1.0\n",
      "  [Client 0] Training 7778 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.7180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m cipher_updates = []\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cl \u001b[38;5;129;01min\u001b[39;00m clients:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     cipher = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     cipher_updates.append(cipher)\n\u001b[32m     42\u001b[39m global_state = federated_average(cipher_updates, round_key, [c[\u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m clients])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mLocalTrainer.train\u001b[39m\u001b[34m(self, client_id, client_ds, global_state, round_key)\u001b[39m\n\u001b[32m    102\u001b[39m loss = out.loss\n\u001b[32m    103\u001b[39m loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m epoch_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m opt.step()\n\u001b[32m    107\u001b[39m scheduler.step()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# CELL 10: FINAL FEDERATED TRAINING (DP-SGD: batch_size=1)\n",
    "# =====================================================\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "N_FOLDS = 3\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"STARTING FEDERATED TRAINING (DP-SGD + ENCRYPTION)\")\n",
    "\n",
    "fold_results = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_ds)), train_ds.labels)):\n",
    "    print(f\"\\n{'='*25} FOLD {fold+1}/{N_FOLDS} {'='*25}\")\n",
    "\n",
    "    fold_train = Subset(train_ds, train_idx)\n",
    "    fold_val   = Subset(train_ds, val_idx)\n",
    "\n",
    "    sim = ClientSimulator(n_clients=HP['clients'])\n",
    "    clients = sim.split(fold_train)\n",
    "\n",
    "    global_state = get_model().state_dict()\n",
    "\n",
    "    # DP-SGD: batch_size=1 enforced in LocalTrainer\n",
    "    trainer = LocalTrainer(\n",
    "        lr=HP['lr'],\n",
    "        epochs=HP['local_epochs'],\n",
    "        clip=1.0,\n",
    "        noise=0.1\n",
    "    )\n",
    "\n",
    "    for rnd in range(1, HP['rounds'] + 1):\n",
    "        print(f\"  Round {rnd}/{HP['rounds']}\")\n",
    "        round_key = get_random_bytes(32)\n",
    "        cipher_updates = []\n",
    "\n",
    "        for cl in clients:\n",
    "            cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "            cipher_updates.append(cipher)\n",
    "\n",
    "        global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients])\n",
    "\n",
    "        val_loader = DataLoader(fold_val, batch_size=16, shuffle=False)\n",
    "        val_metrics = evaluate(global_state, val_loader)\n",
    "        print(f\"    Val → Acc: {val_metrics['acc']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "    test_metrics = evaluate(global_state, test_loader)\n",
    "    print(f\"    TEST → Acc: {test_metrics['acc']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "    fold_results.append(test_metrics)\n",
    "\n",
    "# Final Summary\n",
    "accs = [r['acc'] for r in fold_results]\n",
    "f1s = [r['f1'] for r in fold_results]\n",
    "print(f\"\\nFINAL K-FOLD RESULT:\")\n",
    "print(f\"  Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"  F1-Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ede8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 12 – FULL VISUALIZATION (Accuracy, CM, ROC, AUC, Distribution)\n",
    "# --------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# --- 1. COLLECT PREDICTIONS FROM ALL FOLDS ---\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "print(\"Collecting predictions from all folds...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_ds)), train_ds.labels)):\n",
    "    fold_test = Subset(train_ds, val_idx)  # using val as \"test\" for viz\n",
    "    test_loader = DataLoader(fold_test, batch_size=8, shuffle=False)\n",
    "    \n",
    "    model = get_model()\n",
    "    model.load_state_dict(global_state)  # use final global model\n",
    "    model.eval()\n",
    "    \n",
    "    fold_preds = []\n",
    "    fold_labels = []\n",
    "    fold_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            \n",
    "            outputs = model(ids, attention_mask=mask)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            fold_preds.extend(preds.cpu().numpy())\n",
    "            fold_labels.extend(labels.cpu().numpy())\n",
    "            fold_probs.extend(probs[:, 1].cpu().numpy())  # prob of positive class\n",
    "    \n",
    "    all_preds.append(fold_preds)\n",
    "    all_labels.append(fold_labels)\n",
    "    all_probs.append(fold_probs)\n",
    "\n",
    "# --- 2. ACCURACY & F1 PER FOLD ---\n",
    "fold_accs = [accuracy_score(all_labels[i], all_preds[i]) for i in range(N_FOLDS)]\n",
    "fold_f1s  = [f1_score(all_labels[i], all_preds[i]) for i in range(N_FOLDS)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].bar(range(1, N_FOLDS+1), fold_accs, color='skyblue', edgecolor='navy')\n",
    "ax[0].set_title(\"Accuracy per Fold\")\n",
    "ax[0].set_xlabel(\"Fold\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "ax[0].set_ylim(0, 1)\n",
    "\n",
    "ax[1].bar(range(1, N_FOLDS+1), fold_f1s, color='lightcoral', edgecolor='darkred')\n",
    "ax[1].set_title(\"F1-Score per Fold\")\n",
    "ax[1].set_xlabel(\"Fold\")\n",
    "ax[1].set_ylabel(\"F1\")\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle(\"Performance per Fold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accs):.4f} ± {np.std(fold_accs):.4f}\")\n",
    "print(f\"Mean F1-Score: {np.mean(fold_f1s):.4f} ± {np.std(fold_f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/accuracy_f1.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. CONFUSION MATRIX (AVERAGE + PER FOLD) ---\n",
    "fig, axes = plt.subplots(1, N_FOLDS + 1, figsize=(4*(N_FOLDS + 1), 4))\n",
    "cm_avg = np.zeros((2, 2))\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    cm = confusion_matrix(all_labels[i], all_preds[i])\n",
    "    cm_avg += cm\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'])\n",
    "    axes[i].set_title(f\"Fold {i+1} CM\")\n",
    "    axes[i].set_xlabel(\"Predicted\")\n",
    "    axes[i].set_ylabel(\"True\")\n",
    "\n",
    "# Average CM\n",
    "cm_avg = (cm_avg / N_FOLDS).astype(int)\n",
    "sns.heatmap(cm_avg, annot=True, fmt='d', cmap='Greens', ax=axes[-1],\n",
    "            xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'])\n",
    "axes[-1].set_title(\"Average CM\")\n",
    "axes[-1].set_xlabel(\"Predicted\")\n",
    "axes[-1].set_ylabel(\"True\")\n",
    "\n",
    "plt.suptitle(\"Confusion Matrices\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/confusion_metrics.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53bab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. DATASET CLASS DISTRIBUTION (CORRELATION-STYLE) ---\n",
    "labels_all = [lbl for fold in all_labels for lbl in fold]\n",
    "df_dist = pd.DataFrame({\n",
    "    'Dataset': 'Train+Val',\n",
    "    'Sentiment': ['Positive' if x == 1 else 'Negative' for x in labels_all]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df_dist, x='Sentiment', palette='viridis')\n",
    "plt.title(\"Dataset Class Distribution\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Positive: {sum(labels_all)} | Negative: {len(labels_all) - sum(labels_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/corelation.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. ROC CURVE & AUC (ALL FOLDS) ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    fpr, tpr, _ = roc_curve(all_labels[i], all_probs[i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.7, label=f'Fold {i+1} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    # Interpolate for mean\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "\n",
    "# Mean ROC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='darkorange', lw=3,\n",
    "         label=f'Mean ROC (AUC = {mean_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (3-Fold Cross-Validation)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean AUC: {mean_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/auc-roc.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 7 – evaluate function (ROBUST + BERT-COMPATIBLE)\n",
    "# # --------------------------------------------------------------\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import numpy as np\n",
    "\n",
    "# def evaluate(model_state, loader):\n",
    "#     \"\"\"\n",
    "#     Evaluates a global model state on a DataLoader.\n",
    "#     Returns accuracy and F1.\n",
    "#     \"\"\"\n",
    "#     model = get_model()\n",
    "#     model.load_state_dict(model_state)\n",
    "#     model.eval()\n",
    "\n",
    "#     all_preds, all_labels = [], []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in loader:\n",
    "#             ids = batch['input_ids'].to(DEVICE)\n",
    "#             mask = batch['attention_mask'].to(DEVICE)\n",
    "#             labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "#             # ← PASS labels (required by BERT, ignored in eval)\n",
    "#             outputs = model(ids, attention_mask=mask, labels=labels)\n",
    "#             preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     acc = accuracy_score(all_labels, all_preds)\n",
    "#     f1 = f1_score(all_labels, all_preds, average='binary')  # ← explicit for binary\n",
    "#     return {'acc': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 8 – ClientSimulator (REPRODUCIBLE + FAIR)\n",
    "# # --------------------------------------------------------------\n",
    "# import torch\n",
    "# from torch.utils.data import Subset\n",
    "# import random\n",
    "\n",
    "# # Optional: set seed once at top of notebook\n",
    "# # torch.manual_seed(42); random.seed(42); np.random.seed(42)\n",
    "\n",
    "# class ClientSimulator:\n",
    "#     def __init__(self, n_clients, seed=42):\n",
    "#         self.n_clients = n_clients\n",
    "#         self.seed = seed\n",
    "#         self.rng = torch.Generator().manual_seed(seed)\n",
    "\n",
    "#     def split(self, dataset):\n",
    "#         \"\"\"\n",
    "#         Splits dataset into n_clients subsets.\n",
    "#         Uses torch.randperm → reproducible + fair.\n",
    "#         \"\"\"\n",
    "#         n = len(dataset)\n",
    "#         indices = torch.randperm(n, generator=self.rng).tolist()  # ← REPRODUCIBLE\n",
    "#         per_client = n // self.n_clients\n",
    "#         clients = []\n",
    "\n",
    "#         for i in range(self.n_clients):\n",
    "#             start = i * per_client\n",
    "#             end = (i + 1) * per_client if i < self.n_clients - 1 else n\n",
    "#             client_idx = indices[start:end]\n",
    "#             clients.append({\n",
    "#                 'id': i,\n",
    "#                 'dataset': Subset(dataset, client_idx),\n",
    "#                 'size': len(client_idx)\n",
    "#             })\n",
    "#         return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0048bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TUNING: {'lr': 1e-05, 'batch': 8, 'rounds': 6, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.self.query.bias, classifier.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.value.bias, classifier.weight, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.token_type_embeddings.weight, bert.embeddings.LayerNorm.weight, bert.pooler.dense.weight, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.bias, bert.pooler.dense.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.output.dense.bias, bert.embeddings.position_embeddings.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.self.query.bias, classifier.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.value.bias, classifier.weight, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.token_type_embeddings.weight, bert.embeddings.LayerNorm.weight, bert.pooler.dense.weight, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.bias, bert.pooler.dense.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.output.dense.bias, bert.embeddings.position_embeddings.weight\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m values \u001b[38;5;129;01min\u001b[39;00m product(*grid.values()):\n\u001b[32m     93\u001b[39m     config = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grid.keys(), values))\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     best_acc_run, acc_history = \u001b[43mrun_single_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     rounds_eval = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(acc_history)*\u001b[32m2\u001b[39m + \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m     96\u001b[39m     plt.plot(rounds_eval, acc_history, marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mrun_single_config\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m     58\u001b[39m trainer = TempTrainer(lr=config[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m], epochs=config[\u001b[33m'\u001b[39m\u001b[33mlocal_epochs\u001b[39m\u001b[33m'\u001b[39m], batch=config[\u001b[33m'\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cl \u001b[38;5;129;01min\u001b[39;00m clients:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     cipher = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     cipher_updates.append(cipher)\n\u001b[32m     63\u001b[39m global_state = federated_average(cipher_updates, round_key, [c[\u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m clients], global_state)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mTempTrainer.train\u001b[39m\u001b[34m(self, client_id, client_ds, global_state, round_key)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m     34\u001b[39m     opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     ids = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     mask = batch[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n\u001b[32m     37\u001b[39m     lbl = batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # HYPERPARAMETER TUNING + PLOT (ACCURACY PER ROUND)\n",
    "# # --------------------------------------------------------------\n",
    "# from itertools import product\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from torch.optim import AdamW\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from tqdm.auto import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# # --- TEMP TRAINER (NO DP) ---\n",
    "# class TempTrainer:\n",
    "#     def __init__(self, lr, epochs, batch):\n",
    "#         self.lr = lr\n",
    "#         self.epochs = epochs\n",
    "#         self.batch = batch\n",
    "\n",
    "#     def train(self, client_id, client_ds, global_state, round_key):\n",
    "#         model = get_model()\n",
    "#         model.load_state_dict(global_state)\n",
    "#         model.train()\n",
    "\n",
    "#         loader = DataLoader(client_ds, batch_size=self.batch, shuffle=True)\n",
    "#         opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "#         total_steps = len(loader) * self.epochs\n",
    "#         scheduler = get_linear_schedule_with_warmup(opt, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "#         for _ in range(self.epochs):\n",
    "#             for batch in loader:\n",
    "#                 opt.zero_grad()\n",
    "#                 ids = batch['input_ids'].to(DEVICE)\n",
    "#                 mask = batch['attention_mask'].to(DEVICE)\n",
    "#                 lbl = batch['labels'].to(DEVICE)\n",
    "#                 out = model(ids, attention_mask=mask, labels=lbl)\n",
    "#                 out.loss.backward()\n",
    "#                 opt.step()\n",
    "#                 scheduler.step()\n",
    "\n",
    "#         delta = {k: model.state_dict()[k] - global_state[k] for k in global_state}\n",
    "#         return encrypt_state(delta, round_key)\n",
    "\n",
    "# def run_single_config(config):\n",
    "#     print(f\"\\nTUNING: {config}\")\n",
    "#     sim = ClientSimulator(n_clients=config['clients'], seed=42)\n",
    "#     clients = sim.split(fold_train)\n",
    "\n",
    "#     global_state = get_model().state_dict()\n",
    "#     val_accs = []\n",
    "\n",
    "#     for rnd in range(1, config['rounds'] + 1):\n",
    "#         round_key = get_random_bytes(32)\n",
    "#         cipher_updates = []\n",
    "\n",
    "#         trainer = TempTrainer(lr=config['lr'], epochs=config['local_epochs'], batch=config['batch'])\n",
    "#         for cl in clients:\n",
    "#             cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "#             cipher_updates.append(cipher)\n",
    "\n",
    "#         global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients], global_state)\n",
    "\n",
    "#         if rnd % 2 == 0:\n",
    "#             metrics = evaluate(global_state, val_loader)\n",
    "#             val_accs.append(metrics['acc'])\n",
    "\n",
    "#     return max(val_accs), val_accs  # return best + full history\n",
    "\n",
    "# # --- GRID ---\n",
    "# grid = {\n",
    "#     'lr': [1e-5, 2e-5, 3e-5],\n",
    "#     'batch': [8, 16],\n",
    "#     'rounds': [6],\n",
    "#     'clients': [3],\n",
    "#     'local_epochs': [3]\n",
    "# }\n",
    "\n",
    "# # --- ONE FOLD ---\n",
    "# fold_idx = next(skf.split(np.zeros(len(train_ds)), train_ds.labels))\n",
    "# fold_train = Subset(train_ds, fold_idx[0])\n",
    "# fold_val = Subset(train_ds, fold_idx[1])\n",
    "# val_loader = DataLoader(fold_val, batch_size=16)\n",
    "\n",
    "# # --- RUN & PLOT ---\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# best_hp = None\n",
    "# best_acc = 0\n",
    "# all_curves = []\n",
    "\n",
    "# for values in product(*grid.values()):\n",
    "#     config = dict(zip(grid.keys(), values))\n",
    "#     best_acc_run, acc_history = run_single_config(config)\n",
    "#     rounds_eval = list(range(2, len(acc_history)*2 + 1, 2))\n",
    "#     plt.plot(rounds_eval, acc_history, marker='o', label=f\"lr={config['lr']}, batch={config['batch']}\")\n",
    "\n",
    "#     if best_acc_run > best_acc:\n",
    "#         best_acc = best_acc_run\n",
    "#         best_hp = config\n",
    "#         all_curves.append((acc_history, config))\n",
    "\n",
    "# print(f\"\\nBEST HP (NO DP): {best_hp} | Best Val Acc: {best_acc:.4f}\")\n",
    "\n",
    "# # --- Final Plot ---\n",
    "# plt.title(\"Validation Accuracy per Federated Round (Tuning)\")\n",
    "# plt.xlabel(\"Federated Round\")\n",
    "# plt.ylabel(\"Validation Accuracy\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FEDERATED TRAINING (GRADIENT-ONLY)\n",
      "\n",
      "==================== FOLD 1/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5002 | F1: 0.6667\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4998 | F1: 0.6648\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4944 | F1: 0.6294\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5000 | F1: 0.6664\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5005 | F1: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.4991 | F1: 0.0032\n",
      "\n",
      "==================== FOLD 2/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4998 | F1: 0.6664\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5000 | F1: 0.4298\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4999 | F1: 0.6666\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4999 | F1: 0.0599\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4987 | F1: 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.5005 | F1: 0.6665\n",
      "\n",
      "==================== FOLD 3/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5176 | F1: 0.1953\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5283 | F1: 0.6405\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5053 | F1: 0.6436\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5021 | F1: 0.0868\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5325 | F1: 0.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.5273 | F1: 0.5196\n",
      "\n",
      "FINAL K-FOLD: Acc 0.5090 ± 0.0130 | F1 0.3964 ± 0.2845\n"
     ]
    }
   ],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 9 – FINAL TRAINING LOOP (Cell 10) – FIXED\n",
    "# # --------------------------------------------------------------\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# N_FOLDS = 3\n",
    "# skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# HP = {\n",
    "#     'rounds': 5,\n",
    "#     'clients': 3,\n",
    "#     'local_epochs': 3,\n",
    "#     'lr': 2e-5,\n",
    "#     'batch': 8,\n",
    "#     'clip': 1.0,\n",
    "#     'noise': 0.1\n",
    "# }\n",
    "\n",
    "# print(\"STARTING FEDERATED TRAINING (GRADIENT-ONLY)\")\n",
    "\n",
    "# fold_results = []\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_ds)), train_ds.labels)):\n",
    "#     print(f\"\\n{'='*20} FOLD {fold+1}/{N_FOLDS} {'='*20}\")\n",
    "\n",
    "#     fold_train = Subset(train_ds, train_idx)\n",
    "#     fold_val   = Subset(train_ds, val_idx)\n",
    "\n",
    "#     sim = ClientSimulator(n_clients=HP['clients'])\n",
    "#     clients = sim.split(fold_train)\n",
    "\n",
    "#     global_state = get_model().state_dict()\n",
    "\n",
    "#     for rnd in range(1, HP['rounds'] + 1):\n",
    "#         print(f\"\\nROUND {rnd}/{HP['rounds']}\")\n",
    "#         round_key = get_random_bytes(32)\n",
    "#         cipher_updates = []\n",
    "\n",
    "#         # FIXED: Only pass valid args to LocalTrainer\n",
    "#         trainer = LocalTrainer(\n",
    "#             lr=HP['lr'],\n",
    "#             epochs=HP['local_epochs'],\n",
    "#             batch=HP['batch'],\n",
    "#             clip=HP['clip'],\n",
    "#             noise=HP['noise']\n",
    "#         )\n",
    "\n",
    "#         for cl in clients:\n",
    "#             cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "#             cipher_updates.append(cipher)\n",
    "\n",
    "#         global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients])\n",
    "\n",
    "#         val_metrics = evaluate(global_state, DataLoader(fold_val, batch_size=16))\n",
    "#         print(f\"  Val Acc: {val_metrics['acc']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "#     # Final test\n",
    "#     test_metrics = evaluate(global_state, test_loader)\n",
    "#     print(f\"  TEST → Acc: {test_metrics['acc']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "#     fold_results.append(test_metrics)\n",
    "\n",
    "# # Final average\n",
    "# accs = [r['acc'] for r in fold_results]\n",
    "# f1s = [r['f1'] for r in fold_results]\n",
    "# print(f\"\\nFINAL K-FOLD: Acc {np.mean(accs):.4f} ± {np.std(accs):.4f} | F1 {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4d3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
