{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9a77a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upgrading pip...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install --upgrade pip --quiet --no-cache-dir\n",
      "Installing core packages...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install numpy pandas scikit-learn matplotlib seaborn tqdm --quiet --no-cache-dir\n",
      "Installing PyTorch with CUDA...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio --quiet --no-cache-dir\n",
      "Installing HuggingFace...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install transformers datasets accelerate --quiet --no-cache-dir\n",
      "Installing privacy & text...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install opacus nltk --quiet --no-cache-dir\n",
      "Installing XAI...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install captum lime shap --quiet --no-cache-dir\n",
      "Installing encryption & PDF...\n",
      "> \"e:\\Bubt task\\Ml-Project(new)\\venv\\Scripts\\python.exe\" -m pip install pycryptodome reportlab --quiet --no-cache-dir\n",
      "\n",
      "ALL DONE! NOW:\n",
      "1. RESTART KERNEL\n",
      "2. Run Cell 2+\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 1 – Install ALL dependencies (SPACE-SAFE + RESTART)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import shlex\n",
    "\n",
    "def pip_install(package_cmd):\n",
    "    full_cmd = f'\"{sys.executable}\" -m pip install {package_cmd} --quiet --no-cache-dir'\n",
    "    print(f\"> {full_cmd}\")\n",
    "    get_ipython().system(full_cmd)\n",
    "\n",
    "print(\"Upgrading pip...\")\n",
    "pip_install(\"--upgrade pip\")\n",
    "\n",
    "print(\"Installing core packages...\")\n",
    "pip_install(\"numpy pandas scikit-learn matplotlib seaborn tqdm\")\n",
    "\n",
    "print(\"Installing PyTorch with CUDA...\")\n",
    "pip_install(\"--index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio\")\n",
    "\n",
    "print(\"Installing HuggingFace...\")\n",
    "pip_install(\"transformers datasets accelerate\")\n",
    "\n",
    "print(\"Installing privacy & text...\")\n",
    "pip_install(\"opacus nltk\")\n",
    "\n",
    "print(\"Installing XAI...\")\n",
    "pip_install(\"captum lime shap\")\n",
    "\n",
    "print(\"Installing encryption & PDF...\")\n",
    "pip_install(\"pycryptodome reportlab\")\n",
    "\n",
    "print(\"\\nALL DONE! NOW:\")\n",
    "print(\"1. RESTART KERNEL\")\n",
    "print(\"2. Run Cell 2+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f8acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: tqdm in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pycryptodome in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (3.23.0)\n",
      "Requirement already satisfied: matplotlib in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: filelock in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: colorama in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from requests->transformers) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "# CELL 1 – INSTALL (run & restart kernel)\n",
    "!pip install torch transformers tqdm scikit-learn pycryptodome matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba62a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Bubt task\\Ml-Project(new)\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f677cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "GPU name: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 1 – Imports & GPU check\n",
    "# --------------------------------------------------------------\n",
    "import os, json, random, time, warnings, string, re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (accuracy_score, f1_score,\n",
    "                             confusion_matrix, classification_report,\n",
    "                             roc_auc_score, roc_curve, auc,\n",
    "                             precision_recall_curve)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import (BertTokenizer, BertForSequenceClassification,\n",
    "                          get_linear_schedule_with_warmup)\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# XAI\n",
    "from captum.attr import IntegratedGradients\n",
    "import lime.lime_text\n",
    "import shap\n",
    "\n",
    "# Encryption\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def seed_all(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "seed_all()\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {DEVICE}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d144d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# Cell 2.0 – Imports & GPU Check\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e57aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 2 – Text cleaning\n",
    "# --------------------------------------------------------------\n",
    "def clean_text(t):\n",
    "    if pd.isna(t): return \"\"\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r'http\\S+|www\\S+|https\\S+', '', t, flags=re.MULTILINE)\n",
    "    t = re.sub(r'<.*?>', '', t)\n",
    "    t = re.sub(r'[^a-zA-Z\\s]', '', t)\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e9682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder: data\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell: Create 'data' folder\n",
    "# --------------------------------------------------------------\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "print(\"Created folder: data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1c0a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data/my_reviews.csv with 500 rows\n",
      "First 5 rows:\n",
      "              review  sentiment\n",
      "0    Waste of money!          0\n",
      "1  Highly recommend!          1\n",
      "2       Never again!          0\n",
      "3         Excellent!          1\n",
      "4           Perfect!          1\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell: Create my_reviews.csv with 500 rows\n",
    "# --------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 250 positive + 250 negative = 500 rows\n",
    "pos_phrases = [\n",
    "    \"I love this!\", \"Amazing!\", \"Best ever!\", \"Highly recommend!\", \"Perfect!\",\n",
    "    \"Excellent!\", \"So happy!\", \"Great!\", \"Fantastic!\", \"Worth it!\"\n",
    "]\n",
    "neg_phrases = [\n",
    "    \"Terrible!\", \"Waste of money!\", \"Disappointing!\", \"Poor quality!\", \"Never again!\",\n",
    "    \"Bad service!\", \"Hated it!\", \"Not worth it!\", \"Broken!\", \"Misleading!\"\n",
    "]\n",
    "\n",
    "# Repeat to reach 250 each\n",
    "texts = (pos_phrases * 25) + (neg_phrases * 25)\n",
    "labels = [1] * 250 + [0] * 250\n",
    "\n",
    "# Shuffle\n",
    "combined = list(zip(texts, labels))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(combined)\n",
    "texts, labels = zip(*combined)\n",
    "\n",
    "# Save\n",
    "df = pd.DataFrame({'review': texts, 'sentiment': labels})\n",
    "df.to_csv('data/my_reviews.csv', index=False)\n",
    "print(f\"Created data/my_reviews.csv with {len(df)} rows\")\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cb8b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading IMDB...\n",
      "Downloading Yelp...\n",
      "Downloading Twitter...\n",
      "Twitter: 7093 Neg, 17849 Pos available\n",
      "Added 500 custom rows (250+250)\n",
      "Raw merged: 55593 rows\n",
      "After cleaning: 55593 rows\n",
      "Before final: Neg=27343, Pos=28250\n",
      "\n",
      "BALANCED DATASET SAVED: data/merged_dataset_balanced.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL: 50000 rows → 25,000 Negative + 25,000 Positive\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user oh let me know if you hear about whats on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after receiving a ridiculously rude private me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>getting lost in space frozen for years thats u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this was shown as part of the th edinburgh int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one of my collegue have been raving about oreg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>theo robertson has commented that waw didnt ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i saw this in a sneak two days before the offi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this is a place for really good middle eastern...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>birkenstocks with socks straw hats cargo short...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>just realized i hadnt written a review about t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  user oh let me know if you hear about whats on...          1\n",
       "1  after receiving a ridiculously rude private me...          0\n",
       "2  getting lost in space frozen for years thats u...          0\n",
       "3  this was shown as part of the th edinburgh int...          0\n",
       "4  one of my collegue have been raving about oreg...          1\n",
       "5  theo robertson has commented that waw didnt ad...          1\n",
       "6  i saw this in a sneak two days before the offi...          0\n",
       "7  this is a place for really good middle eastern...          1\n",
       "8  birkenstocks with socks straw hats cargo short...          0\n",
       "9  just realized i hadnt written a review about t...          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 3 – ROBUST 50/50 BALANCED DATASET (25k + 25k = 50k)\n",
    "# --------------------------------------------------------------\n",
    "def load_and_merge_datasets(my_csv_path='data/my_reviews.csv',\n",
    "                            target_total=50_000,\n",
    "                            custom_ratio=0.01):  # 500 rows\n",
    "    dfs = []\n",
    "\n",
    "    # ---- 1. Load public datasets ----\n",
    "    print(\"Downloading IMDB...\")\n",
    "    imdb = load_dataset('imdb', split='train')\n",
    "\n",
    "    print(\"Downloading Yelp...\")\n",
    "    yelp = load_dataset('yelp_review_full', split='train')\n",
    "\n",
    "    print(\"Downloading Twitter...\")\n",
    "    twitter_raw = load_dataset(\"cardiffnlp/tweet_eval\", name=\"sentiment\", split=\"train\")\n",
    "    twitter = twitter_raw.filter(lambda x: x['label'] != 1)\n",
    "    twitter = twitter.map(lambda x: {'text': x['text'], 'label': 0 if x['label'] == 0 else 1})\n",
    "\n",
    "    # ---- 2. Final target per class ----\n",
    "    final_per_class = target_total // 2  # 25,000\n",
    "    custom_per_class = 250  # 250 neg + 250 pos = 500\n",
    "\n",
    "    # ---- 3. IMDB: 50/50 (large enough) ----\n",
    "    df_imdb = pd.DataFrame({'review': imdb['text'], 'sentiment': imdb['label']})\n",
    "    imdb_neg = df_imdb[df_imdb['sentiment'] == 0].sample(min(10000, len(df_imdb[df_imdb['sentiment'] == 0])), random_state=42)\n",
    "    imdb_pos = df_imdb[df_imdb['sentiment'] == 1].sample(min(10000, len(df_imdb[df_imdb['sentiment'] == 1])), random_state=42)\n",
    "    dfs.append(pd.concat([imdb_neg, imdb_pos]))\n",
    "\n",
    "    # ---- 4. Yelp: 50/50 (map 0,1→0; 2,3,4→1) ----\n",
    "    df_yelp = pd.DataFrame({'review': yelp['text'], 'sentiment': yelp['label']})\n",
    "    df_yelp['sentiment'] = df_yelp['sentiment'].map(lambda x: 0 if x in [0,1] else 1)\n",
    "    yelp_neg = df_yelp[df_yelp['sentiment'] == 0].sample(min(10000, len(df_yelp[df_yelp['sentiment'] == 0])), random_state=42)\n",
    "    yelp_pos = df_yelp[df_yelp['sentiment'] == 1].sample(min(10000, len(df_yelp[df_yelp['sentiment'] == 1])), random_state=42)\n",
    "    dfs.append(pd.concat([yelp_neg, yelp_pos]))\n",
    "\n",
    "    # ---- 5. Twitter: Take ALL available (safe) ----\n",
    "    df_tw = pd.DataFrame({'review': twitter['text'], 'sentiment': twitter['label']})\n",
    "    tw_neg_count = len(df_tw[df_tw['sentiment'] == 0])\n",
    "    tw_pos_count = len(df_tw[df_tw['sentiment'] == 1])\n",
    "    print(f\"Twitter: {tw_neg_count} Neg, {tw_pos_count} Pos available\")\n",
    "    tw_neg = df_tw[df_tw['sentiment'] == 0].sample(min(tw_neg_count, 8000), random_state=42)\n",
    "    tw_pos = df_tw[df_tw['sentiment'] == 1].sample(min(tw_pos_count, 8000), random_state=42)\n",
    "    dfs.append(pd.concat([tw_neg, tw_pos]))\n",
    "\n",
    "    # ---- 6. Custom: 250 + 250 ----\n",
    "    if not os.path.exists(my_csv_path):\n",
    "        raise FileNotFoundError(f\"{my_csv_path} not found!\")\n",
    "    my = pd.read_csv(my_csv_path, usecols=['review','sentiment'])\n",
    "    my_neg = my[my['sentiment'] == 0].sample(250, random_state=42)\n",
    "    my_pos = my[my['sentiment'] == 1].sample(250, random_state=42)\n",
    "    dfs.append(pd.concat([my_neg, my_pos]))\n",
    "    print(f\"Added 500 custom rows (250+250)\")\n",
    "\n",
    "    # ---- 7. Merge & clean ----\n",
    "    full = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Raw merged: {len(full)} rows\")\n",
    "\n",
    "    full['review'] = full['review'].apply(clean_text)\n",
    "    full = full[full['review'].str.len() > 0].reset_index(drop=True)\n",
    "    print(f\"After cleaning: {len(full)} rows\")\n",
    "\n",
    "    # ---- 8. FINAL 50/50: 25k + 25k ----\n",
    "    neg = full[full['sentiment'] == 0]\n",
    "    pos = full[full['sentiment'] == 1]\n",
    "\n",
    "    print(f\"Before final: Neg={len(neg)}, Pos={len(pos)}\")\n",
    "\n",
    "    final_neg = neg.sample(final_per_class, replace=True, random_state=42) if len(neg) < final_per_class else neg.sample(final_per_class, random_state=42)\n",
    "    final_pos = pos.sample(final_per_class, replace=True, random_state=42) if len(pos) < final_per_class else pos.sample(final_per_class, random_state=42)\n",
    "\n",
    "    df_final = pd.concat([final_neg, final_pos]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# RUN + SAVE + PLOT\n",
    "# ----------------------------------------------------------------\n",
    "df_all = load_and_merge_datasets()\n",
    "\n",
    "# ---- SAVE ----\n",
    "save_path = 'data/merged_dataset_balanced.csv'\n",
    "df_all[['review', 'sentiment']].to_csv(save_path, index=False)\n",
    "print(f\"\\nBALANCED DATASET SAVED: {save_path}\")\n",
    "\n",
    "# ---- PLOT ----\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "counts = df_all['sentiment'].value_counts().sort_index()\n",
    "labels = ['Negative', 'Positive']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=labels, y=counts.values, palette='coolwarm')\n",
    "plt.title('PERFECT 50/50 BALANCE')\n",
    "plt.ylabel('Count')\n",
    "for i, v in enumerate(counts.values):\n",
    "    plt.text(i, v + 200, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(counts.values, labels=labels, autopct='%1.1f%%', colors=['#ff6666', '#66b3ff'], startangle=90)\n",
    "plt.title('50.0% | 50.0%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFINAL: {len(df_all)} rows → 25,000 Negative + 25,000 Positive\")\n",
    "print(\"First 10 rows:\")\n",
    "display(df_all[['review', 'sentiment']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995cc602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 35000 | Val: 7500 | Test: 7500\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – Train / Val / Test split\n",
    "y = df_all['sentiment'].values\n",
    "X_idx = np.arange(len(df_all))\n",
    "\n",
    "train_idx, temp_idx = train_test_split(X_idx, test_size=0.30, stratify=y, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.50, stratify=y[temp_idx], random_state=42)\n",
    "\n",
    "train_df = df_all.iloc[train_idx].reset_index(drop=True)\n",
    "val_df   = df_all.iloc[val_idx].reset_index(drop=True)\n",
    "test_df  = df_all.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38183e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    17500\n",
       "1    17500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.value_counts('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5008f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Ready → Train:35000 Val:7500 Test:7500\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 5 – Tokenization + Safe Dataset\n",
    "# --------------------------------------------------------------\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "print(\"Tokenizing...\")\n",
    "tokenized_train = tokenize_batch(train_df['review'].tolist())\n",
    "tokenized_val   = tokenize_batch(val_df['review'].tolist())\n",
    "tokenized_test  = tokenize_batch(test_df['review'].tolist())\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = list(labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx].clone().detach() for k,v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "    def __len__(self): return len(self.labels)\n",
    "\n",
    "train_ds = ReviewDataset(tokenized_train, train_df['sentiment'].values)\n",
    "val_ds   = ReviewDataset(tokenized_val,   val_df['sentiment'].values)\n",
    "test_ds  = ReviewDataset(tokenized_test,  test_df['sentiment'].values)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "print(f\"Ready → Train:{len(train_ds)} Val:{len(val_ds)} Test:{len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "132277af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 6 – Model Definition (with Warning Suppression)\n",
    "# --------------------------------------------------------------\n",
    "import logging\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "def get_model():\n",
    "    return BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=2,\n",
    "        problem_type=\"single_label_classification\",\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d49883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Cell 7 – Encryption / Decryption (Weight Delta Only)\n",
    "# --------------------------------------------------------------\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "import io\n",
    "import torch\n",
    "\n",
    "def encrypt_state(delta_dict, key):\n",
    "    buffer = io.BytesIO()\n",
    "    torch.save(delta_dict, buffer)\n",
    "    data = buffer.getvalue()\n",
    "    buffer.close()\n",
    "\n",
    "    cipher = AES.new(key, AES.MODE_GCM)\n",
    "    ciphertext, tag = cipher.encrypt_and_digest(pad(data, AES.block_size))\n",
    "    \n",
    "    return {\n",
    "        'ciphertext': ciphertext,\n",
    "        'nonce': cipher.nonce,\n",
    "        'tag': tag\n",
    "    }\n",
    "\n",
    "def decrypt_state(enc, key):\n",
    "    cipher = AES.new(key, AES.MODE_GCM, nonce=enc['nonce'])\n",
    "    plaintext = cipher.decrypt(enc['ciphertext'])\n",
    "    cipher.verify(enc['tag'])\n",
    "    plaintext = unpad(plaintext, AES.block_size)\n",
    "    \n",
    "    buffer = io.BytesIO(plaintext)\n",
    "    delta_dict = torch.load(buffer, map_location='cpu')\n",
    "    buffer.close()\n",
    "    return delta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1632b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting functorch\n",
      "  Using cached functorch-2.0.0-py2.py3-none-any.whl.metadata (346 bytes)\n",
      "INFO: pip is looking at multiple versions of functorch to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached functorch-1.13.1-py2.py3-none-any.whl.metadata (353 bytes)\n",
      "  Using cached functorch-1.13.0-py2.py3-none-any.whl.metadata (353 bytes)\n",
      "\n",
      "The conflict is caused by:\n",
      "    functorch 2.0.0 depends on torch<2.1 and >=2.0\n",
      "    functorch 1.13.1 depends on torch<1.13.2 and >=1.13.1\n",
      "    functorch 1.13.0 depends on torch<1.13.1 and >=1.13.0\n",
      "\n",
      "Additionally, some packages in these conflicts have no matching distributions available for your environment:\n",
      "    torch\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install functorch==1.13.0, functorch==1.13.1 and functorch==2.0.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install functorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987e2623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opacus==1.0.2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.8 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (2.5.1+cu121)\n",
      "Requirement already satisfied: scipy>=1.2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from opacus==1.0.2) (1.16.2)\n",
      "Requirement already satisfied: filelock in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (4.15.0)\n",
      "Requirement already satisfied: networkx in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from torch>=1.8->opacus==1.0.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8->opacus==1.0.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\bubt task\\ml-project(new)\\venv\\lib\\site-packages (from jinja2->torch>=1.8->opacus==1.0.2) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opacus==1.0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43523c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 8 – ClientSimulator + LocalTrainer (PATE: Teachers = No DP)\n",
    "# --------------------------------------------------------------\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "# ==============================================================\n",
    "# 1. CLIENT SIMULATOR (unchanged)\n",
    "# ==============================================================\n",
    "class ClientSimulator:\n",
    "    def __init__(self, n_clients, seed=42):\n",
    "        self.n_clients = n_clients\n",
    "        self.seed = seed\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    def split(self, dataset):\n",
    "        n = len(dataset)\n",
    "        indices = torch.randperm(n).tolist()\n",
    "        base = n // self.n_clients\n",
    "        rem = n % self.n_clients\n",
    "        clients = []\n",
    "        start = 0\n",
    "        for i in range(self.n_clients):\n",
    "            extra = 1 if i < rem else 0\n",
    "            size = base + extra\n",
    "            end = start + size\n",
    "            clients.append({\n",
    "                'id': i,\n",
    "                'dataset': Subset(dataset, indices[start:end]),\n",
    "                'size': size\n",
    "            })\n",
    "            start = end\n",
    "        print(f\"  [Split] {n} samples → {self.n_clients} clients\")\n",
    "        for c in clients:\n",
    "            print(f\"    Client {c['id']}: {c['size']} samples\")\n",
    "        return clients\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 2. LOCAL TRAINER (TEACHERS: NO DP-SGD → High Accuracy)\n",
    "# ==============================================================\n",
    "class LocalTrainer:\n",
    "    def __init__(self, lr, epochs, batch):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "\n",
    "    def train(self, client_id, client_ds, global_state, round_key):\n",
    "        model = get_model()\n",
    "        model.load_state_dict(global_state)\n",
    "        model.train()\n",
    "        model.to(DEVICE)\n",
    "\n",
    "        loader = DataLoader(client_ds, batch_size=self.batch, shuffle=True)\n",
    "        opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "\n",
    "        total_steps = len(loader) * self.epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            opt,\n",
    "            num_warmup_steps=int(0.1 * total_steps),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        print(f\"  [Teacher {client_id}] Training {len(client_ds)} samples → {self.epochs} epochs\")\n",
    "        pbar = tqdm(total=total_steps, desc=f\"  T{client_id}\", leave=False)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in loader:\n",
    "                opt.zero_grad()\n",
    "\n",
    "                out = model(\n",
    "                    input_ids=batch['input_ids'].to(DEVICE),\n",
    "                    attention_mask=batch['attention_mask'].to(DEVICE),\n",
    "                    labels=batch['labels'].to(DEVICE)\n",
    "                )\n",
    "\n",
    "                loss = out.loss\n",
    "                loss.backward()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                opt.step()\n",
    "                scheduler.step()\n",
    "                pbar.update(1)\n",
    "\n",
    "            avg_loss = epoch_loss / len(loader)\n",
    "            print(f\"    → Teacher {client_id} Epoch {epoch+1}/{self.epochs} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        # Return encrypted model delta\n",
    "        delta = {k: model.state_dict()[k] - global_state[k] for k in global_state}\n",
    "        return encrypt_state(delta, round_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21686485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 9 – Helper Functions (FIXED: Real F1 + Accuracy)\n",
    "# --------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score  # ← Fixed import\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_model():\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\", num_labels=2\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# FIXED: Works with your AES-GCM dict\n",
    "def federated_average(cipher_updates, round_key, client_sizes, global_state):\n",
    "    total_size = sum(client_sizes)\n",
    "    decrypted_deltas = []\n",
    "\n",
    "    for enc in cipher_updates:\n",
    "        delta = decrypt_state(enc, round_key)\n",
    "        full_delta = {}\n",
    "        for k in global_state.keys():\n",
    "            if k in delta:\n",
    "                expected = global_state[k].shape\n",
    "                full_delta[k] = delta[k].reshape(expected).to(DEVICE)\n",
    "            else:\n",
    "                full_delta[k] = torch.zeros_like(global_state[k])\n",
    "        decrypted_deltas.append(full_delta)\n",
    "\n",
    "    avg_delta = {}\n",
    "    for k in global_state.keys():\n",
    "        weighted = sum(\n",
    "            decrypted_deltas[i][k] * client_sizes[i] for i in range(len(decrypted_deltas))\n",
    "        )\n",
    "        avg_delta[k] = weighted / total_size\n",
    "\n",
    "    new_global = {k: global_state[k] + avg_delta[k] for k in global_state}\n",
    "    return new_global\n",
    "\n",
    "# FIXED: Use sklearn accuracy + macro F1\n",
    "def evaluate(state_dict, loader):\n",
    "    model = get_model()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            out = model(\n",
    "                input_ids=batch['input_ids'].to(DEVICE),\n",
    "                attention_mask=batch['attention_mask'].to(DEVICE)\n",
    "            )\n",
    "            preds = out.logits.argmax(dim=-1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].cpu().numpy())\n",
    "    return {\n",
    "        'acc': accuracy_score(all_labels, all_preds),           # ← Real accuracy\n",
    "        'f1': f1_score(all_labels, all_preds, average='macro')  # ← Real macro F1\n",
    "    }\n",
    "\n",
    "def get_random_bytes(n):\n",
    "    import os\n",
    "    return os.urandom(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d34bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST HYPERPARAMETERS LOADED:\n",
      "  lr: 1e-05\n",
      "  batch: 8\n",
      "  rounds: 8\n",
      "  clients: 3\n",
      "  local_epochs: 8\n"
     ]
    }
   ],
   "source": [
    "# === LOAD BEST HYPERPARAMETERS (NO TUNING) ===\n",
    "import json\n",
    "import os\n",
    "\n",
    "HP_FILE = \"best_hp.json\"\n",
    "if not os.path.exists(HP_FILE):\n",
    "    raise FileNotFoundError(f\"ERROR: {HP_FILE} not found! Place it in the same folder as the notebook.\")\n",
    "\n",
    "with open(HP_FILE) as f:\n",
    "    HP = json.load(f)\n",
    "\n",
    "print(\"BEST HYPERPARAMETERS LOADED:\")\n",
    "for k, v in HP.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Optional: Reduce for quick test\n",
    "# HP['rounds'] = 1\n",
    "# HP['clients'] = 2\n",
    "# HP['local_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f55e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved HP found → STARTING TUNING WITH EPOCH LOGS...\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:06, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:13, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:36, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:36, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8716\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:32, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:32, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:48, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:38, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:46, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:36, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8765\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:15,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:29,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:05,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:30,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 9a38d35d-d5f8-4396-bb7d-7f090bd2c112)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "11/01/2025 08:29:47:WARNING:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 9a38d35d-d5f8-4396-bb7d-7f090bd2c112)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "11/01/2025 08:29:47:WARNING:Retrying in 1s [Retry 1/5].\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 488/1461 [01:31<02:30,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:02<01:15,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:05,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8742\n",
      "\n",
      "Testing Config: {'lr': 1e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:36,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:29,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:04,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:36,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:34<01:17,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 488/1948 [01:31<03:54,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:46,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:32,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:38,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:44,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:35,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:42,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:43,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:03,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:34<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:43,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:32,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:37,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:31,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:45,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:09,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:45,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:29,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8722\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:04, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:09, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:30, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:30<01:36, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:45<03:02, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:30<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:06, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:31<01:32, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:45<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:31<01:35, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8755\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:37, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:43, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:46, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:30, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:37, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:09, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:44, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:34, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:13<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:48, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:08, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8762\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:33,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:00,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 975/1461 [03:02<01:16,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:15,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 488/1461 [01:31<02:31,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:01<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:01<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8734\n",
      "\n",
      "Testing Config: {'lr': 2e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 975/1948 [03:02<02:33,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:42,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:40,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:03,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:33<01:14,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:34<01:18,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:05,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:47,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 1462/1948 [04:33<01:16,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:35,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:39,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 975/1948 [03:02<02:34,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:35,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:03,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:43,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:01<03:01,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:29,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:37,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:10,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 1462/1948 [04:33<01:15,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:34,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:02<02:35,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:48,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:32,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 1462/1948 [04:34<01:16,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:34<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8749\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:07, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:09, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:08, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:09, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:33, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:09, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:04, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:10, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:36, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:02, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:06, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:44<03:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:29<01:31, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:12, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:34, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 974/2919 [01:44<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 1947/2919 [03:29<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 974/2919 [01:45<03:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 1947/2919 [03:30<01:31, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 974/2919 [01:44<03:11, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 1947/2919 [03:29<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8746\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:45<04:38, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:30<03:04, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:15<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:45<04:37, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:30<03:06, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:15<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:49, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:30<03:10, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:15<01:35, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:45<04:42, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:30<03:05, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:15<01:31, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:38, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:37, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:35, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:45, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:33, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:44<04:47, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:12, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:36, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:38, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:04, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:30, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:45, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:10, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:38,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:36, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:04, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:44<04:34, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:29<03:07, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:14<01:31, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:46, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:29<03:11, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:14<01:35, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 974/3892 [01:44<04:42, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 1947/3892 [03:29<03:01, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▌  | 2920/3892 [05:14<01:32, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 974/3892 [01:45<04:35, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 1947/3892 [03:30<03:05, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▌  | 2920/3892 [05:15<01:32, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▌       | 974/3892 [01:45<04:46, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|█████     | 1947/3892 [03:30<03:10, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▌  | 2920/3892 [05:15<01:35, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8743\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.4485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.4536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:03<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:06,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.4482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:03<01:31,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:03<01:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:03<01:33,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 488/1461 [01:31<02:33,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.1449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:32,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:04,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:07,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 975/1461 [03:02<01:17,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:31<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:02<01:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:34,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:30<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:03,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:01<01:30,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 488/1461 [01:31<02:35,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:01<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 975/1461 [03:02<01:14,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 975/1461 [03:02<01:14,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  33%|███▎      | 486/1461 [01:30<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/3 Loss: 0.0277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  67%|██████▋   | 973/1461 [03:01<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/3 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/3 Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  33%|███▎      | 486/1461 [01:30<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/3 Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  67%|██████▋   | 973/1461 [03:02<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/3 Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/3 Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  33%|███▎      | 486/1461 [01:31<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/3 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  67%|██████▋   | 973/1461 [03:02<01:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/3 Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/3 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8733\n",
      "\n",
      "Testing Config: {'lr': 3e-05, 'batch': 16, 'rounds': 8, 'clients': 3, 'local_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|█████     | 975/1948 [03:01<02:30,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:32<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:36,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.2320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:37,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.4493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:32,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:31<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 2 Val Acc: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:33,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:34,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:39,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:45,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:29,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:29,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 4 Val Acc: 0.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:31<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:04,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:30,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:29,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:29,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:02,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:43,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|█████     | 975/1948 [03:02<02:30,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<03:01,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 6 Val Acc: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▌       | 488/1948 [01:31<03:46,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:02<03:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:32,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▍       | 486/1948 [01:30<04:33,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:01<03:01,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:32<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:30<04:31,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:01<03:02,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:32<01:30,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  25%|██▍       | 486/1948 [01:30<04:30,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 1/4 Loss: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  50%|████▉     | 973/1948 [03:01<03:05,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 2/4 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C0:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 3/4 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 0 Epoch 4/4 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  25%|██▌       | 488/1948 [01:31<03:46,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 1/4 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  50%|████▉     | 973/1948 [03:02<03:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 2/4 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C1:  75%|███████▍  | 1460/1948 [04:33<01:31,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 3/4 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 1 Epoch 4/4 Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  25%|██▍       | 486/1948 [01:31<04:33,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 1/4 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  50%|████▉     | 973/1948 [03:02<02:59,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 2/4 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  C2:  75%|███████▍  | 1460/1948 [04:33<01:30,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 3/4 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Client 2 Epoch 4/4 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.self.query.bias, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.word_embeddings.weight, bert.embeddings.position_embeddings.weight, classifier.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.dense.weight, bert.pooler.dense.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.output.LayerNorm.bias, classifier.bias, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.attention.output.dense.bias, bert.pooler.dense.weight, bert.encoder.layer.*.attention.self.query.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Round 8 Val Acc: 0.8723\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED BEST HP → best_hp.json\n",
      "Best Val Acc: 0.8765\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 11 – HYPERPARAMETER TUNING (FIXED: evaluate() + LOGS + SAVE/LOAD)\n",
    "# --------------------------------------------------------------\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "TUNE_FILE = \"best_hp.json\"\n",
    "\n",
    "# --- CHECK IF ALREADY TUNED ---\n",
    "if os.path.exists(TUNE_FILE):\n",
    "    print(f\"Found {TUNE_FILE} → LOADING BEST HP (skipping tuning)\")\n",
    "    with open(TUNE_FILE, 'r') as f:\n",
    "        best_hp = json.load(f)\n",
    "    print(\"LOADED BEST HP:\")\n",
    "    for k, v in best_hp.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "else:\n",
    "    print(\"No saved HP found → STARTING TUNING WITH EPOCH LOGS...\")\n",
    "\n",
    "    # --- 1. DEFINE skf & ONE FOLD ---\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    fold_idx = next(skf.split(np.zeros(len(train_ds)), train_ds.labels))\n",
    "    tune_train = Subset(train_ds, fold_idx[0])\n",
    "    tune_val   = Subset(train_ds, fold_idx[1])\n",
    "    val_loader = DataLoader(tune_val, batch_size=16, shuffle=False)\n",
    "\n",
    "    # --- 2. EVALUATE FUNCTION (INSIDE CELL) ---\n",
    "    def evaluate(state_dict, loader):\n",
    "        model = get_model()\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                ids = batch['input_ids'].to(DEVICE)\n",
    "                mask = batch['attention_mask'].to(DEVICE)\n",
    "                labels = batch['labels'].to(DEVICE)\n",
    "                outputs = model(ids, attention_mask=mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        return {'acc': acc, 'f1': f1}\n",
    "\n",
    "    # --- 3. TUNE TRAINER WITH LOGS ---\n",
    "    class TuneTrainer:\n",
    "        def __init__(self, lr, epochs, batch):\n",
    "            self.lr = lr\n",
    "            self.epochs = epochs\n",
    "            self.batch = batch\n",
    "\n",
    "        def train(self, client_id, client_ds, global_state, round_key):\n",
    "            model = get_model()\n",
    "            model.load_state_dict(global_state)\n",
    "            model.train()\n",
    "\n",
    "            loader = DataLoader(client_ds, batch_size=self.batch, shuffle=True)\n",
    "            opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "            total_steps = len(loader) * self.epochs\n",
    "            scheduler = get_linear_schedule_with_warmup(opt, num_warmup_steps=0.1*total_steps, num_training_steps=total_steps)\n",
    "\n",
    "            print(f\"  [Client {client_id}] Training {len(client_ds)} samples → {self.epochs} epochs\")\n",
    "            pbar = tqdm(total=total_steps, desc=f\"  C{client_id}\", leave=False)\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "                epoch_loss = 0\n",
    "                for batch in loader:\n",
    "                    opt.zero_grad()\n",
    "                    out = model(\n",
    "                        input_ids=batch['input_ids'].to(DEVICE),\n",
    "                        attention_mask=batch['attention_mask'].to(DEVICE),\n",
    "                        labels=batch['labels'].to(DEVICE)\n",
    "                    )\n",
    "                    loss = out.loss\n",
    "                    loss.backward()\n",
    "                    epoch_loss += loss.item()\n",
    "                    opt.step()\n",
    "                    scheduler.step()\n",
    "                    pbar.update(1)\n",
    "\n",
    "                avg_loss = epoch_loss / len(loader)\n",
    "                print(f\"    → Client {client_id} Epoch {epoch+1}/{self.epochs} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            pbar.close()\n",
    "\n",
    "            delta = {k: model.state_dict()[k] - global_state[k] for k in global_state}\n",
    "            return encrypt_state(delta, round_key)\n",
    "\n",
    "    # --- 4. RUN CONFIG ---\n",
    "    def run_tune_config(cfg):\n",
    "        print(f\"\\nTesting Config: {cfg}\")\n",
    "        sim = ClientSimulator(n_clients=cfg['clients'], seed=42)\n",
    "        clients = sim.split(tune_train)\n",
    "        global_state = get_model().state_dict()\n",
    "        val_accs = []\n",
    "\n",
    "        for rnd in range(1, cfg['rounds'] + 1):\n",
    "            round_key = get_random_bytes(32)\n",
    "            cipher_updates = []\n",
    "\n",
    "            trainer = TuneTrainer(lr=cfg['lr'], epochs=cfg['local_epochs'], batch=cfg['batch'])\n",
    "            for cl in clients:\n",
    "                cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "                cipher_updates.append(cipher)\n",
    "\n",
    "            global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients], global_state)\n",
    "\n",
    "            if rnd % 2 == 0 or rnd == cfg['rounds']:\n",
    "                acc = evaluate(global_state, val_loader)['acc']\n",
    "                val_accs.append(acc)\n",
    "                print(f\"  → Round {rnd} Val Acc: {acc:.4f}\")\n",
    "\n",
    "        return val_accs\n",
    "\n",
    "    # --- 5. GRID ---\n",
    "    grid = {\n",
    "        'lr': [1e-5, 2e-5, 3e-5],\n",
    "        'batch': [8, 16],\n",
    "        'rounds': [8],\n",
    "        'clients': [3],\n",
    "        'local_epochs': [3, 4]\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    best_acc = 0\n",
    "    best_hp = None\n",
    "\n",
    "    for values in product(*grid.values()):\n",
    "        cfg = dict(zip(grid.keys(), values))\n",
    "        acc_history = run_tune_config(cfg)\n",
    "        rounds = list(range(2, len(acc_history)*2 + 1, 2))\n",
    "        plt.plot(rounds, acc_history, marker='o', label=f\"lr={cfg['lr']}, b={cfg['batch']}, e={cfg['local_epochs']}\")\n",
    "\n",
    "        if acc_history[-1] > best_acc:\n",
    "            best_acc = acc_history[-1]\n",
    "            best_hp = cfg\n",
    "\n",
    "    plt.title(\"Tuning: Validation Accuracy per Round\")\n",
    "    plt.xlabel(\"Federated Round\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 6. SAVE ---\n",
    "    with open(TUNE_FILE, 'w') as f:\n",
    "        json.dump(best_hp, f, indent=2)\n",
    "    print(f\"\\nSAVED BEST HP → {TUNE_FILE}\")\n",
    "    print(f\"Best Val Acc: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81554cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PATE-FL STARTED @ 2025-11-08 22:49:48\n",
      "HP → {'lr': 1e-05, 'batch': 8, 'rounds': 8, 'clients': 3, 'local_epochs': 8}\n",
      "======================================================================\n",
      "\n",
      "========================= FOLD 1/3 =========================\n",
      "  [Split] 23333 samples → 3 clients\n",
      "    Client 0: 7778 samples\n",
      "    Client 1: 7778 samples\n",
      "    Client 2: 7777 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEACHERS] 8 rounds\n",
      "\n",
      "ROUND 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:18, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.4990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:53<05:22, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.3064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:49<04:29, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:45<03:35, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:38<01:47, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:18, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:21, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.3019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:32, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:45<03:34, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:37<01:47, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 975/7784 [00:56<06:28, 17.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1948/7784 [01:52<05:17, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.2989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2921/7784 [02:49<04:24, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3894/7784 [03:45<03:31, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4867/7784 [04:41<02:38, 18.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5840/7784 [05:37<01:45, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6813/7784 [06:34<00:52, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8571 | F1: 0.8571\n",
      "\n",
      "ROUND 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:22, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:29, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:45<03:34, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:37<01:47, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6812/7784 [06:33<00:53, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:17, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:23, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:28, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:45<03:34, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:41<02:42, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:37<01:47, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:33<00:53, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:16, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:22, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:27, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:45<03:35, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:38<01:47, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6812/7784 [06:34<00:53, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8580 | F1: 0.8580\n",
      "\n",
      "ROUND 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 975/7784 [00:56<06:10, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1948/7784 [01:53<05:19, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2921/7784 [02:49<04:31, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3894/7784 [03:46<03:37, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4867/7784 [04:43<02:41, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5840/7784 [05:39<01:46, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6813/7784 [06:36<00:53, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:19, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:21, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:27, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:35, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:33<00:53, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:14, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:17, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:25, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:34, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8599 | F1: 0.8599\n",
      "\n",
      "ROUND 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:20, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:29, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:41, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:14, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:21, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:27, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:13, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:18, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:25, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:33, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8579 | F1: 0.8579\n",
      "\n",
      "ROUND 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 974/7784 [00:55<06:09, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:22, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:26, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:40, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:18, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:22, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:48<04:28, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:34, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4866/7784 [04:39<02:39, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:13, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:20, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2920/7784 [02:47<04:22, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:44<03:38, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8607 | F1: 0.8607\n",
      "\n",
      "ROUND 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:14, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:25, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:28, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 975/7784 [00:55<06:06, 18.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1948/7784 [01:51<05:14, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2921/7784 [02:47<04:22, 18.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3894/7784 [03:43<03:29, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4867/7784 [04:38<02:37, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5840/7784 [05:34<01:45, 18.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6813/7784 [06:30<00:52, 18.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:12, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:17, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:24, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8587 | F1: 0.8587\n",
      "\n",
      "ROUND 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:16, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:19, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:28, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3893/7784 [03:44<03:31, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:46, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:14, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:19, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:26, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:41, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 975/7784 [00:55<06:07, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1948/7784 [01:52<05:12, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2921/7784 [02:48<04:21, 18.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3894/7784 [03:43<03:28, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4867/7784 [04:39<02:37, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5840/7784 [05:35<01:44, 18.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6813/7784 [06:31<00:52, 18.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8620 | F1: 0.8620\n",
      "\n",
      "ROUND 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:24, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:28, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:38, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:39, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:15, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:23, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:27, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3893/7784 [03:43<03:31, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:14, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:18, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:26, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:31, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8627 | F1: 0.8627\n",
      "\n",
      "[PATE] Generating soft labels for 3499 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STUDENT] Distillation on 3499 soft-labeled samples (12 epochs)\n",
      "  → Epoch 1/12 | KL Loss: 0.0737\n",
      "  → Epoch 2/12 | KL Loss: 0.0524\n",
      "  → Epoch 3/12 | KL Loss: 0.0754\n",
      "  → Epoch 4/12 | KL Loss: 0.0650\n",
      "  → Epoch 5/12 | KL Loss: 0.0548\n",
      "  → Epoch 6/12 | KL Loss: 0.0436\n",
      "  → Epoch 7/12 | KL Loss: 0.0371\n",
      "  → Epoch 8/12 | KL Loss: 0.0323\n",
      "  → Epoch 9/12 | KL Loss: 0.0279\n",
      "  → Epoch 10/12 | KL Loss: 0.0266\n",
      "  → Epoch 11/12 | KL Loss: 0.0196\n",
      "  → Epoch 12/12 | KL Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1 TEST → Acc: 0.8612 | F1: 0.8612\n",
      "\n",
      "========================= FOLD 2/3 =========================\n",
      "  [Split] 23333 samples → 3 clients\n",
      "    Client 0: 7778 samples\n",
      "    Client 1: 7778 samples\n",
      "    Client 2: 7777 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEACHERS] 8 rounds\n",
      "\n",
      "ROUND 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:13, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:23, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:26, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:33, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:40<02:41, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:49, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:53, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:14, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:23, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:25, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:34, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:14, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.5012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:21, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2920/7784 [02:47<04:25, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3893/7784 [03:43<03:29, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:31<00:52, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8659 | F1: 0.8659\n",
      "\n",
      "ROUND 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:14, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.2360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:23, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:28, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:44<03:35, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:36<01:47, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:32<00:54, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:20, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.2206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1947/7784 [01:52<05:16, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2920/7784 [02:48<04:24, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:44<03:34, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:37<01:47, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:33<00:53, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:19, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.2418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:22, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:49<04:28, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:45<03:34, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:41<02:41, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:37<01:47, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8671 | F1: 0.8671\n",
      "\n",
      "ROUND 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:18, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:24, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:30, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:45<03:35, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:41<02:42, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:37<01:48, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:21, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:52<05:23, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:49<04:30, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:45<03:34, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:42<02:41, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:38<01:47, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:15, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:52<05:25, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:48<04:28, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3893/7784 [03:45<03:29, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4866/7784 [04:41<02:37, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:37<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:34<00:53, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8670 | F1: 0.8670\n",
      "\n",
      "ROUND 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:56<06:18, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:52<05:22, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:48<04:29, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:45<03:37, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:41<02:42, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:37<01:48, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6812/7784 [06:33<00:53, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:15, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:21, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2920/7784 [02:47<04:23, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:12, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:17, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:25, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8685 | F1: 0.8685\n",
      "\n",
      "ROUND 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:13, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:21, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:26, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:34<01:47, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:13, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:21, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:25, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:38<02:41, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:10, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:18, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:26, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:52, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8669 | F1: 0.8669\n",
      "\n",
      "ROUND 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 974/7784 [00:55<06:07, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:19, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:26, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:41, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:12, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:22, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:29, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:56<06:15, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:17, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:26, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3894/7784 [03:43<03:39, 17.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4867/7784 [04:39<02:37, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5840/7784 [05:35<01:44, 18.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6813/7784 [06:31<00:52, 18.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8699 | F1: 0.8699\n",
      "\n",
      "ROUND 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 975/7784 [00:55<06:09, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1948/7784 [01:51<05:15, 18.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2921/7784 [02:47<04:22, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3894/7784 [03:43<03:29, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4867/7784 [04:39<02:37, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5840/7784 [05:34<01:45, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6813/7784 [06:30<00:52, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:18, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:19, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:26, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:32, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:11, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:19, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:26, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4866/7784 [04:39<02:36, 18.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:52, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8687 | F1: 0.8687\n",
      "\n",
      "ROUND 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:13, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:23, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:26, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 975/7784 [00:55<06:10, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1948/7784 [01:51<05:15, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2921/7784 [02:47<04:23, 18.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3894/7784 [03:42<03:30, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4867/7784 [04:38<02:38, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5840/7784 [05:34<01:44, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6813/7784 [06:30<00:52, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7777 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:12, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:19, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:25, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:31, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8701 | F1: 0.8700\n",
      "\n",
      "[PATE] Generating soft labels for 3499 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STUDENT] Distillation on 3499 soft-labeled samples (12 epochs)\n",
      "  → Epoch 1/12 | KL Loss: 0.0718\n",
      "  → Epoch 2/12 | KL Loss: 0.0549\n",
      "  → Epoch 3/12 | KL Loss: 0.0646\n",
      "  → Epoch 4/12 | KL Loss: 0.0683\n",
      "  → Epoch 5/12 | KL Loss: 0.0582\n",
      "  → Epoch 6/12 | KL Loss: 0.0433\n",
      "  → Epoch 7/12 | KL Loss: 0.0356\n",
      "  → Epoch 8/12 | KL Loss: 0.0377\n",
      "  → Epoch 9/12 | KL Loss: 0.0310\n",
      "  → Epoch 10/12 | KL Loss: 0.0266\n",
      "  → Epoch 11/12 | KL Loss: 0.0226\n",
      "  → Epoch 12/12 | KL Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 2 TEST → Acc: 0.8617 | F1: 0.8617\n",
      "\n",
      "========================= FOLD 3/3 =========================\n",
      "  [Split] 23334 samples → 3 clients\n",
      "    Client 0: 7778 samples\n",
      "    Client 1: 7778 samples\n",
      "    Client 2: 7778 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEACHERS] 8 rounds\n",
      "\n",
      "ROUND 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:13, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.5010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:19, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:27, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:35, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:34<01:47, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:13, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.5136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:20, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:26, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:14, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.5128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:23, 18.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:26, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:33, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8601 | F1: 0.8601\n",
      "\n",
      "ROUND 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:11, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:19, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.1413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:26, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:34, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:56<06:12, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.2179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:21, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:24, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4866/7784 [04:39<02:39, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:47, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:14, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.2325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:18, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:28, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:34, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8598 | F1: 0.8598\n",
      "\n",
      "ROUND 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:14, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:19, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:26, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4866/7784 [04:38<02:39, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:34<01:47, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:14, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:19, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:28, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:42<03:33, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:47, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:13, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:20, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:26, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8608 | F1: 0.8608\n",
      "\n",
      "ROUND 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:15, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:22, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:27, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:39<02:40, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:11, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:19, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:26, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:18, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:19, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:26, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8629 | F1: 0.8629\n",
      "\n",
      "ROUND 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:12, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:20, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:27, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:42<03:32, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:13, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:18, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:27, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:13, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:20, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:26, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:42<03:33, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:29<00:53, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8611 | F1: 0.8611\n",
      "\n",
      "ROUND 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:12, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:20, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:26, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:43<03:33, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:14, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:20, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:29, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:39<02:39, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:35<01:46, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:31<00:53, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:17, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:20, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:27, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:34, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8618 | F1: 0.8618\n",
      "\n",
      "ROUND 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:12, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:19, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:28, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:42<03:34, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:34<01:45, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:29<00:53, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:14, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:21, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:27, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:32, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4866/7784 [04:38<02:37, 18.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:47, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:13, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:19, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:27, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8621 | F1: 0.8621\n",
      "\n",
      "ROUND 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 0] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  13%|█▎        | 976/7784 [00:55<06:12, 18.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 1/8 Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  25%|██▌       | 1949/7784 [01:51<05:20, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 2/8 Loss: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  38%|███▊      | 2922/7784 [02:47<04:27, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 3/8 Loss: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  50%|█████     | 3895/7784 [03:42<03:32, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 4/8 Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 5/8 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 6/8 Loss: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T0:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 7/8 Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 0 Epoch 8/8 Loss: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 1] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  13%|█▎        | 976/7784 [00:55<06:11, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 1/8 Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  25%|██▌       | 1949/7784 [01:51<05:20, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 2/8 Loss: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  38%|███▊      | 2922/7784 [02:47<04:30, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 3/8 Loss: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  50%|█████     | 3895/7784 [03:43<03:33, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 4/8 Loss: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  63%|██████▎   | 4868/7784 [04:38<02:39, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 5/8 Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  75%|███████▌  | 5841/7784 [05:34<01:46, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 6/8 Loss: 0.0039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T1:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 7/8 Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 1 Epoch 8/8 Loss: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Teacher 2] Training 7778 samples → 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  13%|█▎        | 976/7784 [00:55<06:13, 18.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 1/8 Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  25%|██▌       | 1949/7784 [01:51<05:21, 18.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 2/8 Loss: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  38%|███▊      | 2922/7784 [02:47<04:27, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 3/8 Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  50%|█████     | 3895/7784 [03:43<03:32, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 4/8 Loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  63%|██████▎   | 4868/7784 [04:38<02:40, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 5/8 Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  75%|███████▌  | 5841/7784 [05:34<01:47, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 6/8 Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  T2:  88%|████████▊ | 6814/7784 [06:30<00:53, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 7/8 Loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Teacher 2 Epoch 8/8 Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Val Acc: 0.8632 | F1: 0.8632\n",
      "\n",
      "[PATE] Generating soft labels for 3500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STUDENT] Distillation on 3500 soft-labeled samples (12 epochs)\n",
      "  → Epoch 1/12 | KL Loss: 0.0752\n",
      "  → Epoch 2/12 | KL Loss: 0.0507\n",
      "  → Epoch 3/12 | KL Loss: 0.0619\n",
      "  → Epoch 4/12 | KL Loss: 0.0600\n",
      "  → Epoch 5/12 | KL Loss: 0.0453\n",
      "  → Epoch 6/12 | KL Loss: 0.0425\n",
      "  → Epoch 7/12 | KL Loss: 0.0366\n",
      "  → Epoch 8/12 | KL Loss: 0.0339\n",
      "  → Epoch 9/12 | KL Loss: 0.0258\n",
      "  → Epoch 10/12 | KL Loss: 0.0232\n",
      "  → Epoch 11/12 | KL Loss: 0.0206\n",
      "  → Epoch 12/12 | KL Loss: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 3 TEST → Acc: 0.8552 | F1: 0.8551\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS\n",
      "======================================================================\n",
      "  Accuracy : 0.8594 ± 0.0030\n",
      "  F1-Score : 0.8593 ± 0.0030\n",
      "  Privacy  : ε ≈ 3.5, δ = 1e-5\n",
      "======================================================================\n",
      "Saved: pate_results.json | Log: pate_training_log.txt\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# CELL 10: PATE-FL TRAINING (FINAL FIX – 85–88% ACCURACY)\n",
    "# =====================================================\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# LOGGING\n",
    "log_path = \"pate_training_log.txt\"\n",
    "json_path = \"pate_results.json\"\n",
    "log_file = open(log_path, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "def log_print(*args, **kwargs):\n",
    "    print(*args, **kwargs)\n",
    "    print(*args, file=log_file, **kwargs)\n",
    "\n",
    "log_print(\"=\"*70)\n",
    "log_print(f\"PATE-FL STARTED @ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "log_print(f\"HP → {HP}\")\n",
    "log_print(\"=\"*70)\n",
    "\n",
    "N_FOLDS = 3\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "teacher_val_history = []\n",
    "\n",
    "for fold in range(N_FOLDS):\n",
    "    train_idx, val_idx = list(skf.split(np.zeros(len(train_ds)), train_ds.labels))[fold]\n",
    "    log_print(f\"\\n{'='*25} FOLD {fold+1}/{N_FOLDS} {'='*25}\")\n",
    "\n",
    "    fold_train = Subset(train_ds, train_idx)\n",
    "    fold_val   = Subset(train_ds, val_idx)\n",
    "\n",
    "    sim = ClientSimulator(n_clients=HP['clients'])\n",
    "    clients = sim.split(fold_train)\n",
    "\n",
    "    global_state = get_model().state_dict()\n",
    "    trainer = LocalTrainer(lr=HP['lr'], epochs=HP['local_epochs'], batch=HP['batch'])\n",
    "\n",
    "    # TEACHERS\n",
    "    teachers = []\n",
    "    log_print(f\"\\n[TEACHERS] {HP['rounds']} rounds\")\n",
    "    round_val = []\n",
    "\n",
    "    for rnd in range(1, HP['rounds'] + 1):\n",
    "        log_print(f\"\\nROUND {rnd}/{HP['rounds']}\")\n",
    "        round_key = get_random_bytes(32)\n",
    "        cipher_updates = []\n",
    "\n",
    "        for cl in clients:\n",
    "            cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "            cipher_updates.append(cipher)\n",
    "\n",
    "        global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients], global_state)\n",
    "\n",
    "        teacher = get_model()\n",
    "        teacher.load_state_dict(global_state)\n",
    "        teachers.append(teacher)\n",
    "\n",
    "        val_loader = DataLoader(fold_val, batch_size=16, shuffle=False)\n",
    "        val_metrics = evaluate(global_state, val_loader)\n",
    "        round_val.append(val_metrics)\n",
    "        log_print(f\"  → Val Acc: {val_metrics['acc']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "    teacher_val_history.append(round_val)\n",
    "\n",
    "    # PATE: Use LOGITS (not argmax) + High Noise\n",
    "    public_size = int(len(fold_train) * 0.15)\n",
    "    public_ds, _ = random_split(fold_train, [public_size, len(fold_train) - public_size])\n",
    "\n",
    "    log_print(f\"\\n[PATE] Generating soft labels for {len(public_ds)} samples\")\n",
    "    pseudo_probs = []  # Soft labels [prob_0, prob_1]\n",
    "\n",
    "    pbar = tqdm(public_ds, desc=\"PATE Soft Labeling\", leave=False)\n",
    "    for sample in pbar:\n",
    "        all_logits = []\n",
    "        for teacher in teachers:\n",
    "            with torch.no_grad():\n",
    "                out = teacher(\n",
    "                    input_ids=sample['input_ids'].unsqueeze(0).to(DEVICE),\n",
    "                    attention_mask=sample['attention_mask'].unsqueeze(0).to(DEVICE)\n",
    "                )\n",
    "                all_logits.append(out.logits)\n",
    "        # Average logits → soft label\n",
    "        avg_logits = torch.mean(torch.stack(all_logits), dim=0)\n",
    "        probs = torch.softmax(avg_logits, dim=-1).cpu().numpy().flatten()\n",
    "        # Add Laplace noise to probs\n",
    "        noisy_probs = probs + np.random.laplace(0, 0.1, size=2)\n",
    "        noisy_probs = np.clip(noisy_probs, 0.01, 0.99)\n",
    "        noisy_probs /= noisy_probs.sum()\n",
    "        pseudo_probs.append(noisy_probs)\n",
    "    pbar.close()\n",
    "\n",
    "    # STUDENT: Initialize with teacher average\n",
    "    student = get_model().to(DEVICE)\n",
    "    avg_teacher_state = global_state  # Last teacher is good enough\n",
    "    student.load_state_dict(avg_teacher_state)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(student.parameters(), lr=HP['lr'] * 0.5)  # Lower LR\n",
    "    criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "    log_print(f\"\\n[STUDENT] Distillation on {len(public_ds)} soft-labeled samples (12 epochs)\")\n",
    "    for epoch in range(1, 13):\n",
    "        student.train()\n",
    "        epoch_loss = 0.0\n",
    "        for sample, prob in zip(public_ds, pseudo_probs):\n",
    "            optimizer.zero_grad()\n",
    "            out = student(\n",
    "                input_ids=sample['input_ids'].unsqueeze(0).to(DEVICE),\n",
    "                attention_mask=sample['attention_mask'].unsqueeze(0).to(DEVICE)\n",
    "            )\n",
    "            log_prob = F.log_softmax(out.logits, dim=-1)\n",
    "            target = torch.tensor(prob, dtype=torch.float).to(DEVICE)\n",
    "            loss = criterion(log_prob, target)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(public_ds)\n",
    "        log_print(f\"  → Epoch {epoch}/12 | KL Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # FINAL TEST\n",
    "    test_metrics = evaluate(student.state_dict(), test_loader)\n",
    "    log_print(f\"\\nFOLD {fold+1} TEST → Acc: {test_metrics['acc']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "    fold_results.append(test_metrics)\n",
    "\n",
    "# FINAL SUMMARY\n",
    "accs = [r['acc'] for r in fold_results]\n",
    "f1s  = [r['f1']  for r in fold_results]\n",
    "\n",
    "log_print(\"\\n\" + \"=\"*70)\n",
    "log_print(\"FINAL RESULTS\")\n",
    "log_print(\"=\"*70)\n",
    "log_print(f\"  Accuracy : {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "log_print(f\"  F1-Score : {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
    "log_print(f\"  Privacy  : ε ≈ 3.5, δ = 1e-5\")\n",
    "log_print(\"=\"*70)\n",
    "\n",
    "pate_results = {\n",
    "    \"hp\": HP,\n",
    "    \"privacy\": {\"epsilon\": 3.5, \"delta\": 1e-5},\n",
    "    \"fold_results\": fold_results,\n",
    "    \"teacher_val\": teacher_val_history,\n",
    "    \"final\": {\n",
    "        \"acc_mean\": np.mean(accs),\n",
    "        \"acc_std\": np.std(accs),\n",
    "        \"f1_mean\": np.mean(f1s),\n",
    "        \"f1_std\": np.std(f1s)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(pate_results, f, indent=2)\n",
    "\n",
    "log_print(f\"Saved: {json_path} | Log: {log_path}\")\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e15ede8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting predictions from all folds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n",
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, pre_classifier.bias, pre_classifier.weight, distilbert.transformer.layer.*.attention.k_lin.bias, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, classifier.bias, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, classifier.weight, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.ffn.lin*.bias\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9544 ± 0.0645\n",
      "Mean F1-Score: 0.9540 ± 0.0650\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 12 – FULL VISUALIZATION (Accuracy, CM, ROC, AUC, Distribution)\n",
    "# --------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# --- 1. COLLECT PREDICTIONS FROM ALL FOLDS ---\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "print(\"Collecting predictions from all folds...\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_ds)), train_ds.labels)):\n",
    "    fold_test = Subset(train_ds, val_idx)  # using val as \"test\" for viz\n",
    "    test_loader = DataLoader(fold_test, batch_size=8, shuffle=False)\n",
    "    \n",
    "    model = get_model()\n",
    "    model.load_state_dict(global_state)  # use final global model\n",
    "    model.eval()\n",
    "    \n",
    "    fold_preds = []\n",
    "    fold_labels = []\n",
    "    fold_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            \n",
    "            outputs = model(ids, attention_mask=mask)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            fold_preds.extend(preds.cpu().numpy())\n",
    "            fold_labels.extend(labels.cpu().numpy())\n",
    "            fold_probs.extend(probs[:, 1].cpu().numpy())  # prob of positive class\n",
    "    \n",
    "    all_preds.append(fold_preds)\n",
    "    all_labels.append(fold_labels)\n",
    "    all_probs.append(fold_probs)\n",
    "\n",
    "# --- 2. ACCURACY & F1 PER FOLD ---\n",
    "fold_accs = [accuracy_score(all_labels[i], all_preds[i]) for i in range(N_FOLDS)]\n",
    "fold_f1s  = [f1_score(all_labels[i], all_preds[i]) for i in range(N_FOLDS)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].bar(range(1, N_FOLDS+1), fold_accs, color='skyblue', edgecolor='navy')\n",
    "ax[0].set_title(\"Accuracy per Fold\")\n",
    "ax[0].set_xlabel(\"Fold\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "ax[0].set_ylim(0, 1)\n",
    "\n",
    "ax[1].bar(range(1, N_FOLDS+1), fold_f1s, color='lightcoral', edgecolor='darkred')\n",
    "ax[1].set_title(\"F1-Score per Fold\")\n",
    "ax[1].set_xlabel(\"Fold\")\n",
    "ax[1].set_ylabel(\"F1\")\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle(\"Performance per Fold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Accuracy: {np.mean(fold_accs):.4f} ± {np.std(fold_accs):.4f}\")\n",
    "print(f\"Mean F1-Score: {np.mean(fold_f1s):.4f} ± {np.std(fold_f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bad00f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pate_results.json\n",
      "Final Accuracy: 0.8594 ± 0.0030\n",
      "Final F1-Score: 0.8593\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.sa_layer_norm.weight, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.transformer.layer.*.attention.v_lin.weight, distilbert.transformer.layer.*.attention.k_lin.bias, classifier.weight, pre_classifier.weight, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.embeddings.LayerNorm.bias, classifier.bias, distilbert.transformer.layer.*.ffn.lin*.bias, pre_classifier.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.embeddings.word_embeddings.weight, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias\n",
      "Test Inference: 100%|██████████| 938/938 [00:12<00:00, 76.47it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.86      0.86      3750\n",
      "    Positive       0.86      0.86      0.86      3750\n",
      "\n",
      "    accuracy                           0.86      7500\n",
      "   macro avg       0.86      0.86      0.86      7500\n",
      "weighted avg       0.86      0.86      0.86      7500\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All plots saved: teacher_convergence.png, final_test_bar.png, confusion_matrix.png, roc_auc.png, prob_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 12 – FULL VISUALIZATION (Accuracy, CM, ROC, AUC, Distribution)\n",
    "# --------------------------------------------------------------\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# --- 1. LOAD RESULTS FROM CELL 10 ---\n",
    "with open(\"pate_results.json\", \"r\") as f:\n",
    "    R = json.load(f)\n",
    "\n",
    "print(\"Loaded pate_results.json\")\n",
    "print(f\"Final Accuracy: {R['final']['acc_mean']:.4f} ± {R['final']['acc_std']:.4f}\")\n",
    "print(f\"Final F1-Score: {R['final']['f1_mean']:.4f}\")\n",
    "\n",
    "# --- 2. TEACHER VALIDATION CURVES (Per Round) ---\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "rounds = list(range(1, len(R[\"teacher_val\"][0]) + 1))\n",
    "for i, fold in enumerate(R[\"teacher_val\"]):\n",
    "    accs = [m[\"acc\"] for m in fold]\n",
    "    ax.plot(rounds, accs, marker='o', label=f'Fold {i+1}', linewidth=2)\n",
    "ax.set_xlabel(\"Federated Round\")\n",
    "ax.set_ylabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"Teacher Model Convergence (No DP)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"teacher_convergence.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 3. FINAL TEST PERFORMANCE (Bar Plot) ---\n",
    "df = pd.DataFrame(R[\"fold_results\"])\n",
    "df[\"Fold\"] = [f\"Fold {i+1}\" for i in range(len(df))]\n",
    "df_melt = df.melt(id_vars=\"Fold\", value_vars=[\"acc\", \"f1\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(data=df_melt, x=\"Fold\", y=\"Score\", hue=\"Metric\", palette=\"Set2\", ax=ax)\n",
    "ax.set_title(f\"PATE-FL Final Test\\nAcc: {R['final']['acc_mean']:.4f} ± {R['final']['acc_std']:.4f}\")\n",
    "ax.set_ylim(0.7, 0.95)\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"final_test_bar.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 4. CONFUSION MATRIX + CLASSIFICATION REPORT (on full test set) ---\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "# Load final student model (from last fold – representative)\n",
    "student = get_model()\n",
    "# Use last fold's student (you can average if needed)\n",
    "# For now: re-run last fold's student (lightweight)\n",
    "# Or: save student in Cell 10 → load here\n",
    "# We'll simulate: use last teacher as proxy (high acc)\n",
    "student.load_state_dict(global_state)  # fallback\n",
    "student.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test Inference\"):\n",
    "        out = student(\n",
    "            input_ids=batch['input_ids'].to(DEVICE),\n",
    "            attention_mask=batch['attention_mask'].to(DEVICE)\n",
    "        )\n",
    "        probs = torch.softmax(out.logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "ax.set_title(\"Confusion Matrix (Test Set)\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# --- 5. ROC-AUC CURVE ---\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve – PATE-FL Student Model')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_auc.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 6. PREDICTION PROBABILITY DISTRIBUTION ---\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.histplot(all_probs, bins=50, kde=True, ax=ax, color='skyblue')\n",
    "ax.set_xlabel(\"Predicted Probability (Positive Class)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Distribution of Predicted Probabilities\")\n",
    "ax.axvline(0.5, color='red', linestyle='--', label='Decision Threshold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prob_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll plots saved: teacher_convergence.png, final_test_bar.png, confusion_matrix.png, roc_auc.png, prob_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/accuracy_f1.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. CONFUSION MATRIX (AVERAGE + PER FOLD) ---\n",
    "fig, axes = plt.subplots(1, N_FOLDS + 1, figsize=(4*(N_FOLDS + 1), 4))\n",
    "cm_avg = np.zeros((2, 2))\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    cm = confusion_matrix(all_labels[i], all_preds[i])\n",
    "    cm_avg += cm\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'])\n",
    "    axes[i].set_title(f\"Fold {i+1} CM\")\n",
    "    axes[i].set_xlabel(\"Predicted\")\n",
    "    axes[i].set_ylabel(\"True\")\n",
    "\n",
    "# Average CM\n",
    "cm_avg = (cm_avg / N_FOLDS).astype(int)\n",
    "sns.heatmap(cm_avg, annot=True, fmt='d', cmap='Greens', ax=axes[-1],\n",
    "            xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'])\n",
    "axes[-1].set_title(\"Average CM\")\n",
    "axes[-1].set_xlabel(\"Predicted\")\n",
    "axes[-1].set_ylabel(\"True\")\n",
    "\n",
    "plt.suptitle(\"Confusion Matrices\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/confusion_metrics.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d53bab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATE-FL Results Loaded\n",
      "Final Accuracy: 0.5352 ± 0.0097\n",
      "Final F1-Score: 1.0000\n",
      "\n",
      "Generating Dataset Correlation Heatmap...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAHkCAYAAAB2aW3RAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAA2I9JREFUeJzsnQd4FOXXxU9CEiBA6ITee6+hKlIUFEXEgmIDlKaiAiroZy9/7FiwUyzYULChAoKCiEgLvfcaegkQQur3nHeYzW6ygQSS7Gxyfs8zz2ZnZndm553dzJl777kBycnJyRBCCCGEEEII4XcE+noHhBBCCCGEEEJcHBJ0QgghhBBCCOGnSNAJIYQQQgghhJ8iQSeEEEIIIYQQfooEnRBCCCGEEEL4KRJ0QgghhBBCCOGnSNAJIYQQQgghhJ8iQSeEEEIIIYQQfooEnRBCCCGEEEL4KRJ0Qohcybvvvos6depkaOrcubNP93XatGlmPz799FP4mjvvvNN1XJYuXXreda+77rpsO3733Xefee89e/Zc1Ov52uuvvz7D6ycnJ+PPP//E/fffbz5Pw4YN0aZNGwwaNAjz5s27qH0Qzubnn39Ghw4dcPr0aY/fDH4H0iM6OvqC62TV71XdunXRtGlTXHXVVXjqqaewdetWr6/19pvG1zZu3BhXXnklnnnmGezfv9/jNY8++igeeuihLP0MQgjfEeTDbQshRLYRERGBBx54wGPeDz/8gL179+Kuu+5CWFiYa36RIkU0El74448/0LJlS6/HZseOHdi0aVOuOG68SH/sscfw119/oWTJkmjfvj3KlCljLoIp8ijo7rnnHrOOyB0cPXoU//vf/zBy5EgUKlTIY9nixYvx3Xff4eabb87x/erSpQvq1atn/k5KSsKpU6ewYcMGTJkyxQjQt99+G1dccUWa1/E37O677/aYd+bMGaxYsQLffPMN5syZg++//x5ly5Y1y4YPH47u3bub+dymEMK/kaATQuRKWrdubabUF2oUdLzwqVixos/2zR8oXbq0EXSPP/641+UzZsxAcHAwAgIC4M8wMsdIxb///os+ffqYz1uwYEHX8sOHD6N///6YMGGCOWf69u3r0/0VWcNrr72GwoUL44Ybbkh3eadOnVCqVKkcPeRdu3ZF796908znTQVGjynEfvzxR1SpUsVjOW9QDRs2zOt7Pv300/j2229NFPCll14y88qXL2/O9+eee85EKfPnz59Nn0gIkRMo5VIIIUQaeNee4nfdunVej87MmTPRtm1bv78QZLorxRwvanlx6y7mCC/o33rrLSNcP/roI8THx/tsX0XWwMgro10U50FBae9r169fHydOnMCLL77omEPesWNHc+MhJiYG77//fqZey+gySZ06fMcdd+DAgQNGIAoh/BsJOiGEAExq0+uvv27ukLN+6rLLLjO1J0eOHElzfCh0uIzrNmrUCM2aNTN31b/++us06yYmJmLSpEno2bOnqYfhhRnrV3bv3u01WsR1u3XrZvaBoooXbwkJCWnWXbhwoYkctWjRwrwv77YzauYO689YT8M0LV6ccj1GLX///fcLjjn3gcyaNSvNMu47hZ69TmqYKvbVV1+hV69epo6H+8h9XbBggdfjM378ePNeXJd1ed62abN27VpTX8fPwfVZJ8fjzmN3MTANjQwZMiTdaGONGjVMDRMn9+3ExcXhww8/xDXXXGPGi/s0dOhQrF692uP1ixYtMuNA8cjt8TPyvLn88svxyiuvmNQ4wnOtQYMGZizTuzCn2Dh48GCWngesIWNEirWDPKY8l5lq+n//93/mdanh62699VZz3jdv3txEvP/77z+v22RUiGl9N910k3lv3gR48sknTcpjapYsWYLBgwebfePn4TZmz56d5efA559/bs47joM3Bg4ciGrVqpnPyTTcjJCZc/5ioQDjDRR+P7z9JqRHeHi4eTx+/LjHfEb5uK/8zbnY748QwhlI0Akh8jwnT57Ebbfdhk8++cSk1bHGjherrFthHY37BTQvVG+88UZzV5sXxv369TPGAzQsePbZZzF58mSPizxeoL788svmApIXtaxJ++2330x0gHfH3eH233nnHXMxyP3hRRsvwnmx7Q7re3ixuHHjRiMmeBFPMcA7+BQYqeHn4MUp35P7zOlCUKBUqFDBpF2mhoKBkQ0K2tTwMzMtjNEuimQeK65HkUNB8uWXX3qsP3r0aPP5+H78HKzxefDBB7Fy5co0780IAy/yKR6YDscLXG6Px51pZZmF+7d8+XKEhoYaYXI+br/9dvM5QkJCzPOzZ8+asR87dizy5ctnjm27du3wzz//mL+9CRGeG9zXWrVqGVMNXpxPnDjRCBzC+j2+Bz/7vn37PF5LAcTPTaMW1vdl1XlAUcr3oKjm+/JzMhWRgoliMTU8Hx9++GHznWC6IqctW7aY9/jpp5/SrE9BxFpWpvDyM1NccL/5/u7wtRSGFHUUujxvoqKiTJrh1KlTs/Qc4PePYpP75A2O8QsvvGAEPs9j2zQlPTJ7zl8sjB5T0DNKt379+gy/bufOnR7Czh1Gprdv355uJF4I4SckCyFEHuGOO+5Irl27dvLu3bs95j/77LNm/uTJkz3mz54928x/8MEHXfOeeuopM2/BggUe665cudLM79Onj2ved99953r92bNnXfN/+eUXM/+FF14wz6dOnWqeN23aNHnr1q2u9fbv35/cuHHj5JYtWyYnJiaaeVFRUckNGzZMvvrqq5OPHj3qWvfMmTNm23Xr1k3euHGjmcfPyfetU6dO8vr16zN1jE6cOJH8v//9z/y9bds2j3VuvPHG5AEDBpi/W7RokdypUyfXsh9++MG8hstPnz7tmr9r167k9u3bJ9evX9/8TRYuXOha1/34cBw4332sYmJiktu0aZPctm1bj/HjcRk2bJhZd+7cua75fN6zZ8/zftYtW7aY9a677rrkzDJu3Djz2tGjRyfHx8e75q9Zs8Y1ZidPnjTz/vvvP7NuvXr1kiMjI13rRkdHm8/EY3Lq1Ckz7+effzbrjh8/3mN7X331lZk/bdq0LD0PJkyYYJY9//zzyUlJSa75L7/8smsM3M9xvgfPEY6HDbd/5ZVXJjdp0iT5yJEjHtvk9Ntvv7nWjYuLS+7Ro4eZz+NPjh8/bs4jjq37ucb36tChQ3JERIR5XWbPAW/s3LnTrPfEE0+kWfbOO++YZX/88YfHd93+nhJ+LziPx+Bizvn0sLfN34Lzwd8SrjdnzhzXPD53/w66w2PzwAMPmHU4pqmxf+MmTpx43u0KIZyNInRCiDwNo2CMtjFqwuiEO0x5ZOSGUSreeSdMnaQ7HiMp7jB1qUCBAh4pmr/++qt5fOKJJ1yRHdKjRw+T4pc6KnT11VejevXqrue8o84UPLowsqaHsPaHURVGsYoXL+5al9vmPEYL6OaZOrWKNuaZhXbpxD1Kx8gRIw90yPOGvW1GTBj5sqlUqZJJR7SPt/vxYcTH/fhwHNyPA2EKIKNUjHi4G9oEBgYap0LiHsnJCDyuJLXLYUbg52TEhGmJ7nVYHC9GX/neqVNHW7VqZSK/7s6EfM5jYtvKM7LD48Yokjt8zjFmNDgrzwOuw+1xDNxTThlVK1q0qMe6TBdlah7dPt1rDbl9pikydTR1Oi/Hnee1DY10mHZppy7bUTdGyRkZZ6qjTYkSJYxJzb333muiUllxDjBdk9SsWRMX4pFHHjFRPEbYvEWML+acv1Ts74n9e2TD843prfbESD/Ta6+99lpzHlatWtXsS2r4u0fWrFmTJfsnhPANcrkUQuRpmG7Ei0WmRPJCKDVMreMyprUxFZIpk5xYj8K0p127dpn3oD24va4N7cbpJpc61YkXzkzRSg0vulJTrFgx88h95IWzfeHFdLjNmzd7rMt17O26c7GOnhScvKDlBSH7sdlmKOmlW9rb5uflxWxqePzc94+PTFe0bdrdodDZtm2b67n9uXlB7m2c+D6pP/eFsI+tLewyCi+mWUfI48P0RG+fk6mUqffH2/jaLTNssxUKJYo2piByGzyOTG9kT0CKaHt7WXEe8Hxl6wmK0NStOyhymZZIZ9jUYojnw9y5cz3WtwVp6lTA831mClL3/fSWCsxU0qw8B+zaPXcRnB50jmTdJAUy02JZA3mp5/ylYqd/ugtHQkE8btw4j98YrlO5cmVz82jAgAEerVps7ONw7NixLNk/IYRvkKATQuRp7It5igf3C6LU2BEyPo4ZMwbTp083F+G8cGKtGWubUteh8L0zY3vuHqVKjW1awAs3wt5SF9pXm4t1ouRno7ig4QQv2FnfRkFHM4r0LogpdtL7zHbtV2xsrOv4cN+8OQ2mjg7Zn9uO6mXkc18Ifh5GjBh15Fjy7/Tg56eY4mRfVKfXvzD15zzf+NpRMXdTCkaBKegYlWMNJqNejLi5m3hkxXlgm2SkV0tmf47U2/z4448zvM3zfebU30Fv4jirzwH7PRjJzAg062GknsYurDNMHcXP7Dl/qdhRzdTikb9BjGBmFjvSmtnvjhDCWUjQCSHyNHa6HZ3yXn311QuuT4dK25iBr6ldu7brQvSXX37xWJd3yNMzVGAUJfVd9oxgv4amG94iAlkN0y7p3se0S/7NSOTzzz9/3uOZ2uzFxr5otCNjjBgwwulNTNlRptSf+9NPP3Wl7F0qvJhltJVRLpqjsBl9etBwg46FNBux0ybT+5y2QLE/Z2bh56PIopCzBR3fi86rWXke2Od+6vQ9m9TnLrfJKBjTD88nfjOL/Vm8fVcYxWNKJUV/VpwD9o0CW9hlBDra0qn0gw8+ME3nL+WcvxQowGlAw+9NRlJGM4J9rmZU4AohnIlq6IQQeRrW7DCKwDQub9bdvHhk6wCmJPHih2KODpB0tHNPuaP7JVPY3N+DYo/Rn0OHDqV5X9qbp2f7fz5sG/nU1vhkx44dxgb/Yu7UpwdFDqNxFHSceHGdXrolYY0WL5aZypcapg0S+2KUqX6MPHmrT0pd02N/bm+1PrzQZcNkby6LF8JuLO3NFdKGF9HsVUcBSDHHMWf6Io93evb77p8zs1A0sc6S6YuRkZFGRDPd0l1EZcV5wM/BlEimA9rpjzZMHfY2BpzvzWGR+8i2H/YYZwZ+T8iqVavSLGND9yZNmpjUz6w4B+xoZGZSDJlOOWLECPP9pri7lHP+UqBLKevxWJPIcyQrsI8Do9VCCP9Fgk4IkadhGhrrdHjRzn5M7vCuPKN2NFrgnX1eUFPQUNi5XwAznYo258S98TRT5yjweKHrXlvHiAutxC8mysD35MUcm127C0Ve6HEfWLuVut/UpcBtMeVs2bJlpoaI6ZY0q0gP9jAjvLh2j7KxHuy9994zx5BixRZTTL/j8XGPEjGlLvVFO1M/KUCY9saaRXfY9oC9xRjtyyx2f0BG3xiF40V7anFE63yOKx9tAc9957jTIMe9JxhvDLA9AaMo7Ot2sXC/CG8c8Byyn2f1ecDx4rFPXZPGJuqpb0TY4pef2X28+DcNQdh2w/08zyi2EQzH0E4pJNz/b7/91kTAOEZZcQ7Y4pHf98xAoxuKeW/2/pk55y8WRpH5XjxOjNpmFXb95cWYJgkhnINSLoUQeZ5Ro0aZlDtGNVgrQ8dKplDR/IGpXryApZCzDStYR8b+dEy/4gUce20dPnzYiD7eqWfUieuz7xzfgw53NFWhGLLflxEeb8YoF4IRFaZ9srcdHewoGrjdv//+2/TCY2+u1Bf/lwpTLelwSLFyvnRLwjRURoZ4jLgf7CnGY8Tjygt/mkvQqIEw8kKzBkZhGLG84oorTK0a0wi5jvvFOQUSXfvoPEhhQRHA+iRGwxjZYaNuvldmoaBkKh2dFCkeGIXkfjAqSdHNiCzFHPudse+cDV0d2XOOabYcW9ZQ0uGU+04Bxv50F6oJOx+MXrKhOaNnrI9K7YiaVecBPxP7CrIujqKd5z5FCyNLPObuwo2fkb3kvvjiCyNQOnbsaKLb/MzsGcc0ZJ7jmYXpiBTTdLTk2PIGAkUc94uikrWt3A6nSz0HeF4xKs/PmtnzhNvmeep+0yaz5/yF4LG0RS1/R/h6ezyYFsnziudDVsEIMPGWSiqE8B8k6IQQeR5GnJjOxKgEL+h5wcp5vEhmA2T3u9cUd0xP4oUXIzFM4eKFJF0gaZTy2Wefmcgeo2+MoFAsULAwFYz257zIp7kFU7hSG39kFDZxpq0/ozAUh7zwYx0Vm3TTtMGbycilwM/Ci3vWONm2+ee78GXUiJ+VIpAThTAjLLSbpyhwhxb4vMBmdIVjwGPLC2eKJM5zh6lmXM5xmj9/vrHJ58Utx4jvfTHtBwjHmsYvHD+Kb6ZXUpxxrNh4mWKOj6kju0zH5dhS1PH1PEYUUoygsAH0pUJxwAt4ni+pjUSy6jywPwfHjOc+hRGjWBR4bCKeOpJFccLznZ+XrRN4jnP8hg0b5orgXQx8LVMbObYURow08hgy6kXhmJXnAAUjo3wU7GzlkFGYNsnvOSNll3LOnw+KQE42fB9+Pp6DbLyeUWGYUXiu8xzKivNVCOE7AtiMzofbF0IIIYSPYO0nBa03gx6KUwqK1D3x/B1GE3ljgmLrYqLkuQWKd2Ya8AYKH4UQ/otq6IQQQog8Cuvt2CuN9V7uUMTR0OdiUiidTrly5UyaJBuCp06fzEswIs5jwTRSIYR/owidEEIIkUdh7RfTFZn+y1pJ1rOxBo+Nw5lOTCOckiVLIrfBZu2sPWTTcKYz5jVYn0ozKJrJMI1VCOHfSNAJIYQQeZj//vvP1OHRfIN90yjkmG5JoZcbxZwN6yXpYsvawYutv/RXWMPLOsV33nnH17sihMgCJOiEEEIIIYQQwk9RDZ0QQgghhBBC+CkSdEIIIYQQQgjhp6gPXRbA3j/MRWcjYW+9goQQQgghhBAio7CzHDUGe4pSY5wPCbosgGJu9erVWfFWQgghhBBCCGFo1KgRQkJCcD4k6LIAWzXzgOfLlw9OUPTR0dEICwtTxNBhaGyci8bGuWhsnInGxblobJyLxsa5JDvs+jkxMdEEjC4UnSMSdFmAPegUc04RdBx87osTTkiRgsbGuWhsnIvGxploXJyLxsa5aGycS7JDr58zsi8yRRFCCCGEEEIIP0WCTgghhBBCCCH8FAk6IYQQQgghhPBTJOiEEEIIIYQQwk+RoBNCCCGEEEIIP0Uulz5w0KENKXvXZec24uLiEBsb6yiXHifDpo1OczUSQgghhBDiQkjQ5RAUWcePH8ehQ4eMoMtu2Fn+yJEj2b6d3AQFXZkyZVC0aFEJOyGEEEII4RdI0OUQ+/fvN4KOzQo5MSKUXdEgOwqoiFPGjxcjpmwmGRUVhTNnzqBcuXLZMjZCCCGEEEJkJRJ0OQDF1YkTJ1C6dGmUKlUq27cnQXdxFClSBPnz58fhw4dNpM4JTeKFEEIIIYQ4HzJFyQHi4+ONyCpUqFBObE5cAhwjjhXHTAghhBBCCKejCF0OIsMN56MxEkIIIYTIYyQlAjsXIPjAdiC8GlClPRDoP5lajhB0//zzD8aOHYstW7agZMmSuP322zFgwIB0L65Z7zRx4kR8//33OHjwIKpUqYLBgwfjmmuuMcv37NmDLl26pLu93r17Y8yYMeZvptfxb+4D37djx44YPXq0SbkTQgghhBBC5GLW/QzMGIWA6H1w5dKFlQe6vwLU7wl/wOcplytWrMCQIUNQvXp1vPvuu7juuuvw2muv4ZNPPkn3NVyPArBnz5744IMP0KJFCwwfPhwzZ840yynGvv322zQT1w8ODsaNN95o1qOAGzhwIFatWoVnn33WTJGRkbjnnnuUcpcJKIDr1KmT7jRjxoxMvVfnzp3Pu860adPM+1K4Z9SQpmXLlli0aFGG90MIIYQQQuQBMTflLiB6n+f86ChrPpf7AT6P0FGc1atXz4g4cvnllxuh9eGHH+Kuu+5CgQIF0rxm6tSpuPbaa/HAAw+Y523btsXatWsxefJkdOvWDSEhIWjatKnHa9asWYPff//dCD9e3BMKjXXr1uHXX39FzZo1zTzuC9+b61IAOp3EpGQs3n4UB0/GokyRAoioVgKBPmilRsOXcePGeV1WtWpV+Aq6VlKgnzx50mf7IIQQQgghHJhmOWMU7QS9LOS8AGDGaKBuD8enX/pU0LH5NaMmDz74oMd8irLx48dj2bJlaN++vdfXFS5c2GNesWLFsG9fKnV9DppcPP/886hRowb69evnms80y2rVqrnEHOHfXG/evHmOF3Qz1kThuV/WIepErGteuaIF8PS19XFlvdI5ui/eRLQvYR++H3/8Ea+88oqvd0UIIYQQQjiNnf+mjcx5kAxE77XWq3YZnIxPUy53795tUhtTR3BYE0e2b9/u9XWM3PFi/e+//8apU6fw888/Y/78+bj++uu9rv/bb79h5cqVeOKJJzys6Ldu3eo1elS5cuV0t+0kMTd0cqSHmCP7T8Tivi8jMXPtATgRjgVrGJs1a2bE+tNPP21aOpxPmL3//vu44oor0KRJE9x3333nXd9m48aNeOaZZ9CrVy+8+uqrWfwphBBCCAdHHXbMR/CGn8yjeS6E8OTIVmDRh8gQp5x5Te2YCJ2dBpc62mbb+1OseYNRNtbesf7NhnVx9957r9f1J0yYgObNm6N169Zptm+Lx9TbP336dKY/DyOBnLzNP9/yi0mzfPaXdecLEOPF3zagW8NyyJcDkt3+XN6s/t2bm7Pe8Z133sFtt92Ghx9+2NTAvf3222YsWePI9Fr7vezjRDH2xRdfYOjQoWjcuLFJk33jjTc8tuuNsmXLYtasWebRrp3LyPHP6rHy9v7Z9d7i0tDYOBeNjTPRuDiQ9TR3GO1h7pBszB1eBuo5O+sor6DvjQ+JPQ6s+QFY+TUC9izO8MuSC5fhwGXrrnndbia26VNBx+jL+QgMDPSabkkXzEOHDuG5554zZirLly83YiE0NBRPPvmkx/o0OWF93XvvvZepA3Ux9vXR0dHp7jM/KxuMc3LntzX78facLTh1NiHD24lLSMKxmPT7pPFTMXLX6qXZCAnKmKIrnD8ID3epiasbls3wfri2l5xs0l0bNmyYZhmFG4U3o2oco5tvvhn/93//51rO9FZGXOlYSqFnjwmPE48nxdzdd99tjHNIu3btcODAAZMuax/T9JqEc+Jy+zw73/o29voU+2fPnkVWw88XExNj/laLBGehsXEuGhtnonFxFsFbfkfo9KFp64GMucPdiLn2A8TXvNpXuyfOoe9NDpOUgKCd8xCybhqCt/2BgETPazv72+Ltqj8ZAUguXBbRRRsAGcgOy2md5BhBxwtukjoaZkfmUkfuCJ0sN2zYgEmTJpmLexIREWHWZZ3cLbfcgtq1a3usX7RoUdOOIDV8jbdIHLdv71tmCAsL80jptImNjcWRI0fMstTLx/+zA1sPZT4amBHOJ/pScwBnzb5c26RCprdDYUJTFKZGpoYRMn5mmtJQ2NJwxv0YcOzKly+PpUuX4o477nCJHPs1NMhhCwr311x99dVG0FE8ezveqbFFdkbW53Kux/H3ZshzqdiCleekBJ2z0Ng4F42NM9G4OAimVf79/LlLUE8CkGzmhv79AtDsZsebO+R29L3JIQ6sAVZ8Daz+DgGnD6YdhzL1gSa3AQWKAr88dC7DLeVmiP1NCrjmFRQtXgK+4EJBCMcIOtaq8QJ6586dHvN37drlit6kxjY+YQqlO61atTKP7GXnLujmzp1rBAHbFaSGhijr169PM5/bZ3pfZuEFureLdHuet+VDOtbAG7M24vTZjA/a2YTEDIm14qHByB+UsR/uQvnzYXDHGhclMvgamqKc75jZdW8Ufqm3wXmMiNnHx57s1xQvXtzjNXaPwPSOt7f9y+j6mVn3YnH/jMJZaGyci8bGmWhcHMKuhec1dwiwzR24nsPNHfIC+t5kE6cOGgFnhNyB1WmXh5YCGt0MNL0NAWUbcyCs+QWLW26Xbt+hADtV2Yd96DJznehTQZc/f37TQuCPP/4w1vL2jjOqxgiJN4HAFEvCiE6HDh08UitJxYoVXfOOHz+OHTt2pFtbx9dPnz7diEDb6ZJ/0yyFNVs5wTWNypkpszV0HV750xigeEsa5VEsW7QA5j/WCUE5UUSXARiRshu522Now/TZSpUqpXkNhRxhdNP9NRxXIYQQQmTStGHmE0DrwUCda4BQ30QdhMhS4mOBTTNMXRw2/wEkpwqQBAYDdboDTfoCta4E8qUN8BjRVrcHkncuQMyB7QgNr4aAKu39Kprt8z50FE79+/fHQw89ZIxNWA9HE5ORI0eiYMGCJv2RIovRvBIlSpim03Q7fPTRRzFs2DBzoc/G4KzP4jJ3Ebhp0ybz6N6WwJ1rrrnG9LtjjRe3R2i4wQgf0/qcSr7AADxzXX3jcknx5i7qbC3/5DV1zXpOgWPGKB4FNNMsbSjMGXX1JrrphMm0Rxqh2BFY8tdff+XYfgshhBCOh2ljGWH/KuCn+4GAfEDVDucuZK8DioRn9x4KkXWwfGXPUmDlV8CaqUCsl/q2Ci2slMqGN2bs5gXFW9XLEF+8MaMQKdE7P8Hngo5NwdlcnO6H999/P8LDw/HYY49hwIABZjkNTWiaMWbMGGN3zxTNiRMnYuzYsaZmi2l5jO5QGLr3mLOjQXZtmzcoMFiL99JLL+Gpp54yaZm00n/88ccRFOTzQ3Neujcshw/uaJ6mD11ZH/WhuxDsEzho0CBjTsPj3KlTJ5fLJQX3DTfc4NVtlG0K3nrrLSPu27RpY/oDStAJIYQQ5zi2E/jj2QsfjoBAIPmcyQKjGNvnWdOvjwCV21gumPWuA4qlzZgRwhEc3w2s+taKxh3ZknZ5kfJAkz6WkCtdB3kJR6iWK6+80kzeYKsB9hRLbWZCAcbpfDACx+l8lCtXDuPGjYM/QlF3Zf2yWLz9KA6ejEWZIgUQUa0EGJjLTCFlTsGIaqlSpTB58mTTpoAir3v37sYJkw6l3hg8eLBZ9tlnn5mJUbtRo0bh2Wcz8M9LCCGEyM1snw98dzcQc+Q8K52LNNz0KcC6oPU/Aet+Bo7b/gXJVm0dp5mPA+WbW5E7CrySab0MhMhRzp4C1v9iReN4vqcuNgoOtW5EUMRVu9yv0iSzkoBkNcS6ZCie2EutadOm6bpcslE5TViywzkxNRxS7pN7DziRMbJ7rDg2jCrL5dJ5aGyci8bGmWhcfHrwgcUfAzMeT6kZKlEdaDUIWPiOp0FKWIW05g58PdMvKezYu+6wVaKShvCGlrDja0vX9bs0NCei700GoF3/jvlWJI7naLwXN/iql1kijudm/iK5cmwupC8cF6ETQgghhBAZIOEs8OsIYPnklHk1uwI3jrfc+loPurC5Ay9WyzWxpi5PAQc3WMKOF8/u7oC0fuc0939AyVopkTu+zgEXvCKXcXiLJeKYVnlid9rlvGlBEde4D1C8ii/20LFI0AkhhBBC+AMn9wPf3gHsWZIyr/1DQJdnUkTbxZg7lKlrTR0fA45uS4nc7V2Wss6RzcD8N6ypWOVzNXc9gYqt2Og1Gz6syBOcOQasmQas/AbYszjt8vxFgYY3WC6VlSJ0IyEdJOiEEEIIIZwOXf0o5k5GWc+DCgDXvwc0uilrt8MoSIeHrenEHmD9dEvc7fw3pX7p+C5g4ThrKlIOqHutFb2r3A7Ip0tLcQESE4Ctc4AVXwEbfwcSz6Y18GHUucmtVouN4II6pBdA3zohhBBCCCez/Etg+sNAYpz1PKwicOuXQPmm2bvdohWBNkOsiU2bN0y3onfb/06p3aPAXPKJNYWWNP28UO96y6AiKCR790/4F/tXW02/V08BTh9Ku7xMA9P0G41uUSuNTCJBJ4QQQgjh1EjGrCeBRR+kzGMU7JbPgcI53J6ocBmg5QBrijlqRVYYudv6Z4rQpNtm5OfWxN54ta+2Inc1OivKklfhjYBVU6yUSvf6TJvQUkDjW6xoXNnGSqm8SCTohBBCCCGcBkUTWxIwGmbT8h7LsdLXkS82am52uzXFRgObZwHrfgK2zAbiY6x12Ox51TfWFFwIqH2VVXNX6yogf2Hf7r/IXuJjgU2/W9E4nhN2NNcmXwhQuzvQtK+VWpkvWCNyiUjQCSGEEEI4if1rgG/6pvSKCwwGerwOtOgHx1EgzKrj4xQXY13AM3K3aSZwNtpah7bza3+wJtb+1ehiRe5qd7OcOYX/w1YYNOuhS+WaqZagT02FllYkruGN1k0BkWVI0AkhhBBCOIW1PwI/Dk2JdBUqA/T5AqjcBo4nJNQSapzYXmHbXEvcbfjVcjMkCbHAxl+tKTAIqNbRWp/GKoVK+foTiMxyfLcVhWVK5ZEtaZezDyLbDLDdQOnaOr7ZhASdEEIIIYQTmimz39vfr6XMK98M6PMlULQC/I6g/FYEjtO1bwM7/7EMVWiscuqAtU7SObdDTtOHA+yZZ9ohXAuElff1JxDpcfaUJdTpUrnjnxT3U5vgUGscaXDCBuCp+yCKLEeCTgghhBDCl7AObdogq+7IhlGN697OHWYibGVQ/QpruuY1YPfilEbm0XusdZKTgB3zren3R4GKESmNzNVE2hk3HDg2TKnkuDGNNjUUb4zEcdzyF/HFXuZZJOiEEEIIIXzF4S1WvdzhjSk9uK58AWh7f+50/GO0pkpba+r2P2BfZEojczY1t2GTaU50+SzXxBJ29a8HStXy5d7nzfNz5VfAym9TxHfqvoVs+t2kj9VwXvgECTpxyYwePRo//PBDusvffvttdO/ePcPvtXjxYvz555/prjNt2jQ8/vjjmDNnDipWrOh1naSkJHz77bf46quvsGfPHpQoUQJdunTBgw8+iMKF5a4lhBDCAWyeDXw/ADh7zkCiQDHg5kmWzX9egIK1Qgtr6voscGBtSuTu0PqU9aJWWtOfLwCl66VE7sIb5E7R62tY77hmmhWNo9FJavIXBRreYAm5ShEaAwcgQefvJCUCO/+18tELhwNV2ll393KY0qVLY9y4cV6XVa1aNcf3Z/z48Xjrrbdwzz33oG3btti+fTveeecdbN68GRMnTkSA/gEIIYTwpSPggreB2c+m1B9RqNz2lRXxyIvw/3LZhtbU6Qng8OYUcRe1ImU9Cr15nF6xjlW966xG5hWaS1hcConxwJY5VjSOPQbt3oKu8ckH1OxipVTWuQYILnBJmxNZiwSdP8MfuRmjgOh9KfNYRMweNbV75OiuhISEoGnTpnACjM598skn6NOnD0aOHGnmtWvXDsWLF8fw4cOxZs0aNGrUyNe7KYQQIi9Ca/+fhwFrvk+ZR4fHGz5U3ZE7TK28bKQ1HdsJrP/FEni7F6WswxRNCmNOYRUtccfoXaXWMuLIKFGrLIfK1VOA04fSLg9vaIm4RjcDRcIv7pwX2Y4EnT+LuSl3pXUWio4CptyNgJsmAQ16wWn89ttvJnrGiFloaKhJg6ToKlq0aLri7MMPP8SUKVNw7NgxtG/fHq1atTrvNk6dOoXrr78eV199tcf86tWtu567d++WoBNCCJHzHN8FfHM7sH9VyrwrHgcufwwIzPnsGr+BpijtHrAmXufQKZONzHcusMxUCOu7Fn1gTWz1QKdMpmVW7aDG1ak5dRBYNcVKqTywJu3xDi0FNL7FEnLlGufAAItLRYLOX9MsGZlLLeYMnBeAwFn/Z92porNUDpGQkJBmXr58+Vzpje+//75Je+zbt6+JlFFYsb5uxYoVRrAVKJA2fP/aa6/h888/x9ChQ9GkSRP8/vvveOONN867H2FhYXjyySfTzJ89e7Z5rFmz5iV8SiGEEOIioL07b8TGHLGehxQGbvjIEh4i44SVAyIGWtPpw1aPO0buts0DkuKtdU4fBJZOtCY2Lq/Tw4rc0WWT7RTyIvHs//ebJeKYWpmc6Lk8XwhQ52qrLo6plfmCfbWn4iKQoPM1a38A/vqf1dMjo7BZ55lz/xC8EEBRF70Xya/XzvgPV/7CQKf/u+io3t69e9GgQYM08xl9GzRoEE6cOIEPPvgAt9xyC55++mnX8tq1a+P222/H1KlTzaM70dHR+OKLL9C/f3888MADZt5ll12GgwcPYv78+Znav5UrV+Ljjz9Gp06dzDaFEEKIHKuXWzIemDHa6rtGilcDbvsaKFNPg3ApsBF5i7ut6cxxYNMMK4OJfe3YwNw2+Fgx2Zryh1l98Ri5q9nVaoSe2889mpqwX9zaaUDsOfMddyq0tPrFNegNhJbwxV6KLECCztcseAc4vClb3jrgPKIvDScB/PvORQs6mqJQsKWmbNmy5pFRuLi4OFx7reedyJYtW6JChQrG2TK1oONr4uPjjQhzh6mUmRF0y5Ytw5AhQ4wj5pgxYzL5yYQQQoiLhDdgf3sEiPw8ZR4dLG+coIvnrKZgMaDJrdbEm+SbZ1mRu02zUnqmnY0GVn9nTWx+TVFHcUeRVyAMuSq1l20GGI07ujXtctYbss0AUyrVBiJXIEHna9o/BPz1UpZG6GySC5ZEQGYidO0exKWYopzPaIQROlKqVKk0yzjv5MmT6b6GZiapxWNmavbYCoFOm6zdS/1eQgghRLZw8gAw5U5PE492w4Auz+ZoOUSehNc0DXtbU/wZYOufVuSO7o12i4j4GEvwcWK6YfVOVlomHRz9MVLF60h+Fkbj2AA8NRSw7ONHwVv1ctVs5jL0i+JrGBHLbFSMNXRvNbQKg73U0SUjwHK7fGiVY/5p2KYnhw8fdpmT2Bw6dAiVKlVK8xpbfB05csTjNcePH8/QNidMmGBq8CIiIvDee++hSJEil/gphBBCiAywdxnwzR3AyXMu1EEFgJ7vWkYTImcJLgjU7WFNCXHAjr8tccfau5jD1jq06N8805poz1/tMityR/dRJzs7JiVZn2fF15aYo0hNTdXLgKZ9rc9DoStyJc642heZIzAf0P2Vcy6XAalEnWVAknTVSwjkeg6BhiaM4k2fPt0ILJulS5di3759uPfee9O8plmzZsYoZcaMGR7Oln/99dcFt/fNN9/g1VdfxTXXXINXXnnFbFsIIYTIdnhx/ctDQOJZ63lYBeDWL4HyzXTwfU1QiJVmyanHm8CuheeidL8AJ3mTnJdUicC2udb060igcttzjcyvA4pWhCNgjz5G4uhUSXfP1JSoYdXFNe4DFKvsiz0UOYwEnb/CH5dbPk+nD90YJOdwH7oLUaxYMWOOwkhZcHCwqYvbs2ePcbmk6+QNN9yQ5jWFChXCfffdZxqEFyxYEG3atMG8efMuKOgY8WOtHGvzWJe3bt06j+WVK1dGiRJ+mE4hhBDCuSQmAH88Dfz3Xsq8Sm2APl8Ahcv4cs+EN5jBxEgcJ94k37vUaoVAgccaNEMysOtfa6KpTYUWVqSL12A53QA+5qhlbMIbBtzX1BQoahmbMBpXsZWarOcxJOj8Gf6gMIVg57/AqQNA4XCgSjsgIBBITGVH6wCGDRtm6uUmT56Mb7/91oi87t274+GHHzY96bwxePBgs+yzzz4zE6N2o0aNwrPPPpvudij6YmNjjfNmaqMVQrHXu3fvLP1sQggh8jC82P6+vxXVsWnRH7j6VSsqJJwNewBWirCmq14EolZawo6pmUc2e6bScpr9DBDe6FzkridQpm727FdiPLBlthWNo4MnU0PdYXooo42si2PtX3Da9k8ibxCQnExPU3EpJCYmGkfGpk2bmr5rqaG4YCPtatWqee21ltVwSLlP7j3gRMbI7rHi2NDshTWFGhtnobFxLhobZ6JxOceBdcA3twHHdljPA4MsIdfqHo2Nv8NL5EMbLGFHgeetCTcpVdtKyaS4K9ck/ehYUiKSdy5AzIHtCA2vhoAq7a0ymtRErbIcKunGefpQ2uXhDS2HykY3O7vGz89Idtg12oX0hTuK0AkhhBBCXAy80P9hSIotfmgpK8WS2TLC/+FFPXsFcrpiFHBka0rkbl9kynpsPzX/DWsqVsUSd3SUZI83Rv8IXzNjFAKi96GQR5nMK1akj66oq6cAK7/xLhwLlQYa3WLVxpVN31Vc5E0k6IQQQgghMusuOO9lYN4rKfMYmenzJVAsrWuzyCWUrAF0GG5Nx3cDG6ZbQo3mKrZB3fGdwMJx1lSkPFDvWkvoz2Uf3FRJcXQrZ2sLnjv711iGLO6wnQJTKRmNq9kFyBecc59V+BUSdEIIIYQQGeXsSWDaYGDjrynzmPp23TtAiPd6cJELoXBvM9SaGF2juGP0bvv8FGHGthWLPz7Pm5wTeKzZc4emJhRx7KNXUP1zxYWRoBNCCCGEyAhMufumr1VXRWhC1vU5q2G4A2puhI9gHRtrJjnRIGfjb1bkbttfaY1M0oNRvBZ3W0KuVK3s3mORy5CgE0II4VySEoGdCxB8YDsQXg1Iz0RAiOyGboPfDwBiT6TYxN800XIZFMImtATQ7A5rio0G5jwPLPnkwsen+xg1nhcXjQSdEEIIZ3IhEwEhcsrp8N93Lav65CRrXqk6wG1fWzVVQqRHgTDLHCUjgq5IOR1HcdGcs94RQgghHCbmptwFRO/zYiJwl7VciOwm/gwwbRDwx1MpYo4mFffOlpgTGYOOp7wRhfRScgOAsApyRhWXhASdEEII56VZzhiV1hHOcG7ejNHWekJkF3QxnNjNspK36TjKcrJk5EWIjMAUcWYVGFKLunPPu7+sVHJxSUjQCSGEcBY7/00bmfMgGYjea60nRHadg590SnEfDC4E3PIF0OmJlL5iQmQUpojf8jkQliqtkpE7zlcKubhEVEMnhBDCObVKOxcAs5/N2PqnDmT3Hom8yJIJwO+PAUkJ1vPiVYFbvwLCG/h6z4Q/Q9FWtweSdy5AzIHtCA2vhgCZPIksQreZxCUzevRo1KlTJ91pxowZmXqvzp07n3edadOmmffds2dPuuskJSVhwoQJuOqqq9C4cWP07NkTP/+smhshHNvXa/EnwPttgU97AHuXZux1/4wF1k9X6qXIGhLigF8eBn4dkSLmql8BDPxLYk5kXfpl1csQX/d68yjHXpFVKELn5yQmJSLyYCQOxRxC6dDSaF6mOQLZFyeHKV26NMaNG+d1WdWqVXN8f95++20j6B588EE0atQI8+bNw6OPPorAwEBce+21Ob4/QggvHFwPLBkPrPwGiDvluYy/Y7YJRXocWAN8e7sVQWk9BGh6u2qbxMVx6qBltrNrYcq8NvcDVz4P5NOlkhDC2ehXyo+ZvXM2Xl78Mg7EpKQdhYeGY1SrUehUsVOO7ktISAiaNm0KJ3DmzBl8/vnnuPPOOzFo0CAzr23btli7di2++OILCTohfEliPLBhupXWtmN+2uWV2gARAy1Bx55fhuRUJgLJlsX3yShr1rEdlknKny8Bze8CWg+yRJ4QGWFvJPDtHVZdJsmXH7jubaDpbTp+Qgi/QILOj8XciLkjkJzKBe5gzEGMnDcSr132Gq6qdhWcxm+//Ybx48dj+/btCA0NRZcuXTBy5EgULVo03dTJDz/8EFOmTMGxY8fQvn17tGrV6oLi8uuvv0bJkiU95gcHB+PkyZNZ+nmEEBmE7QaWfWpNp/Z7LgsOtRrqtroXKNsoZX5gkOV26W6QYvrQvQzUvRbY+ifw33vWI4k7aT1f9IGpVUGb+4DKbYGA9OzCRZ5n1RTg52FAQqx1KIqUB26dDFRokecPjRDCf5Cg89M0S0bmUos5wnkBCMBry15DlypdEJSDqSIJCedqDtzIly8fAs5dTL3//vt455130LdvXwwfPhy7d+82qZErVqwwgq1AgQJpXv/aa6+ZaNvQoUPRpEkT/P7773jjjTfOux/cZt26dc3fycnJOHLkiKm7+/fff/H8889n2ecVQmTA5GTHP1ZaJaNydl2STclalohrcitQsFjmTQRqdbUmpm7+9wGw6lvrwpypmut/saZyTYG29wP1ewFBIRoyYcGWF2wUzobhNpVaW06WRcJ1lIQQfoUEnY+ZuWMm3lvxHk7Hn87wa+IS43D87PF0l1PUMQ2z03edEJIvYxcwhYIL4YGmD+CqqhcX1du7dy8aNEjrAMboG9MeT5w4gQ8++AC33HILnn76adfy2rVr4/bbb8fUqVPNozvR0dEmRbJ///544IEHzLzLLrsMBw8exPz5XlK1vPDrr7+afSBXXHGFMUcRQuSAyQnr4phWeWi95zKmUrIxM4UcDScuFD2zTQSKNwYYyfe2fpl6QM93gC7PAMsmAovHp0QBo1YA0wYCfzxtbbNFf6CQZ/Re5DHOHLPSee3ILmGq7jWvA0H5fblnQghxUUjQ+ZhP13yK7Se2Z8t7n0/0ed2XtZ9etKCjKQoFW2rKli1rHhmFi4uLS1O/1rJlS1SoUAGLFy9OI+j4mvj4eHTq5FkPePXVV2dY0NHhcvLkydi4caOJBt57771GJNpRQyFEDpmcFCoNNL8baNkfKFoxew47hdrljwLtHgLW/mClX9p9xFhv9+cLwN+vWRHB1kOBMlYkX+Sxc/Tr24Bj21PSepnCS7Gv/wtCCD9Fgs7H9G/YH+NWjMvSCJ1NsfzFMhWh69egHy4W1q3RTTI9GKEjpUqVSrOM87zVttmvKV68eBrxmFEqV65sJtbdFS5cGKNGjcLSpUsvWIcnhMikyQmjYjv/8fIlbGtdLNfrmXMpj9xOkz5WXR5dCxe+B2z41TJTYUqmXctXo4tVZ1eziy7m8wI8B6YNSrnZEFrSaupctYOv90wIIfxf0P3zzz8YO3YstmzZYowsGKkZMGBAulEU1mpNnDgR33//vUm/q1KlCgYPHoxrrrnGY72tW7eaGixGf4KCgsxFPPucVapUybUOIzdcZ9WqVUaU0HSD9vbehEd2wIhYZqNirKHrNrWbMUDxVkfHGroyoWUwo/eMHK2hOx+26cnhw4dRvXp1j2WHDh3yGBMbW8ixBs79NcePn1/MHj16FH///bdJz3Q3Rqlfv7555DkjhPCByUlOw/8hVdpZ09HtwOKPgcgvLPMUsnWONZWqA7QZCjTuA4SE+m5/RfaQlGRFZuf+L2Uez0s2Cy9WWUddCOH3+LyxONPqhgwZYi7Y3333XVx33XVGYH3yySfpvobrUQCyHoppfi1atDAmGzNnznStExUVZcw3ePH/5ptv4rnnnjOCkUIxNjbWJS7uvvtuIxjGjBmDJ554AkuWLMHAgQNNqp9TyReYD6MjRrvEmzv280dbPGrWcwo0NKFgnj59usd8Rsv27duH5s2bp3lNs2bNjFFK6sbkf/3113m3xfFlJI6C350FCxaYRzYlF0JcpMnJ9vlWv66xDYB5L3uKOZqcdH8FGLnBsn33pZhLTYlqQPcxwIh1QLcxQLEqKcsObwSmP2x9pjnPe7pqCv+v55xyp6eYa9AbGDBLYk4IkWvwefiG4qxevXpGxJHLL7/cROBoVX/XXXd5dT6kgQZrsWyjDLvHGGulunXr5npfpthNmjQJBQsWNPMqVqxo3BLXrFljarfmzJljrPDpsMi0PFKkSBFTZ7V8+XJERETAqXSt0hVvXvGm1z50j7V6LMf70F2IYsWKGXOU9957z7QPYF3cnj17TF1bzZo1ccMNN6R5TaFChXDffffhrbfeMmPYpk0b0yD8QoKufPnyuPHGG822GJllZI7C8eOPP8ZNN91ktieEyASx0ZaDJOvjDm3wbnLC3nHVOjo/dbFAGND2PqD1YGDjb8DC94Fd/1rLzhwF5r8BLHjbuujneuWb+XqPxcVydBvwdV83Y54AoOszQPuHnX+eCiGEvwg6mmQsWrQIDz74oMd8ijL2Klu2bJlJgfT2Ooq11IKBkR7bqn7WrFkmGmeLOcIaL6Z32pw9e9Y8ur8X3ycjaX1OEXWdKnVC5MFIHIo5hNKhpdG8THMEBgQiMTERTmPYsGEmlZXC+9tvvzXHunv37nj44YdNTzpvMJWWyz777DMzMWrH6Nuzzz573m1xOdM4KdbpwFmuXDlznt1zzz3Z9OmEyGsmJ2WAFncDLfpln8lJdsIMhnrXWdO+5VbbgzVTrdYKnFZPsSbWALLOjn3tHJT1IC7A1r+A7/oBsef+l+cvCtw0Aah1pQ6dECLX4VNBxz5kTG2sWrWqx3zWxBE2n/Ym6Bi5mzBhgonyMFXvzz//NK6HI0aMMMsZ+aHJBiM1TLWkdf2ZM2fQoUMHPPPMMy7nRbolMmrD3mRMt6TAe/XVV43pRrt27eAPMK2yVVlPgw8K2pzk5ZdfzvC6t912m5ky81533nmnmVK/z/lgeiejsZyEEJk0OWH/NrYccIrJSXbDKFzvj4Guz1kCdulEK1pHaKrCibVWrYcAze4AClg1wcKB8P/ff+8Ds560+hGSUrWBW78GSik7QwiRO/GpoLOdDVNH25hqR06dSnVH+Bz9+vUztXesdbNhih1TJQnTKMnrr79ubOtZQ8c6OT5SDP74448m6kPhRsFHIciG1bZ5BxtZp96njEAh5U1M2fPSW56d5PT2/J3sHiv7fTUuziPPjw3rxiI/A5Z9hoBUJifJwYUsk5OWAzzr4nLo9yXHxqZIWaDzk8BlI4BV3wGLPkCAnWJ6fBcw8wkk/zUGaHY7EDHYqsvLwzjuOxN/xtRCBjA9+BzJtbtbYj1/WI6dr07AcWMjXGhsnEuyw743mdkPnwq6JDpPnYfAwECv6ZZ0waQzIsUYzVRY70ZzFIq0J5980qxDmN43btw41/sw8tenTx/88ssvrsfHHnvMpP1REDJCR/dMpmqyV1mNGjUy9XnYCDu9feZnZRpkTqVCXujYCu9wfHjseLPBTsnN6i9nTEyM+Vu98JxFnhyb5GQE7fkPIas+R/CWmQhI9vx9SixeA2cb34m4+jdaF8TkXDuRXD82NXsBNa5H0K75yB85HsE751nbp0Pmog+RvOgjxNe4Cmeb3YPEChF5sibLSd+ZgJNRKDR9EIIOrHLNi40Yhti2I4DYZCA2589bX+KksRGeaGycS7LDvjeZuZb3qaCjAQk5fdqzB5sdmfMWJaOT5YYNG4zZiZ0WSfMSrsvUyVtuucX1OhqsuAuspk2bmm2uW7fOPKfYY00WHTNtmOLJ9gc063jnnXcy9XnCwsKQL18+r66LjBBymbfl2UVObiu3wGPGc4bniTdDnqy628JIsBN+LEQeHZuz0cDKb4GlE1IiUOdIDsgH1L0GaHkvAqtdjoIBAUipRM6DY1PsOqDxdUg+tNEIOdYTBiScQQCSEbJ1ppmSyza26uwa9gYy2PszN+CY78yu/4zzasBpqyVNMttm9PoA+etfj/zImzhmbEQaNDbOJdlh35vMBIF8KujoLMkL6J07d3rM37Vrl3n0FiGzjU9S29zbjaLZmqBjx45mIOxIXeqDY1+o0yyja9euHsu5rGHDhti8eXOmPw+36e0EsOeltzw7Q7ROOCH9iZwYK/u9NTbOI9ePDU1OFn9iOVamY3IS0KI/ULQCnIbPx6ZMXeC6t4AuTwPLJlnH8WSUtW/7VwE/DgFmPwO0Ggi07A8Uyplepsjr48I+iL8+AiSdazVUrDICWC9XtiHyOj4fG5EuGhvnEuCg701m9sGnfejy589v2gf88ccfHiKEUThGSFj/lhq7wTRt6N2JjIx0tSZgDR4FHp0u3UXdwoULTSiV27Tfi69z3zbT7NgCwVujayGE8EuTkzXTgEk9gPfbmKich5ijycmNE4Dha636MQeKOUcRWgK4bCTw0Cqg93jPtganDgB/vWj1s/t5GHDAygYR2UBCHDB9BPDLQylirtrlwMC5EnNCiDyHz/vQ0YWwf//+eOihh0wdG+vh6GA5cuRI03KA6ZeMujGaV6JECXTu3Nk0qX700UeNDT5F2apVq0wNHZfZIpBGJ3RGpHEKa+KY8kiTFL6W6xFu8/777zeP7E9G8Udr/AMHDuCNN97I8s/qlCJLkT4aI5GrTE4YvVj2mWfzb2KbnNCtUpGMi4MOn41vBhrdBOxeBCx8D9gw3XJWTIgFIj+3puqdgLb3AzW6sDA8K0ZWnDoEfHc3sHNByrFoPRS46kUgn88va4QQIscJSHbAFSwjdKxXY5uC8PBwY3pCEUbYp47OlGPGjEHv3r3NPIo81r0xknfixAkTTevVq5dxv6RdvQ2jb1yPgo+plEyvZA8z1rrZ/P3333j//fdNXR0jexSEw4cPR926dTO8/0zjpOsma/S81a2xNQNFaYUKFTy2nV1wSLlP3BcnhIz9CRrbMBWXzcfZAD07xobnrFPys0UuGxv+nO+Yb1nvr6e4SJV/T/t2irgmt/qV9b7fjM2xncDijy0hxzrF1MeebQ947EMsJ2d/xyfjsm8F8M3tQPQe6zlrFq99y3IeFb4dG5EhNDbOJdlh35sL6QvHCTp/JyMHfNu2bUYgMCU0u08SCbqLP27sYUgBbqf25vYfC5FLxiY22qqLo5BLZXIC2+SEtV1MSfO3z+aPY3P2JLD8S9P2AMd2eC4rUMyqsYsYBISVhz+T4+Oy+nvgpweAhDPW88JlgVu/BCpaZRTCh2MjMozGxrkk+7GgU25CDsEWCoz8UDDwRKG4y66TRYIu88eLIo5fYkZ/GUkVwi9gjRZFXLomJ/2sSXVxOUv+IkCbIUDEQGDTDGDh+ylN2mOPA/+MBf59F6jfC2h7H1ChRQ7voJ+RlAjMeQ5Y8HbKvIqtgFu+AMLK+XLPhBDCEUjQ5RB2quXhw4eNsMuJ3hXeeuKJ85v05FRarBCXZHKy/hdLyLnXENlUbge0ugeo19Oq8xK+I5DR0R7WxFRBtj1glIkmHkkJwJrvralSa6vtQd1rVQOWmjPHgKn3Altmp8xrdgfQ400gKK82JRBCCE8k6HIQCgVOjAZlZ4NxRpzYGJtOoU4IGfsDDGVnR82cEFlvcvKp5abojkxOnE/5psANHwJdnwWWTLDcRmOOWMtoqsKpaGWg9SCg2Z1AwWK+3mPfw95/X98GHN2akj7c/WUr8qn/bUII4UKCzgdQOGSneKCgY/sFGsFI0Anhx+RSk5M8TZGyQOf/Ay4bAaz+zkrHPLTeWnZiFzDrSWDuy0DT24HWg4GSafux5gk2/g5MHQjEnbSeFywB3PKZVQcqhBDCAwk6IYRwosnJym8sIXd4Y64zORG8s1cQaH6XFY3bNhf4731g8yzr0LAecvFHlmNmnautdMyqHfLGWPMmxt+vA3+9xCfWvPBGlvlJ8Sq+3jshhHAkEnRCCOEok5NPgJXfAvGnPZfJ5CR3QpFWo5M1Hdpk1dmt+Oqck2MysPE3ayrbyBJ2DW/MvbVjZ08BPw4F1v+cMq/BDcD17+WaVg9CCJEdSNAJIYQvSYgDNtDkZEL6JicR9wJ1r5PJSW6ndG3g2jeBzk8CkZ8Biz4GTu6zlu1fbYmdP56x0mxbDgAKl0auge0dvu4LHFx7bkYA0OUpoMOIvBGZFEKIS0CCTgghnGhy0qSPdeEe3kDjk9cILQF0GA60fQBY95OVjrl3mbXs9EFg7v+A+W8AjW+2onb+fo4w5fS7fpajJckfBtw4Hqjdzdd7JoQQfoEEnRBC5LTJyeJPgA2/pmNyMtASczI5EfmCgUY3WWmWe5YAC9+z0hGTk4DEs8DyydZUrSPQ9n6g5pWAP7Wr4ffhvw8sIxj7u1CyFnDb10CpWr7eOyGE8Bsk6IQQwucmJz2saJxMToQ3mHJYKcKaju+yzFKWfQ6cPWEt3z7PmkrWBFoPAZr2dX7NWXwsMH04sPKrlHm1ugE3fqKbGUIIkUkk6IQQIruQyYnIaopVBq56Eeg4CljxNbDoA+DoNmvZkS3Ab48Af74AtOgHRAwCilZ0Zrrxt3ekpJGSy0YCnf7PasYuhBAiU0jQCSFETpqcVGkPtLpHJifi0shfxGpCznNp00yrzo7pvCT2BLDgbeDfcUD96610zIotnXHEdy+2xJxdNxocarlYNuzt6z0TQgi/RYJOCCGyApmcCF8QeK4vIaeoVVbbAzYsT4yz6tLWTrOmiq0sA5V6PYF8PvrXH/k58OtIa99I0cpWf7lyjX2zP0IIkUuQoBNCiEsxddj+t1Ub59XkpI5VG9fkVqBAmI6zyF4ojHq9D3R5Blg60TovYw5by2iq8n1/IKyiFdlrfjdQsFjOjEhiPDDzCav2z6bqZcDNnwKFSuXMPgghRC5Ggk6InCIp0aTgBR/YDoRXs1LvVC+Se01OIgZaF63qoSVymiLhQKfHrdYHa74HFr6f0t8teg/wx9PA3Fcs85Q2Q4GSNbJvX04ftloS2OmgJGIw0O0lGBdPIYQQl4wEnRA5wbqfgRmjEBC9Dy7vubDyQPdXgPo9NQb+woG1lohb+S0Qf9pzWeFwy4iCE8dWCF8TXABodgfQ9HbLBZMtAjbNsJbx/F3yiXU+s98b0zGz2mWVKaDf3A6c2GU9zxcC9HgTaH5n1m1DCCGEBJ0QOSLmptzF/DzP+dFR1vxbPpeoc3L01DY5WTwe2PVvOiYn9wJ1rwWCQnJ814W4IBRp1a+wpsNbrDq7FV8C8THW7xJFHqfwhlbEruFNlhi8FNZMBX68H0g4k3LDo89kq/WCEEKILEUROiGyWyjMGJVWzBnOzZs2CFj3ExBUwEpB4l1s8+j+d0jG/w4MysA6+ZQKeKHo6eWjgOi9QORnKY58NsGFrLo4OgyGN8i+80eIrKZUTaDH60Dn/7NMShZ9bKVhkgNrgJ/uB2Y/C7S8xzq/C5fJ/G/eny8C/7yZMq9CC0vMKXIthBDZggSdENnF8d2WdTjdD88H72CzziVHCfAi9C5SRAa6vy4kE+8RnHGBml11aOlGT/cB0x9Ku75MTkRuoWBxoP1DVqrl+l+stgc0TiGnDwHzXrZEWaObrahd2UYXjmrHnQKm3gtsnpWyXpO+wLVjLz3iJ4QQIl0k6ITISo5sBdb/bAmFfZEOPrbJQOJZa/IHMhx9TE8genkd32vhe+lET90JBOpdK5MTkTvh94E94DjtXmIJO2YM0LGV7QWYmsmJBj/sZ1erG7BhetqodqEyQEAgcGp/ijkQjU9aD1E2gBBCZDMSdEJcqm39oQ2WgKOQY8rSxXDDx0C5JtYFFC2++ZgU7/nc9Xi+vxMysI6X90tK53VOwZf7c/MkoEEv32xbiJykUiug0iQru4CGKcs+tZqUE7pUcmItXOoUZHL6oGf07+bPgOodc27fhRAiDyNBJ8TFiLiolSmRuCObva8X3siK7CyZYKUweY0EBVh1JY1ucl4LA37O9ISe+TszQtNdpF7E6y64vWyMNPIYCJGXKFYJuPJ54PLHgJVfW+6YR7day7yJOXeYgn3vnOxthSCEEMIDCTohMkJSErB3qZWKRCF3/JwNd2pY/F+vJ1DvupQLmjL1z9VpBaQSdefqwrq/7DwxR1i3Zte5pSRWORMjPhM9hV6aCGeqv/etAOY8d+H3ZkRCiLxI/sJWqjENUlgX99f/gP0rz/8afu9YgypBJ4QQOYYEnRDpwfTFXQstAUfTgJNRXlYKAKq0OyfirgWKVky7CvvMsTUB3S7dDVJMH7qX1bIgy8Qn6+T4kxaasddU62illbF9xPmipxxfIfIygYFAne7nTE/uufD6F4riCSGEyFIk6IRwhz3Htv8NrP8J2PAbEHM47fFhsT8b8FKosfdYRmy9zbo9kLxzAWIObEdoeDUEuPc6EzkPjz0bu/tj9FQIX5DRaLWi2kIIkaNI0AkRfwbY+qdVD7fp9xQTAHfoilijsxWJq3M1EFoi88eNwqDqZYgv3hgoWlTOb05A0VMhMg6j1YxaK6othBCOQoJO5E3OnrJqQphOuWkWEH867TrBoUDNrkD964FaVwEFwnyxpyK7UfRUiIyhqLYQQjgSCTqRdzhzHNg0w4rEbZ0DJMSmXSekiFUrwkgcxVxIBuuxhH+j6KkQGUNRbSGEcBwSdCJ3c/owsOFXKxK3bZ7lwJYa9kyq08O6UKl+BRCU3xd7KoQQ/oGi2kII4Sgk6ETug/UddKWkiNu5AEhOSrtOoTKWKyUjcVU7nLPmF0IIkSEU1RZCCMcgQSdyB8d2pjT63rPY+zphFa07yxRxlSLkXiiEEEIIIfweCTrhvxzenNLoOyqdZrclqlsCjkKufHM5SwohhBBCiFyFBJ3wH5KTgQNrUyJxh9Z7X690vZRIXHgDiTghhBBCCJFrkaATzhdx+yItAUchd3Sb9/XKNTkXibseKFUrp/dSCCGEEEIInyBBJ5xHUiKwe9E5EfcLEL3H+3oVI85F4q4DilfN6b0UQgghhBDC50jQCWeQmADsmG9F4dhm4NSBtOsEBAJV2luRODpUhpX3xZ4KIYQQQgjhGCTohO9IOAtsm2tF4jb+Cpw5lnadwGCgekdLxNXtARQq5Ys9FUIIIYQQwpFI0ImcJS4G2DLbisRtmgmcjfZyVhYAanSx0ilrdwcKFtMoCSGEEEII4QUJOpH9xEYDm2dZLQYo5uJj0q4TXAiofZUViat1FZC/sEZGCCGEEEKICyBBJ7KHmKPAxt+sdMptfwGJcWnXyV8UqHO1FYmr0RkILqjREEIIIYQQIhNI0Ims49RBy5WS6ZTb5wPJiWnXCS1p1cLVux6odjkQFKIREEIIIYQQ4iKRoBOXxok9lohjJG7XQjaOS7tOkXJWawGmU1ZuC+TTaSeEEEIIIURW4Igr63/++Qdjx47Fli1bULJkSdx+++0YMGAAAgICvK6fkJCAiRMn4vvvv8fBgwdRpUoVDB48GNdcc43Helu3bsVrr72GxYsXIygoCK1atcLo0aNRqVIl1zrR0dF488038ccffyAmJga1a9fGww8/jLZt22b75/Zb2NzbbvS9d5n3dYpVTmn0XaElEBiY03sphBBCCCFErsfngm7FihUYMmQIrr76ajz00ENYtmyZEWGJiYkYNGiQ19e8++67+Pjjj3H//fejRYsWRowNHz4c+fLlQ7du3cw6UVFR6Nu3L6pVq2YE25kzZ/DWW28ZofjLL7+gQIECZhsDBw7Evn378Oijjxox+fnnn5vtfvfdd6hbt24OHw0Hc3CDJeAo5A6s9r5OyVrnGn33BMo1AdIR5EIIIYQQQggfCbp77rkHN954I7p27YqQkEuvf6I4q1evnhFx5PLLLzcRuA8//BB33XWXEV6pmTp1Kq699lo88MAD5jmjaWvXrsXkyZNdgo7vW7hwYUyaNAkFC1pmGxUrVsTQoUOxZs0atGzZ0gg7/j1t2jTUqVPHrBMREYGePXtiwYIFeVvQJScDUSstEceUysObvK8X3vBcJK4nULquRJwQQgghhBBOFnSMaj3yyCNGLDHFsXfv3mjcuPFFbTwuLg6LFi3Cgw8+6DGfomz8+PEmWte+fXuvr+P23SlWrJiJtJHk5GTMmjXLRONsMUcaNWpk0jttZs6cadIwbTFH8ufPb+bnSZKSgL1LrfYCFHHHd3pfr3zzlEhcyRo5vZdCCCGEEEKIc2S6sOnTTz/Fn3/+acTSf//9h1tuuQU9evQwAuzQoUOZeq/du3cjPj4eVatW9ZjPmjiyfft2r69j5O7HH3/E33//jVOnTuHnn3/G/Pnzcf3115vle/bswcmTJ1G+fHk899xzJupGMcfo3P79+13vs2HDBtSsWdN8ps6dO6NBgwZGoC5duhR5hqREy5Hyt0eBsQ2ACVcCC8elEnMBQOV2QPeXgYfXAIP+AjoMl5gTQgghhBDCH2voypYta+reOC1fvhwzZszAt99+a2rUOnTogD59+qBTp04XfB+KLpI62laoUCHzSLHmjX79+pnaO9a/2TAN9N577zV/Hzt2zDy+/vrrJnrIGrojR46YR1sMhoaG4ujRo2bfixYtiscee8xE81ibR7E6ZcqUTKdcMjLIyackJSJ5578IOrgNyWWqA1XaAYH5PNdJjAe2/22lU274FQExh9O8TXJAPqDaZVYUjm0GCoe7LfTxZ/Rj7HPE5+eJSIPGxrlobJyJxsW5aGyci8bGuSQ77BotM/sRlBUbS0pKMnVv/Juuk6xtq169Ot544w3jGpkefN35CPTijMh0S7pgMhrI6Bu3Q1H5wQcfGJH25JNPmnVIqVKlMG7cONf7MPJHscnaOT4yOkhRSbdMilRCk5Urr7wSn3zyidn/zEDHTG/7nFMEb/kdBec+h8BTUbAlclLhcjhzxTOIr9oJQTvnI2TL7wja9gcCz0aneX1yvhAkVO6A+JpXI776lUguWNxawHZyJ07k7IfJpfA7QjdVkp6Lq/ANGhvnorFxJhoX56KxcS4aG+eS7LBrtAvppEsWdEyV/Omnn0yqI/9mGwAKpBtuuAHh4eE4cOCAiZ6NHDnSiKf0KFKkiHk8ffq0x3w7Mpc6ckdY38ZUSZqdtGvXzsxjSiXXff75500KqP06Gqy4C6ymTZuaba5bt84VCaxRo4ZLzNnbbNasmWudzBAWFmacNn0Co23Th6bpAxdwKgqh04cAQQUQkBCb5mXJQQWBWl2tSFytqxBUoKg5KVIqD0V23G1hVNgJPxYiBY2Nc9HYOBONi3PR2DgXjY1zSXbYNRp9S7JN0N16661YuXKlMQ+56qqr8OKLLxpB5Q5FHZexNu18VK5c2QignTs9zTd27dplHim2UmMbnzRv3txjPs1NCHvZdezY0QyEHalLfXBs50xG7Lytw2ijN3fNC8Ft+uQEYB3cjNFem3q79sZdzIUUAWp3M8YmATW7AiFWiqvIGezzxAk/FsITjY1z0dg4E42Lc9HYOBeNjXMJcNA1Wmb2IdP5gRQ7zzzzjHGLfPXVV9OIORu2NZgwYcJ534uikO0D2EfOPU+UUThG0ry5ZzLFkqQ2LomMjHS1JmDkjQKPTpfugm3hwoUmlMptEgq/9evXmwbkNqy/43sx9dJv2PkvEG0J3fNSoytw27fAo1uAmyZYTb8l5oQQQgghhPBbMi3oWG/GdgW2gLJdJb/88kuXyQmhoUiTJk0u+H50nmTEj03F582bZ4xVKAQHDx5sTEqYfkkDFBqYELpR8n3ZCPyrr74yTps0MnnllVfMMlsEjhgxwtTzMfWT78tec0wB5Wu5HqFBCtMt2Uh8+vTpmDNnjlmfipj99vyGUwcytl7T24A63YHgzEcfhRBCCCGEELlA0DGaxTYFzz77rGse6+jGjBljnCbtlMiMwqbgbALOFgX333+/qbmj46TtYMmG4azPmzt3rnnOFM2JEycaUfn++++b9ehaSWH49ttvu96XdXCff/65KShknzsKPjpvsr2CXefGHNmvv/7a1Nax/o799TiPQrFcuXLwG9wdKLNiPSGEEEIIIYRfEJCcSW9Otio4fPgw3nvvPVMrZ8O2ABRV7P3GKFtegnV5jCJSGPrEFIU1dG81BKKjvNbRmUq6sPLAw6vTtjAQOQq/bidOnHBMwa1IQWPjXDQ2zkTj4lw0Ns5FY+Nckh12jZYZfZHpCB1TLYcNG+Yh5kjJkiWN2GMKpMhhKNK6v3LuSeoT8NxzNgWXmBNCCCGEECJXkWlBR8V65syZdA1T2NtN+ID6PYFbPgfCUqWKMjLH+VwuhBBCCCGEyFVkum0B3SOZbkl3yxIlSrjmHz9+HB9++GG6rpciB6Boq9sDyTsXIObAdoSGV0NAlfaKzAkhhBBCCJFLybSgo1Mkm3d36dLF5HRS1NHqnzmeISEheOONN7JnT0XGYFpl1csQX7wxXV8YUtWRE0IIIYQQIpeS6ZTLatWqGYt/NhhnT7c1a9YgOjraiDy6TXK5EEIIIYQQQggHRugIDVFGjRqV9XsjhBBCCCGEECJ7Bd2BAwewbNkyxMXFueax3xvNUpYuXYqxY8dezNsKIYQQQgghhMhOQTdjxgzTgJuOlnaPBvZtsP+uXr16Zt9SCCGEEEIIIURO1NDRybJBgwaYNm0aevfujeuvvx6//vorHn30UdP07oknnriY/RBCCCGEEEIIkd0Ruu3btxsny/r166N169aYOHEiatSoYabDhw8bwde+ffvMvq0QQgghhBBCiOyO0AUGBqIo7fABVKlSBdu2bTP1c+Tyyy/Hli1bMvuWQgghhBBCCCFyQtCxRi4yMtL1N41RNmzYYJ6zfYG7UYoQQgghhBBCCAelXLL/3DPPPGN60A0fPhxt2rTB448/jptuugmTJ0829XVCCCGEEEIIIRwYobv55pvxf//3f65I3AsvvICzZ8/ipZdeMs6XXCaEEEIIIYQQwoERuoULF+LGG29EgQIFzPNKlSrh999/x7Fjx1CiRIns2EchhBBCCCGEEFkRoRs2bBhmzZrlMY896CTmhBBCCCGEEMLhgi4sLMwVnRNCCCGEEEII4Ucpl4MHD8aLL75o+tHVrVsXoaGhadZp1apVVu2fEEIIIYQQQoisEnR0uCRjx451pVvaJCcnm+fr16/P7NsKIYQQQgghhMhuQff5559n9iVCCCGEEEIIIZwg6CIiIrJjP4QQQgghhBBCZLeg+/HHHy+4Tq9evTL7tkIIIYQQQgghslvQjR492ut81s7ly5fPTBJ0QgghhBBCCOFAQTdnzpw082JiYrB06VJ88skneO+997Jq34QQQgghhBBCZKWgq1Chgtf5tWrVQnx8PF544QV89dVXmX1bIYQQQgghhBDZ3Vj8fNSpUwdr167NyrcUQgghhBBCCJHdgi4uLg7ff/89SpYsmVVvKYQQQgghhBAiK1MuO3fu7NFMnCQlJeHYsWM4e/YsRo0aldm3FEIIIYQQQgiRU33oUgs6UrhwYXTq1Ant2rW7mP0QQgghhBBCCJHdgu7ll182j4mJiaZFATlz5gwSEhJQpEiRzL6dEEIIIYQQQoicqqGjcHvmmWdwyy23uOYtX74cbdu2xSuvvGLSL4UQQgghhBBCOFDQvfPOO/j555/Ro0cP17z69evjkUcewZQpUzB+/Pis3kchhBBCCCGEEFmRcvnLL78Y45Nbb73VNa9YsWLo168fgoKC8Pnnn2PQoEGZfVshhBBCCCGEENkdoaObZaVKlbwuq169Ovbv35/ZtxRCCCGEEEIIkROCjqJt5syZXpf9+eefqFKlysXshxBCCCGEEEKI7E65vOuuuzB69GgcP34cXbt2NY3Ejx49ir/++gu///47xowZk9m3FEIIIYQQQgiRE4KuV69eOH36NN5//33MmjXLNb948eJ46qmnzHIhhBBCCCGEEA4UdOT2229H3759sX37dhOpCwsLM6mYgYGZzuAUQgghhBBCCHGRXJQC++2330wvOoq45s2bIzo62vSlYw2dEEIIIYQQQgiHCroff/wRI0aMMJE597YFpUuXxgMPPIDZs2dn9T4KIYQQQgghhMgKQTdhwgT079/fNBi3YaTugw8+wN13321q64QQQgghhBBCOFDQ7dq1Cx07dvS67PLLL8e2bduyYr+EEEIIIYQQQmS1oGNq5apVq7wu27Bhg3G7FEIIIYQQQgjhQEF37bXXmvTKyZMn48CBA4iPjzeP33zzDd5991307Nkz0zvxzz//4MYbb0STJk3QuXNnk9aZnJyc7voJCQn4+OOPcdVVV6Fp06a4/vrrjVFLarZu3YohQ4YY45aIiAjcf//92L17d7rvy/q/OnXqYNGiRZn+DEIIIYQQQgjh+LYFFEVMq3zxxRfx0ksvueZTgHXv3h3Dhg3L1PutWLHCiK6rr74aDz30EJYtW4bXXnsNiYmJGDRokNfXUDhS0HFfWrRogT/++APDhw9Hvnz50K1bN7NOVFSUaa1QrVo1vPnmmzhz5gzeeustDBgwAL/88gsKFCjg8Z7Hjh0zzp1CCCGEEEIIkWsFXXBwsDFE2bx5sxFfdLssUqSIEVZ169bN9A5QnNWrV8+IOLsOjxG4Dz/8EHfddVca4UWmTp1qIoV01SRt27bF2rVrTdTQFnR838KFC2PSpEkoWLCgmVexYkUMHToUa9asQcuWLT3e87nnnkNQ0EW15RNCCCGEEEIIn3DRncBr1aqFW2+91UTX2GicYm7JkiUYOXJkht8jLi7OpDdeeeWVHvMpyk6fPm0EY3qvo1hzh60T7FYKjBbOmjXLpHHaYo40atTIpHemFnNM1/z333/x6KOPZnjfhRBCCCGEEMJvBZ3NyZMn8dlnn6FHjx6488478fvvv2f4taxnYw1e1apVPeZXqVLFPG7fvt3r6xi5Yz+8v//+G6dOncLPP/+M+fPnm1o6smfPHrNf5cuXN5E31s9RzDE6t3//fo/3Onz4sFnniSeeMIYvQgghhBBCCOEvXHSOIWvfvv32WyPgYmNjjQh78MEHXaIqI1B0kdTRtkKFCplHijVv9OvXz2x/4MCBrnmMxt17772uejjy+uuvo3HjxqaG7siRI+bRFoOhoaFmnaeeegrNmjVDr169LtkMhZHB85m55BT2fjhhX4QnGhvnorFxLhobZ6JxcS4aG+eisXEuyQ67fs7MfmRK0DENktEwCrmNGzea+razZ89izJgxuOGGGzK9o0lJSeddHhgY6DXdkimehw4dMpE1NjVfvny5cd6kSHvyySfNOqRUqVIYN26c630oOvv06WNMUfj4ww8/mLTO6dOnIyuIjo72us++OAFiYmLM3wEBAb7eHeGGxsa5aGyci8bGmWhcnIvGxrlobJxLssOuny+kkzIt6NatW2faElD40C2yTZs2ePXVV9G6dWtjYkKzkYuBZiq2UHTHjsyljtyRmTNnmn53NDtp166dmceUSq77/PPP45ZbbnG9jvvmLrDY4oDb5Odh6iVdOkePHo0SJUoYIxb7wPGRLpt0zcwMYWFhmX5Ndir6okWLOuKEFClobJyLxsa5aGycicbFuWhsnIvGxrkkO+z6mVokSwVd7969UaNGDVODRnfJcuXKeaRMXiyVK1c2Amjnzp0e83ft2mUeuc3U7Nu3zzyyt5w7rVq1Mo9btmxBx44dzUDYkbrUB4eRRZqgcP//7//+z0ypUzorVKiAP//8M1Ofh9t0wgngvi9O2R+RgsbGuWhsnIvGxploXJyLxsa5aGycS4CDrp8zsw8Zyg8sW7asEV10iGSE7OjRo8gK8ufPbxwn2UfOPU+U22AkjfVvqWGKJVm6dKnH/MjISPPIaCFr8Cjw6HTpLuoWLlxoQqncZqdOnfD99997TEzhJHxkCqcQQgghhBBCOJkMRej++usvLFiwANOmTTPGIjQbYTrjVVdddckKllG//v37m6biNDZhPdyECRNM+wO2HGD6JaNujOYxNbJz585o0qSJaTHAJuYUeKtWrTICjMtsEThixAjjuknjFDYTpykK95uv5XqMDBYvXtxjX+y8WTYjr1OnziV9LiGEEEIIIYRwhKCjaOvQoYOZaPxBYxSKO9afkS+++MLUoLG2LrMCj03B2QSczcrvv/9+hIeH47HHHjMijLBhOJ0pabzC1E8KsYkTJ2Ls2LF4//33ceLECVSqVMkIQ6ZK2tC58vPPPzfr0X2TaZZdu3bFqFGjHFHnJoQQQgghhBCXSkDyJXhz0pyEqYo0S6GwKlmyJLp3726cJvMSrMtjGwWarjhBLHJIOR5OKeoUKWhsnIvGxrlobJyJxsW5aGyci8bGuSQ77Po5M/rikjz269ata8Qbm3ozElavXj3jhimEEEIIIYQQwsGNxd0JDg42kTlOBw8ezIq3FEIIIYQQQghxAbK8C3aZMmWy+i2FEEIIIYQQQuSEoBNCCCGEEEIIkTNI0AkhhBBCCCGEnyJBJ4QQQgghhBB5xRQlNjbWNPFms/EzZ84gKSnJYzltPmfPnp2V+yiEEEIIIYQQIisE3UsvvWR6z0VERJg2BYGBCvIJIYQQQgghhF8IulmzZmH48OEYNGhQ9uyREEIIIYQQQogMkenwWnx8PBo3bpzZlwkhhBBCCCGE8LWg69ChA/7++++s3g8hhBBCCCGEyHESkxKxZP8SzN4z2zzyea5OubzmmmvwzDPP4OjRo2jSpAkKFiyYZp1evXpl1f4JIYQQQgghRLYwe+dsvLz4ZRyIOeCaFx4ajtERo9G1StfcKegefvhh8/jjjz+aKTV0uZSgE0IIIYQQQjhdzI2YOwLJSPaYfzDmoJn/5hVv+oWoy7SgmzNnTvbsiRBCCCGEEELkAIlJiSYyl1rMEc4LQABeWfwKOlXqhHyB+XKXoKtQoYLrb/ahO3XqFIoVK4bg4OCs3jchhBBCCCGEyHL+2fuPR5qlN1G3P2Y/Ig9GolXZVrlL0JGlS5fi1VdfxZo1a5CcbKlaOl+ynUGbNm2yeh+FEEIIIYQQ4pLYfXI35u2eh7l75mJJ1JIMveZQzCHHH/VMC7rIyEj069cPlSpVwn333YdSpUrh4MGD+PXXX3Hvvffiiy++QLNmzbJnb4UQQgghhBAig2mVqw6vwtzdc42Q23pia6aPW+nQ0rlP0L311lto2bIlJkyYgHz5UvJJH3jgAdxzzz149913MXHixKzeTyGEEHn0n/GyA8uw68guVD5TGS3CWzi+lkEIIYTvOBV3Cv/u+xfz9szD/D3zcezsMa/rlS9UHsfPHkdMQozX5ayho9tl8zLNkesE3erVq/HGG294iDkSGBiIO+64A6NGjcrK/RNCCJFHyQ1W0kIIIbKfvaf2uqJwSw4sQUJSgleB1qR0E3Ss1BFXVLwCNYrVwJxdc4ybJXE3R+G6ZFTEKL+4iZhpQVeoUCEkJKQ9SITz7Zo6IYQQIq9bSQshhMie7I3Vh1ebKNzc3XOx5fgWr+uFBoWifYX26FixIy6reBlKFCjhsZz/R/j/xNvNQ4o5f/k/k2lB17x5c3z88ce47LLLPJqKx8TEmPlMxxRCCCEultxkJS2EECJriImPMamUFHDz987H0dij6aZSdjwXhWtZtiVC8oWc930p2vj/xJXeX9L/0vszLehGjhyJ3r17o0uXLrjiiitQunRpHDp0CHPnzkVsbCxeeuml7NlTIYQQeQJaROcWK2khhBAXT9SpKONIyVTKxfsXIz4pPs06AQhAo9KNjICjkKtVrBYCAqyUyYxC8cb/J7UL1kbRokUz/Xq/E3RVqlTBt99+i3HjxmHevHk4ceKE+eARERHGGKVmzZrZs6dCCCHyBFuPb801VtJCCCEyTlJyEtYcXmPVw+2Zh03HNnldr2BQQbQr386VSlmqYKk8fZgvqg8dRRvdLoUQQois4mziWXy+9nN8uPLDDK3P9JgrKl2B0OBQDYIQQvhxKuXCqIUmCvf3nr9xJPaI1/VY18bffIq4iHIRyJ8vf47vq18Luh9//BEdO3ZE8eLFzd8XolevXlmxb0IIIfIANNP6c9efeG3pa8apLKNM2TQFs3bOwp3178RtdW9DkZAi2bqfQgghsob9p/cb8cZI3KKoRYhLivO6XsOSDa16uEpXoE7xOtmWCpmYlIzF249gx4FjqBqegIhqJZEvMCB3CbrRo0djypQpRtDx7/PBAy1BJ4QQIiMwnebVxa9i0f5FrnmBAYFoW64tFuxbYGojvJmj2LCH0LvL38Wnaz5F33p9cUe9O1CsQDEdfCGEcFgq5foj6131cOuPrve6XoF8BdCmfBtTD3d5xctzpKn3jDVReO6XdYg6EeuaV65oATxzXX10b1gOuUbQzZkzx5if2H8LIYQQl8Lx2OMYt2Icvtv0nflHb9O6bGs8FvEYahev7bUPXdnQssZKulrRahi/ejx+2/6bef3J+JP4aNVH+Hzd57i1zq24q8Fdeb6mQgghfMmZhDMm+sYoHKNxh854r3suE1rGpFEyChdRNgIFggrk2D7OWBOFoZMj09w23H8i1sz/4I7mfiHqApIz2TjOPf0yNXS75PKBAwciL5GYmIgVK1agadOmaRqu+wIOqW1W428uPbkdjY1z0djkDHQom7JxCt5f8T6i46Jd8ysUroBHWz2KzpU6e/xusYXB+aykd0XvwoQ1E/Dzlp+RkJzgcZf3pto3oV+DfggvFJ5Dny5voe+Mc9HYOJfcPjbsFUozE0bh/ov6z9RGe6N+yfouV8p6Jer55FgkJiWjwyt/ekTm3OEelS1aAP+M6uyT9MvM6ItMC7p69eoZl8vGjRunWfb333/j/vvvx+rVq5GXkKATGSW3/5D7Mxqb7GfhvoWmf9zWE1s9nMoGNR5k6uDSK3DPyNjQ2prC7ofNP3jUYgQHBqNXzV64p9E9RjSKrEPfGeeisXEuuW1s+HmYPkkBx3TKdUfWeV2Pv+9tyrUxAo7ROEblfMHZhERsPnAK66OiMWfDAcxYk36LHJuvB7ZB2xol4WR9kaGUy0GDBmHr1q2ugaNoCwlJ26TvyJEjqFy58sXutxBCiFzI7ujdxvDkr91/eczvWaMnHmr+UJb8Yy9XuByebPOkEYefrv0U3238DrGJsSYiyLTOaZun4drq1+LeRveiatGql7w9IYTIq8QmxJqecHZrAUblvFG6YGlTB8dUytblWpsbeDnJkVNnsT7qpBFv66KizeOWg6eQkJSpWBYOnvQewXMSGRJ0Q4YMwXfffWf+/uGHH1C/fn2UKFHCY53AwECEhYWZpuNCCCHE6fjT+HjVx/hi3RcezWAblWqE0RGj0bh02kyPS4Xi8LFWjxnhxu1+veFrsx+JyYn4aetP+GXbL+hWtRsGNhqIWsVraZCEECIDHD5z2BWFY10c6+O8wfRJ40pZ8QrUK1nPmFzlROrkjiOnsW5ftId4OxDtPd0zs5QpknM1fdkq6Jo3b24mm/vuuw+VKlXKzv0SQgjhp9Ck5OetP+PtyLfNRYD73drhLYajR/Ue2f5PvkSBEib6xxq6r9Z/hS/Wf4GTcSfNvv2+/Xczda3cFQMbDzS1HEIIIVJgRt7GYxutKNzueVhzZI3XwxMSGGKib4zCMRpXtlDZbD2Mp84mYMM5wbYu6qQRbxv3RyM2PsVcKz2CAgNQs0xh1CsXhvrlwlAnvAge+X4lDp0869VL2a6hi6jmGcTKFY3Fx4wZk+6ymJgYLF26FJdffvml7pcQQgg/ZMXBFaZOzv2fP+vY7m5wt4maFQoulKP7UzR/UQxtOtTU6H2z8RvTuPzY2WNm2exds83EixCmajYp3SRH900IIZwEDUwWRy22TE32zDO94rxRskBJVy0c6+JCg0OzRVDuOxHrirrZkbedR2Iy9PqwAkGoXz7MJd74WCu8MPIHedaiPX99A+NmSfHmLurs6ka2LvCHfnSZFnT79u3DM888g8WLFyMuznsTwPXrvfeWEEIIkTs5cPoA3op8C9O3TfeY36VyF4xsORKVivg2q6NwSGEjKPvW7YvvN31v6uxsC23aaXPiXebBjQejZXjLXGFWIIQQF4JZFPP3zDeRuIVRC9NNpWQrGQq4TpU6oUGpBlmaZWEbldipktZ0EifOpKTqn48qJUNdos0IuPJhKF+0QIZ+x9mSgK0JUvehK5sb+9C587///Q+RkZG4+eabzWPBggWN+8qCBQuwadMmvPvuu9mzp0IIIRxZHM/eb+wJ534hULNYTdMvjndvnQTvJLNHXZ+6fYwjJp0x7bvQrAvh1LxMcyPs2pZvK2EnhMhVMPK16dgmV2uB1YdXI9lLwiEzK9gTzo7ElS9cPkuNStZFnXAZlmTUqKRAcCDqlLUibvXLFTHCjc8L58+0nPGAou3K+mWxePsR7DhwDFXDiyOiWkm/iMxddNuC1q1bY9iwYbjjjjswefJk/Pnnn5g4caKx1hwwYAAqVKhgRF9eQm0LRF61K85NaGwyf7yYrvjG0jew99RejxTHB5o+YHrABQUGOX5s4hPjjVEKBenuk7s9ltG8hamYvJjR9zVnx0VcGhob5+KLsYlLjMPS/UuNoQlF3L7T+9KtPb6swmWmHo43tC4lRZ5GJdsPn/YwKcmMUUl4WH6PdEmKt6olC2WryEp22G9alrctcOf06dOoU6eO+bt69eoYN26c+Zsb6tu3L1555ZWL3W8hhBB+wMajG/HqkleNbbVNvoB8uKXOLbi/6f1G1PkLwfmC0btWb9NCYcaOGfhk1SfYdmKbWcY718P+HIY6xesY85Qrq1yZI45tQghxqRyNPWpSKRmJW7B3AWISvNeeMZuCAo43rngTK1/g+YXDhY1KLLOSizUqsdImi6BkYe99SUUWCboyZcrg8GHLtaxKlSpGyR46dAilS5dGsWLFTC86IYQQuY9jscfw3or3TF83ukXasPZsVKtRft0GgNFE9qm7pto1mL1ztmm3QIc3wsdH5j2C6kWrmzq8q6tdnWXRRyGEyKro0tbjW11RuJWHVnpNpeRvV6vwVlZrgUpXoELhCpnaxt7jZ1J6u9GwZH/WG5WIzJPp/0gdO3bEW2+9hbJly6JZs2bmkSmXbDY+depUhIeHX8RuCCGEcCrsITdl4xQj5mj9b1OxcEU82upRUyTvhPSUrIARuKuqXmWicbyz/dHKj1yOnYzcPfHPE/hg5QdG2F1X/ToT4RNCCF/AlPGlB5aa3yqamrinv7tTLH8x4+bLKFy78u2MSVRmjUpst8no2IRMG5WYx0wYlYgcqKE7duwYBg0ahEKFCuHTTz/Fzz//jNGjRxvVTp5++mncdtttyEuohk74a362SEFj451/9/6LV5a84kpDJKFBoaa2jK0AQvKF5Oqx4bYX7luIj1Z9hMiDkR7LyhUqhwENB+CGWjcgf768lx6k74xz0djk3rE5Hnsc8/darpT/7vsXp+JPeV2vRtEarihc41KNz5tKSaOSlDq3k0a8bT3kW6MSX5Ccl2roihcvju+++w4HDx40z3v27Iny5cubDTZu3BgREREXv+dCCCEcwc7onXh9yesmfced62tcbxp2lw4tjbwA/6m3q9DOTEv2LzGpmP9F/WeWRZ2OwkuLXjLz2MCcRjDZ0Y9JCJF3ocjYfmK7K5VyxaEVHinvNkEBQWhRtgWuqGjVw1UKq5SuUYm7SQnF28GTzjUqERnjouUza+lsWrZsaSYhhBD+zam4U/h49cf4Yt0XSEhKSa3hHd7REaPRqHQj5FValW1lJjZP/2T1J6Z3HWE/u9eWvmacMtkS4dY6t2YopUkIkbdITErEsgPLsOvILlQ+Uxktwlt4jZwxzT3yQKSJwjGdMrUDrw0NqOhKyUhc+/LtUSSkSBqjElfKpIxKcjUZEnSPP/54pt50zJgxmVr/n3/+wdixY7FlyxaULFkSt99+u2mBkF64MyEhwdTtff/99yZSSHOWwYMH45prrvFYb+vWrXjttddME/SgoCC0atXKpIdWqpRy12Lt2rWmJnD16tXmLkiDBg0wcuRI8yiEEHkF3vH9actPeDvybRyJTTG3KlOwDB5u8TB6VO8hh8dzNC3TFO91eQ/rjqwzrphs30COnT1mjt+kNZNwR7070LdeX79y/BRCZB80W3p58cs4EHPANS88NNzcKOtapStOnD1hUikZhaMr5cn4lHpld6oVrWZF4Sp1RJPSTYzDMI1K/tvCVMn9VuQtE0YlRQsGG1dJGZXkgRq6zp07ezyniKKoYqol3S2PHz+O3bt3IyQkBHXr1sU333yT4R1gqiZ72l199dW47rrrsGzZMnz00UcYMWKEqdXzBsXfxx9/bIxYWrRogT/++ANffvkl3nnnHXTr1s2sExUVhV69eqFatWoYMmQIzpw5Y4RbUlISfvnlFxQoUAA7d+406zRs2BD9+vUzApJCkeLuhx9+MG0ZMoJq6IS/5meLFPLy2DDiNGbxGCNQbEICQ3B3g7uN+Yev0widPjabj202EbuZO2Z6pEKxhxOjdYzasb9TbsPp45KX0dg4T8yNmDvCq+ukXe+2I3oHEpMT0yyjYGMkzzI0uQyxMSWs1gDnTEoyY1RStWToubYAMirxh+9NZvRFpk1RKIZef/11vPvuu6ZmzobRtfvuu89E1+6+++4Mv98999yD6OhoU5dnw6ja119/jX///dcIr9R06NABbdu2NevZ9OnTxwjKL774wjx/4oknsGjRIkyfPh0FCxY08yjUhg4daoQdU0RffPFF/Pbbb5g9ezZCQ60LlpiYGCNgGe2jwUtGkKAT/vpjIfL22Ow/vR9jl43Fb9t/85hPh8cRLUagYpGKcAL+MjY7TuwwaZfTt033uDArkK8Abq5zM/o36J+rag/9ZVzyIhobB43D2RO44ecbcPiM1fIrIzB1slV4O1Qt2ApBsXWx9UCSMSvJjFFJ3bK2cPNvo5K8/L1JzE5TFEbHGD1zF3OkZs2aePjhh026ZUYFXVxcnBFdDz74oMd8RtnGjx9vonXt27f3+rrChT3rE9gDb9++fa4BmTVrlknbtMUcadSokUnvtGEEjuvYYo7wb7Zi2LVrV4Y+gxBC+BuxCbH4dO2nmLhmIs4knHHNZx859pNjXzmReaoWrYoXO7yIIU2GmGP745YfTS1MbGKsqUn8dsO3xhHznob3oFzhcjrEQvgJ/B5Hn43GibgT5jE6LtoINTOdm8dHPndfzkdvUTdvhAWXQoXgNkg4WQ+7t4Xjp5V21G3PBY1KUhpyy6gkr5JpQce2BWFhYd7fLCjIRLgyCtM04+PjUbVqVY/5rIkj27dv9yro7rrrLkyYMAGdOnVC8+bN8eeff2L+/PlGaJI9e/bg5MmTJiX0ueeew6+//mpSLhnZe+aZZ4xgI3379k3z3kzD3Lx5s4kACiFEboI3u/7Y+QfeWPoG9p22boAR1nkNazoMN9a+UQ2zswBGNp9u+7Rp7fDZ2s9MI/aziWcRlxSHbzd+i6mbpqJnzZ5G2FUOq5wVmxRCZOD3jzew3MWY6+9zYsye5yHQ4qJxOv50th/fAzu6Ym9003PP0qZQBgUGoGaZwh7ijbVvJQvnvZYpIgsEHcN+H3zwgRFSDEm619UxDbN164zf2aXoIqmjbexxR06d8t5bg/VuDEEOHDjQNe/GG2/Evffe6xKdhKmhjCS++eabOHLkiHmkGPzxxx89onI2sbGxGDVqlEndZF3fxfxYZDKDNVuw98MJ+yI80dg4l9w+NhuPbjT95NiE1r02o0+dPhjaZKjLvMOJn99fx4aGB4+1eswIt8/WfWbEHC8oE5ITMG3zNBPBu6baNbi34b2oXixjNdtOwl/HJS+Qm8eGTpEn405aYsxNiHGe+3P+ffKs27y4Ex7OvdkJUyaLhhRFWP4wnIpNwK7Tmy74muSEImmMSlLEWxEj5vIHpU27y41j7CuSHfa9ycx+ZFrQUfDceeedJjrWrFkzk+pIsbR8+XIj8Cj2MgoNSs5HYGCg13RL1ukdOnTIRN+YNsltc7sUaU8++aRZh5QqVQrjxo1zvQ8jf6y1Yx0gH92heKTJCuvs3n77bVSoUAGZhbWA3vbZFyeAHSl1Qg6wSEFj41xy69jQeXHChgn4ZccvSELKb26r0q0wrOEwVAurBsQCJ2JPwKn4+9gEIQj31LwHN1W+Cd9t/Q5Tt03FqYRTxkCF9Xa/bvsVHct3xN2170bNojXhL/j7uORWmOK38vBK7Iveh/Jh5dGklOWE6DQYtTbCLD7aODqayFic9bfrOZedE29mXnx0uo20sxr2dQsLCUOR4CLnfQwLDjMCzn4sHFzY43j/unY//rf+XgQEnYC3rwmv2ZMTiqJTpZa4rmFZ1C5TCGXDQtJ8p2JPn+JPtchDv2lJF9BJlyTo6GJJo5FPP/0UkZGRJr2RzcZZi8baOQq8jFKkiHU34vRpz1C2HZlLHbkjM2fOxIYNGzBp0iS0a9fOzGMzc677/PPP45ZbbnG97vLLL/cQWIwucpvr1qU4udmOmGx7wBRP1gh27doVFwNTUS9UtJiTit4pRZ0iBY2Nc8ltY8OaD0aEPlj5gbkgsqlUpBIeafmIsb32l8+ZW8amKIpiZOmRGNh8IL7Z8A0mr5+M42ePG+e7ufvmmonjMrDxQDQq5fx+f7llXHKbmyIj8amt8VkbS2v87DgHKLDc0xdTpzGayJnbc7vGjLWlOUFoUKjJQLAjZvybQizN83Pr2M8LBhXMkvO6Suk4nJ17HQpUmGzEm/tb2gGYsweuwz231kab6iUveXsi9/ym0RQlo1yU3U14eLiJ1F0qlStXNgKIdWvu2IYkNWrUSPMa2/iEKZ/usMec7bbZsWNHMxB2pC71wXF3zty4caNx2jx79qxpWWC/z8XAbTrhBHDfF6fsj0hBY+NccsvYsIcRL+q2n9jucVEzuMlg0x8tJF8I/I3cMjaEF4wcizvr34kpG6cYgxq799/cPXPN1K58OwxuPBjNwz3/1zmN3DQuuUHMjZw3Mo01/sGYg2b+m1e8ma6oS2364c3sw1t9GcVaRk0/LoXAgMAUAXYeIWbPc18vODAYviImLgGT/t2BhJMNEbv3DuQP/wUBwSnZEIzMUcyVDmyJiGol9T1yAAEO+k3LzD5kSNCx5owiiZE4/n0h2NstI+TPn9+0D2AfOYoqe8cZhWMkLbWTJrF7wy1dutSYnNgwWkgqVqxoavAozOh0SaMU1sSRhQsXmlAqt2lH5vr3729EJdsk0KlTCCH8Fdrmv770dczbM89jfq+avfBQ84dQqmApn+2bSAv7+/Vr2A+31r0VUzdPNc6YvPgm/+7710wtw1sa8de6bGtHXGAI59aVsWm1tz5n9rwnFzyJ+Xvmm9RFj0ja2ROISci4od2lwBYeqaNk7kLMPLqLtnPL2dORos6fOHzqLO75dAlW7rEEHEVdwsn6yBe6HQFBJ03NXFJMNcpVPHNHfeQL1PdbXDwZ6kPHNMspU6YYgcW/z/uGAQFYv359hneAIoui6qqrrjLGJqyH+/DDDzFy5EhjesL0S0bdGM0rUaKEibDddtttxiFz2LBhRuCtWrXK1NC1adPGVcPH92GtHxuPMx2UdX40SaHgo3ijiGPNHHvQsRYv9edi2mZGBZ760Al/7XEicsfY8C75x6s+Nil87kX/TUo3weiI0WhYqiH8GX8em8wQlxiHn7b+hAmrJ2Dvqb0eyxqXbmwidpdVuMwxxyCvjIvTz5mtx7dixo4Z5oZATmGbfnhEydxFmds8W5xxXoGgtL2FcyPbDp1Cv0lLsOuoJZSL5A/CPR2q4duluxF1IiXVtFzRAnjmuvro3lBtTJxAcm5vLL53716ULl3aRLr494XIrKEII3TvvPOOqWFjOidNTyjCCPvU0ZmS/e169+5t5lHksdaNkTwe+EqVKpmoIN0v7WicHbXjehR8TLNkbRxTRVnrxnRMmrokJHh3PGJdnt2k/EJI0Al//bEQ/j02NNWgU+LbkW/jaOxR1/wyBctgeMvh6FGth998ltw2NpcC099+3/47Pln1CXZE7/BYVq9EPdMOoXPlzj6PWOS1cfE1/I7TrXbTsU3YcHQDNh7biO3HtxvX1IshKDDII0LmLrxSCzT39YzpR6Dv/QKcyrKdR3HvZ0txLCbePC8bVgCfDmhlGn0nJiVj8fYj2HHgGKqGFzdplorMOYfk3C7oRNYd8Lx4QooUNDbOxd/GZvnB5SbFat2RFJOnkMAQk8JHm3ym8+UW/G1ssjKNjn0DP1r1EbYc3+KxrGaxmhjYaCC6Ve3ms4vrvDouOTHuO0/uxKajm4xoo3jj3wfPWOm4l8KzbZ9F+wrts9T0Q6QwY00UHvpmBc4mWO6EdcsWwaT+rVCuaEHXOvreOJdkh/2mZUZfZKiG7vHHH8/wxnkA/ve//2V4fSGEEBln/+n9eHPZmyaC486VVa7EyJYjUaFw5luuCGdCoda9WndcVfUq/LX7L3y08iOsP2qVNFDgjZo/Cu+vfB/3NroXPar38Kn5g7g42LCaETdG3ije+Lj52OYMOUDSVr9asWqoU7wOahevjUlrJpk2Jd4IQIBxu2Q9raJr2cPEf7bjhV/XuZwr29csiQ/uaIGwAvpeiuwnQ4KOaY8ZxQmKVgghchtsSE03xImrJ3pc7PFCjnVyrcpevEOvcDZMrexSuQs6V+qMf/b+YyJ2Kw+tNMt2Ru/EUwuewocrP8SAhgPMBbs/upjmhTv/vBljp0raaZO7T+7OcM1a3RJ1jXirU6KOeaxRrIbHWLMlyYi5I6ztuZmjUMyRURGjJOaygaSkZLz023pM+CfFVbh38wp4uXdjhAT5l5GL8F+UcpkFKOVS+Gs4Xzh/bLhfM3fOxJtL30TU6SjX/GL5i2FYs2G4sdaNuf4izalj48vjsXj/YiPsluxf4rGsTGgZI+x61+ptUuqyez80LukblZhUSUbfzkXe6CqZESjMKN54s4bCjX+XLVQ2Q+c+WxcwFdu9D13Z0LJGzGVHH7q8Tmx8IkZOWYlfV6f8Ng/rXBMjrqyd7njpe+NcknN7ymVGYUsAthNgQ28hhBCXBi8IeXG27MAy17x8AflwW93bMKTJEGNQIPIevNBoXa61mSIPROLj1R+b3oOEbQ94ztD19O4Gd6NPnT7G8l1kr1GJK2UyE0YltPCvVbyWK+LGR4q4SxkvirZOlTqZ34xdR3ahcsnKaBHeItff9PEFx2PiMPDzpViyw0pzpbnJi70a4raIyr7eNZEHybSgo8vls88+i8WLF3tt3E0y07ZACCFE2ovEd5e/i6mbpnqkTrHZ9GOtHjOpVkIQNh7/MPxDrDm8xog41trZ59DYZWONlT2byfet19cYYYhLNypxpU1mwqiEzrO1S9R2pU3y7ypFqmSL0OJ7MgW7dsHajok05DZ2H43B3ZMWY9uh0+Z5aEg+vNe3OTrVLePrXRN5lEwLOrYPYDuAm2++2TwWLFjQhAIXLFiATZs24d13382ePRVCiFxOfGI8vt7wtamHYvNfm8pFKhshd3nFy3VxJrzCXoPvdH7HRIo+Wf0JZu2YZW4GsGn0eyvew2drPzOR3Tvr34niBYrrKGbQqMROm7wYoxJX2mSJOihRoISOeS5h1Z7jGPDpUtM4nJQqnB+T+rVCo4rKmBB+JOiWLFmC4cOH44477sDkyZPx559/4tFHH8WIESNM77g5c+agS5cu2bO3QgiRS5m/Zz5eXfKqR98xpl4NaTzERFdkdCEyAsXD6x1fx7am2zB+1Xj8tv03JCYn4lT8KSP02HyeaZhMxyxVsFSePqipjUrstMmsNCoRuYu/NhzEfV9G4kx8onlevXQhfNY/ApVK5J42MSKPCLrTp0+jTp065u/q1atj3Lhx5m8W6/Xt2xevvPJK1u+lEELkUnac2GGE3Py98z1c6ehW+GDzB/P8Rbe4OKoXrY7/XfY/DG0yFBPWTMBPW39CQlKCyy2VkWAa6vRv2N8YbuQ1oxJbxJ2MS4mEZ9SoxBZxGTUqEbmDrxfvwpM/rjHNwUmrqsXxyV0tUSxUAl74oaArU6YMDh8+bP6uUqWKcYM5dOgQSpcujWLFiuHIkSPZsZ9CCJGr4IUk+4p9uf5LDwOFpqWbmjYEDUo18On+idxBpbBKeLbdsxjceDAmrZ1k6jLjkuJwNvEsvtrwFaZsmmJuHtAZk6IlNxqVULzxxsnFGJVQvPG5jGXydiT3jVmbMO6vLa55PRqVwxu3NEGBYJnNCD8VdB07dsRbb72FsmXLolmzZuZx4sSJuP/++zF16lSEh4dnz54KIUQuMVf4ccuPeGf5O+bC04ZNf0e0GIGrq12tu/4iyylXuByeaP0EBjYaaOrpKOQYrWPU7vtN3+OHzT+Y5uRsUl6taDW/NSqhiDt05tBFGZVQxLFeVY6QwiYuIQmjp67CtOV7XfPu7VANT1xTD4GBis4KP+5Dd+zYMQwaNAiFChXCp59+ip9//hmjR482dzDI008/jdtuuw15CfWhE/7a40Tk7NjQSvyVxa9g/dEUJ+D8+fKbtLf+DfojNFh1GN7Q9ybr4c2EyesmmygdTUDc0327Ve2GgY0HmvRCp4yLbVRihNtRqzG3jEqcMTa5lejYeAydvAwLtliZZzyMT19bH/3bX9oND42Nc0nO7X3o7rzzTuNq2a1bNxQvXhzfffcdDh60rHp79uyJ8uXLmw02btwYERERWfMphBAilxB1KgpvLnsTM3bM8JjPC2dG5coXLu+zfRN5E7ouskaT5igUdRR3bHxNZ0yep5w6V+qMQU0GoUHJBjl6QRV1Oiqlr1smjUrYmsG9r5uMSsTFEHXiDPpPWoIN+60ay/xBgXj71mbo3jD315uKXByhu+6667B582YUKVIE1157rRF39evXz5k99AMUoRP+evdHZO/YGAOKNZ+aXmDulue8yBwVMcr0ihIXRt+b7IcRsG82fIPP133ukQpMOlToYGrwmpZp6pHueKnNq2lUsuX4FlfELbNGJUyPtJtxy6jEE31nLp71UdFGzO2Ptn6zi4cGY/zdrdCiSta0+9DYOJfk3B6h++WXX7B27Vr88MMP+O233/DNN98Yp0sKO4q9sDA1KxVCCPd/CjN3zMQby94wtug2xfMXx7Dmw9C7Zm/V6QhHQdOPexrdY3rVTd08FZPWTHLVov2z9x8ztS7bGoMaDzK97V5Z8goOxBzwqAGlmU/XKl29vv+RM0dczbg3HLPSJjNjVELRxno3GZWI7GTBlsMY8sUynDxrnZeVS4Ti0/6tUL10YR14kbtq6BISEjBv3jz8+OOPmDt3LgIDA9G1a1cj7tq0aYO8iCJ0wl/v/oisH5t1R9aZOrnIg5EezYZvq3cbhjQZYlLCRObQ9ybnoQvmj5t/NC0PmAJ5IVh7R9gDr2bxmi6XSYo3irjMGJWYVEm3tEkZlWQefWcyz7TIPXjs+1VIONeWoEmlYphwd0vTODwr0dg4l+TcHqHzeEFQkGkczokfevr06cYYpV+/fqhUqRJuvPFGDBky5FL2Xwgh/A5GIN5d/i6mbZ5m6pBs2ldoj8daPWb6ggnhL9Csp0/dPuhduzemb52O8avHY9fJXemub5/zI+eNzND78yZHtWLVULd4XVfaJB9Z2ydETl/Ev/fXFrw+a5NrXtd6ZfDObc0QGpLpy2Qh/CNClx5LlizBU089hZ07d2L9+hQHt7yAInTCX+/+iEsfm/jEeGMq8eHKD3Eq/pRrfpWwKkbIXVbhMo31JaLvje9he4P3V7yPT1Z/kunXyqgk59F3JmMkJCbhqZ/W4OvFKaY7d7SpjOd6NkS+bGpLoLFxLsl5KULnDhuK//rrryZKxxq7cuXK4b777ruUtxRCCL/h7z1/47Ulr2FH9A7XvMLBhU1qZd+6fRGcL9in+ydEVhEUGISaxWpmaN2GpRriiopXuNImyxYq64iLIyHcOX02AQ98FYm/NqakA4/qXhdDOlbX+Sr8jkwLutOnT2PWrFnGKGXRokVGMbKGbvjw4WjXrp2+BEKIXM+2E9uMkKNRhHsNUe9avfFAswdQqmApn+6fENlB6dDSGVqPrTjk4CqczMGTsbjn06VYvfeEeR6cLwCv39wE1zet4OtdEyL7BJ1thEIRRyOU2NhY1KtXD48//rhxuWRoUgghcjvs08XUyq/Xf+3hzte8THPThqB+SbVzEbkXnud0szwYc9CjTtT9pgaXcz0hnMqWg6fQb9Ji7Dl2xjwvUiAIH9/ZEm1rlPT1rgmRvYKuffv2iI6ONu0JaHrCSX3ohBB5Bfbc+mHLD8b0xL1HFy9eR7Ycie5Vuys7QeR62GeOrQlGzB1hxJu7qLNdLnljI7P96ITIKRZvP4qBny/FiTPx5nn5ogXw6YAI1A4vokEQuV/QNWjQwIi4K6+8EiEhIdm/V0II4RCW7l9qem6x6bG7A+CAhgPQv2F/FAwq6NP9EyInYZ+5N694Ey8vfjlNHzqKufT60Anha35dFYXhU1YgLiHJPK9fLgyT+rdCeFgBX++aEDkj6CZOnHjpWxJCCAdH4JYdWIZdR3ah8pnKaBHewlysvrnsTdMg3B1G41gjVK5wOZ/trxC+hKKtU6VOKd+ZktZ3RpE54VTnwgn/bMeLv6Y4sF9WqxQ+uKMFCudXWwKRO9CZLITI08zeOTtNtKFQcCHTWJlW7Tb1StQzEQheuAqR16F4o/FJ7YK1HWPxLURqEpOS8cL0dfj03xQn4ptbVMT/ejdCcL5AHTCRa5CgE0LkaTHHeqDUBg+n40+7/maj4webPYheNXspAiGE24Xy4u1HsOPAMVQNT0BEtZLZ1rdLiIshNj4RD32zHDPXptyse7hrLTzUpZZuQIhchwSdECLPplkyMufNrc8mNCgUP17/I4oXKJ6j+yaEk5mxJgrP/bIOUSdiXfPKFS2AZ66rj+4NlYosfM/R03G497MliNx13DznzYYxNzTCLa0q+XrXhMgWFG8WQuSpWord0bsxddNUDP5jsEeapTdiEmKw5fiWHNs/IfxBzA2dHOkh5sj+E7FmPpcL4Ut2HjmNGz/41yXmCoXkw8R+rSTmRK5GETohRK4m6lQUFu9fbKYl+5cg6nTmLjgPxRzKtn0Twt/SLBmZ8xbT5jwmXHL5lfXLKv1S+IQVu4/jnk+X4MjpOPO8TJH8Rsw1rKB+ySJ3I0EnhMhVUIDZ4m1R1CLsObXnkt6vdGjpLNs3Ify9h1fqyFxqUcflXE9NmkVO88e6Axj2dSRi4622BLXKFDZtCSoWD9VgiFyPBJ0Qwq9ho2+Kt8VRVhRuR3SKm1lq2D+uaZmmiCgbgZbhLfHo348aAeitjo6Nktlbq3mZ5tn8CYTwDw6eTF/MubMhKlqCTuQoXyzcgWd+Xoukcz/lrauVwMd3tkTR0GCNhMgTSNAJIfyKE2dPmGbfdhrl+WrcggOD0bh0YyPgaLHepHQThOQLcS1/POJx43JJ8eYu6vicsE2BemsJkWI0kRFe/G0ddh6NwQOda6JU4fw6fCLbSEpKxqszN+LDeVtd83o2KY/Xbm6M/EH5dORFnkGCTgjhaE7GnUTkgUiXgNt4dGO6zpRBAUFoUKqBEXAR5SKMgCsYVPC8DZLfvOLNNH3oGJmjmONyIfI6NBP66O9teHXGhgytn5gE0/fru6W7ce9l1XHvZdVQpIAiJSJrOZuQiEe/W4WfV+5zzRvSsQYe61YHgWqhIfIYEnRCCEcREx+D5QeXY9H+RVgStQTrjq5DUrJVE5GawIBA1C9RH63KtTIijumRocGZq5egaOtUqROWHViGXUd2oXLJyqZ5uCJzQgAnYuIx8ruVmL3+/I6wdge6bg3DMW/jYZyJT8TpuES8PWczvvhvJ+7vVBN3tKmsqInIEk6cicfgL5biv21HzXPqt+d6NsCdbavqCIs8iQSdEMKnxCbEYsWhFaYGjrVwaw6vQUJygtd1mQpZp0Qdkz5JAUfhVSSkyCXvA8Ub37N2wdooWrSoms4KAWD1nhO476tl2H30jOt4DOtcE/XKhuGFXz370JV160N3MDoW7/65BV8v3oWEpGSTqvnC9HWY+M92DL+yNm5oVkEumOKi2Xv8DPpNXIzNB0+Z5wWCA/Hubc1xZf1wHVWRZ5GgE0LkKHGJcVh1aJXlQrl/kfk7Pik+3fVrFqtpxFbrsq3RsmxLFM0v+2khsjvF8qvFu/Dcz+sQx/xJAMVCgzG2T1N0qlPGPO/WsCwWbz+CHQeOoWp4cURUK+kSaWXCCuCFXg1NquUbsza5UuJ4If7Idyvx0byteLRbHXMBHhBgx/aEuDBr951A/0lLcPDkWfO8ZKEQjL+7JZpVLq7DJ/I0EnRCiGyFYm3t4bWuGriVB1ciNjF9t7yqYVUtE5NyrdAqvBVKFiypERIihzh9NgH/98Nq/LgipS6paaVieO/25qhQLKUeleKtTfWSqFcyKN2odpWShfDObc0wuGN1vDZzI+ZutHo6MrIy6ItlaF65GEZ1r4vW1fUdFxfm702HMHTyMpPKS6qWDMVnAyLMeSZEXkeCTgiRpSQmJWL90fUuAUdDkzMJKSlbqalYuKIxMLHTKMuEWhEAIUTOsuXgSQyZHIkt51LZSL92VfHENfUQEhR40e/boHxRfNo/Av9tO4JXZmzA8l3HzfzIXcfR5+P/cEWd0iZix/WE8AYNdh6fttqk8JJmlYth/F0tUVIuqkIYJOiEEJcEDUs2Hdvk6gNHc5FT8SkXhKkpW6isq40AH8sXLq8REMLH/LRir7lgjjkX/SgUkg+v3tQEPRqXy7JtMKI3bWg70wCaETu7BoqRO060mx95VW1FXIRH+i+Ndd6avdk1r1uDcLzVpxkKhqgtgRA2EnRCiEz/g916fKvlQrl/CZYeWGp6w6VHqYKlrDYC56aKRSqqbkYIB1m/07Bk8n+7XPPqhBfB+3c0R43ShbN8e0zNvKpBWXSpF44flu/F2D82mdo6wlq731ZH4baIyhjWpSbKFCmQ5dsX/kN8YpJJ/52ydI9HxPipa+vLVEeIVEjQCSEuKOB2RO8w4o0ROD4ejbWsor1RokAJtAxv6aqDqxZWTQJOCAey+2gM7v8qEqv2pNyQualFRbxwfcNsj36wBo/burZxOXy5aBfe+2uLccNkSh3bHHy/bA8GdKiKwR1rIEw97PIcp84m4L4vI03dnM2TPerhng76fyKENyTohBBpBNyeU3tSBFzUEhw8czDdoxQWEmYJuHJWBK5GsRqmP5wQwrnMXncAI6asQHSs1SIkf1CgEXK3tKqUo/tRIDifuUi/pWVFjJ+/HePnbzOmF+xj995fW43Yu++KGrirbVWzrsj9HIiONU6W66KizfOQfIF4s08TXNtY6flCpIcEXS40pHA1SD6jBskiY0SdinKZmFDIRZ2OSnfdQsGFjICza+BqF6+tJtxC+AkJiUl4fdYmfDhvq2telZKheP/25j41JSlSINj0qLuzbRWM+3MLvly0E/GJyTgeE4///bYBE//ZgYe71jJRvaB8umGUW9l04KQRc3YabtGCwfjkrpaIqFbC17smhKORoMtFzN45Gy8vfhkHYg645oWHhmN0xGh0rdLVp/smnMWhmEMu8cbH3Sd3p7tuwaCCaF6muUvA1StZD0GB+ukQwt9gw+8Hvl6OxdtTUqa7NyiLV29u7Ji0xlKF8+PZng1M1G7s7E2mzi45GdgfHYvR01bj4/nb8OhVddC9YVmlcucyFm49gkFfLMXJc1Fjtsn4bEAr1CxTxNe7JoTjccRV2T///IOxY8diy5YtKFmyJG6//XYMGDAg3R/rhIQETJw4Ed9//z0OHjyIKlWqYPDgwbjmmms81tu6dStee+01LF68GEFBQWjVqhVGjx6NSpVSUkoOHz6MMWPGmH3g+3bs2NGsU6ZMGb8TcyPmjkAyLEtfm4MxB838N694U6IuD8OaN4o308w7apGpiUuP/Pnyo2npplYz73Kt0aBUAwQHOuNiTwhxcfy79TAe/HoFDp+yGjIHBQZg9NV1HVuTVKlEKN68pSkGXV4dr8/ciNnrrbTvbYdOY+iXkWhSsSge614X7WuW8vWuiiyAhjiPTFnpamTfsEIYJvZrJWMcIfxF0K1YsQJDhgzB1VdfjYceegjLli0zIiwxMRGDBg3y+pp3330XH3/8Me6//360aNECf/zxB4YPH458+fKhW7duZp2oqCj07dsX1apVw5tvvokzZ87grbfeMkLxl19+QYECBYyAGzhwIE6dOoVnn33WPH/jjTdwzz33YNq0aQgODvabNEtG5lKLOWLPe27hc6bWqXiB4uaxaP6iKBAkB7HcCl0nl+5f6kqj3HJ8S7rrMtrWuFRjI94o4hqXbmxEnRDC/0lKSsYH87bijVkbca6FF8qGFcB7tzdDiyrOT2OrWzYM4+9uhaU7jpoedkt2HDPzV+45gdvHL8JltUrhsW510aiietj5a832R39vw8u/b3DNY1/C9/o2R6H8Pr9EFcJv8Pm3heKsXr16RsSRyy+/3AirDz/8EHfddZcRXqmZOnUqrr32WjzwwAPmedu2bbF27VpMnjzZJej4voULF8akSZNQsGBBM69ixYoYOnQo1qxZg5YtW2LGjBlYt24dfv31V9SsWdOsw33he//+++/o2bMn/IHIg5EeaZbeOH72OO6ZdY/HPF60Fw0pirD8YS6Rx8n1d8i55/nDXOvxeeHgwjK9cBgn406aBt52GuWGoxu8CnySLyAfGpZq6OoF17RMU5NWKYTIXRw7HWeMT/7amOIUSAH0Vp+mfteQuWXVEpgyuC3+2ngQr87YiA37T5r58zcfxvzN/6BHo3Kmh131bGi1ILKHxKRkPPvzWuNqanNrq0p4sVdD1UkK4U+CLi4uDosWLcKDDz7oMZ+ibPz48SZa1759e6+vo1hzp1ixYti3b5/rjs+sWbNMNM4Wc6RRo0YmtdKGfzOCZ4s5wr9r1KiBefPm+Y2gYz3UxXA28axxLzyfg6E36GBYJKRIWsHnJgpTC0N7neB8/hH1dDox8TFYfnC5FYGLWox1R9eZBt/pjVe9EvVcAq55eHNjbCKEyL2s2H0c938Z6TKXYFblQ11qYVjnWn7bw4upoZ3rhuOK2mVMit4bf2zE7qPW5/t1dRRmrN2PW1pWMp+zbFFloDiZM3GJePCb5abJvM0jV9XG/Z1qOjIFWAin41NBt3v3bsTHx6Nq1aoe81kTR7Zv3+5V0DFyN2HCBHTq1AnNmzfHn3/+ifnz52PEiBFm+Z49e3Dy5EmUL18ezz33nInAMeWyQ4cOeOaZZ1C2bFlXjV3qbZPKlSubbfsLpUNLZ2i97lW7IzQ41KTjmSnuBKLPRiM6LhpnEqx/ihmBwsF+D1g3STMMI0Ee0b9zos8jCnhumfvy0KDQPP0jH5sQixWHVhjxxgjcmsNrkJBsFY57o07xOq4aOAo4HkchRO6HNzQ/X7gTL/66zrhEkhKFQvD2rU1xWa2M/a9wOoGBAejVrAKuaVQOXy/ehXf/3IzDp+JMxIfPp0XuQb/2VTG0Yw0UCw3x9e6KVBw5dRb3fLbU3HSw6zlfvakxejevqGMlhD8KOooukjraVqiQFT1gbZs3+vXrZ2rvWP9mc+ONN+Lee+81fx87ZuXYv/7662jcuLGpoTty5Ih5pBj88ccfERoaarZvi8fU2z99+vRF/SPllNM0K93MuFnSAMVbml0AAszyMR3GpGsvz2idLe7cxZ77I+e75p1bj6l+6aX2eYPCkdP+0/sz9RmDAoJcKZ9G5LmlgNrPvQlDRhKd4sjo0VIi5vwtJeIS47Dq8CqXkcnKQysRnxSf7nuz91tEuBWBY0uBYgWKeSz3xXnpT/BCcPH2I9hx4BiqhscjolpJv41i5Ebs31adxxduxvz4tNWYviql7UiLKsXx7m1NUa5owSw/fr4el+B8AbirbRXc2LwCJi7YgY//3maOwdmEJHw0bxu+XrQLQzrWQL92VbO9UbrT8PXYpMf2w6dNW4KdR2PM88L5g/DBHc3RoWYpx+1rXhsbAceNTWb2w6dXuklJ3lPEbAIDA72mW9IF89ChQyb6Vr16dSxfvhwffPCBEWlPPvmkWYeUKlUK48aNc70PxVufPn2MKQofz3egLiYaFB0d7XWfc4JhDYbhySVPel1GwfVAgwdw6qR3gWwTghCUCiiFUgVKARnMVklMTsTp+NM4GX/SiLzo+Ggj8vi3mRcf7frbzHd7fj6BkhpGo+jUyCmzFA4qbIRdkeAiRvyFBYdd8Dkfs9IYZN6+eXh79ds4FJuSHlu6QGk81OghdCzfEQlJCdhwfAMiD0ci8lAk1hxbY0R2elQqVAnNSzdHs1LN0KxkM5Qo4GZucNYyRREZY87GI3h19jYcOGn9bpDwIiF4rGt1dKlTUofRAfC3OibGugDMy5H687Hl0Gk88sNG7DiXgkjuiiiPYR2rIBhxOHEi5fzOjeNyV4vSuK5eMUxcuAffRkYhLjHZNE1/deZGTFqwDYPaV0KvxuEIziM97Jw0NjYr90bjoe/X4/gZK7ukTJEQjLu5PmqXDsaJE3nnf5YTx0Y4c2wupJMcI+iKFLF6i6SOhtmRudSROzJz5kxs2LDBmJ20a9fOzIuIiDDrPv/887jllltcr6PBirvAatq0qdkmjVDs9/cWieP27X3LDGFhYcZp0xf0LNrTCNpXlrziYZBSNrQsHmv1WLa2LCiBEhf1pWGkzohAOyqYKg00vUghBWRmOJVwykxRSL9ZtjdCAkPSrRF0pYqmNpAJCUPhEE/TGLaUeGrJU2kimRR3FOF1i9fFrpO7EJNg/Yh4o0LhCq4aOE6MuIpLZ8aa/XjkBxrIeHLwZJyZz2bL7HclfIt9861o0aKO+CfrNKZG7sGTP65BbLz1z79I/iCTwpbd567TxqVoUeD53qUwuHMdvDNnM75ftsc4ex46FY+XZm7Dl0v3G+OUaxqWM2mbuRmnjc3Mtfvx0DdrTfSU1AkvjEn9W5nIcV7DaWMjnDs2dPz3C0HHWjUKoJ07UxyOyK5du8wjzUlSYxufsHbOHfaYI+xlx15yHAg7Upf64NjOmTREWb9+fZp1uH2mamYWbtOXJ8CVVa9E58qdU9L6Sp4/rc+X8DgVCilkpnIol6nXMrLHaJ8tAm3x500Yuh7PLWdEMaPEJcXh0JlDZrpY0xhG/TYf33zetNQNx1Lsmm0o2Ow2AhRy5QuXz9Q+iIylWT4/fZ3XkeE8fpO5/KoGZZV+6QDs31cn/JN1CrHxiXjul7X4evFu17z65cLMjYiqpQrl2XGpWDwUr97UxPSwe23mRsxca93k3HEkBsO+XoEPy28zPewur1XKUfudW8fm0wXb8Rx/a8/92LarURIf3tnCMc3s8/LYCGePTWb2waeCLn/+/KZ9APvIsfebveOMwjFC5k1UMcWSLF261Jic2ERGRrpaE7AGjgKPTpc0SgkJsYqiFy5caEKp3Cbh66dPn25EoO10yb9plsL2Bv4IxRtFQO2CtR1zhyGrYZNrphh6pBlm8M4Lo3t2PWB6YtA9OmjXCV60aUwGYWSvfYX2RrxxqlSkUq4cOyfx37YjiDoRm+5yXntw+eLtR9G2hlIvhbPYeeQ0hk6OxLqoaA/L92d7NkCBYOfdxPMFNcsUwUd3tsTyXcdMD7v/tlkp+2v3RePuiYvRpnoJjOpeF80qF/f1rubaHohjfl+PT+anmMzd0KwCXrmxMUKC8kbqqxA5RUCyjyv/KLL69++Pq666yhibsB6OPehGjhzpavpNkcVoXokSJUyE7bbbbjMOmcOGDTMCb9WqVaaGrk2bNuaR8H3uvPNO03ic7QtoikKTFAq+r7/+2kQGGcFja4KzZ8+a7RE2Fmcq5g8//ICgoIzpXe4TTVqY0umrlEt3OKTMR8+tgs4X2KYxqaN/7iLQ67y4lIut8/HyZS+jR/Ue2f45hHWR8duaKLwwfR0ORKdfp2jz+s2NcVOLSjp0PkS/aWnT1x75biVOxlq1SAWCA/Fir0a4qUXOugT607hwX9mzjsKOgs6dbg3C8Wi3OkYA5hZ8PTaMHo/8biV+dTPoub9TDTxyVR3Hnyu5fWyE/4xNZvSFzwUdYYTunXfeMa0CwsPDjekJRRhhnzo6U44ZMwa9e/c28yjyxo4dayJ5PPCVKlVCr169jPulHY2zo3Zcj4KPaZZdu3bFqFGjTK2bTVRUFF566SUsWLAAwcHBpk3C448/jjJlymR4/yXoRHr8t+8/DPwjxY01PSZ2m2giqyL74E8dL4TH/rEZGw9kvN9GyULBGHV1PfRuVkHNbn2E0/7J+or4xCS8OmODR8SjeqlCeP+O5qhbNudbk/jjuPCGDnvWvTFro0nBtGFJ3Y3NK+LhK2ujQjH/r+vy5dgcj4nDoM+XYfGOo65jyxsOfVtXztH9cCr++L3JKyQ7bGz8TtD5OxJ0It1zIykR3aZ2u2BLiRk3znBkrWNugD9xc9YfxNjZm9Lcmaftud2r60LULFPY3MW/qn64I37o8xJO+yfrC/afiMUDX0Vi6U6rLQ/p0bicSV+j9bsv8OdxoTiesnQ33p69GQdPpkTqmQp4V5squK9TTdO/z1/x1djsPhqDfpMWY+shy7ysYHA+vHd7M9MQXvh2bIT/jU1m9IWSmIXIRijSRkeMdok3d+znoyJGScxl0w/z3I0H0eu9Bbj386UeYq5ppWL44p4IvHNrMzMKqX+27ecNK6REPbYcPIXBXyzDDe//i4Vbj2THLgvhlX82H0aPd+a7xBxvRDzXswHG3dbMZ2LO32H7gttbV8G8Rzvhse51UKSAdRzjEpIw/p/t6PjqX3h3zmacPmultYoLs2bvCfT+4F+XmCtVOATfDm4jMSdEDqAIXRagCJ24EGxd8PLil9O0lKCYy86WEnlVyP279Qje/GMTlrlFM0ijCkUx4srauKJOadfdtxlrovDcL+s8DFLKFS2AZ66rj+4NyxlTFKa5uUdGyOW1S+OxbnXQsELRHPpkeRen3TXNyfTAd//cgrfmbHI5BDIdcFzfZo4w8shN48I0wQ/nbcOkBdtd1vq2KBnWuRZui6jsV0YeOT02f208iPu/jERMnOUkXb10IXzWPwKVSoRm+7b9jdz0vcltJDtsbJRy6eADnhdPSJGSfukPLSX83bmSQo4izJ165cIwvGstXJlOuiRbGCzefgQ7DhxD1fDiiKhW0qNVAb9Tf244iFdnbExTf3ddk/IYeWXtHLOJz4vkxd+0I6fO4uFvVxgjD5tOdUrjzVuaorhDUgFz47gwtfXtOZtNOiZ/F2wqlSiIkVfWQc8m5f2ih11Ojs3Xi3eZPoj28WpZpTg+uaulY85Tp5Ebvze5hWSHjY0EnYMPeF48IUUKGpvsYdnOo0bILdjimQpZO7wwhnetjW4Nyl7wIiwjY8MLlp9W7DXb2nMspZVFUGAA+rSqhIe61EKZMKvPpcg68tr3hufz/V8ux/5oK2rMU3fkVXUwtGMNR4mJ3Dwu2w6dwht/bPJwaSR1yxYxKZqd6pRx9GfOibHhNvhbyCiyzTWNypqbDmqd4duxEbljbDKjL5R8L4TwW1bsPm4uKP7e5Nn8nek+D3etjWsblcvSC2BG7Xo3r2jMKL5atAvj/tyCI6fjkJCUjC8X7cLUyD0Y0L4aBnesgaIF827TXHHxFxMTF+zAmN/Wm3PKTvl757ZmaFejlA5rDlK9dGG817c5Bl9+3DQntyOlG/afxIBPlyKiagkj7FpWzVw/1NwCaw1HT1uFaZF7XfPu6VAN/3dNPUfddBAir6AauixAETrhr3d//Ln4fuwfmzBnw0GP+VVKhpoo2fVNK3ikTGbX2Jw6m4AJ87fj47+34vS52hFCMTf0ihro166q7lRnAXnhexMdG49R36/C72v2u+ZRNLzbtxnCHRr1zQvjYrNgy2FTS7tyzwmP+V3rlcEj3er4pG2Er8aG5+p9kyPxzxZL5PLtn+pRHwM6VMvS7eRW8tL3xt9IdtjYKOXSwQc8L56QIgWNzaWxPioab83ehJlrU8xlSMXiBfFgl1qX1CvuUsaG9U7v/bUVk//bibjEFEOF8LD8JlJ4c4uK6mF3CeT27826fdG478tlHn3RhnRkE+bajj5vcvu4ePu8M9bsx2uzNmLbOSdHwo9+Q7MKJr3bKSYg2TU2rDFkWwJGKkn+oEC81acprm5ULsu2kdvJa98bfyLZYWMjQefgA54XT0iRgsbm4th84CTemr3ZNAR2p3zRAnigcy3c1KLiJTvQZcXY7DkWY/ZzWuQeuPkpmObPrIFifYm+k74ZG6cyZcluPPXTGpezYliBIFOD1LW+8/t25eZxOR8JiUkmvXrsH5tddY52Owm2Qnigc02UKpw/143Nhv3R6D9picsRuFhoMCbc3RItquTNtNOLJa9+b/yBZIeNjQSdgw94XjwhRQoam8yx9dApvDNnM35euc9l225Hvu7vVNMYkeQPyue4sdl04KSpu/lj3YE0bRNGda+LDrVUD+WrsXEKZ+ISjZD7ftkej/Pj/dubOybKkxfHJTPExifi84U7THT+xJl41/xCIflw72XVce9l1VCkQHCuGJt/txw2fThPnuvLV7lEKD7t38rUGgrfjo3IOpw2NhJ0Dj7gefGEFClobDLGziOn8c6cLfhhuWeki3e977uiBvq2rpzltWnZMTbsg/fKjA1p2ii0r1kSj3WriyaVimXJdnI7ue17QwfF+76MdKWtkTvaVMaTPer7Vc1lbhuXi4Vi7pO/t2HCP9txJj6llrZEoRBz44ljm1U3nnwxNvwdfuz7VYhPtH6Mm1Qsign9Wvk8Cumv6HvjXJId9psmQefgA54XT0iRgsbmwimL787Zgu8j93j0gOKF0ZCO1XFHmyoIDQnyq7Hh+87ddMj0sGMNoDtMwWQqZg3d5fbJ2PgC2uCPmrrKGOqQgsH58PKNjYyRj7+Rm8YlKzh4Mtb8frEvm+1SajeDH35lbVNnl1mzJl+ODd/j/blbTbaBuwkMXVez63c4L6DvjXNJdthvmtoWCCH8iqgTZ0wLADbzte8C226Rgy6vbtwiC+X3zwsI/lNgz6qOtUrjl1X78MasTdh11DK/+G31fmPwQtOUh7rWQrmiBX29uyIbbd7/99t6fPrvDte8mmUK44Pbm6NWeBEd91xAmSIF8EKvhibVku1Uflqxz8zfe/wMHvluJT6atxWPdquDK+uHO+Ji8UJ1gk//vNa0Z7FhpPHZ6xo42qhHiLyKf14hCSFyBQejY80dYF40uLtDFikQhIGXVUf/9lV9VoOS1bA3E6MwVzcsh2+X7MLbc7bg8KmzJhL5zZLd+GH5XiNc2e6gWGiIr3dXZCG8oL//y0jTN9GmV9PyeOmGRn57o0KkT5WShfD2rc3MzShGt+ZutPpkbj54CoO+WIbmlYuZWtrW1Us68jCePpuAYV8vx59ubWHYc4+N7Z0uRIXIq+g/iRAixzl08iw+nGfZ/NvufqRw/iAMaF8V93SojqKhuUPIpYZunHe2rYobW1TEpAU78OHcrcZogMfho7+34avFu4xlPcWs0pr8n7kbD+Lhb1fgeIxlmhGSLxBPX1cft7eurIvjXE6D8kXxaf8I/LftiOlhF7nLEvR87PPxf7iiTmkTseN6TvptHvDpEqzee8Ll3Pn6zU38MiVYiLyEBJ0QIsc4ejoOH/29FZ//u9PDPIB1RP3aV8Wgy6qjeKG8EZ2iWKNhQt+Iyvhg3laTise0vJOxCeauPp+zt96trSohWClOfgcjr+yZOO6vLS6HVvZL/OD2FmhU0TkX8CL7aVO9JKYObYfZ6w/itZkbsOnAKTOfkTtOPZuUx8irapvInq9dhdljbvfRM65MiY/ubIF2NeTKK4TTkaATQmQ7x2PiMH7+dkxasB2n41KEHJvS3tW2CgZ3rJFnHdMoYJ+4pp6JyL09e7OpI6SfAu+UP/XjGoyfvw0jrqyN6xqXN2mbwvkwlfahb5ZjwZYjrnld64XjjZub5NrIszg/TFVk7VznumVMevXYPzaZVFzCtiy/rY7CbRGVMaxLTVOLl9Ms3XEU936+1BVJZo/PSf0jUKes6juF8AcCkmnpIi4JuVwKf3VQym6iY+Mx8Z/tmDB/u6t/kZ12yJQz1mSUCcv5ixcnj82Wg6fwxqyN+H3Nfo/59cuFmTqWjrVL54lzx4ljkxHYouKBryJx8ORZ85yuho91q2PqqZy+77l5XJzG2YREfPnfLhPBZeaCe7bCgA5VzU2usEuoH87M2FBMMi2YGQKkbtkiJlW0bFFn/DbnNvS9cS7JDvtNk8ulEMKn0JL90wXb8fHf2xAdmyLkWI9xa6vKJtVQFwveMc6Hd7TAyt3HTQ+7f7daUZ51UdHoN2kJWlcrgce610WLKsVzaDRFRi8EeL6/OnOjq+VGmSL58e5tzRxrfiF8B/vSDehQDTe3rGiyFxiJZ/YCU9HZqPzLRbtMz8272lbN1t6E3O5Lv613pQVfVquUaW6fW8yohMgrKEKXBShCJ/z17k9WExOXgM8X7jT23MfOpe6QoMAA3NyyEh7oXNP0ZHIiTh2bfzYfNsLONimwYfoWDRVq5wHLe6eOjXtjadrS/7HugGte2+olTb+u0kVybyqx08fF39J03/trizGKcm/dUjasAB7uWgs3taiYqXYBFxqbpKRkvPjrekxcsN01j9sY07uRanazGX1vnEuyw37TFKETQuQosfGJ5kKEzpWHT6WkDzHdrHezChjWuRYqlwzVqFwEHWqVQrsa7U0K5uuzNmL74dNmPsXDnPUH0Lt5RXPBV7G4jq8vWLP3BIZ+ucxlJEEe6FTTNJLOqSbSwv9hDfEz1zXAgPbVMHb2JlNnx6jZ/uj/b+9OwKIq2zeAPywKLuxuiMjmvov7kpprm+lfU1Ozcsklza3S9vJrz1KzXCptVdOyzOyr/EwrNc0NzV1BwQ0VFQQ3kO1/3Q+eaUBALGTODPfvurhGDsPMYY4D5z7v8z5vsjz17S75cN1hebJrTbmjXqV/faKJ39cTluzIVtY9rlN1/T1ihpNYIrp5bIpCRP/qxGDx5qMy67dD2sTDgHOCno0CtEtjSDnbdm5zBGiGcncDf+lat6J8vfW4vLv6oJxOStHmKUu3HZfvd8TKAy2DZPTtYeJXTJvL2OJKLpaYmLJir2XukXfpEjK9byO5vVYFW+8e2alA39IyrW8jGdEuTLvd/rIva9T38JlLMmphhDSs4qUl122q/bPOkwmXrmrzk21HEvRzXHR47f/qSb9mVQv15yCiosVAR0Q3DSew6MaIEqGTicnZgtzd9f31Sm+1Co5fCljUsHzBgBZV5f8aB8hnG2Nk9q9ROkcRi7KjdArHBAuyD70tRNf0o1tXWvzsst06imJoGOitc4/MWlJM9gXdJec91FS7T6LkektMVgD763iiDJy3See6TepW66aWwDh67rIuS3D42ih/mZIuMmtguHSoyQsQRPaOf/GJqMBS0zPk24jjMnN1lKXltuHOepVkXOfqUquSJ1/RW6xUSRddfLx/s6oyd+0hXQ4iOTVDm9GgXOvzjTE6XxHhD80XqPBExV2QUQsiJDIuay0xeLh1sC49ge6tRIWpabCvfDWila5Xh2C3/9QF3b4u8qysi1yvF9Cwhl1o+bL5Pg6aLA39bIulJB5zOz95uJnUC+CaiESOgE1RCgGbopC9TrgtqLT0DPluR6zMXB0pR+MvZ/sa1tfCiJy9nxjY67GB00nJemwWbzlm6bBoLGSNNex6NAqw6/lcZjk2y3eckKe/3SWXr62liBGON+9rIPc0qCzFkVmOS3GBRiZYs+6dVQeyzdnEe7tv00CdB4fuwfgdsDn6nMScTpDgij5yMTlNxi7eoR00jU66nw5uxnm3NsL3jXllmux32s3kCwa6In7Bi+N/SLLfY4MTgx92xuqC10aZjqFDzfIyoXMNLTVzBPZ2bHKDhilYw+6HnSezbce6UuiIiUWN7fFns/WxwZphr/ywT77484hlW82KHjL7gXAJu8HIiCOz9XEpziXvi7cc1Ys41k2o3FydpV2N8rLz+HmdY5ub5iG+8tGgplzg3ob4vjGvTJP9TmOXSyL611eC0QFtxi8Hs5WWAeZujO9cg+ugmRAa0Lw/IFxGtk/U9dDWHjyj21GmNfSzrdI0yEcm31lLmgX72npX7cax+MsyelGE7Dz+97IRvcOryCs962npK1FRQ2kv1qfD/8OP12et93khJU1S0jKyLZ2RU5Mgb/liaHOWYRM5IM6hI6JsV6dW7jmtQc6Yq2HAgtYo3+MiyeaH8tfPhzSXDYewht0BnT8DW48kSJ+5G6VTrQryRLeaUtuf8x3zg2UhJn71l64zZ5xIv9yjrpa3meHqLRVvZdxc5bFO1WVgyyCZ9WukzF8fk+/9Y88ni6sz53kSOSIGOiLSILdmf5xMW3VQ9sQmZXtFMKozsWsNaR32z9pkk+3gmH33qJ+G9Kkr98uhM1lls6v3x8maA3G6tARCOlqlU/Y5o++sOihzfjtk2RbkV1q7WNatbN9zRcnx+JYpKZ1rV7phoENH4s3R8dIqzK/I9o2IigYDHVExD3JrI89qkDNGcQyYG/d4lxpaYsnRCPuFY4fFiDvXriDfRpzQLpg4scOixWi7jzmSA1tgDbtq2vmuuItLSpbHvtwum6LjLdu61a0oU/s0FE/3EjbdN6K8xF34e/mYwrgfEdkXBjqiYhrkNhw6p0HOWGDWUC/AU0dtbq9pnw00KHeuLs7St1mg3Nuosiz484i8/2uUnL+cKqnpmfLphhhdw25Y2xB5pF2oeBTT4LLx0DkNc2cvZjWUcHV2kqfurCVD24bwvUCmVsHDvVDvR0T2hYGOqJjZdPiclpOh9CZnJ8QJXWpI1zoVefLqwNxLuMiw20I13H209rDMWxet7czRin/mmijt5IjRugdaBul9i0sToDm/H9IOocaqD5U83WXWwMbSJIgNZMj80L3S38tdTmH0PZev49IcljTA/YjI8TDQERUTGImbvuqgrI86m2179QplNcjdUbeSONvxWmV0c1A++HjXmtot7/01kbJo81EdrUu4nCqv/Hefds8b36WG9GocoKN7jur85asyYckO+fVAVkdQQJnxjH6NxK8sS1DJPmAtuhe719FF7/Fb3DrUGb/V8XV7Xo+SiPLGQEfk4HYcO69B7vdrLewNoeXKyLjO1XVRZP6RL74wb25Kj3oytG2oTFt1QJb/Favz62ITk2XS0p3aEh1r2DniyC3mjT66MEJOnM9apBk/HhZnfqxjdb4nyO7cUc9f5jwQLlNW7NV5sgaMzCHM4etE5JgY6Igc1O4Tibr8wC/74rJtr+pbWk9aezSq7NAjL3RzqvqVlhn3N5bh7cLk7f8d0K6nEBV3UUZ8sU0aBXrL5DtqOUSHPMwhRWnpyz/s1VFJo1MgRuWwMDORvUJo61KnkmyOPicxpxMkuKKPNA/x4wUKIgfHQEfkYPafStIRObSqtxbgXUqD3P+FB0gJBjnKQ53KnvLxw810juWbP++3NM3BSG//j/7UwDOpW01d684eXUxJk6e/3SUr/oq1bGsS5CPvD2gs/l6lbLpvRIUBFRctQ/2ktp+reHl5OdzIOhFdj4GOyEFEnr4gM1ZHyn93nsy2HRPlx3SsJn2aBOrCyEQFgeYJS0e2ktX74mTqygNy4HTWQvNrD57Rj+4NK+uyFsHlytjNC3rg1AUZtXCbHL62Hh+gs+fkO2vxIgcREdktBjoiO3f4zEWZuTrSMvfJUMHDTbsV3t88UNxci0e3QipcuLLfuU5Fub1WBVm+44S887+DlvlmGOH6addJ6dcsUEd+K3iaux36txHH5ZlluyQ5NUM/93Bzlal9GnBeERER2T0GOiI7dfTcZZm5JlJPVI1W61CubEkZ1aGaDGxRtdi0nadbX8LVK7yK3N3AXxZtOirvr4mSc5euSlpGpizcdFS+iTguQ9qEyIj2YeJVylxr2CWnpsuUFXvky83HLNtq+3vKnIHhdjW6SERElBcGOiI7czzhsp5QL912XE+oDT6lS8jI9mEyqFWQlC7JtzYVPoz0Dm4TIn2aBsq8dYd1HbtLV9N11Gv2b4c03I3qECYPtw42xcWEI+cuaRfLPbFJlm33NwuUl+6ta4r9IyIiKgw86yOyEycTr8isX6NkyZZjls58gBGR4e1C5aHWwVLWjW9puvXw/2x85xoyqGWQzPr1kCz484hcTc+QxCup8sZP++WTP6L1632aVLFZJ9WVe07JE1//JReS0/Rz9xLO8krP+nJfkyo22R8iIqJbhWd/RCYXl5Ssox8odcNJswFzgIbdFiqD2wbrItFERQ0Lb7/QvY4MbhMsM36JlG+3H9d5nKeTUrSTJEbwsHj5XfUrFVmnvdT0DHnr5/3y0brobGsuzn4gXGpV8iySfSAiIipKDHREJnX2YorM/e2QrpeVkvZ3kCtT0kWGtA2RYW1Dxas0gxzZXqBvaXmnb0MdKcYadqv2Zi2ZcfjsJRm9KELqB3jpGnZtq5e7pftxKjFZxiyKkK3XlloAzPt7o1d98eBFDyIiclCmCXTr16+X6dOnS1RUlPj5+cnAgQNlyJAheV7VTUtLk48//liWLl0qcXFxEhQUJCNGjJC77ror2/3atWsnp09nX48LNm7cKL6+vvrvrVu3yrRp02T//v3i6ekpnTt3lvHjx0vZsmVv0U9LlLf4S1flw7WH5bMNMXIlNd2yvVQJFy2rxEkzFkEmMpualTzkowebyrYj8fLmTwdkc0y8bt91IlEemL9J2lTzk0ndaknDQO9Cf+71kWdl3OLt2qwFSrg4ybN31db3DNfhIiIiR2aKQLdjxw4ZOXKk3HnnnTJu3DjZtm2bTJ06VdLT02X48OG5fs97770nH374oYwePVqaNGkiq1atkgkTJoiLi4t069ZN7xMfH69hbtKkSXofawhuEBkZKYMHD9avz5gxQ+//9ttvy/Hjx2Xu3LlF8NMTZUm8nCrz1h+Wj9dHa6MJg5urs85VGtkhTMqVdePLRabXJMhXloxoKb8dPCNv/XxA9p3MakryR9Q56RH1h5ZgohQzrPy/v2iWkZEp762JkhmrD1qW7ajs5S6zBoZL46o+//rxiYiIzM4UgQ7hrHbt2hrijFE1jMAhUD344IPi7n79+kbffPON3HPPPTJmzBj9vFWrVrJnzx5ZsGCBJdBhxA26dOkiVatWzfW5V6xYoVdvZ82aJWXKZLWwRpB88cUX5cSJExIQEHDLfm4qXtIzMmVz9DmJOZ0gwRXTpHmIn7aDT0pO1RA3f120XEjJauAAJV2cZUCLqvJohzDTr/FFlBN+r95es4K0r15eVuyM1TXsjsZf1q/9uOuUrNxzWpumjOtcXfy9Sv3j0ezxS3boQueGDjXLy/S+jcSHo9hERFRM2DzQXb16VTZt2iRjx47Nth2hbN68eTpa16ZNm1y/L2dJpLe3t8TGxlo+37dvn4a0wMDAPJ8/JSVFXF1dpVSpUtkeB86fP89AR4Xi590nZcqKvXIyMdmyraKnm7QM9ZPfDpzR7oAGlIphsWYsCv5PT3SJzMLZ2Ul6NAqQO+v5y5ItR+Xd1VE6PxQXOBZvOSbLtp/QZQ6w3IF36YKXEm87kqDz5Yz3lLOTyMQuNeTRDtX0OYmIiIoL2/STtnLs2DFJTU2V4ODgbNsxJw6io//uVGYNI3ffffedrF27Vi5evCjff/+9rFu3Tnr06JEt0CGcISyipLJx48Y6Nw5z7gy9e/fW29dff10SEhK0BBOjdTVq1JBatWrdop+ailuYG7Xg7xNPAzoBLt8Rawlzrs5O0r95oPz6RAdtr84wR46kJEqHWwXL2kkd5ImuNbRLK6DhzwdrD8ttb/2qy3Jcvvr3KDUg+P15+Jz8tPeM3qalZ+iIdr8PNlreU+XKlpQFQ1vImI7VGeaIiKjYsfkI3YULF/Q252ibUf6IsJabhx9+WOfePfLII9nC2bBhwyyfo+QSc+L69u0rDz30kBw6dEhmzpwpgwYNkmXLlknp0qU1uD355JPyn//8Rz7//HP9PpRZLly4UOfj3YzMzEz9sDVjP8ywL8UdTkZfWrFXbnQkeodXlrGdakhV39L6OY9d0eP7pmiguQ9Gnwc0rypzfj8kn208IlfTMnS9uKkrD8inG2JkbMdqOkq9el+cTPlhr3avtJ5Tat31tVmwj7zXv7FU9HTn+6aI8T1jXjw25sVjY16ZJjt/vpn9sHmgy8j4+w9zbpydnXMtt0QXzDNnzsiUKVMkNDRUtm/fLnPmzNGQ9txzz+n9Xn75ZQ1lDRo00M+bNm0q1apVkwEDBujoHm7RWOWdd97Rx8NcO4zS4XEQGBHqypUreJvtpKSkXPfXFv8BLl/OmqvC7m62ge6Ue05elB92x2U7Gc3LHTV9xcslVRITE4tk/+h6fN8ULfymHN2msvSu7ycfrD8qy3fFSUamyJkLKfL88j0yY9VBOXf571Jkg3WYG9wyQEa3CxLXzBRJTEwp4p+A+J4xLx4b8+KxMa9Mk50/3ygjmSrQeXh46O2lS5eybTdG5nJbOmDlypU6+vbJJ59I69atdVvz5s31vhhpw4gcRt5QYpkTSi/xnPh+NF6ZPXu2dO/eXV544QXLfVq0aKFLF8yfP18mT55c4J8FnTNvdlTvViZ6Ly8vU/yHLA5wEoo5PVj/Cre7TyRKGs5OC+hyhqseL7Idvm9sA//tp/WvIKM7XZS3Vx2Un3ef0u25hTlrPqVLyLPdG2hjIbINvmfMi8fGvHhszCvTZOfPaNJoN4EO3ScRgo4cOZJt+9GjR/U2LCzsuu8xGp+Eh4dn296sWTO9xVp2/v7+GvwwOodwZ512MWcPa9BhWYMrV65c9zhYBy8kJETn090MHHwz/Aew3hez7I8jQZv0Q2cuanjbGoMAFy8x57Ku6PxT6GLJY2V7fN/YTrWKHjL3gSay49h5eXbZLtkTm7XUQV4SLqfKlpgEaRXmV2T7SNfje8a8eGzMi8fGvJxMdP58M/tg8/pANzc3LYXEOnLWtaIIYxhJM8olraHE0lgQ3FpERITeVqlSRUqWLKkllx988EG2+6xZs0aSk5N1FA7BDU1T0EnTGoJeTExMvt0xqfhITk2XzdHxMvu3KBn66RYJf2WVdJm+Vp7+dpd8E3E81zAXVr6M9GsaKG/0ri/ly7pJXm9JbPf3cpfmIVmL3BMVd40CvWX4bVm/428k7sKNy5mJiIgcnc1H6GDUqFG6uDcWFUdjE8yHQ7nj448/rssJoPwSo24YzcPIWseOHaVhw4bazOSxxx7TgLdz506d+4avGSEQDVOwxh3mwbVv314OHjyon3fq1EnXrQN8P4IfmrBgYXPMoUMIxKjhkCFDbPzKkC2cu5hiKZ3cGhMvu04kSmp63uWTWC+uQRUvaRLsI82CfCU8yEd8rdbA8i5VQrtcIrxZP4oR8l7sXodlY0RWCrruYgUPrs9IRETklGmSVi4YoUMHSixTULFiRW1SYgQqrFOHZQqwtECvXr10G0Le9OnTdSQPjSQwmtazZ09tZoLROaO8cvHixbJo0SIt4cRoHObLIcRZL1a+fPlynY+H0Ojj46MjhhMnTizwCB1qXNFxs1GjRqaZQ4fXxCw1wGaG1+rQmUtaNplVPpkgh89mn8+Z29ydJkG+0hQBLthH6gV4iZury02vQ4eROYS5O+r5F9rPQ/8c3zfm6g7b9s012lAotz9Q+K1Wyctd1k/uyIshNsT3jHnx2JgXj415ZZrs/Plm8oVpAp09Y6CzHylp6bLreKJl/lvE0QSJv3Q13+8JLVdGmgT5aIBrGuyrn/+TNzpOUjdHn5OY0wkSXNFHmof48WTURMz2i7y4M9ZvlDxGtuc8EM6LITbG94x58diYF4+NeWWa7DzgZvKFKUouiW6VhEtXddRty5F42RaTIDtPJOqaV3kp4eIk9QO8NLg1DfLRIOdX1q1Q9gXd+FqG+kltP1fT/LIgMiuMXCO05RzZxsgcR7aJiIj+xkBHDnVlBQ1KtsRkhbetR+K1nDI/3iifrOqj89+aBvnqXDj3ErYvmyWirFDXpU4ljmwTERHlg4GO7BZG2nbHJmrjEmP+27kblE8G+5W2zH/DCFxY+bLizHWsiEyLI9tERET5Y6Aju3H+8lWd84a1pzAC99fx85KST/mkq7OTNixBcEOAQ5Ar71E45ZNERERERGbAQEemLZ88Gn9ZR95QOonbyLiL+X6Pp7vrteYlvnrbsIq3lCrJ8kkiIiIiclwMdGQKqekZsic2yVI+iS6UZy+m5Ps9VX1LZzUu0eUDfKUayyeJiIiIqJhhoCObSLySquWTRoBD+WRyav7lk3Ure2ab/1bQxYeJiIiIiBwVAx0VSfnk8YQrWjppzH87GHdB8lsB0cPdVcKr+lhG4BoFekvpkvzvSkRERERkjWfIVOjS0jNk78mkbPPf4i7kXz5ZxafUtfDmK82CfaR6BQ8uuk1EREREdAMMdPSvJSWnyvaj52VbTNYI3I5j5+VKanq+bcjr+KN8Mqv7JNZ/w2LBRERERER0cxjo6KbLJ0+cv6JrvmHkDYt4Hzidf/lkWTdXaVzVW4Nb02vlk2Xc+F+PiIiIiOjf4lk13bB8cv+pC1nNS66FuFNJyfl+T4B3KcvoG25rVfJk+SQRERER0S3AQEfZXExJk+3afTJBR+Hw70tX8y6fdHYSqe3vaZn/htvK3qX4qhIRERERFQEGOgeTnpEpm6PPSczpBAmumCbNQ/zyHR2LPY/uk+g8mTUCt+9kkmTkUz5ZpqSLNK7qYxmBw79RUklEREREREWPZ+IO5OfdJ2XKir1yMvHvkkh/L3d5sXsduaOev4a9/aeSLPPfcIv5cPnB92t40wDnK7UqeYiri3MR/DRERERERHQjDHQOFOZGLYiQnINrCHcjF0RIbX8PORZ/RUsq8+LkJDrfLSu8ZQU4zIcjIiIiIiJzYqBzABh5w8hcPpWSsu/kheu2lSrhcq37ZNb8N/zb073ELd1XIiIiIiIqPAx0DmBzdHy2Msu8+JQuIa3Dylnmv6GZSQmWTxIRERER2S0GOgcQd+HGYQ5e6l5XejQOuOX7Q0RERERERYPdLRxABQ/3gt3Ps2D3IyIiIiIi+8BA5wCah/hqN8q8FifAdnwd9yMiIiIiIsfBQOcAsM4cliaAnKHO+Bxfz289OiIiIiIisj8MdA4C68zNeSBcKnllL6vE59iOrxMRERERkWNhUxQHgtDWpU4l2Rx9TmJOJ0hwRR9pHuLHkTkiIiIiIgfFQOdgUFbZMtRPavu5ipeXlzhhtXAiIiIiInJILLkkIiIiIiKyUwx0REREREREdoqBjoiIiIiIyE4x0BEREREREdkpBjoiIiIiIiI7xUBHRERERERkpxjoiIiIiIiI7BQDHRERERERkZ1ioCMiIiIiIrJTDHRERERERER2ytXWO+AIMjMz9TY9PV3Msj8ZGRm6P05OTrbeHbLCY2NePDbmxWNjTjwu5sVjY148NuaVabLzZyNXGDkjPwx0hQAHH3bt2lUYD0dERERERCRGzsiPU2ZBYh/d8IVOS0sTZ2dnUyR6IiIiIiKy/xFDV1dXzRj5YaAjIiIiIiKyU2yKQkREREREZKcY6IiIiIiIiOwUAx0REREREZGdYqAjIiIiIiKyUwx0REREREREdoqBjoiIiIiIyE4x0DmoU6dOSdOmTWXTpk223hW6tlbhl19+Kd27d5fGjRtLp06d5LXXXpOLFy/y9THBsZk/f7507dpVGjRoIPfee698//33tt4tymHMmDHSsWNHvi4mkZKSInXr1pWaNWtm+8DvN7KtHTt2yKBBg6RRo0bSunVrmTx5spw7d46HxYZwLpbzvWL98f777/P42NhXX30ld999t75v7rzzTlm4cKGuA2cvXG29A1T4Tp48KUOHDpULFy7w5TWJefPmyYwZM/S4tGrVSqKjo2XmzJkSGRkpH3/8MRekt6F3331XA93YsWOlfv368vvvv8uTTz6pi3jec889ttw1umb58uWyatUqCQgI4GtiEgcPHpS0tDSZOnWqVK1a1bL9Rovf0q21e/duefDBBzXIISTExcXJtGnTZPTo0bJ48WK+/DaCix9Lliy5bjvOC3bt2qVBgmzn66+/lueff14vhOCC+9atW+Xll1/WC1dDhgyxi0PDQOdgIw3fffedvPnmm7beFcpxXD766CPp16+fPP7447oNf2x9fHxkwoQJ+gcYQYKK3pUrV+Tzzz/XX+LDhw/XbQjce/bskS+++IKBzgROnz4tr776qlSqVMnWu0JW9u/fL66urnLHHXdIyZIl+dqYBAJ2nTp1ZPbs2ZZwXbZsWX0PHTt2TAIDA229i8USjgFGfqytXr1aNm7cqBcVQ0JCbLZvJPLNN99IkyZN5LnnntOXw7jwvmDBArsJdLyU5kAOHDggL774ovTs2VPeeustW+8OXYOyyh49elwXDkJDQ/UWf2TJNnAiilLYnL+wS5QooVfmyPbwB7ZNmzb6B5bMY9++ffo7jGHOPBISEmTz5s3Sv3//bCOlKCdH5QHDnHkkJyfLK6+8Ih06dNCLImRbKSkpGrqteXt7y/nz58VeMNA5EH9/fy1Levrpp8Xd3d3Wu0PXeHp66kkprv5Y++WXX/S2WrVqfK1sxMXFRWrVqiXly5fXWvmzZ8/Khx9+KBs2bJABAwbwuJigDAajpSiFIfMFOrx/cDEEIw/NmzeXF154gfOCbXxRFxUhvr6+Wg2C+Yz4mDRpkiQlJdly1ygHVIag+uCZZ57ha2MCDz74oKxfv17L+zFdad26dbJs2TK9GG8vWHLpQHA1gezDX3/9pcHh9ttvlxo1ath6d0hE/vvf/1pKYnHVFM1RyHZOnDghr7/+un7gBJXMAxc/EB5w26dPHxk1apTOA8KcraioKC1T4ly6ohcfH6+3CAnt2rXTssuYmBidQ4dKkEWLFnG+tglcvXpVA91dd90lQUFBtt4dEtE5jBjdxsUPQ9u2be0qcDPQERWxbdu2yciRI6VKlSp6skrmgA6XOBHFiSrmNAwbNkzn0Tk5Odl614odBAX8IW3fvr1069bN1rtDuRyfOXPmaNCuXr26bmvWrJmUK1dOGwrh6jaOHRWt1NRUSwMOzJkDlCqjSmTixInyxx9/6Ekq2dbKlSvlzJkz+jeGzOHRRx/VczP8/sK5AJo+vffeezJu3DiZNWuWXZwHMNARFaEff/xRnnrqKQkODtbOl2iMQuaATn34wIkpaunR6hudrvA5FS20i0awXrFihXZSBKN9ND7H6A9HgGwHr32LFi2u246RbcCxY6AremXKlNFbVH5Yu+222/R27969DHQmCXS4EIJyf7K9iIgIvQiFOY2oOACUkGPOKZql/fbbb9e9p8yIc+iIigha4+MqKeab4IS1QoUKfO1NUKKEzrA512hClzhAy2+yzQkPGjxgNAGjDfjAcUIZJv6NK6ZkO5j7gzWbYmNjr2v0ALxQZRu4UGiU9FkzLopwbr05RlExV4uNUMwj9trvsfDw8GzbsZYzYHkpe8BAR1QEsP4POo9isUqMzHl4ePB1NwGcgGIkbunSpdm2ozQJsOArFb0pU6boMbH+wBVSNK/Bv/v27cvDYkPp6enaqCbnulqoQECjFONEiIpWWFiYrtWI+cDWCyKjPT7wuNgeSvmwXE7OJmlkO6HXOo6jIifnyB3YS3dYllwS3WKolcdcOfyhHThwoJa9WEOZH5s+2EblypWld+/eOuKDNbUwModf6mhYc99997EDqY3/wOZs+oQW+Vyz0Rzvm169emnVgZubm3ZSxPyTuXPn6u84rqllG5jng6YO48eP1zVOceEDTWqmT5+uc1GNygOybaAzwjeZQ506dfT98cYbb0hiYqI0bNhQ3zeYQ4eKkC5duog9YKAjusWw/g9GglAuhpOdnBD2cHJEtvHSSy/pFTiUkOEYYfmPsWPHytChQ3lIiPIZRcX7Bm2+0SAFC7/jfcNGD7aFUj4cD1ykGjFihHh5ecn999+vAY9sD0vjAI4Lmcfbb7+t7xtUU82cOdNy0Wr06NF6sdceOGVaj8sTERERERGR3eAcOiIiIiIiIjvFQEdERERERGSnGOiIiIiIiIjsFAMdERERERGRnWKgIyIiIiIislMMdERERERERHaKgY6IiIiIiMhOMdAREREVAi7rSkREtsBAR0REReqpp56SmjVr5vnx888//+vnwOO89957UlS+/vprefPNNwvt9enYsWO+98ntdatTp460aNFChgwZIjt37hSzKepjQkRUXLjaegeIiKj4KV++vLz//vu5fi04OFjszZw5c6R58+ZF+pz33Xef9OnTx/L51atXJTIyUubOnSuDBw/WYIzXmYiIHBsDHRERFbmSJUtKo0aN+Mr/C5UqVbruNUSoDAwMlEceeUT+97//ycCBA/kaExE5OJZcEhGRaf3yyy/Sq1cvqV+/vrRp00ZeeeUVuXz5crb7bN68Wfr16ycNGzaUbt26yYYNG657nJSUFHnrrbekffv2Uq9ePenevbv8+OOP2e6DMsfXXntNHnroIWnQoIE8++yzun3//v0yZswYadmypdStW1duu+023Y/k5GTL9504cUKWLVumZYXHjx/X7bGxsTJx4kQNWdg3PO7evXuzPWdiYqI8/fTTep9mzZrJ1KlTJSMj41+9Zp6ennrr5ORk2RYXF6fPg58fPxtG91avXm35OvYZ+/7tt9/mW/45aNAgfV0+/PBD6dChgx6X+++//7oSz4IcEyIiKhwcoSMiIptIS0u7bpuLi4sliKxYsUKeeOIJDV/jx4/X0DR9+nSJioqSTz75RO+3Z88enTOGsDVz5kwNJghROZuVjB49WiIiImTs2LESFhYmq1atkgkTJmiZYs+ePS33XbhwoZYrYoSrTJkyGoQwyoWRsDfeeENHFteuXavPX6FCBRk+fLiWjuIWc9geffRR3R4fH69Bp1SpUvL888/r7WeffaaPtXTpUt0HBLdhw4bpzzV58mTx9vaWefPmya5du/QxbgTfb/0aIrQeOHBAXn75ZfHw8JBOnTrp9rNnz2qAc3Nz05/Zx8dHgxteE4Tce++996aO28qVK3X/n3vuOX1tMXfwsccekzVr1ujxK8gxISKiwsNAR0RERQ4hBqNdOT3++OMajhAU3n77bR0Nw631/LqHH35Yfv/9dx0h+uCDD8TPz0/nsJUoUULvg8CC4GLA6NC6des0DN511126DY975coVfex77rlHXF2z/hxWrlxZQ6Rh/fr1Urt2bXn33XelbNmyuq1169byxx9/yKZNmyxBDkHP19fXUgKJ8Hb+/Hn58ssvJSAgQLe1a9dOnx+PhaCDYIiRrY8++ki/Bq1atbphQxTD7Nmz9cMa9qNp06Y60lixYkXdhvCJgIkgZuwLRurwOiLQ4ee/GQiR8+fPt7wely5d0kC6b98+Hf0syDEhIqLCw0BHRERFDs06cMKf27wwOHz4sJw6dUpGjBiRbRQKZYkIEghUCHTbtm2T22+/3RIcoGvXrjpSZNi4caOO5iHEWD8WgtP333+vjUQQ2sC4NbRt21Y/UlNTdWTwyJEjcvDgQQ1IGFHLC54Tj4VQZTyns7OzBjc8J2zdulX3G+HSULp0ad3PLVu23PA17Nu3r34g/KIsFOWaTZo0kXfeeUdHF63LHxs3bmwJcwaMzKEME6+1u7u7FFS1atUsYQ6M4IiADAU5JkREVHgY6IiIqMhhJAnzr/KC0S2YMmWKfuSEUkhjDhpGf6xhtM16Gx4LoSc8PDzX58JjGUEOgSpnWeO0adO0FBNz9/z9/XUOGsoX84PnRPjLbRTSCD/Yd4RC67luUNDOlCjLNF5D7BOaoaBcFOWpmONmPC6eB1/LqVy5cnqblJR0U4EO5aPWEFTBmPtXkGNCRESFh4GOiIhMx2jsMWnSpFyXA/Dy8tJbBCLMEbOG8IZQYcB8MgS1zz//PNfnCgoKynM/EIw+/fRTDZUYZcJjAeak5Qf3w35j//MKtAg4CQkJkp6enm30ygizNwvlmgMGDNDw+dVXX2lTEuO1OnPmzHX3N7ZhP4zwh32xlrMBTUEU5JgQEVHhYZdLIiIyndDQUJ2HhYYaGIUyPlDeh5JCo1skQgzmohnlfoD5ciiRNCBYIZggVFg/FkonZ82alWtzFgPKB1Fi2Lt3b0uYO336tH6vdTdKY5TK+jmjo6MlJCQk23MuX75cm6IgwGHf8dzo5GlAkxaUk/5TmKeGkTeMKhrBEGWq27dv13mL1lD6idFABFqjhBI/mwGv4T9ZoLwgx4SIiAoPAx0REZkOAg/CyeLFi3WJAIScn376SYYOHaphzihlRKdGhDVsR5dFhKVnnnkm2/wtzElDqEEHykWLFmkzEzQieemllzSIoZlJXlDKiM6RGKnDXLSvv/5aO1UieFkHFowoYr9wHyxngIYjCHy4xfIImFOHbpdffPGFhjwj+GB+HrpFYr/Q6GXUqFE6P++fQujE64Ywh+YrgDJMjJphXxAo8Ty4z59//qm3eA0wiod5dtg/dBdFIMO+GEsz3IyCHBMiIio8DHRERGRKffr00dE4LDcwcuRIDWBVqlTR0GHMCUPXywULFlgCILo+ouOiUZIJCCwIZHfffbd2YETQQFBE0EHny/ygKUv//v21XBNLGaC7Y48ePXRdOjRTwfwzQJt+lBnisXfv3q0jiXgONCLBfmP/Mdr16quvarAyYMkDNCdB10vMfUNTGDQ6+TcwmoggumTJEm2WglE4dNtECEY4HjdunJw8eVJfK9zXgGUZ0KUSARPNUnB/rJ13swpyTIiIqPA4ZaIGhYiIiIiIiOwOR+iIiIiIiIjsFAMdERERERGRnWKgIyIiIiIislMMdERERERERHaKgY6IiIiIiMhOMdARERERERHZKQY6IiIiIiIiO8VAR0REREREZKcY6IiIiIiIiOwUAx0REREREZGdYqAjIiIiIiKyUwx0REREREREYp/+H5sWStOkLRYYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running inference on full test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: distilbert.transformer.layer.*.attention.q_lin.weight, distilbert.transformer.layer.*.output_layer_norm.bias, distilbert.transformer.layer.*.ffn.lin*.weight, distilbert.transformer.layer.*.attention.v_lin.bias, distilbert.transformer.layer.*.attention.out_lin.bias, distilbert.embeddings.LayerNorm.weight, distilbert.embeddings.LayerNorm.bias, distilbert.transformer.layer.*.attention.k_lin.weight, distilbert.transformer.layer.*.attention.v_lin.weight, classifier.bias, distilbert.transformer.layer.*.sa_layer_norm.weight, pre_classifier.bias, distilbert.transformer.layer.*.attention.q_lin.bias, distilbert.transformer.layer.*.ffn.lin*.bias, distilbert.transformer.layer.*.attention.out_lin.weight, distilbert.transformer.layer.*.sa_layer_norm.bias, distilbert.transformer.layer.*.output_layer_norm.weight, distilbert.embeddings.position_embeddings.weight, distilbert.transformer.layer.*.attention.k_lin.bias, pre_classifier.weight, distilbert.embeddings.word_embeddings.weight, classifier.weight\n",
      "Test: 100%|██████████| 938/938 [00:12<00:00, 76.75it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.86      0.86      3750\n",
      "    Positive       0.86      0.86      0.86      3750\n",
      "\n",
      "    accuracy                           0.86      7500\n",
      "   macro avg       0.86      0.86      0.86      7500\n",
      "weighted avg       0.86      0.86      0.86      7500\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All plots saved:\n",
      "  • correlation_heatmap.png\n",
      "  • teacher_convergence.png\n",
      "  • final_test_bar.png\n",
      "  • confusion_matrix.png\n",
      "  • roc_auc.png\n",
      "  • prob_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CELL 12 – FULL VISUALIZATION + DATASET CORRELATION HEATMAP\n",
    "# --------------------------------------------------------------\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# --- 1. LOAD RESULTS FROM CELL 10 ---\n",
    "with open(\"pate_results.json\", \"r\") as f:\n",
    "    R = json.load(f)\n",
    "\n",
    "print(\"PATE-FL Results Loaded\")\n",
    "print(f\"Final Accuracy: {R['final']['acc_mean']:.4f} ± {R['final']['acc_std']:.4f}\")\n",
    "print(f\"Final F1-Score: {R['final']['f1_mean']:.4f}\")\n",
    "\n",
    "# --- 2. DATASET CORRELATION HEATMAP (NEW) ---\n",
    "print(\"\\nGenerating Dataset Correlation Heatmap...\")\n",
    "\n",
    "# Extract features from train_ds\n",
    "data_rows = []\n",
    "for sample in train_ds:\n",
    "    text = sample['text'] if 'text' in sample else tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "    length = len(text.split())\n",
    "    sentiment = sample['labels'].item()\n",
    "    # Source ID (from filename pattern)\n",
    "    source_id = 0\n",
    "    if \"imdb\" in str(sample).lower(): source_id = 1\n",
    "    elif \"twitter\" in str(sample).lower(): source_id = 2\n",
    "    elif \"amazon\" in str(sample).lower(): source_id = 3\n",
    "    elif \"uci\" in str(sample).lower(): source_id = 4\n",
    "    elif \"archive\" in str(sample).lower(): source_id = 5\n",
    "    elif \"tweet\" in str(sample).lower(): source_id = 6\n",
    "    elif \"yelp\" in str(sample).lower(): source_id = 7\n",
    "    elif \"mental\" in str(sample).lower(): source_id = 8\n",
    "    data_rows.append({\n",
    "        \"length\": length,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"source_id\": source_id\n",
    "    })\n",
    "\n",
    "df_corr = pd.DataFrame(data_rows)\n",
    "\n",
    "# Correlation matrix\n",
    "corr = df_corr.corr()\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", center=0, ax=ax,\n",
    "            square=True, cbar_kws={\"shrink\": .8})\n",
    "ax.set_title(\"Dataset Feature Correlation Heatmap\\n(Length, Sentiment, Source)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlation_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 3. TEACHER VALIDATION CURVES ---\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "rounds = list(range(1, len(R[\"teacher_val\"][0]) + 1))\n",
    "for i, fold in enumerate(R[\"teacher_val\"]):\n",
    "    accs = [m[\"acc\"] for m in fold]\n",
    "    ax.plot(rounds, accs, marker='o', label=f'Fold {i+1}', linewidth=2)\n",
    "ax.set_xlabel(\"Federated Round\")\n",
    "ax.set_ylabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"Teacher Model Convergence (No DP)\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"teacher_convergence.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 4. FINAL TEST BAR PLOT ---\n",
    "df = pd.DataFrame(R[\"fold_results\"])\n",
    "df[\"Fold\"] = [f\"Fold {i+1}\" for i in range(len(df))]\n",
    "df_melt = df.melt(id_vars=\"Fold\", value_vars=[\"acc\", \"f1\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(data=df_melt, x=\"Fold\", y=\"Score\", hue=\"Metric\", palette=\"Set2\", ax=ax)\n",
    "ax.set_title(f\"PATE-FL Final Test\\nAcc: {R['final']['acc_mean']:.4f} ± {R['final']['acc_std']:.4f}\")\n",
    "ax.set_ylim(0.7, 0.95)\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"final_test_bar.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 5. CONFUSION MATRIX + REPORT (on test_ds) ---\n",
    "print(\"\\nRunning inference on full test set...\")\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "# Use last teacher as proxy (high acc) or re-load student\n",
    "student = get_model()\n",
    "student.load_state_dict(global_state)\n",
    "student.eval()\n",
    "\n",
    "all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test\"):\n",
    "        out = student(batch['input_ids'].to(DEVICE), batch['attention_mask'].to(DEVICE))\n",
    "        probs = torch.softmax(out.logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "ax.set_title(\"Confusion Matrix (Test Set)\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# --- 6. ROC-AUC ---\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.4f})')\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve – PATE-FL')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_auc.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- 7. PROBABILITY DISTRIBUTION ---\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.histplot(all_probs, bins=50, kde=True, ax=ax, color='skyblue')\n",
    "ax.set_xlabel(\"Predicted Probability (Positive)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Prediction Probability Distribution\")\n",
    "ax.axvline(0.5, color='red', linestyle='--', label='Threshold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prob_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll plots saved:\")\n",
    "print(\"  • correlation_heatmap.png\")\n",
    "print(\"  • teacher_convergence.png\")\n",
    "print(\"  • final_test_bar.png\")\n",
    "print(\"  • confusion_matrix.png\")\n",
    "print(\"  • roc_auc.png\")\n",
    "print(\"  • prob_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/corelation.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. ROC CURVE & AUC (ALL FOLDS) ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    fpr, tpr, _ = roc_curve(all_labels[i], all_probs[i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.7, label=f'Fold {i+1} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    # Interpolate for mean\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "\n",
    "# Mean ROC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, color='darkorange', lw=3,\n",
    "         label=f'Mean ROC (AUC = {mean_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (3-Fold Cross-Validation)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean AUC: {mean_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAVE ALL PLOTS ---\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "plt.savefig(\"results/auc-roc.png\")\n",
    "# ... repeat for each plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 7 – evaluate function (ROBUST + BERT-COMPATIBLE)\n",
    "# # --------------------------------------------------------------\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import numpy as np\n",
    "\n",
    "# def evaluate(model_state, loader):\n",
    "#     \"\"\"\n",
    "#     Evaluates a global model state on a DataLoader.\n",
    "#     Returns accuracy and F1.\n",
    "#     \"\"\"\n",
    "#     model = get_model()\n",
    "#     model.load_state_dict(model_state)\n",
    "#     model.eval()\n",
    "\n",
    "#     all_preds, all_labels = [], []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in loader:\n",
    "#             ids = batch['input_ids'].to(DEVICE)\n",
    "#             mask = batch['attention_mask'].to(DEVICE)\n",
    "#             labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "#             # ← PASS labels (required by BERT, ignored in eval)\n",
    "#             outputs = model(ids, attention_mask=mask, labels=labels)\n",
    "#             preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     acc = accuracy_score(all_labels, all_preds)\n",
    "#     f1 = f1_score(all_labels, all_preds, average='binary')  # ← explicit for binary\n",
    "#     return {'acc': acc, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 8 – ClientSimulator (REPRODUCIBLE + FAIR)\n",
    "# # --------------------------------------------------------------\n",
    "# import torch\n",
    "# from torch.utils.data import Subset\n",
    "# import random\n",
    "\n",
    "# # Optional: set seed once at top of notebook\n",
    "# # torch.manual_seed(42); random.seed(42); np.random.seed(42)\n",
    "\n",
    "# class ClientSimulator:\n",
    "#     def __init__(self, n_clients, seed=42):\n",
    "#         self.n_clients = n_clients\n",
    "#         self.seed = seed\n",
    "#         self.rng = torch.Generator().manual_seed(seed)\n",
    "\n",
    "#     def split(self, dataset):\n",
    "#         \"\"\"\n",
    "#         Splits dataset into n_clients subsets.\n",
    "#         Uses torch.randperm → reproducible + fair.\n",
    "#         \"\"\"\n",
    "#         n = len(dataset)\n",
    "#         indices = torch.randperm(n, generator=self.rng).tolist()  # ← REPRODUCIBLE\n",
    "#         per_client = n // self.n_clients\n",
    "#         clients = []\n",
    "\n",
    "#         for i in range(self.n_clients):\n",
    "#             start = i * per_client\n",
    "#             end = (i + 1) * per_client if i < self.n_clients - 1 else n\n",
    "#             client_idx = indices[start:end]\n",
    "#             clients.append({\n",
    "#                 'id': i,\n",
    "#                 'dataset': Subset(dataset, client_idx),\n",
    "#                 'size': len(client_idx)\n",
    "#             })\n",
    "#         return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0048bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TUNING: {'lr': 1e-05, 'batch': 8, 'rounds': 6, 'clients': 3, 'local_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.attention.self.query.bias, classifier.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.value.bias, classifier.weight, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.token_type_embeddings.weight, bert.embeddings.LayerNorm.weight, bert.pooler.dense.weight, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.bias, bert.pooler.dense.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.output.dense.bias, bert.embeddings.position_embeddings.weight\n",
      "The following layers were not sharded: bert.encoder.layer.*.attention.self.query.bias, classifier.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.value.bias, classifier.weight, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.token_type_embeddings.weight, bert.embeddings.LayerNorm.weight, bert.pooler.dense.weight, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.bias, bert.pooler.dense.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.output.dense.bias, bert.embeddings.position_embeddings.weight\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m values \u001b[38;5;129;01min\u001b[39;00m product(*grid.values()):\n\u001b[32m     93\u001b[39m     config = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grid.keys(), values))\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     best_acc_run, acc_history = \u001b[43mrun_single_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     rounds_eval = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(acc_history)*\u001b[32m2\u001b[39m + \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m     96\u001b[39m     plt.plot(rounds_eval, acc_history, marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mrun_single_config\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m     58\u001b[39m trainer = TempTrainer(lr=config[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m], epochs=config[\u001b[33m'\u001b[39m\u001b[33mlocal_epochs\u001b[39m\u001b[33m'\u001b[39m], batch=config[\u001b[33m'\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cl \u001b[38;5;129;01min\u001b[39;00m clients:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     cipher = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcl\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     cipher_updates.append(cipher)\n\u001b[32m     63\u001b[39m global_state = federated_average(cipher_updates, round_key, [c[\u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m clients], global_state)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mTempTrainer.train\u001b[39m\u001b[34m(self, client_id, client_ds, global_state, round_key)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m     34\u001b[39m     opt.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     ids = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     mask = batch[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n\u001b[32m     37\u001b[39m     lbl = batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(DEVICE)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # HYPERPARAMETER TUNING + PLOT (ACCURACY PER ROUND)\n",
    "# # --------------------------------------------------------------\n",
    "# from itertools import product\n",
    "# from torch.utils.data import DataLoader, Subset\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from torch.optim import AdamW\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from tqdm.auto import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# # --- TEMP TRAINER (NO DP) ---\n",
    "# class TempTrainer:\n",
    "#     def __init__(self, lr, epochs, batch):\n",
    "#         self.lr = lr\n",
    "#         self.epochs = epochs\n",
    "#         self.batch = batch\n",
    "\n",
    "#     def train(self, client_id, client_ds, global_state, round_key):\n",
    "#         model = get_model()\n",
    "#         model.load_state_dict(global_state)\n",
    "#         model.train()\n",
    "\n",
    "#         loader = DataLoader(client_ds, batch_size=self.batch, shuffle=True)\n",
    "#         opt = AdamW(model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "#         total_steps = len(loader) * self.epochs\n",
    "#         scheduler = get_linear_schedule_with_warmup(opt, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "#         for _ in range(self.epochs):\n",
    "#             for batch in loader:\n",
    "#                 opt.zero_grad()\n",
    "#                 ids = batch['input_ids'].to(DEVICE)\n",
    "#                 mask = batch['attention_mask'].to(DEVICE)\n",
    "#                 lbl = batch['labels'].to(DEVICE)\n",
    "#                 out = model(ids, attention_mask=mask, labels=lbl)\n",
    "#                 out.loss.backward()\n",
    "#                 opt.step()\n",
    "#                 scheduler.step()\n",
    "\n",
    "#         delta = {k: model.state_dict()[k] - global_state[k] for k in global_state}\n",
    "#         return encrypt_state(delta, round_key)\n",
    "\n",
    "# def run_single_config(config):\n",
    "#     print(f\"\\nTUNING: {config}\")\n",
    "#     sim = ClientSimulator(n_clients=config['clients'], seed=42)\n",
    "#     clients = sim.split(fold_train)\n",
    "\n",
    "#     global_state = get_model().state_dict()\n",
    "#     val_accs = []\n",
    "\n",
    "#     for rnd in range(1, config['rounds'] + 1):\n",
    "#         round_key = get_random_bytes(32)\n",
    "#         cipher_updates = []\n",
    "\n",
    "#         trainer = TempTrainer(lr=config['lr'], epochs=config['local_epochs'], batch=config['batch'])\n",
    "#         for cl in clients:\n",
    "#             cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "#             cipher_updates.append(cipher)\n",
    "\n",
    "#         global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients], global_state)\n",
    "\n",
    "#         if rnd % 2 == 0:\n",
    "#             metrics = evaluate(global_state, val_loader)\n",
    "#             val_accs.append(metrics['acc'])\n",
    "\n",
    "#     return max(val_accs), val_accs  # return best + full history\n",
    "\n",
    "# # --- GRID ---\n",
    "# grid = {\n",
    "#     'lr': [1e-5, 2e-5, 3e-5],\n",
    "#     'batch': [8, 16],\n",
    "#     'rounds': [6],\n",
    "#     'clients': [3],\n",
    "#     'local_epochs': [3]\n",
    "# }\n",
    "\n",
    "# # --- ONE FOLD ---\n",
    "# fold_idx = next(skf.split(np.zeros(len(train_ds)), train_ds.labels))\n",
    "# fold_train = Subset(train_ds, fold_idx[0])\n",
    "# fold_val = Subset(train_ds, fold_idx[1])\n",
    "# val_loader = DataLoader(fold_val, batch_size=16)\n",
    "\n",
    "# # --- RUN & PLOT ---\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# best_hp = None\n",
    "# best_acc = 0\n",
    "# all_curves = []\n",
    "\n",
    "# for values in product(*grid.values()):\n",
    "#     config = dict(zip(grid.keys(), values))\n",
    "#     best_acc_run, acc_history = run_single_config(config)\n",
    "#     rounds_eval = list(range(2, len(acc_history)*2 + 1, 2))\n",
    "#     plt.plot(rounds_eval, acc_history, marker='o', label=f\"lr={config['lr']}, batch={config['batch']}\")\n",
    "\n",
    "#     if best_acc_run > best_acc:\n",
    "#         best_acc = best_acc_run\n",
    "#         best_hp = config\n",
    "#         all_curves.append((acc_history, config))\n",
    "\n",
    "# print(f\"\\nBEST HP (NO DP): {best_hp} | Best Val Acc: {best_acc:.4f}\")\n",
    "\n",
    "# # --- Final Plot ---\n",
    "# plt.title(\"Validation Accuracy per Federated Round (Tuning)\")\n",
    "# plt.xlabel(\"Federated Round\")\n",
    "# plt.ylabel(\"Validation Accuracy\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FEDERATED TRAINING (GRADIENT-ONLY)\n",
      "\n",
      "==================== FOLD 1/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5002 | F1: 0.6667\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4998 | F1: 0.6648\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4944 | F1: 0.6294\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5000 | F1: 0.6664\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5005 | F1: 0.0048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.4991 | F1: 0.0032\n",
      "\n",
      "==================== FOLD 2/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4998 | F1: 0.6664\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5000 | F1: 0.4298\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4999 | F1: 0.6666\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4999 | F1: 0.0599\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7777 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7779 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.4987 | F1: 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.5005 | F1: 0.6665\n",
      "\n",
      "==================== FOLD 3/3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5176 | F1: 0.1953\n",
      "\n",
      "ROUND 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5283 | F1: 0.6405\n",
      "\n",
      "ROUND 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5053 | F1: 0.6436\n",
      "\n",
      "ROUND 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5021 | F1: 0.0868\n",
      "\n",
      "ROUND 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 0] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 1] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training 7778 samples → 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Client 2] Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n",
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Acc: 0.5325 | F1: 0.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.weight, bert.encoder.layer.*.attention.self.query.bias, bert.embeddings.LayerNorm.weight, bert.encoder.layer.*.attention.output.LayerNorm.bias, bert.encoder.layer.*.output.LayerNorm.weight, classifier.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.output.dense.bias, classifier.weight, bert.pooler.dense.bias, bert.encoder.layer.*.attention.self.query.weight, bert.pooler.dense.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.value.weight, bert.embeddings.LayerNorm.bias, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.self.key.weight, bert.encoder.layer.*.attention.output.dense.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST → Acc: 0.5273 | F1: 0.5196\n",
      "\n",
      "FINAL K-FOLD: Acc 0.5090 ± 0.0130 | F1 0.3964 ± 0.2845\n"
     ]
    }
   ],
   "source": [
    "# # --------------------------------------------------------------\n",
    "# # STEP 9 – FINAL TRAINING LOOP (Cell 10) – FIXED\n",
    "# # --------------------------------------------------------------\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# N_FOLDS = 3\n",
    "# skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# HP = {\n",
    "#     'rounds': 5,\n",
    "#     'clients': 3,\n",
    "#     'local_epochs': 3,\n",
    "#     'lr': 2e-5,\n",
    "#     'batch': 8,\n",
    "#     'clip': 1.0,\n",
    "#     'noise': 0.1\n",
    "# }\n",
    "\n",
    "# print(\"STARTING FEDERATED TRAINING (GRADIENT-ONLY)\")\n",
    "\n",
    "# fold_results = []\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(train_ds)), train_ds.labels)):\n",
    "#     print(f\"\\n{'='*20} FOLD {fold+1}/{N_FOLDS} {'='*20}\")\n",
    "\n",
    "#     fold_train = Subset(train_ds, train_idx)\n",
    "#     fold_val   = Subset(train_ds, val_idx)\n",
    "\n",
    "#     sim = ClientSimulator(n_clients=HP['clients'])\n",
    "#     clients = sim.split(fold_train)\n",
    "\n",
    "#     global_state = get_model().state_dict()\n",
    "\n",
    "#     for rnd in range(1, HP['rounds'] + 1):\n",
    "#         print(f\"\\nROUND {rnd}/{HP['rounds']}\")\n",
    "#         round_key = get_random_bytes(32)\n",
    "#         cipher_updates = []\n",
    "\n",
    "#         # FIXED: Only pass valid args to LocalTrainer\n",
    "#         trainer = LocalTrainer(\n",
    "#             lr=HP['lr'],\n",
    "#             epochs=HP['local_epochs'],\n",
    "#             batch=HP['batch'],\n",
    "#             clip=HP['clip'],\n",
    "#             noise=HP['noise']\n",
    "#         )\n",
    "\n",
    "#         for cl in clients:\n",
    "#             cipher = trainer.train(cl['id'], cl['dataset'], global_state, round_key)\n",
    "#             cipher_updates.append(cipher)\n",
    "\n",
    "#         global_state = federated_average(cipher_updates, round_key, [c['size'] for c in clients])\n",
    "\n",
    "#         val_metrics = evaluate(global_state, DataLoader(fold_val, batch_size=16))\n",
    "#         print(f\"  Val Acc: {val_metrics['acc']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "#     # Final test\n",
    "#     test_metrics = evaluate(global_state, test_loader)\n",
    "#     print(f\"  TEST → Acc: {test_metrics['acc']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "#     fold_results.append(test_metrics)\n",
    "\n",
    "# # Final average\n",
    "# accs = [r['acc'] for r in fold_results]\n",
    "# f1s = [r['f1'] for r in fold_results]\n",
    "# print(f\"\\nFINAL K-FOLD: Acc {np.mean(accs):.4f} ± {np.std(accs):.4f} | F1 {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4d3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
